{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Investigations performance – interpretation and recommendations  \n",
    "*(OPG)*\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Quality - coverage & Overview\n",
    "\n",
    "### 1.1 Data Summary\n",
    "\n",
    "**Table 1 – Dataset snapshot**\n",
    "\n",
    "| Item                         | Value                                    |\n",
    "|------------------------------|------------------------------------------|\n",
    "| Number of cases              | 2,000                                    |\n",
    "| Number of columns            | 16                                       |\n",
    "| Time period – received date  | 01 Jan 2024 – 26 Oct 2024                |\n",
    "| Time period – allocation     | 05 Jan 2024 – 21 Nov 2024                |\n",
    "| Time period – PG sign-off    | 22 Jan 2024 – 13 Feb 2025                |\n",
    "| Outcome (legal_review = 1)   | 152 cases (7.6%)                         |\n",
    "| Outcome (legal_review = 0)   | 1,848 cases (92.4%)                      |\n",
    "| Duplicate IDs                | 0                                        |\n",
    "\n",
    "**Table 2 – Missing data (key fields)**\n",
    "\n",
    "| Column                       | % missing |\n",
    "|------------------------------|-----------|\n",
    "| `date_pg_signoff`           | 28.8%     |\n",
    "| `days_to_signoff`           | 28.8%     |\n",
    "| `days_to_alloc`             | 14.9%     |\n",
    "| `date_allocated_investigator` | 14.9%   |\n",
    "| `case_type`, `risk_band`, `date_received_opg`, `id`, `region`, `team` | 0% |\n",
    "\n",
    "**By legal review status (for `days_to_signoff`):**\n",
    "\n",
    "| legal_review | % missing `days_to_signoff` |\n",
    "|--------------|-----------------------------|\n",
    "| 0            | 28.7%                       |\n",
    "| 1            | 29.6%                       |\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- We have a **large, clean dataset** covering roughly a year of incoming investigations.\n",
    "- Around **29%** of cases have no sign-off date yet, these are **open or recently opened cases**, not data errors.\n",
    "- Missingness is **not materially different** between cases with and without legal review, so we are **not selectively losing the more complex cases**.\n",
    "- There are **no extreme outliers** in days to sign-off (all values fall within the expected range), so the timeliness statistics are reliable.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "\n",
    "> The data is appropriate for strategic decisions about backlog, timeliness and risk. Continued focus should be on **timely recording of allocation and sign-off dates** to keep performance dashboards “near real time”.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Timeliness of investigations (PG sign-off)\n",
    "\n",
    "### 2.1 Overall time to sign-off (by risk band)\n",
    "\n",
    "**Table 3 – Time to PG sign-off (days) by risk band**\n",
    "\n",
    "| Risk band | 25% of cases (q25) | 50% (median) | 75% (q75) |\n",
    "|-----------|--------------------|--------------|-----------|\n",
    "| High      | 45 days            | 68 days      | 88 days   |\n",
    "| Medium    | 48 days            | 72 days      | 94 days   |\n",
    "| Low       | 43 days            | 68 days      | 94 days   |\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- Across all risk bands, **half of investigations are closed in ~2–2.5 months** (around 68–72 days).\n",
    "- **A quarter of cases** per band take more than **~3 months** (up to ~94+ days).\n",
    "- High-risk cases are **not dramatically faster** overall; they sit near the organisation-wide averages.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Set a clear, risk-sensitive timeliness standard, for example:  \n",
    "> *“At least 80% of investigations closed within 90 days, with tighter oversight of high-risk cases that go beyond 90 days.”*\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Overall trend - how long cases take to complete\n",
    "\n",
    "**Figure 1 – Monthly median days to PG sign-off (ALL case types)**\n",
    "![Monthly median: days_to_pg_signoff — ALL case types](src/data/out/plot/plots/monthly_trend_days_to_pg_signoff_ALL.png)\n",
    "\n",
    "**Interpretation**\n",
    "- Each point is the **typical (median) number of days** from concern received to PG sign-off for that month, across **all investigation types**.\n",
    "- The median number of days to sign-off **rose to a peak** (above 100 days), then **declined steadily**.\n",
    "- Earlier months show medians around the **high 80s to 100+ days**.  \n",
    "- Recent months show medians nearer **40–60 days**, indicating **real improvement** in timeliness.\n",
    "- There is still some **month-to-month noise**, but the direction of travel is positive.\n",
    "- Over time, the line **slopes downwards**. Recent months are much lower, visually closer to **a few weeks rather than three–four months**.\n",
    "- There are some “spikes” up and down, but the **overall direction is clearly improving**.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "- The system has **genuinely become faster at closing cases**.  \n",
    "- This improvement is **sustained**, not just a single good month.\n",
    "> The improvement in timeliness suggests that **recent process and resourcing changes are working**. The priority now is to **lock in these gains** so performance doesn’t drift back.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Trend by case type (Differences between case types)\n",
    "\n",
    "**Figure 2 – Monthly median days to PG sign-off by case type**\n",
    "![Monthly median: days_to_pg_signoff by case_type](src/data/out/plot/plots/monthly_trend_days_to_pg_signoff_by_case_type.png)\n",
    "\n",
    "\n",
    "**Figure 3 – Same chart with “ALL case types” line overlaid**\n",
    "![Monthly median: days_to_pg_signoff by case_type + ALL](src/data/out/plot/plots/monthly_trend_days_to_pg_signoff_by_case_type_with_ALL.png)\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- Each coloured line is a **different case type** (e.g. Fraud, Section 49, Multiple, Priority).\n",
    "- Across all types, most lines:\n",
    "  - Sit in a similar **band of values**, and  \n",
    "  - Show the same **“up then down” pattern** seen in the overall chart.\n",
    "- Some case types show **sharp spikes** in particular months, far above or below the others. These are especially visible in the more specialist categories.\n",
    "\n",
    "- Most cases (**LPA, Deputyship, Other** sub-types) follow the **same broad pattern** as the overall line:\n",
    "  - A period of longer completion times followed by **improvement**.\n",
    "- Some specific categories (e.g. Fraud, Section 49, Multiple investigations) show **large spikes** in certain months, these are typically **small-volume categories where a handful of very complex cases can move the median**.\n",
    "- The “ALL case types” line runs **through the middle of the individual lines**, showing that **no single case type dominates the overall trend**.\n",
    "\n",
    "**Why some lines are “noisy”**\n",
    "- Many case types have **relatively low volumes each month**.  \n",
    "- If just a handful of very complex cases are signed off in a month, the **median for that type can jump dramatically**, even though the system overall has not changed.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "- When a case-type line is persistently higher than the overall line (for example, a consistently slower case type), that is where we should:\n",
    "  - Review specific **workflows, guidance and resourcing** for that type.\n",
    "  - Ask whether the slower performance reflects **appropriate complexity** or **avoidable delays**.\n",
    "> Operational discussions should focus on the **overall trend and key risk types**, not over-react to one or two spiky months in small categories.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Month-on-month change in timeliness (volatility)\n",
    "\n",
    "**Figure 4 – Monthly MoM delta in median days to PG sign-off – ALL case types**\n",
    "![Monthly MoM delta: days_to_pg_signoff — ALL case types](src/data/out/plot/plots/monthly_mom_delta_days_to_pg_signoff_ALL.png)\n",
    "\n",
    "**Interpretation**\n",
    "- Each point is **how much the median time changed compared with the previous month** (in days).\n",
    "- Most changes are within a band of roughly **±10 days**.  \n",
    "- There are occasional larger positive or negative jumps (big improvements or deteriorations).\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Performance should be judged over **rolling quarters** rather than single months, particularly for niche or low-volume case types where a few complex cases can distort monthly statistics.\n",
    "\n",
    "\n",
    "**Figure 5 – MoM delta by case type**\n",
    "![Monthly MoM delta: days_to_pg_signoff by case_type](src/data/out/plot/plots/monthly_mom_delta_days_to_pg_signoff_by_case_type.png)\n",
    "\n",
    "**Figure 6 – MoM delta by case type + ALL overlay**\n",
    "![Monthly MoM delta: days_to_pg_signoff by case_type + ALL](src/data/out/plot/plots/monthly_mom_delta_days_to_pg_signoff_by_case_type_with_ALL.png)\n",
    "\n",
    "**Interpretation**\n",
    "- Each coloured line is a case type; the vertical axis shows **how many days faster or slower** that type was than the previous month.\n",
    "- Lines for individual case types are **much more jagged** than the overall line:\n",
    "  - Some months show big positive jumps (cases took much longer than last month).\n",
    "  - Other months show big negative jumps (cases were completed much faster).\n",
    "- When we overlay the **“ALL case types”** line (in bold), it is noticeably **smoother** and stays closer to zero.\n",
    "- The high volatility at case-type level is mainly due to **small monthly numbers** – a few complex cases arriving or being closed can make the trend look chaotic.\n",
    "- The smoother overall line tells us the **system as a whole is more stable** than individual case-type charts might suggest.\n",
    "\n",
    "\n",
    "**Decision-making point & implications**\n",
    "- At the **overall level**, month-to-month changes in median duration usually sit within **±10 days**, with occasional larger swings.\n",
    "- At the **case-type level**, changes can be **much larger** (both better and worse) because each month may contain **relatively few cases** in that category.\n",
    "- The overall line in Figure 6 is much smoother than the individual case-type lines: the system as a whole is **reasonably stable**, even though individual categories can be noisy.\n",
    "- For **high-volume case types** (e.g. LPA, Deputyship), month-on-month changes can be informative.  \n",
    "- For **low-volume specialist types**, we should:\n",
    "  - Look at **longer time windows** (e.g. quarterly or yearly) when judging performance.\n",
    "  - Use charts mainly to spot **persistent patterns**, not to judge a team on one bad month.\n",
    "- When a particular case type shows **repeated positive MoM jumps** (getting slower for several months in a row), that is a flag to:\n",
    "  - Check **capacity, training, and process** specific to that pathway.\n",
    "\n",
    "> Performance should be judged over **rolling quarters** rather than single months, particularly for niche or low-volume case types where a few complex cases can distort monthly statistics.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 2.5  Future work and recommendations\n",
    "1. **Lock in the improvement**  \n",
    "   - Use the overall median trend to set a clear timeliness standard (e.g. *80% of cases closed within 90 days*).\n",
    "\n",
    "2. **Use overall lines for governance, detailed lines for diagnostics**  \n",
    "   - In senior packs, focus on the **ALL case types** plots; use the case-type breakdowns when a specific area is under review.\n",
    "\n",
    "3. **Review persistently slower case types**  \n",
    "   - Where a case type’s line sits above the overall line for several months, commission a **process review** (are delays justified by complexity or fixable?).\n",
    "\n",
    "4. **Avoid over-reacting to one “bad” month**  \n",
    "   - Use **rolling 3–6 month views** and be cautious with low-volume case types where a handful of cases can create big spikes.\n",
    "\n",
    "5. **Turn this into a regular dashboard**  \n",
    "   - Embed these plots into monthly and quarterly performance packs so that trends in timeliness are **tracked routinely, not ad hoc**.\n",
    "  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 3. Case type, risk and legal review\n",
    "\n",
    "### 3.1 Case type × risk band summary\n",
    "\n",
    "**Table 4 – Case type by risk band (volume, legal rate, median days to sign-off)**\n",
    "\n",
    "| Case type  | Risk band | n   | Legal review rate | Median days to sign-off |\n",
    "|------------|-----------|-----|-------------------|-------------------------|\n",
    "| Deputyship | High      | 86  | 10.5%             | 70.5                    |\n",
    "| Deputyship | Medium    | 209 | 9.1%              | 71.5                    |\n",
    "| Deputyship | Low       | 292 | 4.8%              | 67.0                    |\n",
    "| LPA        | High      | 184 | 9.2%              | 68.0                    |\n",
    "| LPA        | Medium    | 441 | 9.3%              | 72.0                    |\n",
    "| LPA        | Low       | 569 | 6.2%              | 67.0                    |\n",
    "| Other      | High      | 23  | 17.4%             | 55.0                    |\n",
    "| Other      | Medium    | 86  | 10.5%             | 77.0                    |\n",
    "| Other      | Low       | 110 | 3.6%              | 85.5                    |\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- **High-risk “Other” cases** have the **highest legal review rate (~17%)** but a **shorter median duration (~55 days)** – suggesting they are **prioritised and escalated appropriately**.\n",
    "- LPA and Deputyship show **consistent median durations (~67–72 days)** across risk bands, with **higher legal review rates** in the High/Medium bands.\n",
    "- Low-risk categories have **lower legal review rates**, as expected, but not always dramatically faster completion times.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Risk is influencing legal involvement as intended, but there may be scope to **speed up low-risk work further** to free capacity for high-risk and complex cases.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Interaction: risk band × time-to-sign-off → legal review\n",
    "\n",
    "**Table 5 – Legal review rate by risk band and time-to-sign-off bucket**\n",
    "\n",
    "| Risk band | 20–40 days | 40–61 days | 61–80 days | 80–99 days | 99–120 days |\n",
    "|-----------|------------|------------|------------|------------|-------------|\n",
    "| High      | 5.0%       | 11.8%      | 15.0%      | 13.3%      | 11.1%       |\n",
    "| Medium    | 4.6%       | 10.4%      | 8.4%       | 10.4%      | 9.4%        |\n",
    "| Low       | 3.2%       | 6.8%       | 5.6%       | 6.8%       | 5.3%        |\n",
    "\n",
    "\n",
    "**Interpretation**\n",
    "- For all risk bands, **longer-running cases have higher legal review rates**.\n",
    "- High and Medium risk cases that “drag on” are **particularly likely to attract legal input**.\n",
    "- Low-risk cases have lower rates throughout but still show **a rise in legal involvement** as they get older.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> A simple **“risk × age” early warning flag** would let managers identify cases that are **both high-risk and slow-moving**, prioritising them before they become very overdue.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Backlog, staffing and workload\n",
    "\n",
    "### 4.1 Recent daily picture\n",
    "\n",
    "**Table 6 – Sample of daily backlog and investigators on duty**\n",
    "\n",
    "| Date       | Backlog | Investigators on duty (mean) | 7-day avg backlog | 7-day avg invs |\n",
    "|------------|---------|------------------------------|-------------------|----------------|\n",
    "| 2024-10-22 | 474     | 14.0                         | 514.3             | 14.9           |\n",
    "| 2024-10-23 | 483     | 13.5                         | 527.3             | 14.4           |\n",
    "| 2024-10-24 | 605     | 15.3                         | 541.7             | 14.5           |\n",
    "| 2024-10-25 | 480     | 14.9                         | 519.4             | 14.5           |\n",
    "| 2024-10-26 | 451     | 15.5                         | 520.7             | 14.4           |\n",
    "\n",
    "### 4.2 Lagged relationship – backlog vs staffing\n",
    "\n",
    "**Table 7 – Lag correlations (backlog vs investigators’ average workload)**\n",
    "\n",
    "| Lag (days) | Correlation (backlog vs inv_mean) |\n",
    "|------------|-----------------------------------|\n",
    "| 1          | 0.03                              |\n",
    "| 7          | 0.06                              |\n",
    "| 14         | −0.05                             |\n",
    "\n",
    "**Interpretation**\n",
    "- Backlog remains typically in the **450–600 range** despite some variation in daily staffing.\n",
    "- The correlation between backlog and investigators on duty (or workload) is **very weak**, even when we look 1, 7 or 14 days ahead.\n",
    "- This suggests backlog is driven more by **structural factors** (case mix, process, hand-offs) than by **short-term staffing fluctuations**.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Tackling backlog will require **process redesign and prioritisation**, not just marginal changes in daily headcount.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Team-level KPIs\n",
    "\n",
    "**Table 8 – Monthly KPIs by team (sample)**\n",
    "\n",
    "| Team  | Month (YYYY-MM) | Backlog | Median allocations/day | Legal review rate |\n",
    "|-------|-----------------|---------|------------------------|-------------------|\n",
    "| A     | 2024-01         | 392     | 18.0                   | 10.5%             |\n",
    "| A     | 2024-02         | 576     | 17.5                   | 11.2%             |\n",
    "| A     | 2024-03         | 512     | 15.0                   | 6.2%              |\n",
    "| A     | 2024-04         | 556     | 17.0                   | 6.9%              |\n",
    "| A     | 2024-05         | 621     | 14.0                   | 4.8%              |\n",
    "| A     | 2024-06         | 565     | 17.0                   | 3.5%              |\n",
    "| A     | 2024-07         | 402     | 14.0                   | 4.2%              |\n",
    "| A     | 2024-08         | 501     | 13.0                   | 12.1%             |\n",
    "| A     | 2024-09         | 537     | 16.0                   | 9.1%              |\n",
    "| A     | 2024-10         | 553     | 16.0                   | 6.3%              |\n",
    "| B     | 2024-01         | 488     | 14.0                   | 8.0%              |\n",
    "| B     | 2024-02         | 521     | 14.0                   | 4.9%              |\n",
    "\n",
    "**Interpretation**\n",
    "- Team A’s backlog **rises and falls**, indicating periods of progress followed by renewed pressure.\n",
    "- Median daily allocations move generally between **13–18 per day**, suggesting **some flexibility but no clear upward step change**.\n",
    "- Legal review rates vary month-to-month but stay within a band of **3–12%**, reflecting changes in case mix.\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Team KPIs should be monitored in a **balanced way**: backlog, throughput (allocations) and legal review rate together, not in isolation.  \n",
    "> Where backlog is rising and allocations are static, we should explore whether **process changes, triage rules or cross-team support** are needed.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Relationships between core numeric measures\n",
    "\n",
    "**Table 9 – Spearman correlations**\n",
    "\n",
    "|                       | days_to_alloc | days_to_signoff | investigators_on_duty | allocations | backlog |\n",
    "|-----------------------|--------------:|----------------:|----------------------:|-----------:|--------:|\n",
    "| **days_to_alloc**     | 1.00          | 0.05            | −0.03                 | −0.04      | −0.00   |\n",
    "| **days_to_signoff**   | 0.05          | 1.00            | 0.01                  | −0.02      | −0.02   |\n",
    "| **investigators_on_duty** | −0.03     | 0.01            | 1.00                  | −0.02      | −0.00   |\n",
    "| **allocations**       | −0.04         | −0.02           | −0.02                 | 1.00       | −0.01   |\n",
    "| **backlog**           | −0.00         | −0.02           | −0.00                 | −0.01      | 1.00    |\n",
    "\n",
    "**Interpretation**\n",
    "- All correlations are **weak** (close to zero). In plain terms:\n",
    "  - **Taking longer to allocate** is *not* strongly linked with increased time to sign-off.\n",
    "  - Backlog is **not directly tracking** with investigators on duty or allocations.\n",
    "- This again supports the conclusion that **structural and case-mix factors** matter more than simple headcount.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Outcome imbalance and modelling considerations\n",
    "\n",
    "**Table 10 – Legal review outcome balance**\n",
    "\n",
    "| Outcome            | Count | Share |\n",
    "|--------------------|-------|-------|\n",
    "| No legal review (0)| 1,848 | 92.4% |\n",
    "| Legal review (1)   | 152   | 7.6%  |\n",
    "\n",
    "**Interpretation**\n",
    "- Legal review is a **rare but important outcome** (~8% of cases).\n",
    "- Any predictive modelling or dashboards for “likelihood of legal review” must account for **class imbalance** (few positives).\n",
    "\n",
    "**Decision-making point & implications**\n",
    "> Modelling should be used to **prioritise likely legal-review cases early**, not to expand the overall number of cases going to Legal.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Overall recommendations before simulation\n",
    "\n",
    "1. **Set and communicate a clear timeliness standard**\n",
    "   - Use the KM quantiles to define a realistic but stretching target (e.g. *80% of cases closed within 90 days*).\n",
    "   - Apply **stricter oversight** to high-risk cases exceeding 90 days.\n",
    "\n",
    "2. **Focus on the “long tail” of slow cases**\n",
    "   - Regular **ageing reports** (≥90, ≥120, ≥180 days) to be reviewed at team and director level.\n",
    "   - Assign explicit responsibility for clearing the oldest cases.\n",
    "\n",
    "3. **Reduce time to allocation**\n",
    "   - Current median allocation times (~2–3 weeks) are a significant part of total cycle time.\n",
    "   - Aim to move towards **allocation within 7 days** via better triage, ownership and automation.\n",
    "\n",
    "4. **Use risk × age as an early-warning flag**\n",
    "   - Create simple indicators combining **risk band** and **days open**.\n",
    "   - Use them to trigger **earlier Legal and senior-investigator involvement**.\n",
    "\n",
    "5. **Treat backlog as a structural problem, not just a staffing issue**\n",
    "   - Weak correlation between backlog and staffing suggests the need for:\n",
    "     - Process redesign and lean reviews;\n",
    "     - Clear prioritisation rules;\n",
    "     - Possibly new case pathways for low-risk, standard investigations.\n",
    "\n",
    "6. **Embed the interval plots and dashboards into routine governance**\n",
    "   - Include the **trend and MoM delta plots** in monthly and quarterly performance packs.\n",
    "   - For the Board, focus on **overall trend lines** with a small set of key risk case types.\n",
    "\n",
    "7. **Support transparent modelling and simulation**\n",
    "   - The clean data and low redundancy make it suitable for:\n",
    "     - Predictive models (e.g. risk of delay, risk of legal review),\n",
    "     - **Discrete-event simulation** of different staffing and process options.\n",
    "   - Emphasise **transparent, interpretable models** to avoid a “black box” perception among stakeholders.\n",
    "\n",
    "> Taken together, the analyses show **real progress in timeliness**, but also highlight a persistent backlog and a long tail of slow cases. The next phase should combine **targeted process changes, better triage and early-warning flags** with **simulation and forecasting**, so that OPG can manage investigations proactively rather than reactively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
