{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Predictive modelling (New Cases) \n",
    "The priority is providing the work that supports the predicting new case styles for investigations. \n",
    "Not predicting the backlog, because what they're looking for is a tool in the short term that they can better:\n",
    "1. predict how many new case styles,\n",
    "2. how many new investigations they can start as they increase the number of staff or vice versa.\n",
    "3. If they wanted to be able to say you want to increase the numbers of cases that we investigate, what staffing levels would that require\n",
    "4. And initially, you know, we've talked about doing that using a sort of a dynamic micro-simulation model or a micro-simulation model in order to do that.\n",
    "5. I can pick up the stuff around the work around forecasting the actual investigation. So the number of cases that they will continue to receive. We've got, it's the business that might be added to the backlog.\n",
    "6. But what you're doing is then saying within that backlog, that whole gene pair, how quickly can they pick up those cases and start investigation and start investigating them? So in terms of new case styles.\n",
    "7. Is it the new cases, does it mean like a time to allocation, time to allocate to the team, to the investigator? Well, it's the time that they actually start investigating it.\n",
    "\n",
    "- Uses the investigations database (with fields like Case Type, Date Received in OPG, Date allocated to current investigator, Status, Weighting, etc.) to build:\n",
    "    - start_date: the calendar date the investigation really starts.\n",
    "    - **wait_to_start**: how many days each case waited from “concern received” to “investigation started”.\n",
    "\n",
    "- Focuses on new investigations started (when they actually move into “investigation phase”, i.e. when they’re allocated to an investigator):\n",
    "    - New case starts for investigators (i.e. time from one allocation to the next),\n",
    "    - Per investigator, with attention to staff type/FTE pattern (full-time vs 0.5, etc.)\n",
    "    - Not **Simon**’s long lags from allocation → legal review/court.\n",
    "        - From allocation → legal review / court application (small subset of cases, long lags, months/years).\n",
    "\n",
    "- Models daily number of new investigations started by case type as a function of staff FTE (or similar capacity measure).\n",
    "\n",
    "- Lets you run “what-if” scenarios:\n",
    "    - “If we increase staff FTE to X,\n",
    "    - how many new investigations can we start per day by case type?”\n",
    "    - or “If we want to start Y cases per day, how much FTE do we need?”.\n",
    "\n",
    "- **Phase 1 “simple” model code: distribution of time intervals between allocations, by staff type (and optionally case type).**\n",
    "\n",
    "- Plugs into a dynamic simulation later.\n",
    "\n",
    "- We have a backlog (GPEN). Cases sit there until an investigator actually starts investigating them.\n",
    "\n",
    "- Operationally, “**a new case start**” is:\n",
    "    - The day a case is allocated to an investigator and they start working on it\n",
    "    - (i.e. when it leaves backlog and enters someone’s caseload).\n",
    "\n",
    "- For each investigator, over time, we see a sequence of allocations:\n",
    "    - … -> case allocated on 2024-01-03 -> next case allocated on 2024-01-07 -> …\n",
    "\n",
    "- The key quantity to model is:\n",
    "    - For a given investigator (with a given FTE pattern / staff type),\n",
    "    - what is the distribution of time between one allocation and the next?\n",
    "\n",
    "- In a **dynamic simulation** that runs day by day:\n",
    "    - At each day t+1, for each investigator we need the probability they pick up a new case on that day.\n",
    "    - In the simplest version, this can come directly from your empirical distribution of time intervals\n",
    "    - (e.g. full-time staff typically get a new case every ~4–6 days; 0.5 FTE every ~8–10 days, etc.).\n",
    "    - allocation → next allocation (for the same investigator).\n",
    "\n",
    "## Phase 1 simple model: “gap between allocations” by staff type\n",
    "- Data we need (per case)\n",
    "- At minimum, per case we need:\n",
    "    - investigator_id – who it was allocated to\n",
    "    - date_allocated_to_current_investigator – when that investigator started it\n",
    "    - fte or some staff type indicator (e.g. full_time, part_time_0_5, etc.)\n",
    "\n",
    "- Optionally:\n",
    "    - case_type\n",
    "    - closure_date (for more advanced models later)\n",
    "    - weighting (case complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute & summarise time between allocations\n",
    "\n",
    "# 1. Helper: create FTE bands (staff type)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# --- Step 1 – Import EDA classes --- \n",
    "from eda_opg import EDAConfig, OPGInvestigationEDA\n",
    "\n",
    "\n",
    "\n",
    "def add_fte_band(cases: pd.DataFrame,\n",
    "                 fte_col: str = \"fte\",\n",
    "                 band_col: str = \"fte_band\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a simple categorical staff-type band based on FTE.\n",
    "\n",
    "    Example bands:\n",
    "      - 'FT_0_8_to_1_0'    : mostly full-time\n",
    "      - 'PT_0_5_to_0_8'    : mid part-time\n",
    "      - 'PT_lt_0_5'        : small part-time\n",
    "      - 'Unknown_FTE'      : missing / uncategorised\n",
    "    \"\"\"\n",
    "    df = cases.copy()\n",
    "\n",
    "    def band(f):\n",
    "        if pd.isna(f):\n",
    "            return \"Unknown_FTE\"\n",
    "        if f >= 0.8:\n",
    "            return \"FT_0_8_to_1_0\"\n",
    "        if f >= 0.5:\n",
    "            return \"PT_0_5_to_0_8\"\n",
    "        if f > 0:\n",
    "            return \"PT_lt_0_5\"\n",
    "        return \"Unknown_FTE\"\n",
    "\n",
    "    df[band_col] = df[fte_col].apply(band)\n",
    "    return df\n",
    "\n",
    "\n",
    "## 2. Compute gaps between allocations per investigator\n",
    "\n",
    "def compute_allocation_gaps(\n",
    "    cases: pd.DataFrame,\n",
    "    investigator_col: str = \"investigator_id\",\n",
    "    alloc_date_col: str = \"date_allocated_to_current_investigator\",\n",
    "    staff_type_col: str = \"fte_band\",\n",
    "    case_type_col: str = \"case_type\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each investigator, compute the number of days between successive allocations.\n",
    "\n",
    "    Returns one row per allocation *after the first* for each investigator:\n",
    "      - investigator_id\n",
    "      - alloc_date (date of the *current* allocation)\n",
    "      - prev_alloc_date (previous allocation date)\n",
    "      - gap_days (days between prev and current)\n",
    "      - staff_type (e.g. fte_band)\n",
    "      - case_type (of the current case, optional)\n",
    "    \"\"\"\n",
    "    df = cases.copy()\n",
    "\n",
    "    # Ensure allocation date is datetime\n",
    "    df[alloc_date_col] = pd.to_datetime(df[alloc_date_col])\n",
    "\n",
    "    # Sort by investigator and allocation date\n",
    "    df = df.sort_values([investigator_col, alloc_date_col])\n",
    "\n",
    "    # Compute previous allocation date per investigator\n",
    "    df[\"prev_alloc_date\"] = df.groupby(investigator_col)[alloc_date_col].shift(1)\n",
    "\n",
    "    # Gap in days between allocations\n",
    "    df[\"gap_days\"] = (df[alloc_date_col] - df[\"prev_alloc_date\"]).dt.days\n",
    "\n",
    "    # Drop the first allocation for each investigator (no previous)\n",
    "    df = df.dropna(subset=[\"gap_days\"]).copy()\n",
    "\n",
    "    # Optional: remove negative or zero-day gaps if you think those are data quirks\n",
    "    df = df[df[\"gap_days\"] > 0]\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    keep_cols = [\n",
    "        investigator_col,\n",
    "        alloc_date_col,\n",
    "        \"prev_alloc_date\",\n",
    "        \"gap_days\",\n",
    "    ]\n",
    "    if staff_type_col in df.columns:\n",
    "        keep_cols.append(staff_type_col)\n",
    "    if case_type_col in df.columns:\n",
    "        keep_cols.append(case_type_col)\n",
    "\n",
    "    return df[keep_cols].reset_index(drop=True)\n",
    "\n",
    "# 3. Summarise gap distributions by staff type (and optionally case type)\n",
    "\n",
    "def summarise_gaps(\n",
    "    gaps: pd.DataFrame,\n",
    "    staff_type_col: str = \"fte_band\",\n",
    "    case_type_col: str = \"case_type\",\n",
    "    by_case_type: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarise the distribution of gap_days between allocations.\n",
    "\n",
    "    If by_case_type is False:\n",
    "        summary is by staff_type only.\n",
    "    If True:\n",
    "        summary is by (staff_type, case_type).\n",
    "    \"\"\"\n",
    "    group_cols = [staff_type_col]\n",
    "    if by_case_type and (case_type_col in gaps.columns):\n",
    "        group_cols.append(case_type_col)\n",
    "\n",
    "    def q25(x): return np.percentile(x, 25)\n",
    "    def q75(x): return np.percentile(x, 75)\n",
    "\n",
    "    summary = (\n",
    "        gaps.groupby(group_cols)[\"gap_days\"]\n",
    "        .agg(\n",
    "            count=\"count\",\n",
    "            mean=\"mean\",\n",
    "            median=\"median\",\n",
    "            p25=q25,\n",
    "            p75=q75,\n",
    "            min=\"min\",\n",
    "            max=\"max\",\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(group_cols)\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# 4. Example end-to-end usage\n",
    "\n",
    "# --- Step 2. Load the investigations data ---\n",
    "if __name__ == \"__main__\":\n",
    "    # OLD: reading from a CSV\n",
    "    # cases = pd.read_csv(\"investigations.csv\")\n",
    "    # cases = cases.rename({...})\n",
    "\n",
    "# --- Step 3 – Paste (or call) the synthetic data creation from demo_eda.py\n",
    "    # ----- 1) Create a small synthetic dataset for demonstration -----\n",
    "    rng = np.random.default_rng(42)\n",
    "    n = 2000\n",
    "\n",
    "    start = pd.Timestamp(\"2024-01-01\")\n",
    "    recv_dates = start + pd.to_timedelta(rng.integers(0, 300, size=n), unit=\"D\")\n",
    "\n",
    "    alloc_delays = rng.integers(1, 31, size=n)\n",
    "    allocated_mask = rng.random(size=n) < 0.85\n",
    "    alloc_dates = pd.Series(recv_dates) + pd.to_timedelta(alloc_delays, unit=\"D\")\n",
    "    alloc_dates = alloc_dates.where(allocated_mask, pd.NaT)\n",
    "\n",
    "    signoff_delays = rng.integers(20, 121, size=n)\n",
    "    so_mask = rng.random(size=n) < 0.70\n",
    "    signoff_dates = pd.Series(recv_dates) + pd.to_timedelta(signoff_delays, unit=\"D\")\n",
    "    signoff_dates = signoff_dates.where(so_mask, pd.NaT)\n",
    "\n",
    "    case_types = rng.choice([\"LPA\", \"Deputyship\", \"Other\"], size=n, p=[0.6, 0.3, 0.1])\n",
    "    risk_band = rng.choice([\"Low\", \"Medium\", \"High\"], size=n, p=[0.5, 0.35, 0.15])\n",
    "    teams = rng.choice([\"Team A\", \"Team B\", \"Team C\"], size=n, p=[0.4, 0.4, 0.2])\n",
    "    region = rng.choice([\"North\", \"Midlands\", \"South\"], size=n)\n",
    "\n",
    "    investigators_on_duty = rng.integers(8, 20, size=n)\n",
    "    allocations = rng.integers(0, 25, size=n)\n",
    "    backlog = np.maximum(0, 500 + rng.normal(0, 60, size=n).astype(int))\n",
    "\n",
    "    base_logit = -3.0 + 0.02 * np.nan_to_num(\n",
    "        alloc_dates - recv_dates\n",
    "    ).astype(\"timedelta64[D]\").astype(float)\n",
    "    risk_bump = np.select([risk_band == \"High\", risk_band == \"Medium\"], [1.2, 0.4], default=0.0)\n",
    "    logit = base_logit + risk_bump\n",
    "    # Clip logits to a reasonable range\n",
    "    logit_clipped = np.clip(logit, -20, 20)\n",
    "    prob = 1 / (1 + np.exp(-logit_clipped))\n",
    "    legal_review = (rng.random(size=n) < prob).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": np.arange(1, n + 1),\n",
    "        \"date_received_opg\": recv_dates,\n",
    "        \"date_allocated_investigator\": alloc_dates,\n",
    "        \"date_pg_signoff\": signoff_dates,\n",
    "        \"case_type\": case_types,\n",
    "        \"risk_band\": risk_band,\n",
    "        \"team\": teams,\n",
    "        \"region\": region,\n",
    "        \"investigators_on_duty\": investigators_on_duty,\n",
    "        \"allocations\": allocations,\n",
    "        \"backlog\": backlog,\n",
    "        \"legal_review\": legal_review,\n",
    "    })\n",
    "\n",
    "# --- Step 4 – Instantiate the EDA toolkit and get the engineered table\n",
    "    # ----- 2) Configure columns and instantiate the EDA toolkit -----\n",
    "    cfg = EDAConfig(\n",
    "        id_col=\"id\",\n",
    "        date_received=\"date_received_opg\",\n",
    "        date_allocated=\"date_allocated_investigator\",\n",
    "        date_signed_off=\"date_pg_signoff\",\n",
    "        target_col=\"legal_review\",\n",
    "        numeric_cols=[\n",
    "            \"days_to_allocate\",  # NOTE: eda will create this\n",
    "            \"days_to_signoff\",   # NOTE: eda will create this\n",
    "            \"investigators_on_duty\",\n",
    "            \"allocations\",\n",
    "            \"backlog\",\n",
    "        ],\n",
    "        categorical_cols=[\"case_type\", \"risk_band\", \"team\", \"region\"],\n",
    "        time_index_col=\"date_received_opg\",\n",
    "        team_col=\"team\",\n",
    "        risk_col=\"risk_band\",\n",
    "        case_type_col=\"case_type\",\n",
    "    )\n",
    "\n",
    "    eda = OPGInvestigationEDA(df, cfg)\n",
    "\n",
    "    # This is your “cases” table for the gap code:\n",
    "    cases = eda.df.copy()\n",
    "\n",
    "\n",
    "# --- Step 5 – Add investigator IDs and FTE to cases ---\n",
    "    # ----- 3) Add synthetic investigator_id and fte (for demo only) -----\n",
    "    # In real data, replace this with a merge from Staff Master.\n",
    "    n_investigators = 40\n",
    "    cases[\"investigator_id\"] = rng.integers(1, n_investigators + 1, size=len(cases))\n",
    "\n",
    "    # Random FTE: mixture of FT and PT patterns\n",
    "    cases[\"fte\"] = rng.choice(\n",
    "        [1.0, 0.8, 0.6, 0.5],\n",
    "        size=len(cases),\n",
    "        p=[0.4, 0.3, 0.2, 0.1],\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # --- Step 6 – # Band staff by FTE  --- \n",
    "    # --- 2. Add staff-type bands (based on FTE) ---\n",
    "    cases = add_fte_band(cases, fte_col=\"fte\", band_col=\"fte_band\")\n",
    "    \n",
    "    # --- 3. Compute gaps between allocations per investigator ---\n",
    "    gaps = compute_allocation_gaps(\n",
    "        cases,\n",
    "        investigator_col=\"investigator_id\",               # we just created this\n",
    "        alloc_date_col=\"date_allocated_investigator\",     # from demo_eda / config\n",
    "        staff_type_col=\"fte_band\",\n",
    "        case_type_col=\"case_type\",\n",
    "    )\n",
    "\n",
    "# --- 4. Summarise by staff type only (simplest model) ---\n",
    "    summary_by_staff = summarise_gaps(\n",
    "        gaps,\n",
    "        staff_type_col=\"fte_band\",\n",
    "        by_case_type=False,\n",
    "    )\n",
    "    print(\"Gap distribution between allocations by staff type:\")\n",
    "    print(summary_by_staff.to_string(index=False))\n",
    "\n",
    "\n",
    "    # --- 5. Optionally summarise by staff type AND case type ---\n",
    "    summary_by_staff_case = summarise_gaps(\n",
    "        gaps,\n",
    "        staff_type_col=\"fte_band\",\n",
    "        case_type_col=\"case_type\",\n",
    "        by_case_type=True,\n",
    "    )\n",
    "    print(\"\\nGap distribution between allocations by staff type & case type:\")\n",
    "    print(\"\\nNote: “Gap” is: number of calendar days between two consecutive allocations to the same investigator.\")\n",
    "    print(summary_by_staff_case.head(20).to_string(index=False))\n",
    "\n",
    "\n",
    "# Data from your summary table\n",
    "fte_bands = [\"FT 0.8–1.0\", \"PT 0.5–0.8\"]\n",
    "median_gaps = [6.0, 5.0]  # median days between allocations\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(fte_bands, median_gaps)\n",
    "plt.ylabel(\"Typical gap between new cases (days)\")\n",
    "plt.title(\"Median days between new case starts by staff type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# For FT_0_8_to_1_0 staff: median gap = 4 days (p25=3, p75=7)\n",
    "# For PT_0_5_to_0_8 staff: median gap = 7 days (p25=5, p75=10)\n",
    "\n",
    "# Case types\n",
    "case_types = [\"Deputyship\", \"LPA\", \"Other\"]\n",
    "\n",
    "# Median gaps from your detailed table\n",
    "median_ft = [5.0, 6.0, 5.0]  # FT_0_8_to_1_0\n",
    "median_pt = [5.0, 5.0, 5.0]  # PT_0_5_to_0_8\n",
    "\n",
    "x = np.arange(len(case_types))  # positions\n",
    "width = 0.35  # width of each bar\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(x - width/2, median_ft, width, label=\"FT 0.8–1.0\")\n",
    "plt.bar(x + width/2, median_pt, width, label=\"PT 0.5–0.8\")\n",
    "\n",
    "plt.xticks(x, case_types)\n",
    "plt.ylabel(\"Typical gap between new cases (days)\")\n",
    "plt.title(\"Median days between new case starts by staff type and case type\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
