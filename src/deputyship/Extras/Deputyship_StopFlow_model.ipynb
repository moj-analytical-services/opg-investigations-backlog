{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Deputyship Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydbtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydbtools\n",
    "import os\n",
    "import calendar\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# Configure logging\n",
    "import warnings\n",
    "# Suppress statsmodels AIC/BIC divide-by-zero runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*divide by zero encountered in log.*\")\n",
    "#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Disable logging output\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    \"\"\"Parse 'YYYY-MM' to datetime.\"\"\"\n",
    "    result = datetime.strptime(month_str.strip().strip(\"'\\\"\"), \"%Y-%m\")\n",
    "    logging.debug(f\"parse_month: parsed '{month_str}' to {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# def clear_directory(path):\n",
    "#     logging.info(f\"clear_directory: clearing path {path}\")\n",
    "#     for filename in os.listdir(path):\n",
    "#         file_path = os.path.join(path, filename)\n",
    "#         try:\n",
    "#             if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "#                 os.unlink(file_path)\n",
    "#                 logging.debug(f\"Deleted file {file_path}\")\n",
    "#             elif os.path.isdir(file_path):\n",
    "#                 shutil.rmtree(file_path)\n",
    "#                 logging.debug(f\"Deleted directory {file_path}\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "def clear_directory(path: str):\n",
    "    \"\"\"Safely delete all files in `path` if it’s a directory.\"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        logging.debug(f\"clear_directory: '{path}' is not a directory, skipping.\")\n",
    "        return\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    logging.info(f\"fetch_cases_for_date: fetching data for {run_date}\")\n",
    "    query = \"...\"  # trimmed for brevity\n",
    "    df = pydbtools.read_sql_query(query)\n",
    "    logging.info(f\"fetch_cases_for_date: returned {len(df)} rows for {run_date}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    logging.info(f\"generate_month_list: from {start_month} to {end_month}\")\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        logging.debug(f\"Added month {current}\")\n",
    "        current += relativedelta(months=1)\n",
    "    logging.info(f\"Generated {len(months)} months\")\n",
    "    return months\n",
    "\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    result = dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "    logging.debug(f\"last_day_of_month: for {dt} result {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all cases & their fee reductions for the given run_date (YYYY-MM-DD)\n",
    "    using pydbtools.read_sql_query, which returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH active_fee_reductions AS (\n",
    "      SELECT\n",
    "        fc.client_id,\n",
    "        SUBSTRING(fr.type,1,1) || LOWER(SUBSTRING(fr.type,2)) AS type,\n",
    "        DATE(fr.startdate) AS startdate,\n",
    "        DATE(fr.enddate)   AS enddate,\n",
    "        fc.payment_method\n",
    "      FROM opg_sirius_prod.fee_reduction fr\n",
    "      JOIN opg_sirius_prod.finance_client fc\n",
    "        ON fc.id = fr.finance_client_id\n",
    "       AND fc.glueexporteddate = DATE('{run_date}')\n",
    "      JOIN (\n",
    "        SELECT\n",
    "          MAX(id)           AS id,\n",
    "          finance_client_id\n",
    "        FROM opg_sirius_prod.fee_reduction\n",
    "        WHERE enddate           >= DATE('{run_date}')\n",
    "          AND startdate         <= DATE('{run_date}')\n",
    "          AND deleted            = FALSE\n",
    "          AND glueexporteddate   = DATE('{run_date}')\n",
    "        GROUP BY finance_client_id\n",
    "      ) latest ON latest.id = fr.id\n",
    "      WHERE fr.glueexporteddate = DATE('{run_date}')\n",
    "    )\n",
    "    SELECT\n",
    "      c.glueexporteddate,\n",
    "      c.caserecnumber            AS casenumber,\n",
    "      c.uid                      AS siriusid,\n",
    "      (\n",
    "        SELECT supervisionlevel\n",
    "        FROM opg_sirius_prod.supervision_level_log sll\n",
    "        WHERE sll.order_id         = c.id\n",
    "          AND sll.glueexporteddate = DATE('{run_date}')\n",
    "        ORDER BY sll.appliesfrom DESC\n",
    "        LIMIT 1\n",
    "      ) AS casesupervisionlevel,\n",
    "      p.risk_score               AS CREC,\n",
    "      c.casesubtype              AS orderType,\n",
    "      c.orderdate                AS ordermadedate,\n",
    "      c.orderstatus              AS orderStatus,\n",
    "      afr.type                   AS feereductiontype,\n",
    "      p.dob,\n",
    "      CASE\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) < 0 THEN 0\n",
    "        ELSE ROUND(DATE_DIFF('day', p.dob, p.createddate) / 365.25)\n",
    "      END AS age_in_years\n",
    "    FROM opg_sirius_prod.persons p\n",
    "    JOIN opg_sirius_prod.cases c\n",
    "      ON p.id                   = c.client_id\n",
    "     AND c.glueexporteddate     = DATE('{run_date}')\n",
    "    LEFT JOIN active_fee_reductions afr\n",
    "      ON afr.client_id          = p.id\n",
    "    WHERE c.orderstatus IN ('OPEN','ACTIVE','DUPLICATE')\n",
    "      AND p.glueexporteddate     = DATE('{run_date}')\n",
    "    ORDER BY c.orderdate;\n",
    "    \"\"\"\n",
    "    return pydbtools.read_sql_query(query)\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    \"\"\"\n",
    "    Return a list of datetime objects for each month-start\n",
    "    from start_month to end_month inclusive.\n",
    "    \"\"\"\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    \"\"\"Return the last day of dt's month as 'YYYY-MM-DD'.\"\"\"\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    return dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "def export_monthly_reports(first_month: str, last_month: str, output_base=\"output\") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    # **Clear the output directory, not the Excel filepath**\n",
    "    clear_directory(output_base)\n",
    "\n",
    "    excel_filename = f\"cases_{clean_first}_to_{clean_last}.xlsx\"\n",
    "    excel_path = os.path.join(output_base, excel_filename)\n",
    "\n",
    "    # List to accumulate each month's DataFrame\n",
    "    all_months = []\n",
    "\n",
    "    # Create Excel workbook and write each month's sheet\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        for dt in months:\n",
    "            month_tag = dt.strftime(\"%Y-%m\")\n",
    "            run_date = last_day_of_month(dt)\n",
    "\n",
    "            # Fetch data for this month-end\n",
    "            df = fetch_cases_for_date(run_date)\n",
    "\n",
    "            # Tag the DataFrame with its month, then collect it\n",
    "            df[\"month\"] = month_tag\n",
    "            all_months.append(df)\n",
    "\n",
    "            # Save CSV for this month\n",
    "            month_folder = os.path.join(output_base, month_tag)\n",
    "            os.makedirs(month_folder, exist_ok=True)\n",
    "            csv_path = os.path.join(month_folder, f\"cases_{month_tag}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "            # Add to Excel workbook\n",
    "            df.to_excel(writer, sheet_name=month_tag, index=False)\n",
    "\n",
    "            print(f\"→ Saved CSV for {month_tag}: {csv_path}\")\n",
    "        pass\n",
    "        print(f\"→ Combined Excel workbook saved at: {excel_path}\")\n",
    "\n",
    "    # After all sheets are written, concatenate & export one big CSV\n",
    "    if all_months:\n",
    "        combined_df = pd.concat(all_months, ignore_index=True)\n",
    "        combined_csv_path = os.path.join(\n",
    "            output_base,\n",
    "            f\"all_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "        )\n",
    "        combined_df.to_csv(combined_csv_path, index=False)\n",
    "        print(f\"→ Combined CSV for all months saved at: {combined_csv_path}\")\n",
    "    else:\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "    # ---- NEW SUMMARY SECTION ----\n",
    "    if not combined_df.empty:\n",
    "        # extract year from the month tag\n",
    "        combined_df[\"year\"] = pd.to_datetime(combined_df[\"month\"], format=\"%Y-%m\").dt.year\n",
    "\n",
    "        # annual summary\n",
    "        annual = (\n",
    "            combined_df\n",
    "            .groupby(\"year\")\n",
    "            .agg(\n",
    "                total_orders=(\"casenumber\", \"size\"),\n",
    "                total_people=(\"casenumber\", \"nunique\")\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # overall summary across entire period\n",
    "        overall = pd.DataFrame([{\n",
    "            \"year\": \"all\",\n",
    "            \"total_orders\": combined_df.shape[0],\n",
    "            \"total_people\": combined_df[\"casenumber\"].nunique()\n",
    "        }])\n",
    "\n",
    "        # combine for easy comparison\n",
    "        summary_df = pd.concat([annual, overall], ignore_index=True)\n",
    "\n",
    "        # print to console\n",
    "        print(\"\\n=== Orders & Unique-People Summary ===\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "    else:\n",
    "        summary_df = pd.DataFrame()\n",
    "        print(\"No data to summarise.\")\n",
    "\n",
    "    return combined_df, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_active_cases(\n",
    "    df: pd.DataFrame,\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base=\"output\"\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each month between first_month and last_month (inclusive), fetch the data,\n",
    "    filter to ACTIVE cases, then aggregate unique casenumber counts by orderType.\n",
    "    Writes a CSV 'monthly_active_cases_<first>_to_<last>.csv' under output_base,\n",
    "    prints yearly order & people counts, and returns:\n",
    "      - result_df: monthly/orderType aggregates\n",
    "      - summary_df: yearly order & unique-case counts\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # Lists to collect each month's summary and raw active data\n",
    "    summaries = []\n",
    "    active_data = []\n",
    "\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date = last_day_of_month(dt)\n",
    "\n",
    "        \n",
    "        # Fetch and filter to ACTIVE\n",
    "        #df = fetch_cases_for_date(run_date)\n",
    "        #df = combined_df\n",
    "        \n",
    "        #df_active = df[df[\"orderstatus\"] == \"ACTIVE\"].copy()\n",
    "        df_active = df\n",
    "        df_active[\"month\"] = month_tag\n",
    "\n",
    "        # Accumulate raw active rows for yearly summary\n",
    "        active_data.append(df_active)\n",
    "\n",
    "        # Aggregate unique casenumbers per orderType\n",
    "        if df_active.empty:\n",
    "            summaries.append(\n",
    "                pd.DataFrame([{\n",
    "                    \"month\": month_tag,\n",
    "                    \"orderType\": None,\n",
    "                    \"active_case_count\": 0\n",
    "                }])\n",
    "            )\n",
    "        else:\n",
    "            summary = (\n",
    "                df_active\n",
    "                .groupby([\"month\", \"ordertype\"], observed=False)[\"casenumber\"]\n",
    "                .nunique()\n",
    "                .reset_index(name=\"active_case_count\")\n",
    "            )\n",
    "            summaries.append(summary)\n",
    "\n",
    "        print(f\"→ Aggregated ACTIVE cases for {month_tag}\")\n",
    "\n",
    "    # Combine monthly summaries\n",
    "    result_df = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    # Write out CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_active_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    result_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly ACTIVE cases CSV saved at: {out_csv}\")\n",
    "\n",
    "    # ---- NEW YEARLY SUMMARY ----\n",
    "    if active_data:\n",
    "        combined_active = pd.concat(active_data, ignore_index=True)\n",
    "        combined_active[\"year\"] = pd.to_datetime(\n",
    "            combined_active[\"month\"], format=\"%Y-%m\"\n",
    "        ).dt.year\n",
    "\n",
    "        # Total orders per year\n",
    "        orders_year = (\n",
    "            combined_active\n",
    "            .groupby(\"year\")\n",
    "            .size()\n",
    "            .reset_index(name=\"order_count\")\n",
    "        )\n",
    "\n",
    "        # Unique cases (people) per year\n",
    "        people_year = (\n",
    "            combined_active\n",
    "            .groupby(\"year\")[\"casenumber\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"unique_cases\")\n",
    "        )\n",
    "\n",
    "        summary_df = orders_year.merge(people_year, on=\"year\")\n",
    "\n",
    "        print(\"\\n=== Yearly Active Orders & Unique Cases ===\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "    else:\n",
    "        summary_df = pd.DataFrame()\n",
    "        print(\"No ACTIVE data to summarise.\")\n",
    "\n",
    "    return active_data, result_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_flow(\n",
    "    #df: pd.DataFrame,\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base=\"output\"\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each month from first_month to last_month (inclusive),\n",
    "    snapshot the set of active casenumbers, then compare to the prior month\n",
    "    to count how many entered, exited, and how many were active.\n",
    "    Writes 'monthly_flow_<first>_to_<last>.csv' under output_base,\n",
    "    prints yearly summaries, and returns (flow_df, summary_df).\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate month list\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # Snapshot active casenumbers per month\n",
    "    snapshots = {}\n",
    "    for dt in months:\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "\n",
    "        # load data frame\n",
    "        df = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        \n",
    "        snapshots[tag] = set(df[\"casenumber\"].unique())\n",
    "        print(f\"→ Snapshot for {tag}: {len(snapshots[tag])} active cases\")\n",
    "\n",
    "    # Build flow records\n",
    "    flow_records = []\n",
    "    entered_sets = {}\n",
    "    exited_sets  = {}\n",
    "    prev_tag = None\n",
    "\n",
    "    for tag in sorted(snapshots):\n",
    "        current = snapshots[tag]\n",
    "        active_cnt = len(current)\n",
    "\n",
    "        if prev_tag is None:\n",
    "            entered = current\n",
    "            exited  = set()\n",
    "        else:\n",
    "            prev = snapshots[prev_tag]\n",
    "            entered = current - prev\n",
    "            exited  = prev - current\n",
    "\n",
    "        entered_sets[tag] = entered\n",
    "        exited_sets[tag]  = exited\n",
    "\n",
    "        flow_records.append({\n",
    "            \"month\":        tag,\n",
    "            \"active_count\": active_cnt,\n",
    "            \"entered\":      len(entered),\n",
    "            \"exited\":       len(exited)\n",
    "        })\n",
    "        prev_tag = tag\n",
    "\n",
    "    # Create DataFrame & save CSV\n",
    "    flow_df = pd.DataFrame(flow_records)\n",
    "\n",
    "    # Remove the forst record as it only shows the whole count of active cases for entered and shows exited = 0\n",
    "    flow_df = flow_df[1:]\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    out_csv = os.path.join(output_base, f\"monthly_flow_{clean_first}_to_{clean_last}.csv\")\n",
    "    flow_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly flow CSV saved at: {out_csv}\")\n",
    "\n",
    "    # Yearly summary\n",
    "    flow_df[\"year\"] = pd.to_datetime(flow_df[\"month\"], format=\"%Y-%m\").dt.year\n",
    "    summary_records = []\n",
    "\n",
    "    for year, group in flow_df.groupby(\"year\"):\n",
    "        months_in_year = group[\"month\"].tolist()\n",
    "        total_entered = group[\"entered\"].sum()\n",
    "        total_exited  = group[\"exited\"].sum()\n",
    "        total_active  = group[\"active_count\"].sum()\n",
    "\n",
    "        unique_entered = len(set().union(*(entered_sets[m] for m in months_in_year)))\n",
    "        unique_exited  = len(set().union(*(exited_sets[m]  for m in months_in_year)))\n",
    "        unique_active  = len(set().union(*(snapshots[m]     for m in months_in_year)))\n",
    "\n",
    "        summary_records.append({\n",
    "            \"year\":            year,\n",
    "            #\"entered_orders\":  total_entered,\n",
    "            \"entered_people\":  unique_entered,\n",
    "            #\"exited_orders\":   total_exited,\n",
    "            \"exited_people\":   unique_exited,\n",
    "            #\"active_orders\":   total_active,\n",
    "            \"active_clients\":  unique_active\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "    print(\"\\n=== Yearly Flow & Active Summary ===\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    return flow_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    import os\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    logging.info(f\"Calculating year-on-year flows and age rates from \"\n",
    "                 f\"{first_month} to {last_month}, redistribute_unknown_age={redistribute_unknown_age}\")\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # Default 1-year bins if none supplied\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins   = list(range(0, 107))\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]\n",
    "    # Ensure \"Unknown\" bucket\n",
    "    if \"Unknown\" not in age_labels:\n",
    "        age_labels = age_labels + [\"Unknown\"]\n",
    "\n",
    "    # Storage\n",
    "    flow_records = []\n",
    "    age_records = []\n",
    "    snapshots_cur  = {}\n",
    "    entered_sets   = {}\n",
    "    exited_sets    = {}\n",
    "\n",
    "    for dt in generate_month_list(first_month, last_month):\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        logging.info(f\"Processing month {tag}\")\n",
    "\n",
    "        df_cur  = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "        set_cur, set_prev = set(df_cur[\"casenumber\"]), set(df_prev[\"casenumber\"])\n",
    "        snapshots_cur[tag] = set_cur\n",
    "        entered_sets[tag]  = set_cur - set_prev\n",
    "        exited_sets[tag]   = set_prev - set_cur\n",
    "\n",
    "        flow_records.append({\n",
    "            \"month\":                tag,\n",
    "            \"active_current\":       len(set_cur),\n",
    "            \"active_previous\":      len(set_prev),\n",
    "            \"entered_orders\":       len(df_cur[df_cur[\"casenumber\"].isin(entered_sets[tag])]),\n",
    "            \"entered_clients\":      len(entered_sets[tag]),\n",
    "            \"exited_orders\":        len(df_prev[df_prev[\"casenumber\"].isin(exited_sets[tag])]),\n",
    "            \"exited_clients\":       len(exited_sets[tag]),\n",
    "        })\n",
    "\n",
    "        # prepare age-grouped DFs\n",
    "        df_base = df_prev.copy()\n",
    "        df_in   = df_cur [df_cur [\"casenumber\"].isin(entered_sets[tag])].copy()\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited_sets[tag])].copy()\n",
    "\n",
    "        for d in (df_base, df_in, df_term):\n",
    "            d[\"age_group\"] = pd.cut(\n",
    "                d[\"age_in_years\"], bins=age_bins,\n",
    "                labels=age_labels[:-1], right=False, include_lowest=True\n",
    "            ).astype(object).fillna(\"Unknown\")\n",
    "\n",
    "        # counts per age\n",
    "        # — clients = unique casenumbers\n",
    "        # base_clients = df_base.groupby(\"age_group\")[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        # in_clients   = df_in  .groupby(\"age_group\")[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        # term_clients = df_term.groupby(\"age_group\")[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        base_clients = df_base.groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "        in_clients   = df_in  .groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "        term_clients = df_term.groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "        \n",
    "        # — orders = row counts (duplicates allowed)\n",
    "        base_orders  = df_base.groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "        in_orders    = df_in  .groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "        term_orders  = df_term.groupby(\"age_group\")[\"casenumber\"].size().reindex(age_labels, fill_value=0)\n",
    "\n",
    "        # redistribute unknowns if requested\n",
    "        if redistribute_unknown_age:\n",
    "            for series in (in_orders, term_orders, base_orders):\n",
    "                unknown = series[\"Unknown\"]\n",
    "                if unknown>0:\n",
    "                    props = series.drop(\"Unknown\")/series.drop(\"Unknown\").sum()\n",
    "                    alloc = (props*unknown).round().astype(int)\n",
    "                    series.loc[props.index] += alloc\n",
    "                    series[\"Unknown\"] = 0\n",
    "            for series in (in_clients, term_clients, base_clients):\n",
    "                unknown = series[\"Unknown\"]\n",
    "                if unknown>0:\n",
    "                    props = series.drop(\"Unknown\")/series.drop(\"Unknown\").sum()\n",
    "                    alloc = (props*unknown).round().astype(int)\n",
    "                    series.loc[props.index] += alloc\n",
    "                    series[\"Unknown\"] = 0\n",
    "\n",
    "        # record per age\n",
    "        for grp in age_labels:\n",
    "            active = base_clients[grp]\n",
    "            ords   = base_orders [grp]\n",
    "            clnts  = base_clients[grp]\n",
    "            ent_o  = in_orders   [grp]\n",
    "            ent_c  = in_clients  [grp]\n",
    "            term_o = term_orders [grp]\n",
    "            term_c = term_clients[grp]\n",
    "            rate_c = (term_c/active) if active else 0\n",
    "            rate_o = (term_o/ords ) if ords   else 0\n",
    "\n",
    "            age_records.append({\n",
    "                \"month\":                 tag,\n",
    "                \"age_group\":             grp,\n",
    "                \"active_orders_age\":     ords,\n",
    "                \"active_clients_age\":    clnts,\n",
    "                \"entered_orders_age\":    ent_o,\n",
    "                \"entered_clients_age\":   ent_c,\n",
    "                \"exited_orders_age\":     term_o,\n",
    "                \"exited_clients_age\":    term_c,\n",
    "                \"termination_rate_clients\": rate_c,\n",
    "                \"termination_rate_orders\":  rate_o\n",
    "            })\n",
    "\n",
    "    # build DataFrames\n",
    "    flows_df = pd.DataFrame(flow_records)\n",
    "    ages_df  = pd.DataFrame(age_records)\n",
    "\n",
    "    # save CSVs\n",
    "    flows_df.to_csv(os.path.join(output_base, f\"flows_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "    ages_df .to_csv(os.path.join(output_base, f\"ages_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "\n",
    "    # yearly summary\n",
    "    flows_df[\"year\"] = pd.to_datetime(flows_df[\"month\"], format=\"%Y-%m\").dt.year\n",
    "    year_recs = []\n",
    "    for yr, g in flows_df.groupby(\"year\"):\n",
    "        year_recs.append({\n",
    "            \"year\":             yr,\n",
    "            \"active_orders\":    g[\"active_current\"].sum(),\n",
    "            \"active_clients\":   len(set().union(*(snapshots_cur[m] for m in g[\"month\"]))),\n",
    "            \"entered_orders\":   g[\"entered_orders\"].sum(),\n",
    "            \"entered_clients\":  len(set().union(*(entered_sets[m]   for m in g[\"month\"]))),\n",
    "            \"exited_orders\":    g[\"exited_orders\"].sum(),\n",
    "            \"exited_clients\":   len(set().union(*(exited_sets[m]    for m in g[\"month\"])))\n",
    "        })\n",
    "    yearly_df = pd.DataFrame(year_recs)\n",
    "    print(\"\\n=== Yearly Summary ===\")\n",
    "    print(yearly_df.to_string(index=False))\n",
    "\n",
    "    # monthly summary\n",
    "    month_recs = []\n",
    "    for _, r in flows_df.iterrows():\n",
    "        m = r[\"month\"]\n",
    "        month_recs.append({\n",
    "            \"month\":           m,\n",
    "            \"active_orders\":   r[\"active_current\"],\n",
    "            \"active_clients\":  len(snapshots_cur[m]),\n",
    "            \"entered_orders\":  r[\"entered_orders\"],\n",
    "            \"entered_clients\": len(entered_sets[m]),\n",
    "            \"exited_orders\":   r[\"exited_orders\"],\n",
    "            \"exited_clients\":  len(exited_sets[m])\n",
    "        })\n",
    "    monthly_df = pd.DataFrame(month_recs)\n",
    "    print(\"\\n=== Monthly Summary ===\")\n",
    "    print(monthly_df.to_string(index=False))\n",
    "\n",
    "    return flows_df, ages_df, yearly_df, monthly_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append current and forecasted tables\n",
    "def get_combined_age_deputyship_table(tbl1, tbl2):\n",
    "    combined = pd.concat(\n",
    "        [tbl1, tbl2],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculate year-on-year flows (entries/exits) and age-specific rates, with optional\n",
    "    imputation of missing ages (\"Unknown\") via proportional redistribution into\n",
    "    integer age groups. When redistribution is enabled, each Unknown row is reassigned\n",
    "    to a concrete integer age group using integer allocations (Hamilton apportionment),\n",
    "    and the 'age_group' value for those rows is updated accordingly.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Local imports for numerical helpers (keeps dependency scope clear)\n",
    "    import numpy as np\n",
    "\n",
    "    # --- Logging the operation and key parameters for traceability\n",
    "    logging.info(\n",
    "        f\"Calculating year-on-year flows and age rates from {first_month} to {last_month}, \"\n",
    "        f\"redistribute_unknown_age={redistribute_unknown_age}\"\n",
    "    )\n",
    "\n",
    "    # --- Ensure the output directory exists to avoid file write errors later\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # --- Establish age bins and labels (default is 0–106 inclusive as integer groups)\n",
    "    # If caller didn't supply custom bins/labels, build the defaults.\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins = list(range(0, 107))                     # Edges for [0,1), [1,2), ..., [106,107)\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]       # String labels '0'...'106' (no \"Unknown\")\n",
    "\n",
    "    # --- Make sure we work with labels that do NOT include 'Unknown' for final outputs\n",
    "    # If a user passed labels that contain 'Unknown', remove it from the cut-labels.\n",
    "    labels_for_cut = [lbl for lbl in age_labels if lbl != \"Unknown\"]  # Used by pd.cut\n",
    "    final_age_labels = labels_for_cut[:]                               # Final index order for outputs\n",
    "\n",
    "    # --- Helper: cut ages into groups and set 'Unknown' for out-of-range/missing ages\n",
    "    def _assign_age_groups_inplace(df: pd.DataFrame) -> None:\n",
    "        \"\"\"Add/overwrite df['age_group'] using bins/labels; out-of-range/missing -> 'Unknown'.\"\"\"\n",
    "        # Compute categorical age groups for known ages using left-closed bins\n",
    "        df[\"age_group\"] = pd.cut(\n",
    "            df[\"age_in_years\"],               # Source age column (assumed present)\n",
    "            bins=age_bins,                    # Integer bin edges (e.g., [0,1), [1,2), ...)\n",
    "            labels=labels_for_cut,            # Only concrete integer labels\n",
    "            right=False,                      # Include left edge, exclude right edge\n",
    "            include_lowest=True               # Include the lowest bound\n",
    "        )\n",
    "        # Convert NaN categories (missing/out-of-range) into the literal string \"Unknown\"\n",
    "        df[\"age_group\"] = df[\"age_group\"].astype(object).where(df[\"age_group\"].notna(), \"Unknown\")\n",
    "\n",
    "    # --- Helper: proportional integer allocation (Hamilton apportionment)\n",
    "    def _proportional_integer_allocation(known_counts: pd.Series, unknown_total: int) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Allocate 'unknown_total' integer units across index labels of 'known_counts'\n",
    "        proportionally to known_counts (or uniformly if all zeros).\n",
    "        Returns a Series of integer allocations indexed like known_counts.\n",
    "        \"\"\"\n",
    "        # Ensure index order matches final labels and fill missing with zero\n",
    "        known_counts = known_counts.reindex(final_age_labels, fill_value=0)\n",
    "\n",
    "        # Sum the known counts to derive proportions\n",
    "        total_known = known_counts.sum()\n",
    "\n",
    "        # If no known info exists, split uniformly; else use proportional shares\n",
    "        if total_known == 0:\n",
    "            # Uniform shares across all age groups\n",
    "            raw = pd.Series(np.full(len(final_age_labels), unknown_total / max(len(final_age_labels), 1.0)),\n",
    "                            index=final_age_labels, dtype=float)\n",
    "        else:\n",
    "            # Proportional shares: each group's fraction times unknown_total\n",
    "            raw = (known_counts / total_known) * unknown_total\n",
    "\n",
    "        # Base integer allocations via floor\n",
    "        base = np.floor(raw).astype(int)\n",
    "\n",
    "        # Remaining units to distribute due to flooring\n",
    "        remainder = int(unknown_total - base.sum())\n",
    "\n",
    "        # Fractional remainders for Hamilton method\n",
    "        frac = raw - base\n",
    "\n",
    "        # Deterministic tie-break: sort by fractional part desc, then by label asc\n",
    "        order = sorted(final_age_labels, key=lambda x: (-frac.loc[x], x))\n",
    "\n",
    "        # Distribute one-by-one to the top 'remainder' labels\n",
    "        for i in range(remainder):\n",
    "            base.loc[order[i]] += 1\n",
    "\n",
    "        # Return allocations as a Series aligned to final_age_labels\n",
    "        return base.reindex(final_age_labels).astype(int)\n",
    "\n",
    "    # --- Helper: impute unknown ages row-wise, deterministically, in-place\n",
    "    def _impute_unknowns_inplace(df: pd.DataFrame, id_col: str = \"casenumber\") -> None:\n",
    "        \"\"\"\n",
    "        For a given df that already has 'age_group' with some 'Unknown',\n",
    "        reassign 'Unknown' rows to concrete integer age groups.\n",
    "\n",
    "        Allocation weights are derived from the df's own composition using\n",
    "        unique {id_col} counts by known age group. The assignment to rows is\n",
    "        deterministic (sorted index order) to ensure reproducibility.\n",
    "        \"\"\"\n",
    "        # Identify which rows are currently Unknown\n",
    "        unknown_idx = df.index[df[\"age_group\"] == \"Unknown\"]\n",
    "        # If nothing to impute, bail early\n",
    "        if len(unknown_idx) == 0:\n",
    "            return\n",
    "\n",
    "        # Build weights using unique case counts by known age group\n",
    "        # (drop Unknown to avoid circularity)\n",
    "        known_unique = (\n",
    "            df.loc[df[\"age_group\"] != \"Unknown\", [\"age_group\", id_col]]\n",
    "              .drop_duplicates()\n",
    "              .groupby(\"age_group\", observed=False)[id_col]\n",
    "              .nunique()\n",
    "              .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "\n",
    "        # Compute integer allocations across age groups for the Unknown total\n",
    "        allocations = _proportional_integer_allocation(known_unique, len(unknown_idx))\n",
    "\n",
    "        # Deterministic row assignment: sort unknown indices so results are stable\n",
    "        unknown_idx_sorted = sorted(unknown_idx.tolist())\n",
    "\n",
    "        # Pointer into the unknown index list as we assign chunks\n",
    "        cursor = 0\n",
    "\n",
    "        # Assign each block of Unknown rows to its allocated age group\n",
    "        for lbl in final_age_labels:\n",
    "            k = int(allocations.get(lbl, 0))     # How many Unknown rows to assign to this label\n",
    "            if k > 0:\n",
    "                take = unknown_idx_sorted[cursor: cursor + k]  # Slice next k rows\n",
    "                df.loc[take, \"age_group\"] = lbl                # Set their age_group to the label\n",
    "                cursor += k                                    # Advance the pointer\n",
    "\n",
    "        # Safety: if any Unknowns remain due to edge cases, place them in the smallest label\n",
    "        if (df[\"age_group\"] == \"Unknown\").any():\n",
    "            leftovers = df.index[df[\"age_group\"] == \"Unknown\"]\n",
    "            fallback = final_age_labels[0] if final_age_labels else \"0\"\n",
    "            df.loc[leftovers, \"age_group\"] = fallback\n",
    "\n",
    "    # --- Containers to accumulate per-month analytics (flows and age-rate details)\n",
    "    flow_records = []         # List of dicts: overall monthly counts (active, entered, exited)\n",
    "    age_rate_records = []     # List of dicts: per-month x age-group counts and rates\n",
    "    snapshots_cur = {}        # Dict: month tag -> set of active casenumbers (current month)\n",
    "    snapshots_prev = {}       # Dict: month tag -> set of active casenumbers (prev-year same month)\n",
    "    entered_sets = {}         # Dict: month tag -> set of casenumbers entered this month\n",
    "    exited_sets = {}          # Dict: month tag -> set of casenumbers exited this month\n",
    "\n",
    "    # --- Iterate each month in the requested window\n",
    "    for dt in generate_month_list(first_month, last_month):\n",
    "        # Compute the month exactly one year earlier for YoY comparisons\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "\n",
    "        # Skip early months that don't have a prior-year comparison within window\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "\n",
    "        # Create a YYYY-MM tag for logging and indexing\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        logging.info(f\"Processing month {tag}\")\n",
    "\n",
    "        # Fetch snapshots of active cases at month-end for current and prior-year month\n",
    "        df_cur = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "        # Convert to sets of IDs for fast set arithmetic\n",
    "        set_cur = set(df_cur[\"casenumber\"])\n",
    "        set_prev = set(df_prev[\"casenumber\"])\n",
    "\n",
    "        # Persist these snapshots for later summaries\n",
    "        snapshots_cur[tag] = set_cur\n",
    "        snapshots_prev[tag] = set_prev\n",
    "\n",
    "        # Entrants are in current but not in previous; exits are the opposite\n",
    "        entered = set_cur - set_prev\n",
    "        exited = set_prev - set_cur\n",
    "\n",
    "        # Cache the entrant/exit sets for people-level yearly/monthly summaries\n",
    "        entered_sets[tag] = entered\n",
    "        exited_sets[tag] = exited\n",
    "\n",
    "        # Record high-level flow counts for this month\n",
    "        flow_records.append({\n",
    "            \"month\":                 tag,\n",
    "            \"active_count_current\":  len(set_cur),\n",
    "            \"active_count_previous\": len(set_prev),\n",
    "            \"entered\":               len(entered),\n",
    "            \"exited\":                len(exited)\n",
    "        })\n",
    "\n",
    "        # Build three DataFrames for age analysis:\n",
    "        #  - df_term: those who exited (from last year's snapshot)\n",
    "        #  - df_in:   those who entered (into this year's snapshot)\n",
    "        #  - df_base: the base population (last year's snapshot)\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited)].copy()\n",
    "        df_in   = df_cur[df_cur[\"casenumber\"].isin(entered)].copy()\n",
    "        df_base = df_prev.copy()\n",
    "\n",
    "        # Assign initial age groups with \"Unknown\" for missing/out-of-range\n",
    "        _assign_age_groups_inplace(df_term)\n",
    "        _assign_age_groups_inplace(df_in)\n",
    "        _assign_age_groups_inplace(df_base)\n",
    "\n",
    "        # Optionally impute Unknown ages by redistributing them into integer groups\n",
    "        if redistribute_unknown_age:\n",
    "            _impute_unknowns_inplace(df_term)   # Replace 'Unknown' with concrete age_group\n",
    "            _impute_unknowns_inplace(df_in)     # Replace 'Unknown' with concrete age_group\n",
    "            _impute_unknowns_inplace(df_base)   # Replace 'Unknown' with concrete age_group\n",
    "\n",
    "        # --- Diagnostics (can be converted to logging.debug if preferred)\n",
    "        # print(\"All records in base:\", len(df_base))\n",
    "        # print(\"Records with age_group assigned (incl. imputed):\", df_base['age_group'].notna().sum())\n",
    "\n",
    "        # --- Compute counts by integer age group (final_age_labels), filling missing with zeros\n",
    "        # People entered per age group (unique casenumbers)\n",
    "        in_counts = (\n",
    "            df_in.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                 .nunique()\n",
    "                 .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "        # People exited per age group (unique casenumbers)\n",
    "        term_counts = (\n",
    "            df_term.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                  .nunique()\n",
    "                  .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "        # Active people in base per age group (unique casenumbers)\n",
    "        base_counts = (\n",
    "            df_base.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                  .nunique()\n",
    "                  .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "\n",
    "        # Orders (row counts) by age group — useful if multiple rows per person exist\n",
    "        in_order_counts = (\n",
    "            df_in.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                 .count()\n",
    "                 .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "        term_order_counts = (\n",
    "            df_term.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                  .count()\n",
    "                  .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "        order_counts = (\n",
    "            df_base.groupby(\"age_group\", observed=False)[\"casenumber\"]\n",
    "                  .count()\n",
    "                  .reindex(final_age_labels, fill_value=0)\n",
    "        )\n",
    "\n",
    "        # --- Build age-rate rows for this month across all integer age groups\n",
    "        for grp in final_age_labels:\n",
    "            active      = int(base_counts[grp])                 # Active unique people in base\n",
    "            orders_age  = int(order_counts[grp])                # Active orders (rows) in base\n",
    "            clients_age = active                                # Alias kept for continuity\n",
    "            term        = int(term_counts[grp])                 # Exits (unique people)\n",
    "            ent         = int(in_counts[grp])                   # Entries (unique people)\n",
    "            rate        = round(term / active, 4) if active else 0.0  # Termination rate\n",
    "            retention   = 1 - rate if rate >= 0 else 1.0        # Retention (1 - termination)\n",
    "\n",
    "            # Append a fully specified record for this (month, age_group)\n",
    "            age_rate_records.append({\n",
    "                \"month\":              tag,\n",
    "                \"age_group\":          grp,\n",
    "                \"active_count\":       active,\n",
    "                \"active_orders_age\":  orders_age,\n",
    "                \"active_clients_age\": clients_age,\n",
    "                \"entered\":            ent,\n",
    "                \"terminations\":       term,\n",
    "                \"termination_rate\":   rate,\n",
    "                \"retention_rate\":     retention\n",
    "            })\n",
    "\n",
    "    # --- Convert accumulated lists to DataFrames for downstream use\n",
    "    flows_df = pd.DataFrame(flow_records)       # Month-level flows\n",
    "    ages_df  = pd.DataFrame(age_rate_records)   # Month x age-group metrics\n",
    "\n",
    "    # --- Persist the outputs for reproducibility/auditing\n",
    "    flows_df.to_csv(\n",
    "        os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "    ages_df.to_csv(\n",
    "        os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}.csv\"),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # --- Yearly people-level summary (unique people across months per year)\n",
    "    flows_df[\"year\"] = pd.to_datetime(flows_df[\"month\"], format=\"%Y-%m\").dt.year  # Extract calendar year\n",
    "    summary_records = []                                                           # Collector for yearly rows\n",
    "\n",
    "    # Iterate each year and union people across the year's months (entered/exited/active)\n",
    "    for year, grp in flows_df.groupby(\"year\"):\n",
    "        months_in_year = grp[\"month\"].tolist()                                     # Months in this year\n",
    "        entered_people = len(set().union(*(entered_sets[m] for m in months_in_year)))  # Unique entrants\n",
    "        exited_people  = len(set().union(*(exited_sets[m]  for m in months_in_year)))  # Unique exits\n",
    "        active_clients = len(set().union(*(snapshots_cur[m] for m in months_in_year))) # Unique active\n",
    "\n",
    "        # Append the yearly summary row\n",
    "        summary_records.append({\n",
    "            \"year\":           year,\n",
    "            \"entered_people\": entered_people,\n",
    "            \"exited_people\":  exited_people,\n",
    "            \"active_clients\": active_clients\n",
    "        })\n",
    "\n",
    "    # Materialize yearly summary table\n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "\n",
    "    # --- Console print for a quick glance (can swap to logging.info if preferred)\n",
    "    print(\"\\n=== Yearly Summary: Orders & Clients ===\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # --- Monthly people-level summary using the cached sets\n",
    "    monthly_records = []  # Collector for monthly rows\n",
    "\n",
    "    for _, row in flows_df.iterrows():\n",
    "        m = row[\"month\"]                                # Month tag\n",
    "        monthly_records.append({\n",
    "            \"month\":           m,\n",
    "            \"entered_people\":  len(entered_sets[m]),    # Unique entrants that month\n",
    "            \"exited_people\":   len(exited_sets[m]),     # Unique exits that month\n",
    "            \"active_clients\":  len(snapshots_cur[m])    # Unique active that month\n",
    "        })\n",
    "\n",
    "    # Materialise monthly summary table\n",
    "    monthly_summary_df = pd.DataFrame(monthly_records)\n",
    "\n",
    "    # Console print for a quick glance\n",
    "    print(\"\\n=== Monthly Summary: Orders & Clients ===\")\n",
    "    print(monthly_summary_df.to_string(index=False))\n",
    "\n",
    "    # --- Final log to indicate successful completion\n",
    "    logging.info(\"Completed calculation of year-on-year flows and age rates\")\n",
    "\n",
    "    # --- Return the four primary outputs: flows, age metrics, yearly and monthly people summaries\n",
    "    return flows_df, ages_df, summary_df, monthly_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_flow_forecast(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    “Stop‐flow” forecast:\n",
    "      active_t    = active_{t–1} + entered_{t–12} – terminated_{t–12}\n",
    "\n",
    "    Returns:\n",
    "      - per_age_df          : month, age_group, active_forecast,\n",
    "                              active_orders_age_fc, active_clients_age_fc\n",
    "      - monthly_summary_df  : month, total_active_orders, total_active_clients\n",
    "      - yearly_summary_df   : year, yearly_active_orders, yearly_active_clients\n",
    "      - base_df             : the input ages_df (for reference)\n",
    "    \"\"\"\n",
    "    # Make a copy of the input data so we don't change the original\n",
    "    df = ages_df.copy()\n",
    "\n",
    "    # Ensure 'month' is a column; if it's an index, reset it, otherwise error\n",
    "    if 'month' not in df.columns:\n",
    "        if 'month' in df.index.names:\n",
    "            df = df.reset_index()\n",
    "        else:\n",
    "            raise ValueError(\"Input ages_df must have a 'month' column or index level\")\n",
    "\n",
    "    # Convert 'month' column to date format, just to be sure\n",
    "    df['month'] = pd.to_datetime(df['month'])\n",
    "\n",
    "    # Find the last (most recent) month in the historical data\n",
    "    last_hist = df['month'].max()\n",
    "\n",
    "    # Make a list of months to forecast (e.g. next 12 months)\n",
    "    fc_months = [last_hist + relativedelta(months=i) for i in range(1, periods+1)]\n",
    "\n",
    "    # Get the data for the last historical month\n",
    "    base = df[df['month']==last_hist]\n",
    "    \n",
    "    \n",
    "    # Store the active counts for each age group from the last month as a starting point\n",
    "    prev_active      = base.set_index('age_group')['active_count'].to_dict()\n",
    "    prev_orders      = base.set_index('age_group')['active_orders_age'].to_dict()  # (Commented out)\n",
    "    prev_clients     = base.set_index('age_group')['active_clients_age'].to_dict()\n",
    "\n",
    "    records = []  # This will store forecast results for each month and age group\n",
    "\n",
    "    # For each month in the forecast period\n",
    "    for m in fc_months:\n",
    "        print(f\"month: {m}\")\n",
    "        # Load all active cases at the end of the current and previous year’s month\n",
    "        #df_cur  = fetch_cases_for_date(last_day_of_month(pd.to_datetime(m)))\n",
    "        #print(df_cur)\n",
    "        \n",
    "        # Find the matching month from 12 months ago (for stop-flow calculation)\n",
    "        lag = m - relativedelta(years=1)\n",
    "        # For each age group\n",
    "        for age in df['age_group'].unique():\n",
    "            #print(f\"age: {age}\")\n",
    "            # Get previous forecasted counts, or 0 if not found\n",
    "            a_prev     = prev_active.get(age, 0)\n",
    "            #print(f\"1.a_prev: {a_prev}\")\n",
    "            o_prev     = prev_orders .get(age, 0)   # (Commented out)\n",
    "            c_prev     = prev_clients.get(age, 0)\n",
    "            #print(f\"c_prev: {c_prev}\")\n",
    "            \n",
    "            # Find the data for this age group from 12 months ago (if it exists)\n",
    "            row        = df[(df['month']==lag)&(df['age_group']==age)]\n",
    "            # Get 'entered' and 'terminations' values; use 0 if missing\n",
    "            entered    = int(row['entered'     ].iloc[0]) if not row.empty else 0\n",
    "            #print(f\"entered: {entered}\")\n",
    "            \n",
    "            term       = int(row['terminations'].iloc[0]) if not row.empty else 0\n",
    "            #print(f\"term: {term}\")\n",
    "            \n",
    "            # Calculate new forecast: previous + entered - terminated (but not below zero)\n",
    "            a_fc = max(0, a_prev + entered - term)\n",
    "            #print(f\"a_fc: {a_fc}\")\n",
    "            o_fc = max(0, o_prev + entered - term)   # (Commented out)\n",
    "            c_fc = max(0, c_prev + entered - term)\n",
    "            #print(f\"c_fc: {c_fc}\")\n",
    "            \n",
    "            # Store the result for this month and age group\n",
    "            records.append({\n",
    "                'month':                 m,\n",
    "                'age_group':             age,\n",
    "                'active_forecast':       a_fc, \n",
    "                'active_orders_age_fc':  o_fc,    # (Commented out)\n",
    "                'active_clients_age_fc': c_fc\n",
    "            }) #active_clients_age_fc\n",
    "\n",
    "            # Update the previous values for the next month in the loop\n",
    "            prev_active[age]  = a_fc\n",
    "            prev_orders[age]  = o_fc   # (Commented out)\n",
    "            prev_clients[age] = c_fc\n",
    "\n",
    "    # Convert all forecast records into a DataFrame (table)\n",
    "    per_age_df = pd.DataFrame(records)\n",
    "\n",
    "    # Make a summary table for each forecast month (total across ages)\n",
    "    monthly = (\n",
    "        per_age_df\n",
    "        .groupby('month')\n",
    "        .agg(\n",
    "            total_active_orders=('active_orders_age_fc' , 'sum'),    # (Commented out)\n",
    "            total_active_clients=('active_clients_age_fc', 'sum')\n",
    "            #total_active=('active_forecast', 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    # print(\"\\n=== Monthly Stop‐Flow Summary ===\")\n",
    "    # print(monthly.to_string(index=False))\n",
    "\n",
    "    # Add a 'year' column for yearly summary\n",
    "    monthly['year'] = monthly['month'].dt.year\n",
    "\n",
    "    # Make a summary table for each year (totals across months)\n",
    "    yearly = (\n",
    "        monthly\n",
    "        .groupby('year')\n",
    "        .agg(\n",
    "            #yearly_active_orders = ('total_active_orders', 'sum'),   # (Commented out)\n",
    "            yearly_active_clients= ('total_active_clients','sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    # print(\"\\n=== Yearly Stop‐Flow Summary ===\")\n",
    "    # print(yearly.to_string(index=False))\n",
    "\n",
    "    # Return all results and the original input data\n",
    "    return per_age_df, monthly, yearly, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Virtualisation: Plotting age-specific active caseloads, termination rate, and new deputyships over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Visualisation & Insight Analysis (append below)\n",
    "# -----------------------------------------------\n",
    "def visualize_and_analyze_deputyship_forecasts(\n",
    "    combined_df: pd.DataFrame,\n",
    "    output_dir: str = \"output\",\n",
    "    hist_last_month: \"pd.Timestamp|str|None\" = None,\n",
    "    top_k: int = 8,\n",
    "    axis_start_month: \"pd.Timestamp|str|None\" = None,   # <-- add this\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Visualize historical + forecasted active caseloads (clients & orders) and produce key insights.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    combined_df : DataFrame with at least:\n",
    "        - 'month' (datetime or string)\n",
    "        - 'age' (string or int age group)\n",
    "        - 'active_caseloads_clients' (or fallbacks: 'active_clients_age', 'active_clients_age_fc', 'active_forecast')\n",
    "        - 'active_caseloads_orders'  (or fallbacks: 'active_orders_age',  'active_orders_age_fc',  'active_forecast')\n",
    "    output_dir : where to save PNGs and insights markdown.\n",
    "    hist_last_month : last historical month (for a vertical cutoff line). If None, no cutoff line is drawn.\n",
    "    top_k : how many age groups to highlight in stacked area and top-movers charts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A small dict of computed summary metrics for programmatic use.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    df = combined_df.copy()\n",
    "\n",
    "    # --- Ensure 'month' is datetime (handles '2025-07' and 'Jul-25' style strings)\n",
    "    if not np.issubdtype(df['month'].dtype, np.datetime64):\n",
    "        # try robust parsing; attempt two common formats\n",
    "        try:\n",
    "            df['month'] = pd.to_datetime(df['month'])\n",
    "        except Exception:\n",
    "            df['month'] = pd.to_datetime(df['month'], format=\"%b-%y\")\n",
    "\n",
    "    # --- Standardise column names via safe coalescing (guards against earlier rename differences)\n",
    "    def coalesce_col(frame, candidates, new_name):\n",
    "        for c in candidates:\n",
    "            if c in frame.columns:\n",
    "                frame.rename(columns={c: new_name}, inplace=True)\n",
    "                return new_name\n",
    "        # if none exist, create an empty numeric column\n",
    "        frame[new_name] = 0\n",
    "        return new_name\n",
    "\n",
    "    clients_col = coalesce_col(\n",
    "        df,\n",
    "        [\"active_caseloads_clients\", \"active_clients_age\", \"active_clients_age_fc\"],\n",
    "        \"active_caseloads_clients\"\n",
    "    )\n",
    "    orders_col = coalesce_col(\n",
    "        df,\n",
    "        [\"active_caseloads_orders\", \"active_orders_age\", \"active_orders_age_fc\"],\n",
    "        \"active_caseloads_orders\"\n",
    "    )\n",
    "\n",
    "    # --- NEW: parse / infer axis_start_month safely ---\n",
    "    if axis_start_month is not None and not isinstance(axis_start_month, pd.Timestamp):\n",
    "        axis_start_month = pd.to_datetime(axis_start_month)\n",
    "\n",
    "    if axis_start_month is None:\n",
    "        # Auto-start at first non-zero month to avoid leading zeros\n",
    "        totals_all = (\n",
    "            df.groupby('month')[[clients_col, orders_col]]\n",
    "              .sum(min_count=1)\n",
    "              .fillna(0)\n",
    "        )\n",
    "        nz = totals_all.sum(axis=1) > 0\n",
    "        axis_start_month = nz.index[nz.argmax()] if nz.any() else df['month'].min()\n",
    "\n",
    "    \n",
    "    # --- Tidy 'age' to string and keep a stable order\n",
    "    if 'age' not in df.columns:\n",
    "        # Fallback if upstream still calls the column 'age_group'\n",
    "        if 'age_group' in df.columns:\n",
    "            df.rename(columns={'age_group': 'age'}, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Expected an 'age' (or 'age_group') column in combined_df.\")\n",
    "    df['age'] = df['age'].astype(str)\n",
    "\n",
    "    # --- Sort for plotting\n",
    "    df = df.sort_values(['month', 'age']).reset_index(drop=True)\n",
    "\n",
    "    # --- Identify last historical month (line on charts) if provided as str\n",
    "    if hist_last_month is not None and not isinstance(hist_last_month, pd.Timestamp):\n",
    "        hist_last_month = pd.to_datetime(hist_last_month)\n",
    "\n",
    "    # # ========== 1) Total caseloads over time (line) ==========\n",
    "    # totals = (\n",
    "    #     df.groupby('month', as_index=False)\n",
    "    #       .agg(total_clients=(clients_col, 'sum'),\n",
    "    #            total_orders=(orders_col, 'sum'))\n",
    "    # )\n",
    "\n",
    "    # # Plot\n",
    "    # plt.figure(figsize=(11, 6))\n",
    "    # plt.plot(totals['month'], totals['total_clients'], label='Total active clients')\n",
    "    # if df[orders_col].sum() > 0:\n",
    "    #     plt.plot(totals['month'], totals['total_orders'], label='Total active orders')\n",
    "    # if hist_last_month is not None:\n",
    "    #     plt.axvline(hist_last_month, linestyle='--', linewidth=1, label='Last historical month')\n",
    "    # plt.title('Active caseloads over time: clients vs orders')\n",
    "    # plt.xlabel('Month'); plt.ylabel('Count'); plt.legend(); plt.tight_layout()\n",
    "    # path_total = os.path.join(output_dir, \"01_totals_clients_orders.png\")\n",
    "    # plt.savefig(path_total, dpi=180); plt.close()\n",
    "\n",
    "    # ========== 7) Total caseloads over time (line + 95% CIs) ==========\n",
    "    \n",
    "    totals = (\n",
    "        df.groupby('month', as_index=False)\n",
    "          .agg(total_clients=(clients_col, 'sum'),\n",
    "               total_orders=(orders_col, 'sum'))\n",
    "    )\n",
    "    \n",
    "    # Optional: start x-axis at axis_start_month if your function has that param\n",
    "    if 'axis_start_month' in locals() and axis_start_month is not None:\n",
    "        if not isinstance(axis_start_month, pd.Timestamp):\n",
    "            axis_start_month = pd.to_datetime(axis_start_month)\n",
    "        totals = totals[totals['month'] >= axis_start_month]\n",
    "    \n",
    "    # def _poisson_ci(series: pd.Series, z: float = 1.96):\n",
    "    #     \"\"\"95% CI for counts via Poisson approx: x ± z*sqrt(x), floored at 0.\"\"\"\n",
    "    #     x = series.to_numpy(dtype=float)\n",
    "    #     sd = np.sqrt(np.clip(x, 0, None))\n",
    "    #     lower = np.maximum(0, x - z * sd)\n",
    "    #     upper = x + z * sd\n",
    "    #     return lower, upper\n",
    "\n",
    "    def _poisson_ci(series: pd.Series, z: float = 1.96, phi: float = 1.0):\n",
    "        \"\"\"95% CI for counts via Poisson approx: x ± z*sqrt(x), floored at 0.\"\"\"\n",
    "        x = series.to_numpy(dtype=float)\n",
    "        sd = np.sqrt(phi * np.clip(x, 0, None))  # phi=1 → Poisson; phi>1 → over-dispersed\n",
    "        lower = np.maximum(0, x - z * sd)\n",
    "        upper = x + z * sd\n",
    "        return lower, upper\n",
    "\n",
    "    # Clients CI\n",
    "    c_lo, c_hi = _poisson_ci(totals['total_clients'])\n",
    "    \n",
    "    # Orders CI (only if any orders exist)\n",
    "    has_orders = (df[orders_col].sum() > 0)\n",
    "    if has_orders:\n",
    "        o_lo, o_hi = _poisson_ci(totals['total_orders'])\n",
    "    \n",
    "    plt.figure(figsize=(11, 6))\n",
    "    \n",
    "    # Plot CIs first so lines sit on top\n",
    "    plt.fill_between(totals['month'], c_lo, c_hi, alpha=0.2, label='95% CI (clients)', zorder=1)\n",
    "    if has_orders:\n",
    "        plt.fill_between(totals['month'], o_lo, o_hi, alpha=0.15, label='95% CI (orders)', zorder=1)\n",
    "    \n",
    "    # Now the lines\n",
    "    plt.plot(totals['month'], totals['total_clients'], label='Total active clients', zorder=2)\n",
    "    if has_orders:\n",
    "        plt.plot(totals['month'], totals['total_orders'], label='Total active orders', zorder=2)\n",
    "    \n",
    "    # Historical cutoff marker\n",
    "    if hist_last_month is not None:\n",
    "        plt.axvline(hist_last_month, linestyle='--', linewidth=1, label='Last historical month')\n",
    "    \n",
    "    plt.title('Active caseloads over time: clients vs orders (with 95% CIs)')\n",
    "    plt.xlabel('Month'); plt.ylabel('Count'); plt.legend(); plt.tight_layout()\n",
    "    \n",
    "    path_total = os.path.join(output_dir, \"01_totals_clients_orders.png\")\n",
    "    plt.savefig(path_total, dpi=180); plt.close()\n",
    "\n",
    "    # # ========== 2) Stacked area by age (clients, top_k) ==========\n",
    "    # # pick top_k age groups by average presence across period\n",
    "    # top_ages = (\n",
    "    #     df.groupby('age', as_index=False)[clients_col].mean()\n",
    "    #       .sort_values(clients_col, ascending=False)['age']\n",
    "    #       .head(top_k)\n",
    "    #       .tolist()\n",
    "    # )\n",
    "    # df_area = df.copy()\n",
    "    # df_area['age_area'] = np.where(df_area['age'].isin(top_ages), df_area['age'], 'Other')\n",
    "\n",
    "    # area_wide = (\n",
    "    #     df_area.groupby(['month', 'age_area'], as_index=False)[clients_col].sum()\n",
    "    #            .pivot(index='month', columns='age_area', values=clients_col)\n",
    "    #            .fillna(0)\n",
    "    # )\n",
    "\n",
    "    # plt.figure(figsize=(11, 6))\n",
    "    # # stack in deterministic order: top ages (descending by latest), then Other if present\n",
    "    # ordered_cols = [c for c in top_ages if c in area_wide.columns]\n",
    "    # if 'Other' in area_wide.columns:\n",
    "    #     ordered_cols = ordered_cols + ['Other']\n",
    "    # plt.stackplot(area_wide.index, area_wide[ordered_cols].T, labels=ordered_cols)\n",
    "    # if hist_last_month is not None:\n",
    "    #     plt.axvline(hist_last_month, linestyle='--', linewidth=1, label='Last historical month')\n",
    "    # plt.title(f'Active clients by age (stacked), top {top_k} groups')\n",
    "    # plt.xlabel('Month'); plt.ylabel('Active clients'); plt.legend(loc='upper left'); plt.tight_layout()\n",
    "    # path_area = os.path.join(output_dir, \"02_clients_stacked_area_by_age.png\")\n",
    "    # plt.savefig(path_area, dpi=180); plt.close()\n",
    "\n",
    "\n",
    "    # ===== 2) Stacked area by age (clients) — 5-year bands from 0, axis starts at start_month, CI band =====\n",
    "    # axis_start_month can be a string (e.g., \"2022-07\") or Timestamp; if None, keep all months\n",
    "    if axis_start_month is not None and not isinstance(axis_start_month, pd.Timestamp):\n",
    "        axis_start_month = pd.to_datetime(axis_start_month)\n",
    "    \n",
    "    # Filter from axis_start_month forward to avoid plotting pre-start zeros\n",
    "    df_band = df.copy()\n",
    "    if axis_start_month is not None:\n",
    "        df_band = df_band[df_band['month'] >= axis_start_month]\n",
    "    \n",
    "    # Parse ages to integers (robust to labels like \"70-74\" by taking the first number)\n",
    "    def _to_int_age(x):\n",
    "        s = str(x)\n",
    "        num = ''.join(ch for ch in s.split('-')[0] if ch.isdigit())\n",
    "        try:\n",
    "            return int(num)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    df_band['age_int'] = df_band['age'].apply(_to_int_age)\n",
    "    df_band = df_band[df_band['age_int'].notna()].copy()\n",
    "    df_band['age_int'] = df_band['age_int'].astype(int)\n",
    "    \n",
    "    # Map to 5-year bands (START AT 0), cap high ages so the final band is 105–109 (covers 105+)\n",
    "    def _band_label(a, width=5, cap=109):\n",
    "        a = max(0, min(int(a), cap))\n",
    "        lo = (a // width) * width\n",
    "        hi = lo + width - 1\n",
    "        return f\"{lo:02d}-{hi:02d}\"\n",
    "    \n",
    "    df_band['age_band'] = df_band['age_int'].apply(_band_label)\n",
    "    \n",
    "    # Build a COMPLETE ordered list of bands from 0 up to the cap (ensures we start at 00-04)\n",
    "    _width = 5\n",
    "    _cap   = 109\n",
    "    full_bands = [f\"{lo:02d}-{lo+_width-1:02d}\" for lo in range(0, _cap + 1, _width)]  # 00-04, 05-09, ..., 105-109\n",
    "    \n",
    "    # Wide table: month x 5-year band (sum clients per band and month), then reindex to include all bands from 0\n",
    "    area_wide = (\n",
    "        df_band.groupby(['month', 'age_band'], as_index=False)[clients_col].sum()\n",
    "               .pivot(index='month', columns='age_band', values=clients_col)\n",
    "               .reindex(columns=full_bands, fill_value=0)   # <-- force presence from 00-04 upward\n",
    "               .fillna(0)\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(11, 6))\n",
    "    # Plot in strict ascending band order from 00-04 upwards\n",
    "    plt.stackplot(area_wide.index, area_wide[full_bands].T, labels=full_bands)\n",
    "    \n",
    "    # Vertical line for last historical month if provided\n",
    "    if hist_last_month is not None:\n",
    "        plt.axvline(hist_last_month, linestyle='--', linewidth=1, label='Last historical month')\n",
    "    \n",
    "    # ---- Uncertainty band (95% Poisson CI) around the total clients series ----\n",
    "    totals_band = area_wide.sum(axis=1)\n",
    "    lower = np.maximum(0, totals_band - 1.96 * np.sqrt(np.clip(totals_band, a_min=0, a_max=None)))\n",
    "    upper = totals_band + 1.96 * np.sqrt(np.clip(totals_band, a_min=0, a_max=None))\n",
    "    plt.fill_between(area_wide.index, lower, upper, alpha=0.2, label='95% CI (total)')\n",
    "    \n",
    "    plt.title('Active clients by age (5-year bands from 0)')\n",
    "    plt.xlabel('Month'); plt.ylabel('Active clients')\n",
    "    plt.legend(loc='upper left', ncol=3)  # more columns so the legend fits many bands\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    path_area = os.path.join(output_dir, \"02_clients_stacked_area_5yr_bands_from0.png\")\n",
    "    plt.savefig(path_area, dpi=180); plt.close()\n",
    "\n",
    "\n",
    "    # ========== 3) Heatmap (clients) — 5-year age bands x month ==========\n",
    "\n",
    "    # 1) Parse 'age' to an integer (handles \"70\" or \"70-74\" by taking the left number)\n",
    "    def _to_int_age(x):\n",
    "        s = str(x)\n",
    "        left = s.split('-')[0]\n",
    "        num = ''.join(ch for ch in left if ch.isdigit())\n",
    "        try:\n",
    "            return int(num)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    df_heat = df.copy()\n",
    "    df_heat['age_int'] = df_heat['age'].apply(_to_int_age)\n",
    "    df_heat = df_heat[df_heat['age_int'].notna()].copy()\n",
    "    df_heat['age_int'] = df_heat['age_int'].astype(int)\n",
    "    \n",
    "    # 2) Map to 5-year bands (cap at 109 so final band is 105–109 catching 105+)\n",
    "    def _band_label(a, width=5, cap=109):\n",
    "        a = max(0, min(int(a), cap))\n",
    "        lo = (a // width) * width\n",
    "        hi = lo + width - 1\n",
    "        return f\"{lo:02d}-{hi:02d}\"\n",
    "    \n",
    "    df_heat['age_band'] = df_heat['age_int'].apply(_band_label)\n",
    "    \n",
    "    # 3) Build band x month matrix (sum of clients per band/month)\n",
    "    heat = (\n",
    "        df_heat.pivot_table(index='age_band', columns='month', values=clients_col, aggfunc='sum')\n",
    "               .fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 4) Sort age bands numerically by their lower bound\n",
    "    heat = heat.reindex(sorted(heat.index, key=lambda s: int(s.split('-')[0])))\n",
    "    \n",
    "    # 5) Plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.imshow(heat.values, aspect='auto', interpolation='nearest')\n",
    "    plt.colorbar(label='Active clients')\n",
    "    \n",
    "    # y-axis: band labels\n",
    "    plt.yticks(ticks=np.arange(len(heat.index)), labels=heat.index)\n",
    "    \n",
    "    # x-axis: month labels (downsample to ~12 ticks for readability)\n",
    "    x_idx = np.arange(len(heat.columns))\n",
    "    step = max(1, len(heat.columns)//12)\n",
    "    plt.xticks(\n",
    "        ticks=x_idx[::step],\n",
    "        labels=[m.strftime('%Y-%m') for m in heat.columns][::step],\n",
    "        rotation=45, ha='right'\n",
    "    )\n",
    "    \n",
    "    plt.title('Heatmap: Active clients by 5-year age band and month')\n",
    "    plt.tight_layout()\n",
    "    path_heat = os.path.join(output_dir, \"03_heatmap_clients_ageband_month.png\")\n",
    "    plt.savefig(path_heat, dpi=180); plt.close()\n",
    "\n",
    "\n",
    "    # ========== 4) Top movers across forecast horizon (delta by age) ==========\n",
    "    # Determine anchor months for delta\n",
    "    # If we have a historical cutoff, compare last hist vs last overall; else earliest vs latest.\n",
    "    if hist_last_month is not None and (df['month'] <= hist_last_month).any():\n",
    "        m0 = df.loc[df['month'] <= hist_last_month, 'month'].max()\n",
    "    else:\n",
    "        m0 = df['month'].min()\n",
    "    m1 = df['month'].max()\n",
    "\n",
    "    # snap0 = df[df['month'] == m0].groupby('age', as_index=False)[clients_col, orders_col].sum()\n",
    "    # snap1 = df[df['month'] == m1].groupby('age', as_index=False)[clients_col, orders_col].sum()\n",
    "\n",
    "    cols_for_delta = list(dict.fromkeys([clients_col, orders_col]))  # de-dup, keep order\n",
    "    snap0 = df[df['month'] == m0].groupby('age', as_index=False)[cols_for_delta].sum()\n",
    "    snap1 = df[df['month'] == m1].groupby('age', as_index=False)[cols_for_delta].sum()\n",
    "\n",
    "    delta = snap1.merge(snap0, on='age', suffixes=('_end', '_start'), how='outer').fillna(0)\n",
    "    delta['delta_clients'] = delta[f'{clients_col}_end'] - delta[f'{clients_col}_start']\n",
    "    delta['delta_orders']  = delta[f'{orders_col}_end']  - delta[f'{orders_col}_start']\n",
    "\n",
    "    # Top increases & decreases for clients\n",
    "    inc_clients = delta.sort_values('delta_clients', ascending=False).head(top_k)\n",
    "    dec_clients = delta.sort_values('delta_clients', ascending=True).head(top_k)\n",
    "\n",
    "    # Plot clients movers (bar)\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    plt.bar(inc_clients['age'], inc_clients['delta_clients'], label='Increases')\n",
    "    plt.bar(dec_clients['age'], dec_clients['delta_clients'], label='Decreases')\n",
    "    plt.title(f'Top movers by age (clients): {m0:%Y-%m} → {m1:%Y-%m}')\n",
    "    plt.xlabel('Age'); plt.ylabel('Δ Active clients'); plt.legend(); plt.tight_layout()\n",
    "    path_movers_clients = os.path.join(output_dir, \"04_top_movers_clients.png\")\n",
    "    plt.savefig(path_movers_clients, dpi=180); plt.close()\n",
    "\n",
    "    # If orders present, do the same\n",
    "    if df[orders_col].sum() > 0:\n",
    "        inc_orders = delta.sort_values('delta_orders', ascending=False).head(top_k)\n",
    "        dec_orders = delta.sort_values('delta_orders', ascending=True).head(top_k)\n",
    "\n",
    "        plt.figure(figsize=(11, 6))\n",
    "        plt.bar(inc_orders['age'], inc_orders['delta_orders'], label='Increases')\n",
    "        plt.bar(dec_orders['age'], dec_orders['delta_orders'], label='Decreases')\n",
    "        plt.title(f'Top movers by age (orders): {m0:%Y-%m} → {m1:%Y-%m}')\n",
    "        plt.xlabel('Age'); plt.ylabel('Δ Active orders'); plt.legend(); plt.tight_layout()\n",
    "        path_movers_orders = os.path.join(output_dir, \"05_top_movers_orders.png\")\n",
    "        plt.savefig(path_movers_orders, dpi=180); plt.close()\n",
    "    else:\n",
    "        path_movers_orders = None\n",
    "\n",
    "    # ========== 5) Ratios & peaks ==========\n",
    "    # Ratio: orders per 100 clients (where clients > 0)\n",
    "    totals['orders_per_100_clients'] = np.where(\n",
    "        totals['total_clients'] > 0,\n",
    "        totals['total_orders'] * 100.0 / totals['total_clients'],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(totals['month'], totals['orders_per_100_clients'])\n",
    "    if hist_last_month is not None:\n",
    "        plt.axvline(hist_last_month, linestyle='--', linewidth=1, label='Last historical month')\n",
    "    plt.title('Orders per 100 clients (level & trend)')\n",
    "    plt.xlabel('Month'); plt.ylabel('Orders per 100 clients') \n",
    "    if hist_last_month is not None: plt.legend()\n",
    "    plt.tight_layout()\n",
    "    path_ratio = os.path.join(output_dir, \"06_orders_per_100_clients.png\")\n",
    "    plt.savefig(path_ratio, dpi=180); plt.close()\n",
    "\n",
    "    # Peak months\n",
    "    peak_clients_idx = totals['total_clients'].idxmax()\n",
    "    peak_orders_idx  = totals['total_orders'].idxmax() if df[orders_col].sum() > 0 else None\n",
    "    peak_clients_month = totals.loc[peak_clients_idx, 'month']\n",
    "    peak_orders_month  = totals.loc[peak_orders_idx,  'month'] if peak_orders_idx is not None else None\n",
    "\n",
    "    # ========== 6) Insights (markdown) ==========\n",
    "    hist_total_clients = totals.loc[totals['month'] == m0, 'total_clients'].sum() if (totals['month'] == m0).any() else np.nan\n",
    "    end_total_clients  = totals.loc[totals['month'] == m1, 'total_clients'].sum()\n",
    "    hist_total_orders  = totals.loc[totals['month'] == m0, 'total_orders' ].sum() if (totals['month'] == m0).any() else np.nan\n",
    "    end_total_orders   = totals.loc[totals['month'] == m1, 'total_orders' ].sum()\n",
    "\n",
    "    abs_change_clients = end_total_clients - hist_total_clients if pd.notna(hist_total_clients) else np.nan\n",
    "    pct_change_clients = (abs_change_clients / hist_total_clients * 100.0) if pd.notna(hist_total_clients) and hist_total_clients else np.nan\n",
    "\n",
    "    abs_change_orders  = end_total_orders - hist_total_orders if pd.notna(hist_total_orders) else np.nan\n",
    "    pct_change_orders  = (abs_change_orders / hist_total_orders * 100.0) if pd.notna(hist_total_orders) and hist_total_orders else np.nan\n",
    "\n",
    "    # Contribution of top movers (clients)\n",
    "    movers_clients = delta[['age', 'delta_clients']].sort_values('delta_clients', ascending=False)\n",
    "    pos_sum = movers_clients[movers_clients['delta_clients'] > 0]['delta_clients'].sum()\n",
    "    top_contrib = movers_clients.head(top_k)['delta_clients'].sum()\n",
    "    share_topk = (top_contrib / pos_sum * 100.0) if pos_sum else np.nan\n",
    "\n",
    "    insights_lines = [\n",
    "        \"# Deputyship caseload forecast — key insights\",\n",
    "        f\"- **Horizon compared:** {m0:%Y-%m} → {m1:%Y-%m}\",\n",
    "        f\"- **Total clients:** {int(end_total_clients):,} at end; change = {int(abs_change_clients):,} ({pct_change_clients:0.1f}%)\" if pd.notna(pct_change_clients) else f\"- **Total clients (end):** {int(end_total_clients):,}\",\n",
    "        f\"- **Total orders:** {int(end_total_orders):,} at end; change = {int(abs_change_orders):,} ({pct_change_orders:0.1f}%)\" if pd.notna(pct_change_orders) else f\"- **Total orders (end):** {int(end_total_orders):,}\",\n",
    "        f\"- **Peak clients month:** {peak_clients_month:%Y-%m} (value: {int(totals.loc[peak_clients_idx,'total_clients']):,})\",\n",
    "    ]\n",
    "    if peak_orders_month is not None:\n",
    "        insights_lines.append(f\"- **Peak orders month:** {peak_orders_month:%Y-%m} (value: {int(totals.loc[peak_orders_idx,'total_orders']):,})\")\n",
    "    if pd.notna(share_topk):\n",
    "        insights_lines.append(f\"- **Top {top_k} age groups account for ~{share_topk:0.1f}% of the positive change in clients.**\")\n",
    "\n",
    "    # List the top 5 client growers & decliners\n",
    "    top_incr = movers_clients.head(5)\n",
    "    top_decl = movers_clients.tail(5).sort_values('delta_clients')\n",
    "    insights_lines.append(\"\\n**Top 5 age increases (clients):** \" + \", \".join(f\"{a} (+{int(d):,})\" for a, d in zip(top_incr['age'], top_incr['delta_clients'])))\n",
    "    insights_lines.append(\"**Top 5 age decreases (clients):** \" + \", \".join(f\"{a} ({int(d):,})\" for a, d in zip(top_decl['age'], top_decl['delta_clients'])))\n",
    "\n",
    "    # Write markdown\n",
    "    insights_path = os.path.join(output_dir, \"00_forecast_insights.md\")\n",
    "    with open(insights_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(insights_lines))\n",
    "\n",
    "    # Console echo for quick read\n",
    "    print(\"\\n\".join(insights_lines))\n",
    "    print(f\"\\nSaved charts:\\n- {path_total}\\n- {path_area}\\n- {path_heat}\\n- {path_movers_clients}\\n\"\n",
    "          f\"{'- ' + path_movers_orders if path_movers_orders else ''}\\n- {path_ratio}\\nInsights → {insights_path}\")\n",
    "\n",
    "    # Return a small metrics dict if you want to log/store programmatically\n",
    "    return {\n",
    "        \"horizon_start\": m0,\n",
    "        \"horizon_end\": m1,\n",
    "        \"end_total_clients\": int(end_total_clients),\n",
    "        \"end_total_orders\":  int(end_total_orders),\n",
    "        \"abs_change_clients\": int(abs_change_clients) if pd.notna(abs_change_clients) else None,\n",
    "        \"pct_change_clients\": float(pct_change_clients) if pd.notna(pct_change_clients) else None,\n",
    "        \"abs_change_orders\":  int(abs_change_orders) if pd.notna(abs_change_orders) else None,\n",
    "        \"pct_change_orders\":  float(pct_change_orders) if pd.notna(pct_change_orders) else None,\n",
    "        \"peak_clients_month\": peak_clients_month,\n",
    "        \"peak_orders_month\":  peak_orders_month\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Running the Deputyship forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Deputyship forecasting model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2022\n",
    "    end_year = 2025\n",
    "    start_month = \"2022-11\"\n",
    "    end_month = \"2025-11\"\n",
    "    output_base=\"output\"\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    # **Clear the output directory, not the Excel filepath**\n",
    "    clear_directory(output_base)\n",
    "    \n",
    "    combined_df, summary_df = export_monthly_reports(start_month, end_month)\n",
    "    summary_df\n",
    "    print(combined_df)\n",
    "    \n",
    "    active_df, monthly_df, yearly_summary = calculate_monthly_active_cases(combined_df, start_month, end_month, output_base=\"output\")\n",
    "    yearly_summary\n",
    "    print(monthly_df)\n",
    "    print(active_df)\n",
    "    \n",
    "\n",
    "    # Calculate historical flows and age rates\n",
    "    final_df, ages_df, summary_df, monthly_summary_df = calculate_yearonyear_flows_and_age_rates(\n",
    "         start_month, end_month,\n",
    "         redistribute_unknown_age=True)\n",
    "    \n",
    "    print(summary_df)\n",
    "    print(monthly_summary_df)\n",
    "    print(ages_df)\n",
    "    print(final_df)\n",
    "\n",
    "    # Compute 2-year stop-flow forecast\n",
    "    per_age_df, monthly, yearly, df = stop_flow_forecast(ages_df, periods=12)    \n",
    "    \n",
    "    print(per_age_df)\n",
    "    print(monthly)\n",
    "    print(yearly)\n",
    "    print(df)\n",
    "\n",
    "    # Combine the historical data and forecasts\n",
    "    current_age_specific_deputyship_agg = ages_df.copy()\n",
    "    current_age_specific_deputyship_agg = current_age_specific_deputyship_agg.rename(\n",
    "        columns={\n",
    "            'age_group': 'age',\n",
    "            #'active_count': 'active_caseloads',\n",
    "            'entered': 'new_deputyships',\n",
    "            'terminations': 'terminated',\n",
    "            'active_clients_age': 'active_caseloads_clients',\n",
    "            'active_orders_age':  'active_caseloads_orders'\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    forecasted_age_specific_deputyship_agg = per_age_df.copy()\n",
    "    forecasted_age_specific_deputyship_agg = forecasted_age_specific_deputyship_agg.rename(\n",
    "        columns={\n",
    "            'age_group': 'age',\n",
    "            #'active_forecast': 'active_caseloads',\n",
    "            'active_clients_age_fc': 'active_caseloads_clients',\n",
    "            'active_orders_age_fc': 'active_caseloads_orders'\n",
    "        }\n",
    "    )\n",
    "    #forecasted_age_specific_deputyship_agg['month'] = pd.to_datetime(forecasted_age_specific_deputyship_agg['month'], format='%Y-%m')\n",
    "    #current_age_specific_deputyship_agg['month'] = pd.to_datetime(forecasted_age_specific_deputyship_agg['month'], format='%Y-%m')\n",
    "    # Final tforcast and actuals\n",
    "    combined_table = get_combined_age_deputyship_table(current_age_specific_deputyship_agg, forecasted_age_specific_deputyship_agg)\n",
    "    # Ensure 'month' is datetime\n",
    "    #combined_table['month'] = pd.to_datetime(combined_table['month'], format='%Y-%m')\n",
    "    final_deputyship_historical_forecasts = combined_table[['month', 'age', 'active_caseloads_clients', 'active_caseloads_orders', 'new_deputyships', 'terminated']]\n",
    "    final_deputyship_historical_forecasts['month'] = pd.to_datetime(final_deputyship_historical_forecasts['month']).dt.strftime(\"%b-%y\")\n",
    "    \n",
    "    # Save in CSV\n",
    "    final_deputyship_historical_forecasts.to_csv(f\"output/final_deputyship_historical_forecasts_{start_year}_{end_year}.csv\")\n",
    "    print(final_deputyship_historical_forecasts)\n",
    "\n",
    "\n",
    "    # Use end_month as the last historical month to draw a vertical line on charts\n",
    "    _ = visualize_and_analyze_deputyship_forecasts(\n",
    "        final_deputyship_historical_forecasts,\n",
    "        output_dir=output_base,\n",
    "        hist_last_month=pd.to_datetime(end_month),\n",
    "        axis_start_month=start_month,   # <-- important\n",
    "        top_k=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtualisation: Plotting age-specific active caseloads, termination rate, and new deputyships over time\n",
    "\n",
    "# Active Caseloads by Age Group\n",
    "active_pivot = combined_table.pivot(index='month', columns='age', values='active_caseloads')\n",
    "    \n",
    "# Pivot for plotting: month on x‐axis, each age a line\n",
    "pivot = per_age_df.pivot(index='month', columns='age_group', values='active_forecast')\n",
    "pivot.index = pd.to_datetime(pivot.index)\n",
    "    \n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for age, series in pivot.items():\n",
    "    ax.plot(\n",
    "        series.index, series.values,\n",
    "        label=f\"{int(age)} yrs\",\n",
    "        marker='o',\n",
    "        linewidth=2,\n",
    "        alpha=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forecasting Active Caseloads:\n",
    "# def stop_flow_forecast(ages_df: pd.DataFrame, periods: int = 12) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     “Stop‐flow” forecast:\n",
    "#       active_t  = active_{t–1} + entered_{t–12} – terminated_{t–12}\n",
    "#     for each age_group, recursively, starting from the last historical month.\n",
    "    \n",
    "#     Returns a DataFrame with columns:\n",
    "#       month (datetime), age_group, active_forecast (int)\n",
    "#     \"\"\"\n",
    "#     # 1) Copy and ensure month is a column\n",
    "#     df = ages_df.copy()\n",
    "#     if 'month' not in df.columns:\n",
    "#         # If month is in the index, pull it out\n",
    "#         if 'month' in df.index.names:\n",
    "#             df = df.reset_index()\n",
    "#         else:\n",
    "#             raise ValueError(\"Input ages_df must have a 'month' column or index level\")\n",
    "    \n",
    "#     # 2) Convert month to datetime flexibly\n",
    "#     df['month'] = pd.to_datetime(df['month'])\n",
    "    \n",
    "#     # 3) Find the last historical month\n",
    "#     last_hist = df['month'].max()\n",
    "#     #print(f\"last_hist: {last_hist}\")\n",
    "    \n",
    "#     # 4) Build the list of future months (1..periods ahead)\n",
    "#     first_fc = last_hist + relativedelta(months=1)\n",
    "#     #print(f\"first_fc: {first_fc}\")\n",
    "    \n",
    "#     fc_months = [first_fc + relativedelta(months=i) for i in range(periods)]\n",
    "#     #print(f\"fc_months: {fc_months}\")\n",
    "    \n",
    "#     # 5) Seed the \"previous active\" from last historical month\n",
    "#     prev_active = (\n",
    "#         df[df['month'] == last_hist]\n",
    "#         .set_index('age_group')['active_count']\n",
    "#         .to_dict()\n",
    "#     )\n",
    "#     #print(f\"prev_active: {prev_active}\")\n",
    "#     records = []\n",
    "#     age_groups = df['age_group'].unique()\n",
    "    \n",
    "#     for m in fc_months:\n",
    "#         lag = m - relativedelta(years=1)\n",
    "#         #print(f\"lag: {lag}\")\n",
    "        \n",
    "#         for age in age_groups:\n",
    "#             a_prev = prev_active.get(age, 0)\n",
    "#             #print(f\"a_prev: {a_prev}\")\n",
    "            \n",
    "#             # grab last year's entered/terminated for this age & lag month\n",
    "#             row = df[(df['month'] == lag) & (df['age_group'] == age)]\n",
    "#             #print(f\"row: {row}\")\n",
    "            \n",
    "#             entered = int(row['entered'].iloc[0]) if not row.empty else 0\n",
    "#             #print(f\"entered: {entered}\")\n",
    "            \n",
    "#             term    = int(row['terminations'].iloc[0]) if not row.empty else 0\n",
    "#             #print(f\"term: {term}\")\n",
    "            \n",
    "            \n",
    "#             # stop‐flow formula\n",
    "#             a_fc = a_prev + entered - term if (a_prev + entered) > term else 0\n",
    "#             #print(f\"a_fc = {a_prev} + {entered} - {term}: {a_prev + entered - term}\")\n",
    "            \n",
    "#             #print(f\"a_fc,: {a_fc}\")\n",
    "            \n",
    "#             records.append({\n",
    "#                 'month':           m,\n",
    "#                 'age_group':       age,\n",
    "#                 'active_forecast': a_fc\n",
    "#             })\n",
    "#             prev_active[age] = a_fc  # update for next iteration\n",
    "#             #print(f\"age: {age}\")\n",
    "#             #print(f\"prev_active[age]: {a_fc}\")\n",
    "            \n",
    "#     return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_yearonyear_flows_and_age_rates(\n",
    "#     first_month: str,\n",
    "#     last_month: str,\n",
    "#     output_base: str = \"output\",\n",
    "#     redistribute_unknown_age: bool = False,\n",
    "#     age_bins: tuple = None,\n",
    "#     age_labels: tuple = None\n",
    "# ) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "#     # Log a message about the operation being performed, with some parameters\n",
    "#     logging.info(f\"Calculating year-on-year flows and age rates from {first_month} to {last_month}, redistribute_unknown_age={redistribute_unknown_age}\")\n",
    "\n",
    "#     # Make the output directory if it doesn't exist\n",
    "#     os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "#     # If age bins or labels aren't given, make defaults: 0-106 years, each as a group\n",
    "#     if age_bins is None or age_labels is None:\n",
    "#         age_bins   = list(range(0, 107))\n",
    "#         age_labels = [str(a) for a in age_bins[:-1]]\n",
    "\n",
    "#     # Prepare lists and dicts to store our results as we process each month\n",
    "#     flow_records = []        # To store overall monthly entry/exit counts\n",
    "#     age_rate_records = []    # To store age-specific rates and counts per month\n",
    "#     snapshots_cur = {}       # Dict to store sets of active cases for each month\n",
    "#     snapshots_prev = {}      # Dict to store sets of active cases a year earlier\n",
    "#     entered_sets   = {}      # Dict to store who entered in each month\n",
    "#     exited_sets    = {}      # Dict to store who exited in each month\n",
    "\n",
    "#     # For every month between first and last month\n",
    "#     for dt in generate_month_list(first_month, last_month):\n",
    "#         # Find the month one year earlier\n",
    "#         prev_dt = dt - relativedelta(years=1)\n",
    "#         # If previous year’s month is before the first month, skip\n",
    "#         if prev_dt < parse_month(first_month):\n",
    "#             continue\n",
    "\n",
    "#         # Create a string tag for this month (e.g., '2023-05')\n",
    "#         tag = dt.strftime(\"%Y-%m\")\n",
    "#         logging.info(f\"Processing month {tag}\")\n",
    "\n",
    "#         # Load all active cases at the end of the current and previous year’s month\n",
    "#         df_cur  = fetch_cases_for_date(last_day_of_month(dt))\n",
    "#         df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "#         # Get sets of case numbers for current and previous months\n",
    "#         set_cur  = set(df_cur[\"casenumber\"])\n",
    "#         set_prev = set(df_prev[\"casenumber\"])\n",
    "\n",
    "#         # Save these sets for later reference\n",
    "#         snapshots_cur[tag]  = set_cur\n",
    "#         snapshots_prev[tag] = set_prev\n",
    "\n",
    "#         # Determine who entered: present this year, not last year\n",
    "#         entered = set_cur  - set_prev\n",
    "#         # Determine who exited: present last year, not this year\n",
    "#         exited  = set_prev - set_cur\n",
    "\n",
    "#         # Store entered/exited sets for summary stats later\n",
    "#         entered_sets[tag] = entered\n",
    "#         exited_sets[tag]  = exited\n",
    "\n",
    "#         # Save summary counts for this month\n",
    "#         flow_records.append({\n",
    "#             \"month\":                 tag,\n",
    "#             \"active_count_current\":  len(set_cur),\n",
    "#             \"active_count_previous\": len(set_prev),\n",
    "#             \"entered\":               len(entered),\n",
    "#             \"exited\":                len(exited)\n",
    "#         })\n",
    "\n",
    "#         # DataFrames for people who exited, entered, and the whole base for age analysis\n",
    "#         df_term = df_prev[df_prev[\"casenumber\"].isin(exited)].copy()\n",
    "#         df_in   = df_cur [df_cur [\"casenumber\"].isin(entered)].copy()\n",
    "#         df_base = df_prev.copy()\n",
    "\n",
    "#         # add an “Unknown” group if it isn’t already in your age labels:\n",
    "#         if age_bins is None or age_labels is None:\n",
    "#             age_bins   = list(range(0, 107))\n",
    "#             age_labels = [str(a) for a in age_bins[:-1]]\n",
    "#         # Add \"Unknown\" group\n",
    "#         if \"Unknown\" not in age_labels:\n",
    "#             age_labels = list(age_labels) + [\"Unknown\"]\n",
    "            \n",
    "#         # Assign an age group (e.g. '70', '71',...) to each person in each DataFrame\n",
    "#         for df_ in (df_term, df_in, df_base):\n",
    "#             df_[\"age_group\"] = pd.cut(\n",
    "#                 df_[\"age_in_years\"],\n",
    "#                 bins=age_bins,\n",
    "#                 labels=age_labels[:-1],  # exclude Unknown for pd.cut, will assign after\n",
    "#                 right=False,\n",
    "#                 include_lowest=True\n",
    "#             )\n",
    "#             df_[\"age_group\"] = df_[\"age_group\"].astype(object).where(\n",
    "#                 df_[\"age_group\"].notna(), \"Unknown\"\n",
    "#             )\n",
    "\n",
    "\n",
    "#         # Count total rows vs. those with valid age_group\n",
    "#         print(\"All records in base:\", len(df_base))\n",
    "#         print(\"Records with age_group assigned:\", df_base['age_group'].notna().sum())\n",
    "\n",
    "#         # Count number of people entered per age group\n",
    "#         in_counts   = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"]\\\n",
    "#                              .nunique().reindex(age_labels, fill_value=0)        # Count number of people exited per age group\n",
    "#         term_counts = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"]\\\n",
    "#                              .nunique().reindex(age_labels, fill_value=0)        # Count number of people in base per age group\n",
    "#         base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"]\\\n",
    "#                              .nunique().reindex(age_labels, fill_value=0)\n",
    "#         # #base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"]\\\n",
    "                             \n",
    "#         # # Count number of orders in base per age group (same as above unless multiple orders per client)\n",
    "#         # order_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"]\\\n",
    "#         #                       .count().reindex(age_labels, fill_value=0)\n",
    "\n",
    "#         # 1. Count number of people entered per age group\n",
    "#         in_order_counts   = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"].count().reindex(age_labels, fill_value=0)\n",
    "#         # 2. Count number of people exited per age group\n",
    "#         term_order_counts = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"].count().reindex(age_labels, fill_value=0)\n",
    "#         # 3. Count number of people in base per age group\n",
    "#         # base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].count().reindex(age_labels, fill_value=0)\n",
    "#         # 4. Orders (usually same as base unless orders/client > 1)\n",
    "#         order_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].count().reindex(age_labels, fill_value=0)\n",
    "    \n",
    "#         if redistribute_unknown_age:\n",
    "#             # --- Redistribute unknown \"entered\" ---\n",
    "#             unknown_in = df_in[\"age_group\"].isna().sum()\n",
    "#             if unknown_in > 0:\n",
    "#                 total_known_in = in_counts.loc[age_labels[:-1]].sum()  # exclude Unknown group itself\n",
    "#                 props_in = in_counts.loc[age_labels[:-1]] / total_known_in if total_known_in > 0 else pd.Series(1/len(age_labels[:-1]), index=age_labels[:-1])\n",
    "#                 alloc_in = (props_in * unknown_in).round().astype(int)\n",
    "#                 in_counts.loc[age_labels[:-1]] += alloc_in\n",
    "#                 in_counts.loc[\"Unknown\"] = 0  # Set to zero after redistribution\n",
    "    \n",
    "#             # --- Redistribute unknown \"terminations\" ---\n",
    "#             unknown_term = df_term[\"age_group\"].isna().sum()\n",
    "#             if unknown_term > 0:\n",
    "#                 total_known_term = term_counts.loc[age_labels[:-1]].sum()\n",
    "#                 props_term = term_counts.loc[age_labels[:-1]] / total_known_term if total_known_term > 0 else pd.Series(1/len(age_labels[:-1]), index=age_labels[:-1])\n",
    "#                 alloc_term = (props_term * unknown_term).round().astype(int)\n",
    "#                 term_counts.loc[age_labels[:-1]] += alloc_term\n",
    "#                 term_counts.loc[\"Unknown\"] = 0\n",
    "        \n",
    "#             # --- Redistribute unknown \"base\" (active) ---\n",
    "#             unknown_base = df_base[\"age_group\"].isna().sum()\n",
    "#             if unknown_base > 0:\n",
    "#                 total_known_base = base_counts.loc[age_labels[:-1]].sum()\n",
    "#                 props_base = base_counts.loc[age_labels[:-1]] / total_known_base if total_known_base > 0 else pd.Series(1/len(age_labels[:-1]), index=age_labels[:-1])\n",
    "#                 alloc_base = (props_base * unknown_base).round().astype(int)\n",
    "#                 base_counts.loc[age_labels[:-1]] += alloc_base\n",
    "#                 base_counts.loc[\"Unknown\"] = 0\n",
    "        \n",
    "#             # --- (Optional) Orders, if you want similar logic applied ---\n",
    "#             unknown_orders = df_base[\"age_group\"].isna().sum()\n",
    "#             if unknown_orders > 0:\n",
    "#                 total_known_orders = order_counts.loc[age_labels[:-1]].sum()\n",
    "#                 props_orders = order_counts.loc[age_labels[:-1]] / total_known_orders if total_known_orders > 0 else pd.Series(1/len(age_labels[:-1]), index=age_labels[:-1])\n",
    "#                 alloc_orders = (props_orders * unknown_orders).round().astype(int)\n",
    "#                 order_counts.loc[age_labels[:-1]] += alloc_orders\n",
    "#                 order_counts.loc[\"Unknown\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "#         # # Find out how many entrants have unknown age\n",
    "#         # unknown = df_in[\"age_group\"].isna().sum()\n",
    "#         # # If redistribution is on, and there are unknowns, share them proportionally across age groups\n",
    "#         # if redistribute_unknown_age and unknown > 0:\n",
    "#         #     total_known = in_counts.sum()\n",
    "#         #     # Compute the proportion for each age group\n",
    "#         #     props = in_counts / total_known if total_known>0 else pd.Series(1/len(age_labels), \n",
    "#         #                                                                     index=age_labels)\n",
    "#         #     # Allocate the unknowns proportionally\n",
    "#         #     alloc = (props * unknown).round().astype(int)\n",
    "#         #     # Add allocated unknowns to each age group count\n",
    "#         #     in_counts += alloc\n",
    "\n",
    "\n",
    "\n",
    "#         # For each age group, calculate stats and append them to the age_rate_records\n",
    "#         for grp in age_labels:\n",
    "#             active       = int(base_counts[grp])\n",
    "#             orders_age   = int(order_counts[grp])\n",
    "#             clients_age  = active\n",
    "#             term         = int(term_counts[grp])\n",
    "#             ent          = int(in_counts[grp])\n",
    "#             rate         = round(term/active,4) if active else 0.0      # Avoid division by zero\n",
    "#             retention    = 1 - rate if rate>=0 else 1.0\n",
    "\n",
    "#             age_rate_records.append({\n",
    "#                 \"month\":              tag,\n",
    "#                 \"age_group\":          grp,\n",
    "#                 \"active_count\":       active,\n",
    "#                 \"active_orders_age\":  orders_age,\n",
    "#                 \"active_clients_age\": clients_age,\n",
    "#                 \"entered\":            ent,\n",
    "#                 \"terminations\":       term,\n",
    "#                 \"termination_rate\":   rate,\n",
    "#                 \"retention_rate\":     retention\n",
    "#             })\n",
    "\n",
    "#     # Convert flow and age stats into DataFrames (tables)\n",
    "#     flows_df = pd.DataFrame(flow_records)\n",
    "#     ages_df  = pd.DataFrame(age_rate_records)\n",
    "\n",
    "#     # Save the DataFrames as CSV files for later use\n",
    "#     flows_df.to_csv(\n",
    "#         os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}.csv\"),\n",
    "#         index=False\n",
    "#     )\n",
    "#     ages_df.to_csv(\n",
    "#         os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}.csv\"),\n",
    "#         index=False\n",
    "#     )\n",
    "\n",
    "#     # --- Yearly summary ---\n",
    "#     # Add a 'year' column for grouping\n",
    "#     flows_df[\"year\"] = pd.to_datetime(flows_df[\"month\"], format=\"%Y-%m\").dt.year\n",
    "#     summary_records = []\n",
    "#     # For each year, summarize all the flows and unique people across months\n",
    "#     for year, grp in flows_df.groupby(\"year\"):\n",
    "#         months_in_year  = grp[\"month\"].tolist()\n",
    "#         entered_orders  = grp[\"entered\"].sum()\n",
    "#         exited_orders   = grp[\"exited\"].sum()\n",
    "#         active_orders   = grp[\"active_count_current\"].sum()\n",
    "#         entered_people  = len(set().union(*(entered_sets[m] for m in months_in_year)))\n",
    "#         exited_people   = len(set().union(*(exited_sets[m]  for m in months_in_year)))\n",
    "#         active_clients  = len(set().union(*(snapshots_cur[m]   for m in months_in_year)))\n",
    "\n",
    "#         summary_records.append({\n",
    "#             \"year\":           year,\n",
    "#             #\"entered_orders\": entered_orders,     # (Commented out)\n",
    "#             \"entered_people\": entered_people,\n",
    "#             #\"exited_orders\":  exited_orders,      # (Commented out)\n",
    "#             \"exited_people\":  exited_people,\n",
    "#             #\"active_orders\":  active_orders,      # (Commented out)\n",
    "#             \"active_clients\": active_clients\n",
    "#         })\n",
    "\n",
    "#     summary_df = pd.DataFrame(summary_records)\n",
    "#     print(\"\\n=== Yearly Summary: Orders & Clients ===\")\n",
    "#     print(summary_df.to_string(index=False))\n",
    "\n",
    "#     # --- Monthly summary ---\n",
    "#     monthly_records = []\n",
    "#     for idx, row in flows_df.iterrows():\n",
    "#         m = row[\"month\"]\n",
    "#         monthly_records.append({\n",
    "#             \"month\":           m,\n",
    "#             #\"entered_orders\":  row[\"entered\"],   # (Commented out)\n",
    "#             \"entered_people\":  len(entered_sets[m]),\n",
    "#             #\"exited_orders\":   row[\"exited\"],    # (Commented out)\n",
    "#             \"exited_people\":   len(exited_sets[m]),\n",
    "#             #\"active_orders\":   row[\"active_count_current\"],    # (Commented out)\n",
    "#             \"active_clients\":  len(snapshots_cur[m])\n",
    "#         })\n",
    "\n",
    "#     monthly_summary_df = pd.DataFrame(monthly_records)\n",
    "#     print(\"\\n=== Monthly Summary: Orders & Clients ===\")\n",
    "#     print(monthly_summary_df.to_string(index=False))\n",
    " \n",
    "#     logging.info(\"Completed calculation of year-on-year flows and age rates\")\n",
    "\n",
    "#     # Return all four tables: flows, ages, yearly and monthly summaries\n",
    "#     return flows_df, ages_df, summary_df, monthly_summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start_year = 2022\n",
    "#     end_year = 2025\n",
    "#     start_month = \"2022-06\"\n",
    "#     end_month = \"2025-06\"\n",
    "\n",
    "#     # Calculate historical flows and age rates\n",
    "#     final_df, ages_df, summary_df, monthly_summary_df = calculate_yearonyear_flows_and_age_rates(\n",
    "#          start_month, end_month,\n",
    "#          redistribute_unknown_age=True\n",
    "#      )\n",
    "\n",
    "\n",
    "#     # Compute 2-year stop-flow forecast\n",
    "#     sf_fc = stop_flow_forecast(ages_df, periods=12)\n",
    "    \n",
    "#     # # Pivot for plotting: month on x‐axis, each age a line\n",
    "#     # pivot = sf_fc.pivot(index='month', columns='age_group', values='active_forecast')\n",
    "#     # pivot.index = pd.to_datetime(pivot.index)\n",
    "    \n",
    "#     # Plot\n",
    "#     # fig, ax = plt.subplots(figsize=(10, 6))\n",
    "#     # for age, series in pivot.items():\n",
    "#     #     ax.plot(\n",
    "#     #         series.index, series.values,\n",
    "#     #         label=f\"{int(age)} yrs\",\n",
    "#     #         marker='o',\n",
    "#     #         linewidth=2,\n",
    "#     #         alpha=0.8\n",
    "#     #     )\n",
    "    \n",
    "#     current_age_specific_deputyship_agg = ages_df.copy()\n",
    "#     current_age_specific_deputyship_agg = current_age_specific_deputyship_agg.rename(\n",
    "#         columns={\n",
    "#             'age_group': 'age',\n",
    "#             'active_count': 'active_caseloads',\n",
    "#             'entered': 'new_deputyships',\n",
    "#             'terminations': 'terminated'\n",
    "#         }\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     forecasted_age_specific_deputyship_agg = sf_fc.copy()\n",
    "#     forecasted_age_specific_deputyship_agg = forecasted_age_specific_deputyship_agg.rename(\n",
    "#         columns={\n",
    "#             'age_group': 'age',\n",
    "#             'active_forecast': 'active_caseloads'\n",
    "#         }\n",
    "#     )\n",
    "#     #forecasted_age_specific_deputyship_agg['month'] = pd.to_datetime(forecasted_age_specific_deputyship_agg['month'], format='%Y-%m')\n",
    "#     #current_age_specific_deputyship_agg['month'] = pd.to_datetime(forecasted_age_specific_deputyship_agg['month'], format='%Y-%m')\n",
    "#     # Final tforcast and actuals\n",
    "#     combined_table = get_combined_age_deputyship_table(current_age_specific_deputyship_agg, forecasted_age_specific_deputyship_agg)\n",
    "#     # Ensure 'month' is datetime\n",
    "#     #combined_table['month'] = pd.to_datetime(combined_table['month'], format='%Y-%m')\n",
    "#     final_deputyship_historical_forecasts = combined_table\n",
    "#     final_deputyship_historical_forecasts['month'] = pd.to_datetime(final_deputyship_historical_forecasts['month']).dt.strftime(\"%b-%y\")\n",
    "    \n",
    "#     # Save in CSV\n",
    "#     final_deputyship_historical_forecasts.to_csv(f\"output/final_deputyship_historical_forecasts_{start_year}_{end_year}.csv\")\n",
    "#     # Plotting age-specific active caseloads, termination rate, and new deputyships over time\n",
    "    \n",
    "\n",
    "    \n",
    "#     # # Active Caseloads by Age Group\n",
    "#     # active_pivot = combined_table.pivot(index='month', columns='age', values='active_caseloads')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
