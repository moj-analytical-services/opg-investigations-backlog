{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pydbtools\n",
    "!pip install --force numpy==1.24\n",
    "\n",
    "import os\n",
    "import calendar\n",
    "import shutil\n",
    "from datetime import datetime,timedelta\n",
    "import pydbtools\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import botocore\n",
    "import s3fs\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# suppress that specific pandas RuntimeWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=RuntimeWarning,\n",
    "    message=\".*invalid value encountered in cast.*\"\n",
    ")\n",
    "\n",
    "# Ensure pydbtools is available\n",
    "try:\n",
    "    import pydbtools\n",
    "except ImportError:\n",
    "    raise ImportError(\"The 'pydbtools' package is required. Install it with: pip install pydbtools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clear_directory(path):\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove file or symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directory and its contents\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all cases & their fee reductions for the given run_date (YYYY-MM-DD)\n",
    "    using pydbtools.read_sql_query, which returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH active_fee_reductions AS (\n",
    "      SELECT\n",
    "        fc.client_id,\n",
    "        SUBSTRING(fr.type,1,1) || LOWER(SUBSTRING(fr.type,2)) AS type,\n",
    "        DATE(fr.startdate) AS startdate,\n",
    "        DATE(fr.enddate)   AS enddate,\n",
    "        fc.payment_method\n",
    "      FROM opg_sirius_prod.fee_reduction fr\n",
    "      JOIN opg_sirius_prod.finance_client fc\n",
    "        ON fc.id = fr.finance_client_id\n",
    "       AND fc.glueexporteddate = DATE('{run_date}')\n",
    "      JOIN (\n",
    "        SELECT\n",
    "          MAX(id)           AS id,\n",
    "          finance_client_id\n",
    "        FROM opg_sirius_prod.fee_reduction\n",
    "        WHERE enddate           >= DATE('{run_date}')\n",
    "          AND startdate         <= DATE('{run_date}')\n",
    "          AND deleted            = FALSE\n",
    "          AND glueexporteddate   = DATE('{run_date}')\n",
    "        GROUP BY finance_client_id\n",
    "      ) latest ON latest.id = fr.id\n",
    "      WHERE fr.glueexporteddate = DATE('{run_date}')\n",
    "    )\n",
    "    SELECT\n",
    "      c.glueexporteddate,\n",
    "      c.caserecnumber            AS casenumber,\n",
    "      c.uid                      AS siriusid,\n",
    "      (\n",
    "        SELECT supervisionlevel\n",
    "        FROM opg_sirius_prod.supervision_level_log sll\n",
    "        WHERE sll.order_id         = c.id\n",
    "          AND sll.glueexporteddate = DATE('{run_date}')\n",
    "        ORDER BY sll.appliesfrom DESC\n",
    "        LIMIT 1\n",
    "      ) AS casesupervisionlevel,\n",
    "      p.risk_score               AS CREC,\n",
    "      c.casesubtype              AS orderType,\n",
    "      c.orderdate                AS ordermadedate,\n",
    "      c.orderstatus              AS orderStatus,\n",
    "      afr.type                   AS feereductiontype,\n",
    "      p.dob,\n",
    "      CASE\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) < 0 THEN 0\n",
    "        ELSE ROUND(DATE_DIFF('day', p.dob, p.createddate) / 365.25)\n",
    "      END AS age_in_years\n",
    "    FROM opg_sirius_prod.persons p\n",
    "    JOIN opg_sirius_prod.cases c\n",
    "      ON p.id                   = c.client_id\n",
    "     AND c.glueexporteddate     = DATE('{run_date}')\n",
    "    LEFT JOIN active_fee_reductions afr\n",
    "      ON afr.client_id          = p.id\n",
    "    WHERE c.orderstatus IN ('OPEN','ACTIVE','DUPLICATE')\n",
    "      AND p.glueexporteddate     = DATE('{run_date}')\n",
    "    ORDER BY c.orderdate;\n",
    "    \"\"\"\n",
    "    return pydbtools.read_sql_query(query)\n",
    "\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    \"\"\"Strip quotes/whitespace and parse 'YYYY-MM' → datetime.\"\"\"\n",
    "    cleaned = month_str.strip().strip(\"'\\\"\")\n",
    "    return datetime.strptime(cleaned, \"%Y-%m\")\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    \"\"\"\n",
    "    Return a list of datetime objects for each month-start\n",
    "    from start_month to end_month inclusive.\n",
    "    \"\"\"\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    \"\"\"Return the last day of dt's month as 'YYYY-MM-DD'.\"\"\"\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    return dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "def export_monthly_reports(first_month: str, last_month: str, output_base=\"output\"):\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    excel_filename = f\"cases_{clean_first}_to_{clean_last}.xlsx\"\n",
    "    excel_path = os.path.join(output_base, excel_filename)    \n",
    "    clear_directory(excel_path)\n",
    "    \n",
    "    # List to accumulate each month's DataFrame\n",
    "    all_months = []\n",
    "\n",
    "    # Create Excel workbook and write each month's sheet\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        for dt in months:\n",
    "            month_tag = dt.strftime(\"%Y-%m\")\n",
    "            run_date = last_day_of_month(dt)\n",
    "\n",
    "            # Fetch data for this month-end\n",
    "            df = fetch_cases_for_date(run_date)\n",
    "\n",
    "            # Tag the DataFrame with its month, then collect it\n",
    "            df[\"month\"] = month_tag\n",
    "            all_months.append(df)\n",
    "\n",
    "            # Save CSV for this month\n",
    "            month_folder = os.path.join(output_base, month_tag)\n",
    "            os.makedirs(month_folder, exist_ok=True)\n",
    "            csv_path = os.path.join(month_folder, f\"cases_{month_tag}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "            # Add to Excel workbook\n",
    "            df.to_excel(writer, sheet_name=month_tag, index=False)\n",
    "\n",
    "            print(f\"→ Saved CSV for {month_tag}: {csv_path}\")\n",
    "\n",
    "        print(f\"→ Combined Excel workbook saved at: {excel_path}\")\n",
    "\n",
    "    # After all sheets are written, concatenate & export one big CSV\n",
    "    if all_months:\n",
    "        combined_df = pd.concat(all_months, ignore_index=True)\n",
    "        combined_csv_path = os.path.join(\n",
    "            output_base,\n",
    "            f\"all_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "        )\n",
    "        combined_df.to_csv(combined_csv_path, index=False)\n",
    "        print(f\"→ Combined CSV for all months saved at: {combined_csv_path}\")\n",
    "        \n",
    "\n",
    "def calculate_monthly_active_cases(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month between first_month and last_month (inclusive), fetch the data,\n",
    "    filter to ACTIVE cases, then aggregate unique casenumber counts by orderType.\n",
    "    Writes a CSV 'monthly_active_cases_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # List to collect each month's summary\n",
    "    summaries = []\n",
    "\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date = last_day_of_month(dt)\n",
    "\n",
    "        # Fetch data for this month-end\n",
    "        df = fetch_cases_for_date(run_date)\n",
    "\n",
    "        # Keep only ACTIVE cases\n",
    "        df_active = df[df[\"orderstatus\"] == \"ACTIVE\"].copy()\n",
    "        if df_active.empty:\n",
    "            # still record zero counts for completeness\n",
    "            summaries.append(\n",
    "                pd.DataFrame([{\"month\": month_tag, \"orderType\": None, \"active_case_count\": 0}])\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Tag with month for grouping\n",
    "        df_active[\"month\"] = month_tag\n",
    "\n",
    "        # Aggregate unique casenumbers per orderType\n",
    "        summary = (\n",
    "            df_active\n",
    "            .groupby([\"month\", \"ordertype\"])[\"casenumber\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"active_case_count\")\n",
    "        )\n",
    "        summaries.append(summary)\n",
    "\n",
    "        print(f\"→ Aggregated ACTIVE cases for {month_tag}\")\n",
    "\n",
    "    # Combine all month summaries\n",
    "    result_df = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    # Fill any missing orderTypes/months with zeros if you want full matrix:\n",
    "    # pivot = result_df.pivot_table(index=\"month\", columns=\"orderType\",\n",
    "    #                               values=\"active_case_count\", fill_value=0).reset_index()\n",
    "\n",
    "    # Write out CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_active_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    result_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly ACTIVE cases CSV saved at: {out_csv}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Forecasting Active Caseloads:\n",
    "\n",
    "## entered: count of cases newly appearing in the active caseload each month\n",
    "\n",
    "## exited: count of cases that dropped out since the prior month\n",
    "\n",
    "def calculate_monthly_flow(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month from first_month to last_month (inclusive),\n",
    "    snapshot the set of active casenumbers, then compare to the prior month\n",
    "    to count how many entered and exited the active caseload.\n",
    "    Writes 'monthly_flow_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the flow DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare snapshots dict: { \"YYYY-MM\": set_of_casenumbers }\n",
    "    snapshots = {}\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date  = last_day_of_month(dt)\n",
    "        df        = fetch_cases_for_date(run_date)\n",
    "        # Only unique casenumbers\n",
    "        snapshots[month_tag] = set(df[\"casenumber\"].unique())\n",
    "        print(f\"→ Snapshot for {month_tag}: {len(snapshots[month_tag])} active cases\")\n",
    "\n",
    "    # Build flow records\n",
    "    flow_records = []\n",
    "    prev_month = None\n",
    "    for month in sorted(snapshots):\n",
    "        current = snapshots[month]\n",
    "        if prev_month is None:\n",
    "            # First month: all are \"new\", none have \"exited\"\n",
    "            flow_records.append({\n",
    "                \"month\": month,\n",
    "                \"entered\": len(current),\n",
    "                \"exited\":  0\n",
    "            })\n",
    "        else:\n",
    "            prev = snapshots[prev_month]\n",
    "            entered = current - prev\n",
    "            exited  = prev - current\n",
    "            flow_records.append({\n",
    "                \"month\":  month,\n",
    "                \"entered\": len(entered),\n",
    "                \"exited\":  len(exited)\n",
    "            })\n",
    "        prev_month = month\n",
    "\n",
    "    # Create DataFrame and write CSV\n",
    "    flow_df = pd.DataFrame(flow_records)\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_flow_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    flow_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly flow CSV saved at: {out_csv}\")\n",
    "\n",
    "    return flow_df\n",
    "\n",
    "\n",
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Combines granular 1-year and custom-bin versions.\n",
    "    - Default: 1-year bins 0-120 with optional unknown-age redistribution.\n",
    "    - Custom: pass age_bins & age_labels for coarse bins.\n",
    "\n",
    "    Returns flows_df, age_rates_df and writes two CSVs to output_base.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # Default bins: 1-year ages 0-120\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins = list(range(0, 122))\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]\n",
    "\n",
    "    months = generate_month_list(first_month, last_month)\n",
    "    flow_records = []\n",
    "    age_rate_records = []\n",
    "\n",
    "    for dt in months:\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        # fetch current and prior snapshots\n",
    "        df_cur = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "        set_cur = set(df_cur[\"casenumber\"])\n",
    "        set_prev = set(df_prev[\"casenumber\"])\n",
    "        entered_set = set_cur - set_prev\n",
    "        exited_set  = set_prev - set_cur\n",
    "\n",
    "        # record overall flows\n",
    "        flow_records.append({\n",
    "            \"month\": tag,\n",
    "            \"entered\": len(entered_set),\n",
    "            \"exited\": len(exited_set)\n",
    "        })\n",
    "\n",
    "        # slice data for age groups\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited_set)].copy()\n",
    "        df_in  = df_cur [df_cur [\"casenumber\"].isin(entered_set)].copy()\n",
    "        df_base= df_prev.copy()\n",
    "\n",
    "        # assign age_group\n",
    "        for df_ in (df_term, df_in, df_base):\n",
    "            df_[\"age_group\"] = pd.cut(\n",
    "                df_[\"age_in_years\"],\n",
    "                bins=age_bins,\n",
    "                labels=age_labels,\n",
    "                right=False,\n",
    "                include_lowest=True\n",
    "            )\n",
    "\n",
    "        # count known-age inflows and optionally redistribute unknowns\n",
    "        in_counts = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        unknown = df_in[\"age_group\"].isna().sum()\n",
    "        \n",
    "        missing = \"\"\n",
    "        \n",
    "        if redistribute_unknown_age and unknown > 0:\n",
    "            missing = \"redistributed_missing\"\n",
    "            # compute proportions\n",
    "            total_known = in_counts.sum()\n",
    "            \n",
    "            if total_known > 0:\n",
    "                props = in_counts / total_known\n",
    "            else:\n",
    "                props = pd.Series(1/len(age_labels), index=age_labels)\n",
    "            alloc = (props * unknown).round().astype(int)\n",
    "            in_counts += alloc\n",
    "\n",
    "        ter_counts  = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        \n",
    "        # compile age-rate records\n",
    "        for grp in age_labels:\n",
    "            active = int(base_counts[grp])\n",
    "            term   = int(ter_counts[grp])\n",
    "            ent    = int(in_counts[grp])\n",
    "            rate   = round(term/active, 4) if active else 0.0\n",
    "            age_rate_records.append({\n",
    "                \"month\": tag,\n",
    "                \"age_group\": grp,\n",
    "                \"active_count\": active,\n",
    "                \"entered\": ent,\n",
    "                \"terminations\": term,\n",
    "                \"termination_rate\": rate\n",
    "            })\n",
    "\n",
    "    print(f\"count known-age inflows: {in_counts}\")\n",
    "    print(f\"count unknown-age inflows: {unknown}\")\n",
    "    print(f\"termination counts: {ter_counts}\")\n",
    "    print(f\"base counts: {base_counts}\")\n",
    "    print(f\"total known-age inflows: {total_known}\")\n",
    "    \n",
    "    flows_df = pd.DataFrame(flow_records)\n",
    "    ages_df  = pd.DataFrame(age_rate_records)\n",
    "\n",
    "    clear_directory(os.path.join(output_base))\n",
    "    # write outputs\n",
    "    flows_df.to_csv(os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}_{missing}.csv\"), index=False)\n",
    "    ages_df .to_csv(os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}_{missing}.csv\"), index=False)\n",
    "\n",
    "    print(f\"→ Saved flows to {output_base}/yearonyear_flows_{first_month}_to_{last_month}_{missing}.csv\")\n",
    "    print(f\"→ Saved age rates to {output_base}/termination_and_entry_rates_by_age_{first_month}_to_{last_month}_{missing}.csv\")\n",
    "\n",
    "    return flows_df, ages_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Suppose entry_counts_by_age is from 2023-2025\n",
    "# age_distribution = entry_counts_by_age / entry_counts_by_age.sum()\n",
    "# print(age_distribution)\n",
    "\n",
    "# # Distribute forecasted totals (one row per month)\n",
    "# forecast_by_age = pd.DataFrame({\n",
    "#     \"month\": forecast.index,\n",
    "#     **{age: forecast.values * prop for age, prop in age_distribution.items()}\n",
    "# })\n",
    "# print(forecast_by_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# flows_df[\"month\"] = pd.to_datetime(flows_df[\"month\"])\n",
    "# monthly_new_orders = flows_df.set_index(\"month\")[\"entered\"].resample(\"M\").sum()\n",
    "\n",
    "# model = ExponentialSmoothing(monthly_new_orders, trend=\"add\", seasonal=\"add\", seasonal_periods=12)\n",
    "# fit = model.fit()\n",
    "# forecast = fit.forecast(12)  # Predict 12 months into 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     first_month = input(\"Enter first month (YYYY-MM): \")\n",
    "#     last_month  = input(\"Enter last month  (YYYY-MM): \")\n",
    "\n",
    "    # export_monthly_reports(first_month, last_month)\n",
    "    # active_summary = calculate_monthly_active_cases(first_month, last_month)\n",
    "    # flow_summary  = calculate_monthly_flow(first_month, last_month)\n",
    "\n",
    "    # # now do month‐to‐month style year‐on‐year deputyship flows:\n",
    "    \n",
    "    # # compute year-on-year flows + age rates across all months\n",
    "    # yoy_flows, age_rates = calculate_yearonyear_flows_and_age_rates(first_month, last_month)\n",
    "\n",
    "    # # after export_monthly_reports(\"2023-05\", \"2025-05\")\n",
    "    # print(\"\\nYear-on-year deputyship flows:\")\n",
    "    # print(yoy_flows)\n",
    "    # # for each month and age‐group, the number of entered (new deputyships) alongside terminations and termination rates:\n",
    "    # print(\"\\nAge-specific termination rates over time:\")\n",
    "    # print(age_rates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 1) Run without redistribution\n",
    "# flows1, rates1 = calculate_yearonyear_flows_and_age_rates(\"2023-04\",\"2025-04\", \"out1\")\n",
    "\n",
    "# # 2) Run with redistribution\n",
    "# flows2, rates2 = calculate_yearonyear_flows_and_age_rates(\"2023-04\",\"2025-04\", \"out2\", redistribute_unknown_age=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def forecast_monthly_new_orders(\n",
    "#     flows_df: pd.DataFrame,\n",
    "#     periods: int = 12,\n",
    "#     freq: str = 'M'\n",
    "# ) -> pd.Series:\n",
    "#     \"\"\"\n",
    "#     Forecast total monthly new orders using Holt-Winters.\n",
    "#     Expects flows_df with columns ['month','entered'].\n",
    "#     Returns a pd.Series indexed by forecast months.\n",
    "#     \"\"\"\n",
    "#     ts = flows_df.copy()\n",
    "#     ts['month'] = pd.to_datetime(ts['month'])\n",
    "#     ts = ts.set_index('month').resample(freq)['entered'].sum()\n",
    "\n",
    "#     model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=12)\n",
    "#     fit = model.fit(optimized=True)\n",
    "#     forecast = fit.forecast(periods)\n",
    "#     return forecast\n",
    "\n",
    "\n",
    "# def distribute_forecast_by_age(\n",
    "#     forecast: pd.Series,\n",
    "#     age_rates_df: pd.DataFrame,\n",
    "#     weight_years = (2023, 2025)\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Distribute forecast totals by age group using average historical proportions.\n",
    "#     \"\"\"\n",
    "#     # filter historical entries\n",
    "#     hist = age_rates_df.copy()\n",
    "#     hist['month'] = pd.to_datetime(hist['month'])\n",
    "#     hist = hist[hist['month'].dt.year.between(*weight_years)]\n",
    "\n",
    "#     # compute average distribution\n",
    "#     dist = (\n",
    "#         hist.groupby(\"age_group\", observed=False)['entered'].sum()\n",
    "#         / hist['entered'].sum()\n",
    "#     )\n",
    "\n",
    "#     # build DataFrame\n",
    "#     rows = []\n",
    "#     for month, total in forecast.items():\n",
    "#         for age, prop in dist.items():\n",
    "#             rows.append({'month': month.strftime('%Y-%m'), 'age_group': age, 'forecasted_new': round(total * prop)})\n",
    "#     return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# def plot_forecast_and_distribution(\n",
    "#     forecast: pd.Series,\n",
    "#     forecast_by_age: pd.DataFrame\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Generates two charts:\n",
    "#       1. Total new orders forecast\n",
    "#       2. Stacked area by age group\n",
    "#     \"\"\"\n",
    "#     # 1. Total forecast\n",
    "#     plt.figure()\n",
    "#     forecast.plot(marker='o')\n",
    "#     plt.title('Monthly New Orders Forecast for 2026')\n",
    "#     plt.ylabel('New Orders')\n",
    "#     plt.xlabel('Month')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # 2. Stacked area chart\n",
    "#     pivot = forecast_by_age.pivot(index='month', columns='age_group', values='forecasted_new')\n",
    "#     pivot.index = pd.to_datetime(pivot.index)\n",
    "#     plt.figure()\n",
    "#     pivot.plot.area()\n",
    "#     plt.title('Forecasted New Orders by Age Group')\n",
    "#     plt.ylabel('New Orders')\n",
    "#     plt.xlabel('Month')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flows, ages = calculate_yearonyear_flows_and_age_rates(\"2023-01\", \"2025-06\", redistribute_unknown_age=True)\n",
    "# forecast = forecast_monthly_new_orders(flows, periods=12)\n",
    "# by_age = distribute_forecast_by_age(forecast, ages, weight_years=(2023,2025))\n",
    "# plot_forecast_and_distribution(forecast, by_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1) EXISTING HELPERS:\n",
    "#flows_df, ages_df = calculate_yearonyear_flows_and_age_rates(\"2023-01\", \"2025-06\", redistribute_unknown_age=True)\n",
    "\n",
    "# 2) NEW: Forecast with prediction intervals\n",
    "def forecast_with_pi(\n",
    "    flows_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    alpha: float = 0.05,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecast monthly new orders with 95% prediction intervals.\n",
    "    Falls back to trend-only if insufficient data for seasonality.\n",
    "    Returns DataFrame with columns ['mean','lower','upper'] indexed by period end.\n",
    "    \"\"\"\n",
    "    ts = flows_df.set_index(pd.to_datetime(flows_df['month']))['entered'].resample('ME').sum()\n",
    "    nobs = len(ts)\n",
    "    # Determine model configuration\n",
    "    if seasonal_periods and nobs >= 2 * seasonal_periods:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "    else:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "    fit = model.fit(optimized=True)\n",
    "\n",
    "    mu = fit.forecast(periods)\n",
    "    resid = fit.resid.dropna()\n",
    "    sigma = resid.std()\n",
    "    z = abs(pd.Series(resid).quantile([alpha/2, 1-alpha/2]).iloc[1])\n",
    "    lower = mu - z * sigma\n",
    "    upper = mu + z * sigma\n",
    "    return pd.DataFrame({'mean': mu, 'lower': lower, 'upper': upper})\n",
    "\n",
    "\n",
    "def distribute_pi_by_age(\n",
    "    pi_df: pd.DataFrame,\n",
    "    ages_df: pd.DataFrame,\n",
    "    weight_years: tuple[int, int] = (2023, 2025)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Allocate forecast mean and PI bounds by age group per historical proportions.\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    hist = hist[hist['month'].dt.year.between(*weight_years)]\n",
    "    dist = hist.groupby(\"age_group\", observed=False)['entered'].sum() / hist['entered'].sum()\n",
    "\n",
    "    rows = []\n",
    "    for m, row in pi_df.iterrows():\n",
    "        for age, p in dist.items():\n",
    "            rows.append({\n",
    "                'month': m.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'mean':   row['mean'] * p,\n",
    "                'lower':  row['lower'] * p,\n",
    "                'upper':  row['upper'] * p\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def plot_total_forecast(pi_df: pd.DataFrame):\n",
    "    plt.figure()\n",
    "    x = pi_df.index\n",
    "    plt.fill_between(x, pi_df['lower'], pi_df['upper'], alpha=0.3)\n",
    "    plt.plot(x, pi_df['mean'], marker='o')\n",
    "    plt.title('Monthly New Orders Forecast (95% PI)')\n",
    "    plt.xlabel('Month'); plt.ylabel('New Orders')\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def plot_age_forecast(pi_age_df: pd.DataFrame):\n",
    "    pivot = pi_age_df.pivot(index='month', columns='age_group', values='mean')\n",
    "    pivot.index = pd.to_datetime(pivot.index)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    pivot.plot.area(ax=ax)\n",
    "    ax.set_title('Forecasted New Orders by Age Group (Mean)')\n",
    "    ax.set_xlabel('Month'); ax.set_ylabel('New Orders')\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flows, ages = calculate_yearonyear_flows_and_age_rates(\n",
    "        \"2023-01\", \"2025-06\",\n",
    "        redistribute_unknown_age=True\n",
    "    )\n",
    "\n",
    "    pi     = forecast_with_pi(flows, periods=12)\n",
    "    pi_age = distribute_pi_by_age(pi, ages, weight_years=(2022,2024))\n",
    "\n",
    "    fig1 = plot_total_forecast(pi)\n",
    "    fig2 = plot_age_forecast(pi_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# export_monthly_reports(\"2023-04\",\"2023-05\")\n",
    "\n",
    "# active_summary = calculate_monthly_active_cases(\"2023-04\",\"2023-05\")\n",
    "# print(active_summary.head())\n",
    "\n",
    "# flow_summary  = calculate_monthly_flow(\"2023-04\",\"2023-05\")\n",
    "# print(flow_summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydbtools\n",
    "# !pip install --force numpy==1.24\n",
    "#!pip install pydbtools\n",
    "# !pip install --force numpy==1.24\n",
    "\n",
    "import os\n",
    "import calendar\n",
    "import shutil\n",
    "from datetime import datetime,timedelta\n",
    "import pydbtools\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import botocore\n",
    "import s3fs\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    \"\"\"Parse 'YYYY-MM' to datetime.\"\"\"\n",
    "    return datetime.strptime(month_str.strip().strip(\"'\\\"\"), \"%Y-%m\")\n",
    "\n",
    "\n",
    "def clear_directory(path):\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove file or symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directory and its contents\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all cases & their fee reductions for the given run_date (YYYY-MM-DD)\n",
    "    using pydbtools.read_sql_query, which returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH active_fee_reductions AS (\n",
    "      SELECT\n",
    "        fc.client_id,\n",
    "        SUBSTRING(fr.type,1,1) || LOWER(SUBSTRING(fr.type,2)) AS type,\n",
    "        DATE(fr.startdate) AS startdate,\n",
    "        DATE(fr.enddate)   AS enddate,\n",
    "        fc.payment_method\n",
    "      FROM opg_sirius_prod.fee_reduction fr\n",
    "      JOIN opg_sirius_prod.finance_client fc\n",
    "        ON fc.id = fr.finance_client_id\n",
    "       AND fc.glueexporteddate = DATE('{run_date}')\n",
    "      JOIN (\n",
    "        SELECT\n",
    "          MAX(id)           AS id,\n",
    "          finance_client_id\n",
    "        FROM opg_sirius_prod.fee_reduction\n",
    "        WHERE enddate           >= DATE('{run_date}')\n",
    "          AND startdate         <= DATE('{run_date}')\n",
    "          AND deleted            = FALSE\n",
    "          AND glueexporteddate   = DATE('{run_date}')\n",
    "        GROUP BY finance_client_id\n",
    "      ) latest ON latest.id = fr.id\n",
    "      WHERE fr.glueexporteddate = DATE('{run_date}')\n",
    "    )\n",
    "    SELECT\n",
    "      c.glueexporteddate,\n",
    "      c.caserecnumber            AS casenumber,\n",
    "      c.uid                      AS siriusid,\n",
    "      (\n",
    "        SELECT supervisionlevel\n",
    "        FROM opg_sirius_prod.supervision_level_log sll\n",
    "        WHERE sll.order_id         = c.id\n",
    "          AND sll.glueexporteddate = DATE('{run_date}')\n",
    "        ORDER BY sll.appliesfrom DESC\n",
    "        LIMIT 1\n",
    "      ) AS casesupervisionlevel,\n",
    "      p.risk_score               AS CREC,\n",
    "      c.casesubtype              AS orderType,\n",
    "      c.orderdate                AS ordermadedate,\n",
    "      c.orderstatus              AS orderStatus,\n",
    "      afr.type                   AS feereductiontype,\n",
    "      p.dob,\n",
    "      CASE\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) < 0 THEN 0\n",
    "        ELSE ROUND(DATE_DIFF('day', p.dob, p.createddate) / 365.25)\n",
    "      END AS age_in_years\n",
    "    FROM opg_sirius_prod.persons p\n",
    "    JOIN opg_sirius_prod.cases c\n",
    "      ON p.id                   = c.client_id\n",
    "     AND c.glueexporteddate     = DATE('{run_date}')\n",
    "    LEFT JOIN active_fee_reductions afr\n",
    "      ON afr.client_id          = p.id\n",
    "    WHERE c.orderstatus IN ('OPEN','ACTIVE','DUPLICATE')\n",
    "      AND p.glueexporteddate     = DATE('{run_date}')\n",
    "    ORDER BY c.orderdate;\n",
    "    \"\"\"\n",
    "    return pydbtools.read_sql_query(query)\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    \"\"\"\n",
    "    Return a list of datetime objects for each month-start\n",
    "    from start_month to end_month inclusive.\n",
    "    \"\"\"\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    \"\"\"Return the last day of dt's month as 'YYYY-MM-DD'.\"\"\"\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    return dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "def export_monthly_reports(first_month: str, last_month: str, output_base=\"output\"):\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    excel_filename = f\"cases_{clean_first}_to_{clean_last}.xlsx\"\n",
    "    excel_path = os.path.join(output_base, excel_filename)    \n",
    "    clear_directory(excel_path)\n",
    "    \n",
    "    # List to accumulate each month's DataFrame\n",
    "    all_months = []\n",
    "\n",
    "    # Create Excel workbook and write each month's sheet\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        for dt in months:\n",
    "            month_tag = dt.strftime(\"%Y-%m\")\n",
    "            run_date = last_day_of_month(dt)\n",
    "\n",
    "            # Fetch data for this month-end\n",
    "            df = fetch_cases_for_date(run_date)\n",
    "\n",
    "            # Tag the DataFrame with its month, then collect it\n",
    "            df[\"month\"] = month_tag\n",
    "            all_months.append(df)\n",
    "\n",
    "            # Save CSV for this month\n",
    "            month_folder = os.path.join(output_base, month_tag)\n",
    "            os.makedirs(month_folder, exist_ok=True)\n",
    "            csv_path = os.path.join(month_folder, f\"cases_{month_tag}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "            # Add to Excel workbook\n",
    "            df.to_excel(writer, sheet_name=month_tag, index=False)\n",
    "\n",
    "            print(f\"→ Saved CSV for {month_tag}: {csv_path}\")\n",
    "\n",
    "        print(f\"→ Combined Excel workbook saved at: {excel_path}\")\n",
    "\n",
    "    # After all sheets are written, concatenate & export one big CSV\n",
    "    if all_months:\n",
    "        combined_df = pd.concat(all_months, ignore_index=True)\n",
    "        combined_csv_path = os.path.join(\n",
    "            output_base,\n",
    "            f\"all_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "        )\n",
    "        combined_df.to_csv(combined_csv_path, index=False)\n",
    "        print(f\"→ Combined CSV for all months saved at: {combined_csv_path}\")\n",
    "        \n",
    "\n",
    "def calculate_monthly_active_cases(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month between first_month and last_month (inclusive), fetch the data,\n",
    "    filter to ACTIVE cases, then aggregate unique casenumber counts by orderType.\n",
    "    Writes a CSV 'monthly_active_cases_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # List to collect each month's summary\n",
    "    summaries = []\n",
    "\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date = last_day_of_month(dt)\n",
    "\n",
    "        # Fetch data for this month-end\n",
    "        df = fetch_cases_for_date(run_date)\n",
    "\n",
    "        # Keep only ACTIVE cases\n",
    "        df_active = df[df[\"orderstatus\"] == \"ACTIVE\"].copy()\n",
    "        if df_active.empty:\n",
    "            # still record zero counts for completeness\n",
    "            summaries.append(\n",
    "                pd.DataFrame([{\"month\": month_tag, \"orderType\": None, \"active_case_count\": 0}])\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Tag with month for grouping\n",
    "        df_active[\"month\"] = month_tag\n",
    "\n",
    "        # Aggregate unique casenumbers per orderType\n",
    "        summary = (\n",
    "            df_active\n",
    "            .groupby([\"month\", \"ordertype\"])[\"casenumber\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"active_case_count\")\n",
    "        )\n",
    "        summaries.append(summary)\n",
    "\n",
    "        print(f\"→ Aggregated ACTIVE cases for {month_tag}\")\n",
    "\n",
    "    # Combine all month summaries\n",
    "    result_df = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    # Fill any missing orderTypes/months with zeros if you want full matrix:\n",
    "    # pivot = result_df.pivot_table(index=\"month\", columns=\"orderType\",\n",
    "    #                               values=\"active_case_count\", fill_value=0).reset_index()\n",
    "\n",
    "    # Write out CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_active_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    result_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly ACTIVE cases CSV saved at: {out_csv}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Forecasting Active Caseloads:\n",
    "\n",
    "## entered: count of cases newly appearing in the active caseload each month\n",
    "\n",
    "## exited: count of cases that dropped out since the prior month\n",
    "\n",
    "def calculate_monthly_flow(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month from first_month to last_month (inclusive),\n",
    "    snapshot the set of active casenumbers, then compare to the prior month\n",
    "    to count how many entered and exited the active caseload.\n",
    "    Writes 'monthly_flow_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the flow DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare snapshots dict: { \"YYYY-MM\": set_of_casenumbers }\n",
    "    snapshots = {}\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date  = last_day_of_month(dt)\n",
    "        df        = fetch_cases_for_date(run_date)\n",
    "        # Only unique casenumbers\n",
    "        snapshots[month_tag] = set(df[\"casenumber\"].unique())\n",
    "        print(f\"→ Snapshot for {month_tag}: {len(snapshots[month_tag])} active cases\")\n",
    "\n",
    "    # Build flow records\n",
    "    flow_records = []\n",
    "    prev_month = None\n",
    "    for month in sorted(snapshots):\n",
    "        current = snapshots[month]\n",
    "        if prev_month is None:\n",
    "            # First month: all are \"new\", none have \"exited\"\n",
    "            flow_records.append({\n",
    "                \"month\": month,\n",
    "                \"entered\": len(current),\n",
    "                \"exited\":  0\n",
    "            })\n",
    "        else:\n",
    "            prev = snapshots[prev_month]\n",
    "            entered = current - prev\n",
    "            exited  = prev - current\n",
    "            flow_records.append({\n",
    "                \"month\":  month,\n",
    "                \"entered\": len(entered),\n",
    "                \"exited\":  len(exited)\n",
    "            })\n",
    "        prev_month = month\n",
    "\n",
    "    # Create DataFrame and write CSV\n",
    "    flow_df = pd.DataFrame(flow_records)\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_flow_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    flow_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly flow CSV saved at: {out_csv}\")\n",
    "\n",
    "    return flow_df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Combines granular 1-year and custom-bin versions.\n",
    "    - Default: 1-year bins 0-119 with optional unknown-age redistribution.\n",
    "    - Custom: pass age_bins & age_labels for coarse bins.\n",
    "\n",
    "    Returns flows_df, age_rates_df and writes two CSVs to output_base.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins = list(range(0, 121))\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]\n",
    "\n",
    "    months = generate_month_list(first_month, last_month)\n",
    "    flow_records = []\n",
    "    age_rate_records = []\n",
    "\n",
    "    for dt in months:\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        df_cur = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "        set_cur = set(df_cur[\"casenumber\"])\n",
    "        set_prev = set(df_prev[\"casenumber\"])\n",
    "        entered_set = set_cur - set_prev\n",
    "        exited_set  = set_prev - set_cur\n",
    "\n",
    "        flow_records.append({\"month\": tag, \"entered\": len(entered_set), \"exited\": len(exited_set)})\n",
    "\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited_set)].copy()\n",
    "        df_in   = df_cur [df_cur [\"casenumber\"].isin(entered_set)].copy()\n",
    "        df_base = df_prev.copy()\n",
    "\n",
    "        for df_ in (df_term, df_in, df_base):\n",
    "            df_[\"age_group\"] = pd.cut(\n",
    "                df_[\"age_in_years\"], bins=age_bins, labels=age_labels, right=False, include_lowest=True\n",
    "            )\n",
    "\n",
    "        in_counts = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        unknown = df_in[\"age_group\"].isna().sum()\n",
    "        if redistribute_unknown_age and unknown > 0:\n",
    "            total_known = in_counts.sum()\n",
    "            props = (in_counts / total_known) if total_known > 0 else pd.Series(1/len(age_labels), index=age_labels)\n",
    "            in_counts += (props * unknown).round().astype(int)\n",
    "\n",
    "        ter_counts  = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "\n",
    "        for grp in age_labels:\n",
    "            active = int(base_counts[grp])\n",
    "            term   = int(ter_counts[grp])\n",
    "            ent    = int(in_counts[grp])\n",
    "            rate   = round(term/active, 4) if active else 0.0\n",
    "            age_rate_records.append({\n",
    "                \"month\": tag,\n",
    "                \"age_group\": grp,\n",
    "                \"active_count\": active,\n",
    "                \"entered\": ent,\n",
    "                \"terminations\": term,\n",
    "                \"termination_rate\": rate\n",
    "            })\n",
    "\n",
    "    flows_df = pd.DataFrame(flow_records)\n",
    "    ages_df  = pd.DataFrame(age_rate_records)\n",
    "\n",
    "    flows_df.to_csv(os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "    ages_df .to_csv(os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "\n",
    "    return flows_df, ages_df\n",
    "\n",
    "\n",
    "def forecast_with_pi(\n",
    "    flows_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    alpha: float = 0.05,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecast monthly new orders with 95% prediction intervals.\n",
    "    Falls back to trend-only if insufficient data for seasonality.\n",
    "    \"\"\"\n",
    "    ts = flows_df.set_index(pd.to_datetime(flows_df['month']))['entered'].resample('ME').sum()\n",
    "    nobs = len(ts)\n",
    "    if seasonal_periods and nobs >= 2 * seasonal_periods:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "    else:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "    fit = model.fit(optimized=True)\n",
    "    mu = fit.forecast(periods)\n",
    "    resid = fit.resid.dropna()\n",
    "    sigma = resid.std()\n",
    "    z = abs(pd.Series(resid).quantile([alpha/2, 1-alpha/2]).iloc[1])\n",
    "    lower = mu - z * sigma\n",
    "    upper = mu + z * sigma\n",
    "    return pd.DataFrame({'mean': mu, 'lower': lower, 'upper': upper})\n",
    "\n",
    "\n",
    "def distribute_pi_by_age(\n",
    "    pi_df: pd.DataFrame,\n",
    "    ages_df: pd.DataFrame,\n",
    "    weight_years: tuple[int, int] # = (start_year, end_year)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Allocate forecast mean and PI bounds by age group per historical proportions.\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    hist = hist[hist['month'].dt.year.between(*weight_years)]\n",
    "    dist = hist.groupby('age_group')['entered'].sum() / hist['entered'].sum()\n",
    "\n",
    "    rows = []\n",
    "    for m, row in pi_df.iterrows():\n",
    "        for age, p in dist.items():\n",
    "            rows.append({\n",
    "                'month': m.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'mean':   row['mean'] * p,\n",
    "                'lower':  row['lower'] * p,\n",
    "                'upper':  row['upper'] * p\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def forecast_age_specific_active(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts active caseload by age by separately forecasting entries and termination rates.\n",
    "\n",
    "    - Fits a time series to each age_group's 'entered' and 'termination_rate'.\n",
    "    - Forecasts both series for `periods` months.\n",
    "    - Iteratively projects: active[t] = active[t-1] * (1 - term_rate[t]) + entered[t].\n",
    "    \"\"\"\n",
    "    # Pivot historical series\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts = hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "\n",
    "    # Forecast containers\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "\n",
    "    for age in entered_ts.columns:\n",
    "        # Prepare series\n",
    "        series_e = entered_ts[age].resample('ME').sum()\n",
    "        series_t = termrate_ts[age].resample('ME').mean()\n",
    "        # Entry forecast\n",
    "        if len(series_e.dropna()) >= 2 * seasonal_periods:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal=None)\n",
    "        fit_e = m_e.fit(optimized=True)\n",
    "        entered_fc[age] = fit_e.forecast(periods)\n",
    "        # Termination rate forecast\n",
    "        if len(series_t.dropna()) >= 2 * seasonal_periods:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal=None)\n",
    "        fit_t = m_t.fit(optimized=True)\n",
    "        termrate_fc[age] = fit_t.forecast(periods)\n",
    "\n",
    "    # Starting active counts\n",
    "    last = hist[hist['month'] == hist['month'].max()].set_index('age_group')['active_count']\n",
    "    active_prev = last.astype(float)\n",
    "\n",
    "    records = []\n",
    "    months = pd.date_range(\n",
    "        start=entered_ts.index.max() + pd.offsets.MonthBegin(1),\n",
    "        periods=periods, freq='ME'\n",
    "    )\n",
    "\n",
    "    for i, month in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr  = termrate_fc[age].iloc[i]\n",
    "            act = active_prev[age] * (1 - tr) + ent\n",
    "            records.append({\n",
    "                'month': month.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'active_forecast': act\n",
    "            })\n",
    "            active_prev[age] = act\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def plot_total_forecast(pi_df: pd.DataFrame):\n",
    "    plt.figure()\n",
    "    x = pi_df.index\n",
    "    plt.fill_between(x, pi_df['lower'], pi_df['upper'], alpha=0.3)\n",
    "    plt.plot(x, pi_df['mean'], marker='o')\n",
    "    plt.title('Monthly New Orders Forecast (95% PI)')\n",
    "    plt.xlabel('Month'); plt.ylabel('New Orders')\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def plot_age_forecast(pi_age_df: pd.DataFrame):\n",
    "    pivot = pi_age_df.pivot(index='month', columns='age_group', values='mean')\n",
    "    pivot.index = pd.to_datetime(pivot.index)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    pivot.plot.area(ax=ax)\n",
    "    ax.set_title('Forecasted New Orders by Age Group (Mean)')\n",
    "    ax.set_xlabel('Month'); ax.set_ylabel('New Orders')\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def forecast_age_specific_active_with_components(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts by age: active, entered, term rate, retention = 1-term_rate.\n",
    "    Returns ['month','age_group','entered_forecast','term_rate_forecast','retention_rate','active_forecast']\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts= hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "    for age in entered_ts.columns:\n",
    "        se = entered_ts[age].resample('ME').sum()\n",
    "        st = termrate_ts[age].resample('ME').mean()\n",
    "        me = ExponentialSmoothing(se, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(se.dropna())>=2*seasonal_periods else ExponentialSmoothing(se, trend='add', seasonal=None)\n",
    "        fe = me.fit(optimized=True).forecast(periods)\n",
    "        mt = ExponentialSmoothing(st, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(st.dropna())>=2*seasonal_periods else ExponentialSmoothing(st, trend='add', seasonal=None)\n",
    "        ft = mt.fit(optimized=True).forecast(periods)\n",
    "        entered_fc[age] = fe\n",
    "        termrate_fc[age] = ft\n",
    "    last = hist[hist['month']==hist['month'].max()].set_index('age_group')['active_count'].astype(float)\n",
    "    active_prev = last.copy()\n",
    "    records = []\n",
    "    months = pd.date_range(start=entered_ts.index.max()+pd.offsets.MonthBegin(1), periods=periods, freq='M')\n",
    "    for i, mo in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr = termrate_fc[age].iloc[i]\n",
    "            ret = 1 - tr\n",
    "            act = active_prev[age] * ret + ent\n",
    "            records.append({'month': mo.strftime('%Y-%m'), 'age_group': age, 'entered_forecast': ent, 'term_rate_forecast': tr, 'retention_rate': ret, 'active_forecast': act})\n",
    "            active_prev[age] = act\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2022\n",
    "    end_year = 2024\n",
    "    start_month = \"2022-01\"\n",
    "    end_month = \"2024-12\"\n",
    "\n",
    "    # Calculate historical flows and age rates\n",
    "    flows, ages = calculate_yearonyear_flows_and_age_rates(\n",
    "        start_month, end_month,\n",
    "        redistribute_unknown_age=True\n",
    "    )\n",
    "\n",
    "    # Forecast total new orders with prediction intervals\n",
    "    pi = forecast_with_pi(flows, periods=12)\n",
    "    # Distribute PI by age\n",
    "    pi_age = distribute_pi_by_age(pi, ages, weight_years=(start_year, end_year))\n",
    "    # Forecast active caseload by age\n",
    "    active_proj = forecast_age_specific_active(ages, periods=12)\n",
    "\n",
    "    # Component forecasts: entries, termination rate, retention, active\n",
    "    comp_df = forecast_age_specific_active_with_components(ages, periods=12)\n",
    "\n",
    "    # Convert age_group to numeric and sort by age_group then month\n",
    "    comp_df['age_group'] = comp_df['age_group'].astype(int)\n",
    "    comp_df_sorted = comp_df.sort_values(['age_group', 'month'])\n",
    "\n",
    "    # Print the sorted table\n",
    "    print(comp_df_sorted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_sorted = comp_df    \n",
    "# convert age_group to numeric and sort\n",
    "comp_df_sorted['age_group'] = comp_df_sorted['age_group'].astype(int)\n",
    "comp_df_sorted = comp_df_sorted.sort_values(['month', 'age_group'])\n",
    "print(comp_df_sorted.to_string(index=False))\n",
    "comp_df_sorted.to_csv(f\"output/comp_df_sorted_{start_year}_{end_year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time Series Forecasting\n",
    "# For forecasting purposes what we need to know is the number of cases actually flowing onto the active caseload each month \n",
    "# and the numbers actually leaving. I need to know ACTIVE cases going in and out of the system \n",
    "# and to draw by logical conclusion what we mean by the active caseload so that \n",
    "# we can deduce from this new cases that have been added (each month) and those that have left. \n",
    "# The simplest way to do that, without having to separately define inputs cases and outputs (terminations) \n",
    "# is to take a snapshot of the active cases each month (by using glueexporteddate as monthly active caseloads, \n",
    "#                                                       which is already implemented in the code below) \n",
    "# and compare it with the previous month so that we can see who has flowed on and who has left.\n",
    "\n",
    "\n",
    "# a simple 12-month projection of how many cases expected to enter and leave the active caseload each month.\n",
    "\n",
    "# Indexing: Converts month strings into a DatetimeIndex at month-start (asfreq('MS')).\n",
    "# Model: Uses ExponentialSmoothing with additive trend+seasonality (period=12).\n",
    "# Forecast: model.forecast(12) gives the next 12 monthly points.\n",
    "# Output: A DataFrame with columns month, entered_forecast, exited_forecast, saved to CSV.\n",
    "\n",
    "\n",
    "\n",
    "def forecast_monthly_flow(flow_df: pd.DataFrame,\n",
    "                          first_month: str,\n",
    "                          last_month: str,\n",
    "                          output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a flow_df with columns ['month','entered','exited'],\n",
    "    fit Holt–Winters models (additive trend+seasonality, period=12)\n",
    "    separately on 'entered' and 'exited', then forecast the next 12 months.\n",
    "    Writes 'forecast_flow_<first>_to_<last>_next12.csv' under output_base\n",
    "    and returns the forecast DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # Prepare the time index\n",
    "    df = flow_df.copy()\n",
    "    #df['month_dt'] = pd.to_datetime(df['month'] + '-01')\n",
    "    df['month_dt'] = pd.to_datetime(df['month'], format='%Y-%m')\n",
    "    df = df.set_index('month_dt').asfreq('MS')  # monthly start frequency\n",
    "\n",
    "    # our two series\n",
    "    entered = df['entered']\n",
    "    exited  = df['exited']\n",
    "\n",
    "    # fit Holt–Winters (additive trend+season, period=12)\n",
    "    hw_entered = ExponentialSmoothing(entered,\n",
    "                                      trend='add',\n",
    "                                      seasonal='mul',\n",
    "                                      seasonal_periods=12).fit()\n",
    "    \n",
    "    hw_exited  = ExponentialSmoothing(exited,\n",
    "                                      trend='add',\n",
    "                                      seasonal='add',\n",
    "                                      seasonal_periods=12).fit()\n",
    "\n",
    "    # forecast next 12\n",
    "    f_entered = hw_entered.forecast(12)\n",
    "    f_exited  = hw_exited.forecast(12)\n",
    "\n",
    "    # assemble forecast DataFrame\n",
    "    forecast_months = f_entered.index.strftime('%Y-%m')\n",
    "    # convert to posivitive array\n",
    "    f_entered = np.abs(f_entered)\n",
    "    forecast_df = pd.DataFrame({\n",
    "        'month':            forecast_months,\n",
    "        'entered_forecast': f_entered.values.astype(int),\n",
    "        'exited_forecast':  f_exited.values.astype(int),\n",
    "    })\n",
    "\n",
    "    # write to CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"forecast_flow_{clean_first}_to_{clean_last}_next12.csv\"\n",
    "    )\n",
    "    forecast_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Forecast CSV for next 12 months saved at: {out_csv}\")\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "# forecast next 12 months\n",
    "forecast_summary = forecast_monthly_flow(flow_summary,\n",
    "                                         first_month,\n",
    "                                         last_month)\n",
    "print(\"\\nForecasted flow for next 12 months:\")\n",
    "print(forecast_summary)\n",
    "    \n",
    "flow_sum = forecast_summary\n",
    "# Convert 'month' from string → datetime\n",
    "flow_sum['month'] = pd.to_datetime(flow_sum['month'], format='%Y-%m')\n",
    "    \n",
    "# Convert both 'month' columns to datetime at the very start\n",
    "flow_sum['month']          = pd.to_datetime(flow_sum['month'],          format='%Y-%m')\n",
    "active_summary['month']    = pd.to_datetime(active_summary['month'],    format='%Y-%m')\n",
    "\n",
    "    \n",
    "# Compute “same month last year” for each forecast row\n",
    "flow_sum['lookup_month'] = flow_sum['month'] - pd.DateOffset(years=1)\n",
    "\n",
    "# Aggregate active_summary by month (if you have multiple rows per month)\n",
    "active_agg = (\n",
    "    active_summary\n",
    "    .groupby('month', as_index=False)['active_case_count']\n",
    "    .sum()\n",
    ")\n",
    "    \n",
    "# Merge (left‐join) the previous‐year active counts in\n",
    "flow_with_active = (\n",
    "    flow_sum\n",
    "    .merge(\n",
    "        active_agg,\n",
    "        left_on='lookup_month',\n",
    "        right_on='month',\n",
    "        how='left',\n",
    "        suffixes=('','_prev')\n",
    "    )\n",
    ")\n",
    "    \n",
    "# Tidy up\n",
    "flow_with_active = (\n",
    "    flow_with_active\n",
    "    .rename(columns={\n",
    "        'month': 'month',                      # forecast month\n",
    "        'active_case_count': 'active_case_count_prev_year'\n",
    "    })\n",
    "    .drop(columns=['month_prev','lookup_month'])\n",
    ")\n",
    "\n",
    "# add another column to the resulted table to calculate for each year-month \n",
    "# the forecasted active caseloads = active_case_count_prev_year + entered_forecast  - exited_forecast\n",
    "flow_with_active['forecasted_active_caseload'] = (\n",
    "    flow_with_active['active_case_count_prev_year']\n",
    "    + flow_with_active['entered_forecast']\n",
    "    - flow_with_active['exited_forecast']\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nForecasted flow with active cases from the previous year for next 12 months:\")\n",
    "print(flow_with_active)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydbtools\n",
    "# !pip install --force numpy==1.24\n",
    "#!pip install pydbtools\n",
    "# !pip install --force numpy==1.24\n",
    "\n",
    "import os\n",
    "import calendar\n",
    "import shutil\n",
    "from datetime import datetime,timedelta\n",
    "import pydbtools\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import botocore\n",
    "import s3fs\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    \"\"\"Parse 'YYYY-MM' to datetime.\"\"\"\n",
    "    return datetime.strptime(month_str.strip().strip(\"'\\\"\"), \"%Y-%m\")\n",
    "\n",
    "\n",
    "def clear_directory(path):\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove file or symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directory and its contents\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all cases & their fee reductions for the given run_date (YYYY-MM-DD)\n",
    "    using pydbtools.read_sql_query, which returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH active_fee_reductions AS (\n",
    "      SELECT\n",
    "        fc.client_id,\n",
    "        SUBSTRING(fr.type,1,1) || LOWER(SUBSTRING(fr.type,2)) AS type,\n",
    "        DATE(fr.startdate) AS startdate,\n",
    "        DATE(fr.enddate)   AS enddate,\n",
    "        fc.payment_method\n",
    "      FROM opg_sirius_prod.fee_reduction fr\n",
    "      JOIN opg_sirius_prod.finance_client fc\n",
    "        ON fc.id = fr.finance_client_id\n",
    "       AND fc.glueexporteddate = DATE('{run_date}')\n",
    "      JOIN (\n",
    "        SELECT\n",
    "          MAX(id)           AS id,\n",
    "          finance_client_id\n",
    "        FROM opg_sirius_prod.fee_reduction\n",
    "        WHERE enddate           >= DATE('{run_date}')\n",
    "          AND startdate         <= DATE('{run_date}')\n",
    "          AND deleted            = FALSE\n",
    "          AND glueexporteddate   = DATE('{run_date}')\n",
    "        GROUP BY finance_client_id\n",
    "      ) latest ON latest.id = fr.id\n",
    "      WHERE fr.glueexporteddate = DATE('{run_date}')\n",
    "    )\n",
    "    SELECT\n",
    "      c.glueexporteddate,\n",
    "      c.caserecnumber            AS casenumber,\n",
    "      c.uid                      AS siriusid,\n",
    "      (\n",
    "        SELECT supervisionlevel\n",
    "        FROM opg_sirius_prod.supervision_level_log sll\n",
    "        WHERE sll.order_id         = c.id\n",
    "          AND sll.glueexporteddate = DATE('{run_date}')\n",
    "        ORDER BY sll.appliesfrom DESC\n",
    "        LIMIT 1\n",
    "      ) AS casesupervisionlevel,\n",
    "      p.risk_score               AS CREC,\n",
    "      c.casesubtype              AS orderType,\n",
    "      c.orderdate                AS ordermadedate,\n",
    "      c.orderstatus              AS orderStatus,\n",
    "      afr.type                   AS feereductiontype,\n",
    "      p.dob,\n",
    "      CASE\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) < 0 THEN 121\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) > 120 THEN 121\n",
    "        ELSE ROUND(DATE_DIFF('day', p.dob, p.createddate) / 365.25)\n",
    "      END AS age_in_years\n",
    "    FROM opg_sirius_prod.persons p\n",
    "    JOIN opg_sirius_prod.cases c\n",
    "      ON p.id                   = c.client_id\n",
    "     AND c.glueexporteddate     = DATE('{run_date}')\n",
    "    LEFT JOIN active_fee_reductions afr\n",
    "      ON afr.client_id          = p.id\n",
    "    WHERE c.orderstatus IN ('OPEN','ACTIVE','DUPLICATE')\n",
    "      AND p.glueexporteddate     = DATE('{run_date}')\n",
    "    ORDER BY c.orderdate;\n",
    "    \"\"\"\n",
    "    return pydbtools.read_sql_query(query)\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    \"\"\"\n",
    "    Return a list of datetime objects for each month-start\n",
    "    from start_month to end_month inclusive.\n",
    "    \"\"\"\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    \"\"\"Return the last day of dt's month as 'YYYY-MM-DD'.\"\"\"\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    return dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "def export_monthly_reports(first_month: str, last_month: str, output_base=\"output\"):\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    excel_filename = f\"cases_{clean_first}_to_{clean_last}.xlsx\"\n",
    "    excel_path = os.path.join(output_base, excel_filename)    \n",
    "    clear_directory(excel_path)\n",
    "    \n",
    "    # List to accumulate each month's DataFrame\n",
    "    all_months = []\n",
    "\n",
    "    # Create Excel workbook and write each month's sheet\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        for dt in months:\n",
    "            month_tag = dt.strftime(\"%Y-%m\")\n",
    "            run_date = last_day_of_month(dt)\n",
    "\n",
    "            # Fetch data for this month-end\n",
    "            df = fetch_cases_for_date(run_date)\n",
    "\n",
    "            # Tag the DataFrame with its month, then collect it\n",
    "            df[\"month\"] = month_tag\n",
    "            all_months.append(df)\n",
    "\n",
    "            # Save CSV for this month\n",
    "            month_folder = os.path.join(output_base, month_tag)\n",
    "            os.makedirs(month_folder, exist_ok=True)\n",
    "            csv_path = os.path.join(month_folder, f\"cases_{month_tag}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "            # Add to Excel workbook\n",
    "            df.to_excel(writer, sheet_name=month_tag, index=False)\n",
    "\n",
    "            print(f\"→ Saved CSV for {month_tag}: {csv_path}\")\n",
    "\n",
    "        print(f\"→ Combined Excel workbook saved at: {excel_path}\")\n",
    "\n",
    "    # After all sheets are written, concatenate & export one big CSV\n",
    "    if all_months:\n",
    "        combined_df = pd.concat(all_months, ignore_index=True)\n",
    "        combined_csv_path = os.path.join(\n",
    "            output_base,\n",
    "            f\"all_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "        )\n",
    "        combined_df.to_csv(combined_csv_path, index=False)\n",
    "        print(f\"→ Combined CSV for all months saved at: {combined_csv_path}\")\n",
    "        \n",
    "\n",
    "def calculate_monthly_active_cases(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month between first_month and last_month (inclusive), fetch the data,\n",
    "    filter to ACTIVE cases, then aggregate unique casenumber counts by orderType.\n",
    "    Writes a CSV 'monthly_active_cases_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # List to collect each month's summary\n",
    "    summaries = []\n",
    "\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date = last_day_of_month(dt)\n",
    "\n",
    "        # Fetch data for this month-end\n",
    "        df = fetch_cases_for_date(run_date)\n",
    "\n",
    "        # Keep only ACTIVE cases\n",
    "        df_active = df[df[\"orderstatus\"] == \"ACTIVE\"].copy()\n",
    "        if df_active.empty:\n",
    "            # still record zero counts for completeness\n",
    "            summaries.append(\n",
    "                pd.DataFrame([{\"month\": month_tag, \"orderType\": None, \"active_case_count\": 0}])\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Tag with month for grouping\n",
    "        df_active[\"month\"] = month_tag\n",
    "\n",
    "        # Aggregate unique casenumbers per orderType\n",
    "        summary = (\n",
    "            df_active\n",
    "            .groupby([\"month\", \"ordertype\"])[\"casenumber\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"active_case_count\")\n",
    "        )\n",
    "        summaries.append(summary)\n",
    "\n",
    "        print(f\"→ Aggregated ACTIVE cases for {month_tag}\")\n",
    "\n",
    "    # Combine all month summaries\n",
    "    result_df = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    # Fill any missing orderTypes/months with zeros if you want full matrix:\n",
    "    # pivot = result_df.pivot_table(index=\"month\", columns=\"orderType\",\n",
    "    #                               values=\"active_case_count\", fill_value=0).reset_index()\n",
    "\n",
    "    # Write out CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_active_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    result_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly ACTIVE cases CSV saved at: {out_csv}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Forecasting Active Caseloads:\n",
    "\n",
    "## entered: count of cases newly appearing in the active caseload each month\n",
    "\n",
    "## exited: count of cases that dropped out since the prior month\n",
    "\n",
    "def calculate_monthly_flow(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month from first_month to last_month (inclusive),\n",
    "    snapshot the set of active casenumbers, then compare to the prior month\n",
    "    to count how many entered and exited the active caseload.\n",
    "    Writes 'monthly_flow_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the flow DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare snapshots dict: { \"YYYY-MM\": set_of_casenumbers }\n",
    "    snapshots = {}\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date  = last_day_of_month(dt)\n",
    "        df        = fetch_cases_for_date(run_date)\n",
    "        # Only unique casenumbers\n",
    "        snapshots[month_tag] = set(df[\"casenumber\"].unique())\n",
    "        print(f\"→ Snapshot for {month_tag}: {len(snapshots[month_tag])} active cases\")\n",
    "\n",
    "    # Build flow records\n",
    "    flow_records = []\n",
    "    prev_month = None\n",
    "    for month in sorted(snapshots):\n",
    "        current = snapshots[month]\n",
    "        if prev_month is None:\n",
    "            # First month: all are \"new\", none have \"exited\"\n",
    "            flow_records.append({\n",
    "                \"month\": month,\n",
    "                \"entered\": len(current),\n",
    "                \"exited\":  0\n",
    "            })\n",
    "        else:\n",
    "            prev = snapshots[prev_month]\n",
    "            entered = current - prev\n",
    "            exited  = prev - current\n",
    "            flow_records.append({\n",
    "                \"month\":  month,\n",
    "                \"entered\": len(entered),\n",
    "                \"exited\":  len(exited)\n",
    "            })\n",
    "        prev_month = month\n",
    "\n",
    "    # Create DataFrame and write CSV\n",
    "    flow_df = pd.DataFrame(flow_records)\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_flow_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    flow_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly flow CSV saved at: {out_csv}\")\n",
    "\n",
    "    return flow_df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Combines granular 1-year and custom-bin versions.\n",
    "    - Default: 1-year bins 0-119 with optional unknown-age redistribution.\n",
    "    - Custom: pass age_bins & age_labels for coarse bins.\n",
    "\n",
    "    Returns flows_df, age_rates_df and writes two CSVs to output_base.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins = list(range(0, 121))\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]\n",
    "\n",
    "    months = generate_month_list(first_month, last_month)\n",
    "    flow_records = []\n",
    "    age_rate_records = []\n",
    "\n",
    "    for dt in months:\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        df_cur = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "\n",
    "        set_cur = set(df_cur[\"casenumber\"])\n",
    "        set_prev = set(df_prev[\"casenumber\"])\n",
    "        entered_set = set_cur - set_prev\n",
    "        exited_set  = set_prev - set_cur\n",
    "\n",
    "        flow_records.append({\"month\": tag, \"entered\": len(entered_set), \"exited\": len(exited_set)})\n",
    "\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited_set)].copy()\n",
    "        df_in   = df_cur [df_cur [\"casenumber\"].isin(entered_set)].copy()\n",
    "        df_base = df_prev.copy()\n",
    "\n",
    "        for df_ in (df_term, df_in, df_base):\n",
    "            df_[\"age_group\"] = pd.cut(\n",
    "                df_[\"age_in_years\"], bins=age_bins, labels=age_labels, right=False, include_lowest=True\n",
    "            )\n",
    "\n",
    "        in_counts = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        unknown = df_in[\"age_group\"].isna().sum()\n",
    "        if redistribute_unknown_age and unknown > 0:\n",
    "            total_known = in_counts.sum()\n",
    "            props = (in_counts / total_known) if total_known > 0 else pd.Series(1/len(age_labels), index=age_labels)\n",
    "            in_counts += (props * unknown).round().astype(int)\n",
    "\n",
    "        ter_counts  = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "\n",
    "        for grp in age_labels:\n",
    "            active = int(base_counts[grp])\n",
    "            term   = int(ter_counts[grp])\n",
    "            ent    = int(in_counts[grp])\n",
    "            rate   = round(term/active, 4) if active else 0.0\n",
    "            age_rate_records.append({\n",
    "                \"month\": tag,\n",
    "                \"age_group\": grp,\n",
    "                \"active_count\": active,\n",
    "                \"entered\": ent,\n",
    "                \"terminations\": term,\n",
    "                \"termination_rate\": rate\n",
    "            })\n",
    "\n",
    "    flows_df = pd.DataFrame(flow_records)\n",
    "    ages_df  = pd.DataFrame(age_rate_records)\n",
    "\n",
    "    flows_df.to_csv(os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "    ages_df .to_csv(os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "\n",
    "    return flows_df, ages_df\n",
    "\n",
    "\n",
    "def forecast_with_pi(\n",
    "    flows_df: pd.DataFrame,\n",
    "    periods: int = 1,\n",
    "    alpha: float = 0.05,\n",
    "    seasonal_periods: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecast monthly new orders with 95% prediction intervals.\n",
    "    Falls back to trend-only if insufficient data for seasonality.\n",
    "    \"\"\"\n",
    "    ts = flows_df.set_index(pd.to_datetime(flows_df['month']))['entered'].resample('ME').sum()\n",
    "    nobs = len(ts)\n",
    "    if seasonal_periods and nobs >= 2 * seasonal_periods:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "    else:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "    fit = model.fit(optimized=True)\n",
    "    mu = fit.forecast(periods)\n",
    "    resid = fit.resid.dropna()\n",
    "    sigma = resid.std()\n",
    "    z = abs(pd.Series(resid).quantile([alpha/2, 1-alpha/2]).iloc[1])\n",
    "    lower = mu - z * sigma\n",
    "    upper = mu + z * sigma\n",
    "    return pd.DataFrame({'mean': mu, 'lower': lower, 'upper': upper})\n",
    "\n",
    "\n",
    "def distribute_pi_by_age(\n",
    "    pi_df: pd.DataFrame,\n",
    "    ages_df: pd.DataFrame,\n",
    "    weight_years: tuple[int, int] # = (start_year, end_year)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Allocate forecast mean and PI bounds by age group per historical proportions.\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    hist = hist[hist['month'].dt.year.between(*weight_years)]\n",
    "    dist = hist.groupby('age_group')['entered'].sum() / hist['entered'].sum()\n",
    "\n",
    "    rows = []\n",
    "    for m, row in pi_df.iterrows():\n",
    "        for age, p in dist.items():\n",
    "            rows.append({\n",
    "                'month': m.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'mean':   row['mean'] * p,\n",
    "                'lower':  row['lower'] * p,\n",
    "                'upper':  row['upper'] * p\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def forecast_age_specific_active(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts active caseload by age by separately forecasting entries and termination rates.\n",
    "\n",
    "    - Fits a time series to each age_group's 'entered' and 'termination_rate'.\n",
    "    - Forecasts both series for `periods` months.\n",
    "    - Iteratively projects: active[t] = active[t-1] * (1 - term_rate[t]) + entered[t].\n",
    "    \"\"\"\n",
    "    # Pivot historical series\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts = hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "\n",
    "    # Forecast containers\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "\n",
    "    for age in entered_ts.columns:\n",
    "        # Prepare series\n",
    "        series_e = entered_ts[age].resample('ME').sum()\n",
    "        series_t = termrate_ts[age].resample('ME').mean()\n",
    "        # Entry forecast\n",
    "        if len(series_e.dropna()) >= 2 * seasonal_periods:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal=None)\n",
    "        fit_e = m_e.fit(optimized=True)\n",
    "        entered_fc[age] = fit_e.forecast(periods)\n",
    "        # Termination rate forecast\n",
    "        if len(series_t.dropna()) >= 2 * seasonal_periods:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal=None)\n",
    "        fit_t = m_t.fit(optimized=True)\n",
    "        termrate_fc[age] = fit_t.forecast(periods)\n",
    "\n",
    "    # Starting active counts\n",
    "    last = hist[hist['month'] == hist['month'].max()].set_index('age_group')['active_count']\n",
    "    active_prev = last.astype(float)\n",
    "\n",
    "    records = []\n",
    "    months = pd.date_range(\n",
    "        start=entered_ts.index.max() + pd.offsets.MonthBegin(1),\n",
    "        periods=periods, freq='ME'\n",
    "    )\n",
    "\n",
    "    for i, month in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr  = termrate_fc[age].iloc[i]\n",
    "            ret = 1 - tr if tr >= 0 else 1.0\n",
    "            act = active_prev[age] * (ret) + ent\n",
    "            records.append({\n",
    "                'month': month.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'active_forecast': act\n",
    "            })\n",
    "            active_prev[age] = act\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forecast_age_specific_active_with_components(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts by age: active, entered, term rate, retention = 1-term_rate.\n",
    "    Returns ['month','age_group','entered_forecast','term_rate_forecast','retention_rate','active_forecast']\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts= hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "    for age in entered_ts.columns:\n",
    "        se = entered_ts[age].resample('ME').sum()\n",
    "        st = termrate_ts[age].resample('ME').mean()\n",
    "        me = ExponentialSmoothing(se, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(se.dropna())>=2*seasonal_periods else ExponentialSmoothing(se, trend='add', seasonal=None)\n",
    "        fe = me.fit(optimized=True).forecast(periods)\n",
    "        mt = ExponentialSmoothing(st, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(st.dropna())>=2*seasonal_periods else ExponentialSmoothing(st, trend='add', seasonal=None)\n",
    "        ft = mt.fit(optimized=True).forecast(periods)\n",
    "        entered_fc[age] = fe\n",
    "        termrate_fc[age] = ft\n",
    "    last = hist[hist['month']==hist['month'].max()].set_index('age_group')['active_count'].astype(float)\n",
    "    active_prev = last.copy()\n",
    "    records = []\n",
    "    months = pd.date_range(start=entered_ts.index.max()+pd.offsets.MonthBegin(1), periods=periods, freq='M')\n",
    "    for i, mo in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr = termrate_fc[age].iloc[i]\n",
    "            ret = 1 - tr if tr >= 0 else 1.0\n",
    "            act = active_prev[age] * ret + ent\n",
    "            records.append({'month': mo.strftime('%Y-%m'), 'age_group': age, 'entered_forecast': ent, 'term_rate_forecast': tr, 'retention_rate': ret, 'active_forecast': act})\n",
    "            active_prev[age] = act\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_age_specific_naive(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Naive age-specific forecast using last year's values:\n",
    "    - For each forecast month, use the same month one year ago to pull:\n",
    "        * base_active = active_count_{t-12}\n",
    "        * entries_naive = entered_{t-12}\n",
    "        * term_rate_naive = termination_rate_{t-12}\n",
    "    - Compute retention_rate = 1 - term_rate_naive\n",
    "    - Forecast active_naive = base_active * retention_rate + entries_naive\n",
    "    Returns ['month','age_group','entries_naive','term_rate_naive','retention_rate','active_naive'] for each age_group and forecast month.\n",
    "    \"\"\"\n",
    "    # Prepare historical lookup\n",
    "    hist = ages_df.copy()\n",
    "    hist['month_dt'] = pd.to_datetime(hist['month'], format='%Y-%m')\n",
    "    # build dicts by (age_group, month->values)\n",
    "    entries_map = {\n",
    "        (row['age_group'], row['month_dt']): row['entered']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    term_map = {\n",
    "        (row['age_group'], row['month_dt']): row['termination_rate']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    active_map = {\n",
    "        (row['age_group'], row['month_dt']): row['active_count']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    # Determine forecast months\n",
    "    last_month = hist['month_dt'].max()\n",
    "    months = pd.date_range(start=last_month + pd.offsets.MonthBegin(1), periods=periods, freq='MS')\n",
    "    records = []\n",
    "    for mo in months:\n",
    "        ref = mo - relativedelta(years=1)\n",
    "        for age in hist['age_group'].unique():\n",
    "            base_active = active_map.get((age, ref), 0)\n",
    "            entries_naive = entries_map.get((age, ref), 0)\n",
    "            tr = term_map.get((age, ref), 0.0)\n",
    "            retention = 1 - tr if tr >= 0 else 1.0\n",
    "            act_naive = base_active * retention + entries_naive\n",
    "            records.append({\n",
    "                'month': mo.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'entries_naive': entries_naive,\n",
    "                'term_rate_naive': tr,\n",
    "                'retention_rate': retention,\n",
    "                'active_naive': act_naive,\n",
    "                'termination_rate'\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start_year = 2023\n",
    "#     end_year = 2025\n",
    "#     start_month = \"2023-06\"\n",
    "#     end_month = \"2025-06\"\n",
    "\n",
    "#     # Calculate historical flows and age rates\n",
    "#     flows, ages = calculate_yearonyear_flows_and_age_rates(\n",
    "#         start_month, end_month,\n",
    "#         redistribute_unknown_age=True\n",
    "#     )\n",
    "\n",
    "    # # Forecast total new orders with prediction intervals\n",
    "    # pi = forecast_with_pi(flows, periods=12)\n",
    "    # # Distribute PI by age\n",
    "    # pi_age = distribute_pi_by_age(pi, ages, weight_years=(start_year, end_year))\n",
    "    # Forecast active caseload by age\n",
    "    # active_proj = forecast_age_specific_active(ages, periods=12)\n",
    "\n",
    "    # # Component forecasts: entries, termination rate, retention, active\n",
    "    # comp_df = forecast_age_specific_active_with_components(ages, periods=12)\n",
    "\n",
    "    # # Convert age_group to numeric and sort by age_group then month\n",
    "    # comp_df['age_group'] = comp_df['age_group'].astype(int)\n",
    "    # comp_df_sorted = comp_df.sort_values(['month', 'age_group'])\n",
    "\n",
    "    # Print the sorted table\n",
    "    # print(comp_df_sorted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydbtools\n",
    "\n",
    "import os\n",
    "import calendar\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import pydbtools\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import botocore\n",
    "import s3fs\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "# Configure logging\n",
    "import warnings\n",
    "# Suppress statsmodels AIC/BIC divide-by-zero runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*divide by zero encountered in log.*\")\n",
    "#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Disable logging output\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "def parse_month(month_str: str) -> datetime:\n",
    "    \"\"\"Parse 'YYYY-MM' to datetime.\"\"\"\n",
    "    result = datetime.strptime(month_str.strip().strip(\"'\\\"\"), \"%Y-%m\")\n",
    "    logging.debug(f\"parse_month: parsed '{month_str}' to {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def clear_directory(path):\n",
    "    logging.info(f\"clear_directory: clearing path {path}\")\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "                logging.debug(f\"Deleted file {file_path}\")\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "                logging.debug(f\"Deleted directory {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    logging.info(f\"fetch_cases_for_date: fetching data for {run_date}\")\n",
    "    query = f\"...\"  # trimmed for brevity\n",
    "    df = pydbtools.read_sql_query(query)\n",
    "    logging.info(f\"fetch_cases_for_date: returned {len(df)} rows for {run_date}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    logging.info(f\"generate_month_list: from {start_month} to {end_month}\")\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        logging.debug(f\"Added month {current}\")\n",
    "        current += relativedelta(months=1)\n",
    "    logging.info(f\"Generated {len(months)} months\")\n",
    "    return months\n",
    "\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    result = dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "    logging.debug(f\"last_day_of_month: for {dt} result {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def fetch_cases_for_date(run_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch all cases & their fee reductions for the given run_date (YYYY-MM-DD)\n",
    "    using pydbtools.read_sql_query, which returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    WITH active_fee_reductions AS (\n",
    "      SELECT\n",
    "        fc.client_id,\n",
    "        SUBSTRING(fr.type,1,1) || LOWER(SUBSTRING(fr.type,2)) AS type,\n",
    "        DATE(fr.startdate) AS startdate,\n",
    "        DATE(fr.enddate)   AS enddate,\n",
    "        fc.payment_method\n",
    "      FROM opg_sirius_prod.fee_reduction fr\n",
    "      JOIN opg_sirius_prod.finance_client fc\n",
    "        ON fc.id = fr.finance_client_id\n",
    "       AND fc.glueexporteddate = DATE('{run_date}')\n",
    "      JOIN (\n",
    "        SELECT\n",
    "          MAX(id)           AS id,\n",
    "          finance_client_id\n",
    "        FROM opg_sirius_prod.fee_reduction\n",
    "        WHERE enddate           >= DATE('{run_date}')\n",
    "          AND startdate         <= DATE('{run_date}')\n",
    "          AND deleted            = FALSE\n",
    "          AND glueexporteddate   = DATE('{run_date}')\n",
    "        GROUP BY finance_client_id\n",
    "      ) latest ON latest.id = fr.id\n",
    "      WHERE fr.glueexporteddate = DATE('{run_date}')\n",
    "    )\n",
    "    SELECT\n",
    "      c.glueexporteddate,\n",
    "      c.caserecnumber            AS casenumber,\n",
    "      c.uid                      AS siriusid,\n",
    "      (\n",
    "        SELECT supervisionlevel\n",
    "        FROM opg_sirius_prod.supervision_level_log sll\n",
    "        WHERE sll.order_id         = c.id\n",
    "          AND sll.glueexporteddate = DATE('{run_date}')\n",
    "        ORDER BY sll.appliesfrom DESC\n",
    "        LIMIT 1\n",
    "      ) AS casesupervisionlevel,\n",
    "      p.risk_score               AS CREC,\n",
    "      c.casesubtype              AS orderType,\n",
    "      c.orderdate                AS ordermadedate,\n",
    "      c.orderstatus              AS orderStatus,\n",
    "      afr.type                   AS feereductiontype,\n",
    "      p.dob,\n",
    "      CASE\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) < 0 THEN 121\n",
    "        WHEN FLOOR(DATE_DIFF('day', p.dob, p.createddate) / 365.25) > 120 THEN 121\n",
    "        ELSE ROUND(DATE_DIFF('day', p.dob, p.createddate) / 365.25)\n",
    "      END AS age_in_years\n",
    "    FROM opg_sirius_prod.persons p\n",
    "    JOIN opg_sirius_prod.cases c\n",
    "      ON p.id                   = c.client_id\n",
    "     AND c.glueexporteddate     = DATE('{run_date}')\n",
    "    LEFT JOIN active_fee_reductions afr\n",
    "      ON afr.client_id          = p.id\n",
    "    WHERE c.orderstatus IN ('OPEN','ACTIVE','DUPLICATE')\n",
    "      AND p.glueexporteddate     = DATE('{run_date}')\n",
    "    ORDER BY c.orderdate;\n",
    "    \"\"\"\n",
    "    return pydbtools.read_sql_query(query)\n",
    "\n",
    "\n",
    "def generate_month_list(start_month: str, end_month: str):\n",
    "    \"\"\"\n",
    "    Return a list of datetime objects for each month-start\n",
    "    from start_month to end_month inclusive.\n",
    "    \"\"\"\n",
    "    start_dt = parse_month(start_month)\n",
    "    end_dt = parse_month(end_month)\n",
    "    if start_dt > end_dt:\n",
    "        raise ValueError(f\"Start month ({start_month}) is after end month ({end_month})\")\n",
    "\n",
    "    months = []\n",
    "    current = start_dt\n",
    "    while current <= end_dt:\n",
    "        months.append(current)\n",
    "        current += relativedelta(months=1)\n",
    "    return months\n",
    "\n",
    "def last_day_of_month(dt: datetime) -> str:\n",
    "    \"\"\"Return the last day of dt's month as 'YYYY-MM-DD'.\"\"\"\n",
    "    day = calendar.monthrange(dt.year, dt.month)[1]\n",
    "    return dt.replace(day=day).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "def export_monthly_reports(first_month: str, last_month: str, output_base=\"output\"):\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    excel_filename = f\"cases_{clean_first}_to_{clean_last}.xlsx\"\n",
    "    excel_path = os.path.join(output_base, excel_filename)    \n",
    "    clear_directory(excel_path)\n",
    "    \n",
    "    # List to accumulate each month's DataFrame\n",
    "    all_months = []\n",
    "\n",
    "    # Create Excel workbook and write each month's sheet\n",
    "    with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "        for dt in months:\n",
    "            month_tag = dt.strftime(\"%Y-%m\")\n",
    "            run_date = last_day_of_month(dt)\n",
    "\n",
    "            # Fetch data for this month-end\n",
    "            df = fetch_cases_for_date(run_date)\n",
    "\n",
    "            # Tag the DataFrame with its month, then collect it\n",
    "            df[\"month\"] = month_tag\n",
    "            all_months.append(df)\n",
    "\n",
    "            # Save CSV for this month\n",
    "            month_folder = os.path.join(output_base, month_tag)\n",
    "            os.makedirs(month_folder, exist_ok=True)\n",
    "            csv_path = os.path.join(month_folder, f\"cases_{month_tag}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "\n",
    "            # Add to Excel workbook\n",
    "            df.to_excel(writer, sheet_name=month_tag, index=False)\n",
    "\n",
    "            print(f\"→ Saved CSV for {month_tag}: {csv_path}\")\n",
    "\n",
    "        print(f\"→ Combined Excel workbook saved at: {excel_path}\")\n",
    "\n",
    "    # After all sheets are written, concatenate & export one big CSV\n",
    "    if all_months:\n",
    "        combined_df = pd.concat(all_months, ignore_index=True)\n",
    "        combined_csv_path = os.path.join(\n",
    "            output_base,\n",
    "            f\"all_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "        )\n",
    "        combined_df.to_csv(combined_csv_path, index=False)\n",
    "        print(f\"→ Combined CSV for all months saved at: {combined_csv_path}\")\n",
    "        \n",
    "\n",
    "def calculate_monthly_active_cases(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month between first_month and last_month (inclusive), fetch the data,\n",
    "    filter to ACTIVE cases, then aggregate unique casenumber counts by orderType.\n",
    "    Writes a CSV 'monthly_active_cases_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare output directory\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "    # List to collect each month's summary\n",
    "    summaries = []\n",
    "\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date = last_day_of_month(dt)\n",
    "\n",
    "        # Fetch data for this month-end\n",
    "        df = fetch_cases_for_date(run_date)\n",
    "\n",
    "        # Keep only ACTIVE cases\n",
    "        df_active = df[df[\"orderstatus\"] == \"ACTIVE\"].copy()\n",
    "        if df_active.empty:\n",
    "            # still record zero counts for completeness\n",
    "            summaries.append(\n",
    "                pd.DataFrame([{\"month\": month_tag, \"orderType\": None, \"active_case_count\": 0}])\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Tag with month for grouping\n",
    "        df_active[\"month\"] = month_tag\n",
    "\n",
    "        # Aggregate unique casenumbers per orderType\n",
    "        summary = (\n",
    "            df_active\n",
    "            .groupby([\"month\", \"ordertype\"])[\"casenumber\"]\n",
    "            .nunique()\n",
    "            .reset_index(name=\"active_case_count\")\n",
    "        )\n",
    "        summaries.append(summary)\n",
    "\n",
    "        print(f\"→ Aggregated ACTIVE cases for {month_tag}\")\n",
    "\n",
    "    # Combine all month summaries\n",
    "    result_df = pd.concat(summaries, ignore_index=True)\n",
    "\n",
    "    # Fill any missing orderTypes/months with zeros if you want full matrix:\n",
    "    # pivot = result_df.pivot_table(index=\"month\", columns=\"orderType\",\n",
    "    #                               values=\"active_case_count\", fill_value=0).reset_index()\n",
    "\n",
    "    # Write out CSV\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_active_cases_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    result_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly ACTIVE cases CSV saved at: {out_csv}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Forecasting Active Caseloads:\n",
    "\n",
    "## entered: count of cases newly appearing in the active caseload each month\n",
    "\n",
    "## exited: count of cases that dropped out since the prior month\n",
    "\n",
    "def calculate_monthly_flow(first_month: str, last_month: str, output_base=\"output\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each month from first_month to last_month (inclusive),\n",
    "    snapshot the set of active casenumbers, then compare to the prior month\n",
    "    to count how many entered and exited the active caseload.\n",
    "    Writes 'monthly_flow_<first>_to_<last>.csv' under output_base,\n",
    "    and returns the flow DataFrame.\n",
    "    \"\"\"\n",
    "    # Clean inputs\n",
    "    clean_first = first_month.strip().strip(\"'\\\"\")\n",
    "    clean_last  = last_month.strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Generate all months\n",
    "    months = generate_month_list(clean_first, clean_last)\n",
    "    if not months:\n",
    "        print(\"No months in range; nothing to do.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Prepare snapshots dict: { \"YYYY-MM\": set_of_casenumbers }\n",
    "    snapshots = {}\n",
    "    for dt in months:\n",
    "        month_tag = dt.strftime(\"%Y-%m\")\n",
    "        run_date  = last_day_of_month(dt)\n",
    "        df        = fetch_cases_for_date(run_date)\n",
    "        # Only unique casenumbers\n",
    "        snapshots[month_tag] = set(df[\"casenumber\"].unique())\n",
    "        print(f\"→ Snapshot for {month_tag}: {len(snapshots[month_tag])} active cases\")\n",
    "\n",
    "    # Build flow records\n",
    "    flow_records = []\n",
    "    prev_month = None\n",
    "    for month in sorted(snapshots):\n",
    "        current = snapshots[month]\n",
    "        if prev_month is None:\n",
    "            # First month: all are \"new\", none have \"exited\"\n",
    "            flow_records.append({\n",
    "                \"month\": month,\n",
    "                \"entered\": len(current),\n",
    "                \"exited\":  0\n",
    "            })\n",
    "        else:\n",
    "            prev = snapshots[prev_month]\n",
    "            entered = current - prev\n",
    "            exited  = prev - current\n",
    "            flow_records.append({\n",
    "                \"month\":  month,\n",
    "                \"entered\": len(entered),\n",
    "                \"exited\":  len(exited)\n",
    "            })\n",
    "        prev_month = month\n",
    "\n",
    "    # Create DataFrame and write CSV\n",
    "    flow_df = pd.DataFrame(flow_records)\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    out_csv = os.path.join(\n",
    "        output_base,\n",
    "        f\"monthly_flow_{clean_first}_to_{clean_last}.csv\"\n",
    "    )\n",
    "    flow_df.to_csv(out_csv, index=False)\n",
    "    print(f\"→ Monthly flow CSV saved at: {out_csv}\")\n",
    "\n",
    "    return flow_df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_yearonyear_flows_and_age_rates(\n",
    "    first_month: str,\n",
    "    last_month: str,\n",
    "    output_base: str = \"output\",\n",
    "    redistribute_unknown_age: bool = False,\n",
    "    age_bins: tuple = None,\n",
    "    age_labels: tuple = None\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    logging.info(f\"Calculating year-on-year flows and age rates from {first_month} to {last_month}, redistribute_unknown_age={redistribute_unknown_age}\")\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    if age_bins is None or age_labels is None:\n",
    "        age_bins = list(range(0, 121))\n",
    "        age_labels = [str(a) for a in age_bins[:-1]]\n",
    "    flow_records = []\n",
    "    age_rate_records = []\n",
    "    for dt in generate_month_list(first_month, last_month):\n",
    "        prev_dt = dt - relativedelta(years=1)\n",
    "        if prev_dt < parse_month(first_month):\n",
    "            continue\n",
    "        tag = dt.strftime(\"%Y-%m\")\n",
    "        logging.info(f\"Processing month {tag}\")\n",
    "        df_cur = fetch_cases_for_date(last_day_of_month(dt))\n",
    "        df_prev = fetch_cases_for_date(last_day_of_month(prev_dt))\n",
    "        set_cur = set(df_cur[\"casenumber\"])\n",
    "        set_prev = set(df_prev[\"casenumber\"])\n",
    "        entered_set = set_cur - set_prev\n",
    "        exited_set = set_prev - set_cur\n",
    "        logging.debug(f\"Month {tag}: entered={len(entered_set)}, exited={len(exited_set)}\")\n",
    "        flow_records.append({\"month\": tag, \"entered\": len(entered_set), \"exited\": len(exited_set)})\n",
    "        df_term = df_prev[df_prev[\"casenumber\"].isin(exited_set)].copy()\n",
    "        df_in = df_cur[df_cur[\"casenumber\"].isin(entered_set)].copy()\n",
    "        df_base = df_prev.copy()\n",
    "        for df_ in (df_term, df_in, df_base):\n",
    "            df_[\"age_group\"] = pd.cut(\n",
    "                df_[\"age_in_years\"], bins=age_bins, labels=age_labels,\n",
    "                right=False, include_lowest=True\n",
    "            )\n",
    "        in_counts = df_in.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        unknown = df_in[\"age_group\"].isna().sum()\n",
    "        logging.debug(f\"Unknown age entries: {unknown}\")\n",
    "        if redistribute_unknown_age and unknown > 0:\n",
    "            total_known = in_counts.sum()\n",
    "            props = in_counts / total_known if total_known > 0 else pd.Series([1/len(age_labels)]*len(age_labels), index=age_labels)\n",
    "            alloc = (props * unknown).round().astype(int)\n",
    "            in_counts += alloc\n",
    "            logging.debug(f\"Allocated unknowns: {alloc.to_dict()}\")\n",
    "        ter_counts = df_term.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        base_counts = df_base.groupby(\"age_group\", observed=False)[\"casenumber\"].nunique().reindex(age_labels, fill_value=0)\n",
    "        for grp in age_labels:\n",
    "            active = int(base_counts[grp])\n",
    "            term = int(ter_counts[grp])\n",
    "            ent = int(in_counts[grp])\n",
    "            rate = round(term/active, 4) if active else 0.0\n",
    "            retention = 1 - rate if rate >= 0 else 1.0\n",
    "            age_rate_records.append({\n",
    "                \"month\": tag,\n",
    "                \"age_group\": grp,\n",
    "                \"active_count\": active,\n",
    "                \"entered\": ent,\n",
    "                \"terminations\": term,\n",
    "                \"termination_rate\": rate,\n",
    "                \"retention_rate\": retention\n",
    "            })\n",
    "    flows_df = pd.DataFrame(flow_records)\n",
    "    ages_df = pd.DataFrame(age_rate_records)\n",
    "    flows_df.to_csv(os.path.join(output_base, f\"yearonyear_flows_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "    ages_df.to_csv(os.path.join(output_base, f\"termination_and_entry_rates_by_age_{first_month}_to_{last_month}.csv\"), index=False)\n",
    "    logging.info(\"Completed calculation of year-on-year flows and age rates\")\n",
    "    return flows_df, ages_df\n",
    "\n",
    "\n",
    "# Append current and forecasted tables\n",
    "def get_combined_age_deputyship_table(tbl1, tbl2):\n",
    "    combined = pd.concat(\n",
    "        [tbl1, tbl2],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    return combined\n",
    "        \n",
    "def forecast_with_pi(\n",
    "    flows_df: pd.DataFrame,\n",
    "    periods: int = 1,\n",
    "    alpha: float = 0.05,\n",
    "    seasonal_periods: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecast monthly new orders with 95% prediction intervals.\n",
    "    Falls back to trend-only if insufficient data for seasonality.\n",
    "    \"\"\"\n",
    "    ts = flows_df.set_index(pd.to_datetime(flows_df['month']))['entered'].resample('ME').sum()\n",
    "    nobs = len(ts)\n",
    "    if seasonal_periods and nobs >= 2 * seasonal_periods:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "    else:\n",
    "        model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "    fit = model.fit(optimized=True)\n",
    "    mu = fit.forecast(periods)\n",
    "    resid = fit.resid.dropna()\n",
    "    sigma = resid.std()\n",
    "    z = abs(pd.Series(resid).quantile([alpha/2, 1-alpha/2]).iloc[1])\n",
    "    lower = mu - z * sigma\n",
    "    upper = mu + z * sigma\n",
    "    return pd.DataFrame({'mean': mu, 'lower': lower, 'upper': upper})\n",
    "\n",
    "\n",
    "def distribute_pi_by_age(\n",
    "    pi_df: pd.DataFrame,\n",
    "    ages_df: pd.DataFrame,\n",
    "    weight_years: tuple[int, int] # = (start_year, end_year)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Allocate forecast mean and PI bounds by age group per historical proportions.\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    hist = hist[hist['month'].dt.year.between(*weight_years)]\n",
    "    dist = hist.groupby('age_group')['entered'].sum() / hist['entered'].sum()\n",
    "\n",
    "    rows = []\n",
    "    for m, row in pi_df.iterrows():\n",
    "        for age, p in dist.items():\n",
    "            rows.append({\n",
    "                'month': m.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'mean':   row['mean'] * p,\n",
    "                'lower':  row['lower'] * p,\n",
    "                'upper':  row['upper'] * p\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def forecast_age_specific_active(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts active caseload by age by separately forecasting entries and termination rates.\n",
    "\n",
    "    - Fits a time series to each age_group's 'entered' and 'termination_rate'.\n",
    "    - Forecasts both series for `periods` months.\n",
    "    - Iteratively projects: active[t] = active[t-1] * (1 - term_rate[t]) + entered[t].\n",
    "    \"\"\"\n",
    "    # Pivot historical series\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts = hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "\n",
    "    # Forecast containers\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "\n",
    "    for age in entered_ts.columns:\n",
    "        # Prepare series\n",
    "        series_e = entered_ts[age].resample('ME').sum()\n",
    "        series_t = termrate_ts[age].resample('ME').mean()\n",
    "        # Entry forecast\n",
    "        if len(series_e.dropna()) >= 2 * seasonal_periods:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_e = ExponentialSmoothing(series_e, trend='add', seasonal=None)\n",
    "        fit_e = m_e.fit(optimized=True)\n",
    "        entered_fc[age] = fit_e.forecast(periods)\n",
    "        # Termination rate forecast\n",
    "        if len(series_t.dropna()) >= 2 * seasonal_periods:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        else:\n",
    "            m_t = ExponentialSmoothing(series_t, trend='add', seasonal=None)\n",
    "        fit_t = m_t.fit(optimized=True)\n",
    "        termrate_fc[age] = fit_t.forecast(periods)\n",
    "\n",
    "    # Starting active counts\n",
    "    last = hist[hist['month'] == hist['month'].max()].set_index('age_group')['active_count']\n",
    "    active_prev = last.astype(float)\n",
    "\n",
    "    records = []\n",
    "    months = pd.date_range(\n",
    "        start=entered_ts.index.max() + pd.offsets.MonthBegin(1),\n",
    "        periods=periods, freq='ME'\n",
    "    )\n",
    "\n",
    "    for i, month in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr  = termrate_fc[age].iloc[i]\n",
    "            ret = 1 - tr if tr >= 0 else 1.0\n",
    "            act = active_prev[age] * (ret) + ent\n",
    "            records.append({\n",
    "                'month': month.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'active_forecast': act\n",
    "            })\n",
    "            active_prev[age] = act\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forecast_age_specific_active_with_components(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12,\n",
    "    seasonal_periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Forecasts by age: active, entered, term rate, retention = 1-term_rate.\n",
    "    Returns ['month','age_group','entered_forecast','term_rate_forecast','retention_rate','active_forecast']\n",
    "    \"\"\"\n",
    "    hist = ages_df.copy()\n",
    "    hist['month'] = pd.to_datetime(hist['month'])\n",
    "    entered_ts = hist.pivot(index='month', columns='age_group', values='entered')\n",
    "    termrate_ts= hist.pivot(index='month', columns='age_group', values='termination_rate')\n",
    "    entered_fc = {}\n",
    "    termrate_fc = {}\n",
    "    for age in entered_ts.columns:\n",
    "        se = entered_ts[age].resample('ME').sum()\n",
    "        st = termrate_ts[age].resample('ME').mean()\n",
    "        me = ExponentialSmoothing(se, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(se.dropna())>=2*seasonal_periods else ExponentialSmoothing(se, trend='add', seasonal=None)\n",
    "        fe = me.fit(optimized=True).forecast(periods)\n",
    "        mt = ExponentialSmoothing(st, trend='add', seasonal='add', seasonal_periods=seasonal_periods) if len(st.dropna())>=2*seasonal_periods else ExponentialSmoothing(st, trend='add', seasonal=None)\n",
    "        ft = mt.fit(optimized=True).forecast(periods)\n",
    "        entered_fc[age] = fe\n",
    "        termrate_fc[age] = ft\n",
    "    last = hist[hist['month']==hist['month'].max()].set_index('age_group')['active_count'].astype(float)\n",
    "    active_prev = last.copy()\n",
    "    records = []\n",
    "    months = pd.date_range(start=entered_ts.index.max()+pd.offsets.MonthBegin(1), periods=periods, freq='M')\n",
    "    for i, mo in enumerate(months):\n",
    "        for age in entered_ts.columns:\n",
    "            ent = entered_fc[age].iloc[i]\n",
    "            tr = termrate_fc[age].iloc[i]\n",
    "            ret = 1 - tr if tr >= 0 else 1.0\n",
    "            act = active_prev[age] * ret + ent\n",
    "            records.append({'month': mo.strftime('%Y-%m'), 'age_group': age, 'entered_forecast': ent, 'term_rate_forecast': tr, 'retention_rate': ret, 'active_forecast': act})\n",
    "            active_prev[age] = act\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def forecast_age_specific_naive(\n",
    "    ages_df: pd.DataFrame,\n",
    "    periods: int = 12\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Naive age-specific forecast using last year's values:\n",
    "    - For each forecast month, use the same month one year ago to pull:\n",
    "        * base_active = active_count_{t-1}\n",
    "        * entries_naive = entered_{t-12}\n",
    "        * term_rate_naive = termination_rate_{t-12}\n",
    "    - Compute retention_rate = 1 - term_rate_naive\n",
    "    - Forecast active_naive = base_active * retention_rate + entries_naive\n",
    "    Returns ['month','age_group','entries_naive','term_rate_naive','retention_rate','active_naive'] for each age_group and forecast month.\n",
    "    \"\"\"\n",
    "    # Prepare historical lookup\n",
    "    hist = ages_df.copy()\n",
    "    hist['month_dt'] = pd.to_datetime(hist['month'], format='%Y-%m')\n",
    "    # build dicts by (age_group, month->values)\n",
    "    entries_map = {\n",
    "        (row['age_group'], row['month_dt']): row['entered']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    term_map = {\n",
    "        (row['age_group'], row['month_dt']): row['termination_rate']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    active_map = {\n",
    "        (row['age_group'], row['month_dt']): row['active_count']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    termination_map = {\n",
    "        (row['age_group'], row['month_dt']): row['terminations']\n",
    "        for _, row in hist.iterrows()\n",
    "    }\n",
    "    # Determine forecast months\n",
    "    last_month = hist['month_dt'].max()\n",
    "    months = pd.date_range(start=last_month + pd.offsets.MonthBegin(1), periods=periods, freq='MS')\n",
    "    records = []\n",
    "    for mo in months:\n",
    "        ref = mo - relativedelta(years=1)\n",
    "        for age in hist['age_group'].unique():\n",
    "            base_active = active_map.get((age, ref), 0)\n",
    "            entries_naive = entries_map.get((age, ref), 0)\n",
    "            terminated = termination_map.get((age, ref), 0.0)\n",
    "            tr = term_map.get((age, ref), 0.0)\n",
    "            retention = 1 - tr if tr >= 0 else 1.0\n",
    "            act_naive = base_active * retention + entries_naive\n",
    "            records.append({\n",
    "                'month': mo.strftime('%Y-%m'),\n",
    "                'age_group': age,\n",
    "                'entries_naive': entries_naive,\n",
    "                'term_rate_naive': tr,\n",
    "                'retention_rate': retention,\n",
    "                'active_naive': act_naive,\n",
    "                'termination_rate': tr,\n",
    "                'terminated': terminated\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stop_flow_forecast(ages_df: pd.DataFrame, periods: int = 24) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    “Stop‐flow” forecast:\n",
    "      active_t  = active_{t–1} + entered_{t–12} – terminated_{t–12}\n",
    "    for each age_group, recursively, starting from the last historical month.\n",
    "    \n",
    "    Returns a DataFrame with columns:\n",
    "      month (datetime), age_group, active_forecast (int)\n",
    "    \"\"\"\n",
    "    # 1) Copy and ensure month is a column\n",
    "    df = ages_df.copy()\n",
    "    if 'month' not in df.columns:\n",
    "        # If month is in the index, pull it out\n",
    "        if 'month' in df.index.names:\n",
    "            df = df.reset_index()\n",
    "        else:\n",
    "            raise ValueError(\"Input ages_df must have a 'month' column or index level\")\n",
    "    \n",
    "    # 2) Convert month to datetime flexibly\n",
    "    df['month'] = pd.to_datetime(df['month'])\n",
    "    \n",
    "    # 3) Find the last historical month\n",
    "    last_hist = df['month'].max()\n",
    "    \n",
    "    # 4) Build the list of future months (1..periods ahead)\n",
    "    first_fc = last_hist + relativedelta(months=1)\n",
    "    fc_months = [first_fc + relativedelta(months=i) for i in range(periods)]\n",
    "    \n",
    "    # 5) Seed the \"previous active\" from last historical month\n",
    "    prev_active = (\n",
    "        df[df['month'] == last_hist]\n",
    "        .set_index('age_group')['active_count']\n",
    "        .to_dict()\n",
    "    )\n",
    "    \n",
    "    records = []\n",
    "    age_groups = df['age_group'].unique()\n",
    "    \n",
    "    for m in fc_months:\n",
    "        lag = m - relativedelta(years=1)\n",
    "        for age in age_groups:\n",
    "            a_prev = prev_active.get(age, 0)\n",
    "            \n",
    "            # grab last year's entered/terminated for this age & lag month\n",
    "            row = df[(df['month'] == lag) & (df['age_group'] == age)]\n",
    "            entered = int(row['entered'].iloc[0]) if not row.empty else 0\n",
    "            term    = int(row['terminations'].iloc[0]) if not row.empty else 0\n",
    "            \n",
    "            # stop‐flow formula\n",
    "            a_fc = a_prev + entered - term\n",
    "            \n",
    "            records.append({\n",
    "                'month':           m,\n",
    "                'age_group':       age,\n",
    "                'active_forecast': a_fc\n",
    "            })\n",
    "            prev_active[age] = a_fc  # update for next iteration\n",
    "    \n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Age-Specific Forecasting Overview\n",
    "\n",
    "This module implements two complementary age-specific forecasting approaches:\n",
    "\n",
    "### 1. Component-Based Holt–Winters Forecast\n",
    "\n",
    "1. **Historical Series Extraction**\n",
    "\n",
    "   * For each age group, extract two monthly time series from `ages_df`:\n",
    "\n",
    "     * **Entries**: Number of new deputyships (`entered`) per month.\n",
    "     * **Termination rate**: Fraction of cases closing (`termination_rate`) per month.\n",
    "\n",
    "2. **Fitting Models**\n",
    "\n",
    "   * If at least two full seasonal cycles are present (≥24 months when `seasonal_periods=12`), fit an **additive trend + seasonality** Holt–Winters model; otherwise, fit a **trend-only** model.\n",
    "   * Perform this separately for each age group’s entries and termination-rate series.\n",
    "\n",
    "3. **Forecasting**\n",
    "\n",
    "   * Forecast **`periods`** months ahead for both series, yielding for each future month *t* and age group *a*:\n",
    "\n",
    "     * `entered_fc[a][t]` (predicted new entries)\n",
    "     * `termlate_fc[a][t]` (predicted termination rate)\n",
    "\n",
    "4. **Iterative Projection**\n",
    "\n",
    "   * Start with the last observed active count for each age group:\n",
    "     $\\text{active}_{0,a} = \\text{active\\_count}_{\\text{last month},a}$\n",
    "   * For each forecast month *t* = 1…*periods*:\n",
    "\n",
    "     $$\n",
    "       \\text{retention}_{t,a} = 1 - \\text{termlate\\_fc}[a][t]  \\\\\n",
    "       \\text{active}_{t,a} = \\text{active}_{t-1,a} \\times \\text{retention}_{t,a} + \\text{entered\\_fc}[a][t]\n",
    "     $$\n",
    "   * Survivors carry forward (previous active × retention) plus new entries.\n",
    "\n",
    "### 2. Naïve “Last Year” Benchmark\n",
    "\n",
    "1. **Reference Lookup**\n",
    "\n",
    "   * For each forecast month *t*, look back 12 months (*t*−12) to retrieve:\n",
    "\n",
    "     * `base_active`: observed active count\n",
    "     * `entries_naive`: observed new entries\n",
    "     * `term_rate_naive`: observed termination rate\n",
    "\n",
    "2. **Compute Retention**\n",
    "   $\\text{retention\\_naive} = 1 - \\text{term\\_rate\\_naive}$\n",
    "\n",
    "3. **Project Forward**\n",
    "   $\\text{active\\_naive}_t = \\text{base\\_active} \\times \\text{retention\\_naive} + \\text{entries\\_naive}$\n",
    "\n",
    "This simple year-over-year carry-forward forecast serves as a baseline to evaluate the performance of the more sophisticated Holt–Winters component model.\n",
    "\n",
    "---\n",
    "\n",
    "## Why These Methods?\n",
    "\n",
    "* **Component models** capture both **trends** and **seasonal patterns** separately for inflows and outflows by age.\n",
    "* The **naïve model** provides a straightforward baseline: “repeat what happened same month last year.”\n",
    "\n",
    "By comparing both, you can quantify the added value of trend + seasonality modeling over simple repetition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2023\n",
    "    end_year = 2025\n",
    "    start_month = \"2023-06\"\n",
    "    end_month = \"2025-06\"\n",
    "\n",
    "    # # Calculate historical flows and age rates\n",
    "    # flows, ages = calculate_yearonyear_flows_and_age_rates(\n",
    "    #     start_month, end_month,\n",
    "    #     redistribute_unknown_age=True\n",
    "    # )\n",
    "    # ages_df = ages\n",
    "\n",
    "    \n",
    "    # # Forecast total new orders with prediction intervals\n",
    "    # pi = forecast_with_pi(flows, periods=12)\n",
    "    # # Distribute PI by age\n",
    "    # pi_age = distribute_pi_by_age(pi, ages, weight_years=(start_year, end_year))\n",
    "    # Forecast active caseload by age\n",
    "    #active_proj = forecast_age_specific_active(ages, periods=12)\n",
    "\n",
    "    # Component forecasts: entries, termination rate, retention, active\n",
    "    #comp_df = forecast_age_specific_active_with_components(ages, periods=12)\n",
    "\n",
    "    # Convert age_group to numeric and sort by age_group then month\n",
    "    #comp_df['age_group'] = comp_df['age_group'].astype(int)\n",
    "    #comp_df_sorted = comp_df.sort_values(['age_group', 'month'])\n",
    "    #comp_df_sorted.to_csv(f\"output/comp_df_sorted_{start_year}_{end_year}.csv\")\n",
    "    # Print the sorted table\n",
    "    #print(comp_df_sorted.to_string(index=False))\n",
    "\n",
    "\n",
    "    # 1) Compute 2-year stop-flow forecast\n",
    "    sf_fc = stop_flow_forecast(ages_df, periods=24)\n",
    "    \n",
    "    # 2) Pivot for plotting: month on x‐axis, each age a line\n",
    "    pivot = sf_fc.pivot(index='month', columns='age_group', values='active_forecast')\n",
    "    pivot.index = pd.to_datetime(pivot.index)\n",
    "    \n",
    "    # 3) Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for age, series in pivot.items():\n",
    "        ax.plot(\n",
    "            series.index, series.values,\n",
    "            label=f\"{int(age)} yrs\",\n",
    "            marker='o',\n",
    "            linewidth=2,\n",
    "            alpha=0.8\n",
    "        )\n",
    "    \n",
    "    current_age_specific_deputyship_agg = ages_df.copy()\n",
    "    current_age_specific_deputyship_agg = current_age_specific_deputyship_agg.rename(\n",
    "        columns={\n",
    "            'age_group': 'age',\n",
    "            'active_count': 'active_caseloads',\n",
    "            'entered': 'new_deputyships',\n",
    "            'terminations': 'terminated'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # forecasted_age_specific_deputyship_agg = comp_df_sorted.copy()\n",
    "    # forecasted_age_specific_deputyship_agg = forecasted_age_specific_deputyship_agg.rename(\n",
    "    #     columns={\n",
    "    #         'age_group': 'age',\n",
    "    #         'active_forecast': 'active_caseloads',\n",
    "    #         'entered_forecast': 'new_deputyships',\n",
    "    #         'term_rate_forecast': 'termination_rate',\n",
    "    #         'terminated': 'terminated'\n",
    "    #     }\n",
    "    # )\n",
    "    \n",
    "    forecasted_age_specific_deputyship_agg = sf_fc.copy()\n",
    "    forecasted_age_specific_deputyship_agg = forecasted_age_specific_deputyship_agg.rename(\n",
    "        columns={\n",
    "            'age_group': 'age',\n",
    "            'active_forecast': 'active_caseloads'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Final tforcast and actuals\n",
    "    combined_table = get_combined_age_deputyship_table(current_age_specific_deputyship_agg, forecasted_age_specific_deputyship_agg)\n",
    "    combined_table.to_csv(f\"output/combined_deputyship_{start_year}_{end_year}.csv\")\n",
    "    # Plotting age-specific active caseloads, termination rate, and new deputyships over time\n",
    "    \n",
    "    # Ensure 'month' is datetime\n",
    "    combined_table['month'] = pd.to_datetime(combined_table['month'], format='%Y-%m')\n",
    "    \n",
    "    # Active Caseloads by Age Group\n",
    "    active_pivot = combined_table.pivot(index='month', columns='age', values='active_caseloads')\n",
    "    # fig1, ax1 = plt.subplots()\n",
    "    # active_pivot.plot(ax=ax1)\n",
    "    # ax1.set_title('Active Caseloads by Age Group Over Time')\n",
    "    # ax1.set_xlabel('Month')\n",
    "    # ax1.set_ylabel('Active Caseloads')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # # Termination Rate by Age Group\n",
    "    # term_pivot = combined_table.pivot(index='month', columns='age', values='termination_rate')\n",
    "    # fig2, ax2 = plt.subplots()\n",
    "    # term_pivot.plot(ax=ax2)\n",
    "    # ax2.set_title('Termination Rate by Age Group Over Time')\n",
    "    # ax2.set_xlabel('Month')\n",
    "    # ax2.set_ylabel('Termination Rate')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # # New Deputyships by Age Group\n",
    "    # new_pivot = combined_table.pivot(index='month', columns='age', values='new_deputyships')\n",
    "    # fig3, ax3 = plt.subplots()\n",
    "    # new_pivot.plot(ax=ax3)\n",
    "    # ax3.set_title('New Deputyships by Age Group Over Time')\n",
    "    # ax3.set_xlabel('Month')\n",
    "    # ax3.set_ylabel('New Deputyships')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_table.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# x‐axis: every 2 months, formatted \"Apr 25\"\n",
    "ax.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %y'))\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "ax.set_title('Stop‐Flow Active Caseload Forecast by Age', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Active Caseloads (forecast)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Legend outside\n",
    "ax.legend(\n",
    "    title='Age Group',\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc='upper left',\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Define exactly which ages to show\n",
    "ages_to_plot = [10, 20, 30, 40, 50, 60, 70]\n",
    "\n",
    "# Filter your combined table\n",
    "filtered = combined_table[combined_table['age'].isin(ages_to_plot)]\n",
    "\n",
    "# Pivot to get one series per month\n",
    "active_age_pivot = filtered.pivot(\n",
    "    index='age',\n",
    "    columns='month',\n",
    "    values='active_caseloads'\n",
    ")\n",
    "\n",
    "# Choose a qualitative colormap with enough distinct colors\n",
    "months = active_age_pivot.columns\n",
    "cmap = plt.get_cmap('tab20')                     # 20 distinct colors\n",
    "colors = cmap(np.linspace(0, 1, len(months)))     # pick evenly spaced\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for (month, series), color in zip(active_age_pivot.items(), colors):\n",
    "    ax.plot(\n",
    "        active_age_pivot.index,\n",
    "        series,\n",
    "        marker='o',\n",
    "        alpha=0.85,\n",
    "        label=month.strftime('%b %y'),\n",
    "        color=color,\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# X‐axis only those ages\n",
    "ax.set_xticks(ages_to_plot)\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Labels & title\n",
    "ax.set_xlabel('Age (years)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Active Caseloads', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Active Caseloads by Selected Age Groups', fontsize=14)\n",
    "\n",
    "# Legend outside\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc='upper left',\n",
    "    title='Month',\n",
    "    fontsize=10,\n",
    "    title_fontsize=11,\n",
    "    frameon=False   # remove legend border for a cleaner look\n",
    ")\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.dates import MonthLocator, DateFormatter\n",
    "\n",
    "# Define exactly which ages to plot\n",
    "ages_to_plot = [10, 20, 30, 40, 50, 60, 70]\n",
    "\n",
    "# Filter your combined table\n",
    "filtered = combined_table[combined_table['age'].isin(ages_to_plot)].copy()\n",
    "\n",
    "# Pivot so that each age group is its own series, with month on the index\n",
    "active_month_pivot = filtered.pivot(\n",
    "    index='month',\n",
    "    columns='age',\n",
    "    values='active_caseloads'\n",
    ")\n",
    "\n",
    "# Ensure the index is datetime for proper formatting\n",
    "active_month_pivot.index = pd.to_datetime(active_month_pivot.index)\n",
    "\n",
    "# Choose a qualitative colormap with distinct colors for each age\n",
    "ages = active_month_pivot.columns.astype(int)\n",
    "cmap = plt.get_cmap('tab10')\n",
    "colors = cmap(np.linspace(0, 1, len(ages)))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for age, color in zip(ages, colors):\n",
    "    ax.plot(\n",
    "        active_month_pivot.index,\n",
    "        active_month_pivot[age],\n",
    "        marker='o',\n",
    "        alpha=0.85,\n",
    "        label=f\"{age} yrs\",\n",
    "        color=color,\n",
    "        linewidth=2\n",
    "    )\n",
    "\n",
    "# X‐axis formatting: every 2 months, labels like \"Apr 25\"\n",
    "ax.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%b %y'))\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Labels & title\n",
    "ax.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Active Caseloads', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Active Caseloads Forecast by Age Group', fontsize=14)\n",
    "\n",
    "# Legend outside, keyed by age\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc='upper left',\n",
    "    title='Age Group',\n",
    "    fontsize=10,\n",
    "    title_fontsize=11,\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "# Grid and layout\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Caseloads across Age Groups for each month (Improved Representation)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "active_age_pivot = combined_table.pivot(index='age', columns='month', values='active_caseloads')\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "# Plot each month's series with transparency and thicker lines\n",
    "for mo in active_age_pivot.columns:\n",
    "    ax1.plot(\n",
    "        active_age_pivot.index,\n",
    "        active_age_pivot[mo],\n",
    "        label=mo.strftime('%b %y'),\n",
    "        alpha=0.7,\n",
    "        linewidth=2\n",
    "    )\n",
    "# Titles and labels with larger fonts\n",
    "ax1.set_title('Active Caseloads by Age Group', fontsize=18, fontweight='bold')\n",
    "ax1.set_xlabel('Age Group', fontsize=14)\n",
    "ax1.set_ylabel('Active Caseloads', fontsize=14)\n",
    "# Tidy grid for readability\n",
    "ax1.grid(True, linestyle='--', alpha=0.3)\n",
    "# X-axis integer ticks only\n",
    "ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "# Legend outside\n",
    "ax1.legend(\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc='upper left',\n",
    "    title='Month',\n",
    "    fontsize=10,\n",
    "    title_fontsize=12\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "# Save with transparency\n",
    "plt.savefig(\n",
    "    'output/Active_Caseloads_by_Age_Group.png',\n",
    "    dpi=150,\n",
    "    transparent=True\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot so age is x-axis and month series are separate lines\n",
    "# Active Caseloads across Age Groups for each month\n",
    "active_age_pivot = combined_table.pivot(index='age', columns='month', values='active_caseloads')\n",
    "fig1, ax1 = plt.subplots()\n",
    "active_age_pivot.plot(ax=ax1)\n",
    "ax1.set_title('Active Caseloads by Age Group')\n",
    "ax1.set_xlabel('Age Group')\n",
    "ax1.set_ylabel('Active Caseloads')\n",
    "# Show every other month in legend, formatted 'Apr 25'\n",
    "months = active_age_pivot.columns\n",
    "labels = [dt.strftime('%b %y') for dt in months]\n",
    "# Move legend outside\n",
    "ax1.legend(labels=labels, bbox_to_anchor=(2.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[30,30,25,30])\n",
    "plt.savefig(\"output/Active Caseloads by Age Group.png\")\n",
    "plt.show()\n",
    "\n",
    "# Termination Rate by Age Group for each month\n",
    "term_age_pivot = combined_table.pivot(index='age', columns='month', values='termination_rate')\n",
    "fig2, ax2 = plt.subplots()\n",
    "term_age_pivot.plot(ax=ax2)\n",
    "ax2.set_title('Termination Rate by Age Group')\n",
    "ax2.set_xlabel('Age Group')\n",
    "ax2.set_ylabel('Termination Rate')\n",
    "labels = [dt.strftime('%b %y') for dt in term_age_pivot.columns]\n",
    "ax2.legend(labels=labels, bbox_to_anchor=(1.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[0,0,0.75,1])\n",
    "plt.show()\n",
    "\n",
    "# New Deputyships by Age Group for each month\n",
    "new_age_pivot = combined_table.pivot(index='age', columns='month', values='new_deputyships')\n",
    "fig3, ax3 = plt.subplots()\n",
    "new_age_pivot.plot(ax=ax3)\n",
    "ax3.set_title('New Deputyships by Age Group')\n",
    "ax3.set_xlabel('Age Group')\n",
    "ax3.set_ylabel('New Deputyships')\n",
    "labels = [dt.strftime('%b %y') for dt in new_age_pivot.columns]\n",
    "ax3.legend(labels=labels, bbox_to_anchor=(1.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[0,0,0.75,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.dates import DateFormatter, MonthLocator\n",
    "\n",
    "# Plot Active Caseloads by Age Group\n",
    "active_pivot = combined_table.pivot(index='age', columns='month', values='active_caseloads')\n",
    "fig1, ax1 = plt.subplots()\n",
    "active_pivot.plot(ax=ax1)\n",
    "ax1.set_title('Active Caseloads by Age Group Over Time')\n",
    "ax1.set_xlabel('Age')\n",
    "ax1.set_ylabel('Active Caseloads')\n",
    "# Show tick every 2 months, formatted as 'Apr 25'\n",
    "ax1.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax1.xaxis.set_major_formatter(DateFormatter('%b %y'))\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "# Move legend outside\n",
    "ax1.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[5,5,5.85,6])\n",
    "plt.show()\n",
    "\n",
    "# Plot Termination Rate by Age Group\n",
    "term_pivot = combined_table.pivot(index='age', columns='month', values='termination_rate')\n",
    "fig2, ax2 = plt.subplots()\n",
    "term_pivot.plot(ax=ax2)\n",
    "ax2.set_title('Termination Rate by Age Group Over Time')\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.set_ylabel('Termination Rate')\n",
    "ax2.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax2.xaxis.set_major_formatter(DateFormatter('%b %y'))\n",
    "plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "ax2.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n",
    "\n",
    "# Plot New Deputyships by Age Group\n",
    "new_pivot = combined_table.pivot(index='age', columns='month', values='new_deputyships')\n",
    "fig3, ax3 = plt.subplots()\n",
    "new_pivot.plot(ax=ax3)\n",
    "ax3.set_title('New Deputyships by Age Group Over Time')\n",
    "ax3.set_xlabel('Age')\n",
    "ax3.set_ylabel('New Deputyships')\n",
    "ax3.xaxis.set_major_locator(MonthLocator(interval=2))\n",
    "ax3.xaxis.set_major_formatter(DateFormatter('%b %y'))\n",
    "plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')\n",
    "ax3.legend(bbox_to_anchor=(1.02, 1), loc='upper left', title='Month')\n",
    "plt.tight_layout(rect=[0,0,0.85,1])\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
