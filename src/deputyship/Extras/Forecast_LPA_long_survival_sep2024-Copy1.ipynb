{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import getpass\n",
    "import datetime as dt\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "import re\n",
    "!pip install xlsxwriter\n",
    "import xlsxwriter\n",
    "!pip install openpyxl\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "#from scipy.stats import kstest, probplot\n",
    "\n",
    "#from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "#import statsmodels.api as sm\n",
    "# Suppress warnings from statsmodels\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#!pip install pymc3\n",
    "#!pip install git+https://github.com/pymc-devs/pymc3\n",
    "#!git clone https://github.com/pymc-devs/pymc3\n",
    "#!cd pymc3\n",
    "#!pip install -r requirements.txt\n",
    "#!python setup.py install\n",
    "#!python setup.py develop\n",
    "import pymc3 as pm\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from scipy.stats import kstest\n",
    "#print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find new clients who have their first order received on a given month\n",
    "\n",
    "# # Choose the most recent available source data\n",
    "# target_date = first_csv_file_name.split('opg-analytical_cases_P')[1].lstrip().split('_S')[0] #'2023-12-31' # \n",
    "\n",
    "# from datetime import datetime as dt\n",
    "\n",
    "# # The final date the data is extracted\n",
    "# final_date = str(target_date)\n",
    "# final_date = pd.to_datetime(final_date, format ='%Y-%m-%d', errors='coerce') #.dt.date\n",
    "# final_date = final_date.strftime('%Y-%m-%d')\n",
    "# print(f\"final_date_extracted: {final_date}\")\n",
    "\n",
    "# # The start date of the analysis\n",
    "# start_date = pd.to_datetime('2017-01-01', format ='%Y-%m-%d', errors='coerce').strftime('%Y-%m-%d')\n",
    "# print(f\"start_date: {start_date}\")\n",
    "\n",
    "# # The end date of the analysis\n",
    "# end_date = pd.to_datetime('2017-11-14', format ='%Y-%m-%d', errors='coerce').strftime('%Y-%m-%d')\n",
    "# print(f\"end_date: {end_date}\")\n",
    "\n",
    "# # The start year of the analysis\n",
    "# start_year = pd.to_datetime(start_date, errors='coerce').year\n",
    "# print(f\"start_year: {start_year}\")\n",
    "\n",
    "# # The end year of the analysis\n",
    "# end_year = pd.to_datetime(end_date, errors='coerce').year\n",
    "# print(f\"end_year: {end_year}\")\n",
    "\n",
    "# # The final year of the analysis\n",
    "# final_year = pd.to_datetime(final_date, errors='coerce').year\n",
    "# print(f\"final_year: {final_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------Step 1: DataHandler Class-------------------- ##\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, bucket_name, folder_path):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.folder_path = folder_path\n",
    "        self.s3_client = boto3.client('s3')\n",
    "        self.selected_columns = [\"receiptdate\", \"cases_glueexporteddate\", \"uid\", \"type\", \"casesubtype\", \"status\", \"donor_dob\", \"donor_postcode\", \"donor_gender\"]\n",
    "        self.combined_df = None\n",
    "        self.snapshot_start = None #'2007-01-01'#'2006-12-31'\n",
    "        self.snapshot_end = None #'2023-12-31' #\n",
    "\n",
    "    def list_files(self):\n",
    "        response = self.s3_client.list_objects_v2(Bucket=self.bucket_name, Prefix=self.folder_path)\n",
    "        file_keys = [obj['Key'] for obj in response.get('Contents', [])]\n",
    "        non_none_file_keys = [key for key in file_keys if key is not None]\n",
    "        file_names = [os.path.basename(key) for key in non_none_file_keys]\n",
    "        csv_extension = '.csv'\n",
    "        filtered_file_names = [fn for fn in file_names if fn.lower().endswith(csv_extension)]\n",
    "        return filtered_file_names\n",
    "\n",
    "    def read_csv_files(self, file_names):\n",
    "        dfs = {}\n",
    "        for file_name in file_names:\n",
    "            s3_path = f's3://{self.bucket_name}/{file_name}'\n",
    "            try:\n",
    "                csv_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=f'{self.folder_path}/{file_name}')\n",
    "                csv_string = csv_obj['Body'].read().decode('utf-8')\n",
    "                df = pd.read_csv(StringIO(csv_string))\n",
    "                df_selected = df[self.selected_columns]\n",
    "                dfs[file_name] = df_selected\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_name}: {e}\")\n",
    "        return dfs\n",
    "\n",
    "    def concatenate_dataframes(self, dataframes):\n",
    "        self.combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "\n",
    "    def set_dates(self, start_date=None, end_date=None):\n",
    "        self.snapshot_start = start_date #if start_date else '2007-01-01' \n",
    "        if end_date:\n",
    "            self.snapshot_end = end_date\n",
    "        else:\n",
    "            first_csv_file_name = self.list_files()[1]\n",
    "            self.snapshot_end = first_csv_file_name.split('opg-analytical_cases_P')[1].lstrip().split('_S')[0] #'2023-12-31' # \n",
    "\n",
    "## -------------------\n",
    "\n",
    "# Enter the corresponding S3 bucket name\n",
    "bucketName = \"alpha-opg-analytical\"\n",
    "\n",
    "# Select the corresponding folder includes new LPA data in S3 bucket:\n",
    "folderPath = \"sirius_data_cuts_3\"\n",
    "\n",
    "# Instantiate the DataHandler\n",
    "data_handler = DataHandler(bucket_name=bucketName, folder_path=folderPath)\n",
    "file_names = data_handler.list_files()\n",
    "dataframes = data_handler.read_csv_files(file_names)\n",
    "data_handler.concatenate_dataframes(dataframes)\n",
    "data_handler.set_dates()\n",
    "#print(data_handler.combined_df.head(2))\n",
    "#print(data_handler.combined_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, combined_df, snapshot_start, snapshot_end):\n",
    "        self.combined_df = combined_df\n",
    "        self.snapshot_start = snapshot_start\n",
    "        self.snapshot_end = snapshot_end\n",
    "        self.lpa_data_sample_imputed = None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        df_filtered = self.combined_df\n",
    "        df_filtered['receiptdate'] = pd.to_datetime(df_filtered['receiptdate'], errors='coerce')\n",
    "        df_filtered = df_filtered.loc[(df_filtered['receiptdate'] > pd.to_datetime(self.snapshot_start))]\n",
    "        df_filtered = df_filtered.loc[(df_filtered['receiptdate'] < pd.to_datetime(self.snapshot_end))]\n",
    "        df_filtered = df_filtered.loc[(df_filtered['type'] == 'lpa')]\n",
    "        df = df_filtered[[\"receiptdate\", \"uid\", \"casesubtype\", \"status\", \"donor_dob\", \"donor_postcode\", \"donor_gender\"]]\n",
    "        lpa_df = df.dropna()\n",
    "        lpa_df['age'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce').dt.year - pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.year\n",
    "        lpa_df['donor_dob'] = pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.date\n",
    "        lpa_df['receiptdate'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce')\n",
    "        lpa_df['year'] = lpa_df['receiptdate'].dt.year\n",
    "        lpa_data_sample_imputed = lpa_df\n",
    "\n",
    "        criteria = lpa_data_sample_imputed[(lpa_data_sample_imputed['age'] < 0) | (lpa_data_sample_imputed['age'] > 126)]\n",
    "        lpa_data_sample_imputed.loc[criteria.index, 'age'] = np.nan\n",
    "\n",
    "        most_common_age = lpa_data_sample_imputed.groupby('year')['age'].apply(lambda x: x.mode().iloc[0])\n",
    "        lpa_data_sample_imputed['age'] = lpa_data_sample_imputed.apply(lambda row: most_common_age[row['year']] if pd.isna(row['age']) else row['age'], axis=1)\n",
    "\n",
    "        # Ensure all ages from 18 to 106 are present\n",
    "        all_ages = pd.DataFrame({'age': range(18, 107)})\n",
    "        lpa_data_sample_imputed = lpa_data_sample_imputed.merge(all_ages, on='age', how='right')\n",
    "\n",
    "        # Impute missing values in all columns based on the distribution of that particular age in previous years\n",
    "        for column in lpa_data_sample_imputed.columns:\n",
    "            if column not in ['age', 'year']:\n",
    "                lpa_data_sample_imputed[column] = lpa_data_sample_imputed.groupby('age')[column].transform(lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x.mean()))\n",
    "        \n",
    "        self.lpa_data_sample_imputed = lpa_data_sample_imputed\n",
    "\n",
    "    def calculate_annual_receipts(self):\n",
    "        df = self.lpa_data_sample_imputed\n",
    "\n",
    "        def count_working_days(year):\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-31'\n",
    "            date_range = pd.date_range(start_date, end_date, freq='B')\n",
    "            return len(date_range)\n",
    "\n",
    "        results = {\n",
    "            'year': [],\n",
    "            'Average Daily Reciept': [],\n",
    "            'Yearly Receipt': [],\n",
    "            'Standard Deviation Daily Reciept': [],\n",
    "            'Yearly Standard Deviation': []\n",
    "        }\n",
    "\n",
    "        for year in df['year'].unique():\n",
    "            df_year = df[df['year'] == year]\n",
    "            daily_reciept = df_year.groupby('receiptdate').size()\n",
    "            average_daily_reciept = daily_reciept.mean()\n",
    "            std_dev_daily_reciept = daily_reciept.std()\n",
    "            working_days = count_working_days(year)\n",
    "            yearly_reciept = average_daily_reciept * working_days\n",
    "            yearly_std_dev = average_daily_reciept * working_days\n",
    "\n",
    "            results['year'].append(year)\n",
    "            results['Average Daily Reciept'].append(average_daily_reciept)\n",
    "            results['Yearly Receipt'].append(yearly_reciept)\n",
    "            results['Standard Deviation Daily Reciept'].append(std_dev_daily_reciept)\n",
    "            results['Yearly Standard Deviation'].append(yearly_std_dev)\n",
    "\n",
    "        annual_receipts = pd.DataFrame(results)\n",
    "        annual_receipts = annual_receipts.sort_values(by=['year'])\n",
    "\n",
    "        return annual_receipts\n",
    "\n",
    "    def create_unique_identifier(self):\n",
    "        lpa_unique = self.lpa_data_sample_imputed\n",
    "        lpa_unique['donor_postcode'] = lpa_unique['donor_postcode'].str.strip().str.replace(' ', '')\n",
    "        lpa_unique['unique_key'] = lpa_unique['donor_dob'].astype(str) + lpa_unique['donor_gender'] + lpa_unique['donor_postcode']\n",
    "\n",
    "        duplicate_mask = lpa_unique.duplicated('unique_key', keep=False)\n",
    "        lpa_unique = pd.concat([lpa_unique.loc[duplicate_mask & lpa_unique[['age', 'donor_gender', 'donor_postcode']].ne(0).any(axis=1)], \n",
    "                                lpa_unique[~duplicate_mask]])\n",
    "\n",
    "        lpa_unique['month_year'] = lpa_unique['receiptdate'].dt.strftime('%b-%y')\n",
    "        lpa_unique = lpa_unique.sort_values(by=['receiptdate'])\n",
    "        return lpa_unique\n",
    "\n",
    "    def calculate_unique_donors_per_year(self, lpa_df_index):\n",
    "        lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "        annual_unique_donors = lpa_df_index.groupby(['year', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        annual_unique_donors = annual_unique_donors.sort_values(by=['year', 'age'])\n",
    "        return annual_unique_donors\n",
    "\n",
    "    def calculate_unique_donors_count_monthly(self, lpa_df_index):\n",
    "        lpa_df_no_index = lpa_df_index.reset_index()\n",
    "        lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "        monthly_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        monthly_unique_donors = monthly_unique_donors.sort_values(by=['year', 'month', 'donor_gender', 'age'])\n",
    "        return monthly_unique_donors\n",
    "\n",
    "    def calculate_unique_donors_per_day(self, lpa_df_index):     \n",
    "        lpa_df_no_index = lpa_df_index.reset_index()\n",
    "        lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "        lpa_df_no_index['day'] = lpa_df_no_index['receiptdate'].dt.day\n",
    "        daily_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'day', 'receiptdate', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        daily_unique_donors = daily_unique_donors.sort_values(by=['receiptdate', 'year', 'month', 'day', 'donor_gender', 'age'])\n",
    "        return daily_unique_donors    \n",
    "    \n",
    "    def calculate_unique_donors_age_specific(self, lpa_df_index):\n",
    "       #lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "        annual_unique_donors_age_specific = lpa_df_index.groupby(['year', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        annual_unique_donors_age_specific = annual_unique_donors_age_specific.sort_values(by=['year', 'age'])\n",
    "        return annual_unique_donors_age_specific\n",
    "        \n",
    "    def calculate_unique_donors_count_daily(self, lpa_df_index):\n",
    "        #daily_unique_donors = lpa_df_index.groupby(['year'])['unique_key'].nunique().reset_index(name='count')\n",
    "        #daily_unique_donors = daily_unique_donors.sort_values(by=['year'])\n",
    "        # Group by 'year' and count unique 'unique_id'\n",
    "        annual_unique_counts = lpa_df_index.groupby(lpa_df_index['year'])['unique_key'].nunique()    \n",
    "        return annual_unique_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# short-term forecast the rest of age-specific count of donor demands for the remaining months in 2024 based on a bunch of short-term drivers like Martin Lewis broadcast \n",
    "As we have only first quarter of age-specific count of donor demands (annual_donors_age_2024), to short-term forecast the rest of quarters age-specific count of donor demands for the remaining months in 2024:\n",
    "- Estimate the short-term forecasts for the remaining of 2024 by first, take the average number for receipts at working day across 2024 which currently is 5600 multiplied by the total number of working days in the year which is 256 give me the total number of expected receipts for the year (5600 * 256 = 1.433 million receipts across the whole of 2024). \n",
    "    1. Calculate the number of reciepts across the whole year (for the available data (only 6 months) on average are going to be for 2024 = average_daily_reciepts_2024\n",
    "    2. Muliply (average_daily_reciepts_2024) to the Number of working days in 2024 (num_working_day_2024) = total_annual_reciepts_2024\n",
    "    3. Estimate the Ratio of total_annual_reciepts_2024 to annual_donors_age_2024: ratio_reciept_donor_2024 = total_annual_reciepts_2024 / annual_donors_age_2024\n",
    "- Once you have calculated the total number of receipts for 2024 then by looking at 2022/2023 historical data count how many receipts there were in 2022/2023 and how many donors were in 2022/2023 just to get the overall ratio. The starting point is just the total number for receipts so according to this that would be just over 1.4 million more receipts then scale that back based on total number for receipts 2022/2023 e.g., 70% then that would suggest that would be 1,000,000 donors roughly. E.g., just to keep it simple we consider the same overall ratio in 2022/2023 (e.g., 70%) should be use in 2024, as 2022 and 2023 are the nearest year to 2024. This will give us an estimate for the total number of donors that we might expect in 2024 based on what we're seeing about average receipts across the year in 2024.      \n",
    "    1. Calculate the number of reciepts across the whole year on average for 2023 = average_daily_reciepts_2023\n",
    "    2. Muliply (average_daily_reciepts_2023) to the Number of working days in 2023 (num_working_day_2023) = total_annual_reciepts_2023\n",
    "    3. Muliply (average_daily_reciepts_2022) to the Number of working days in 2022 (num_working_day_2022) = total_annual_reciepts_2022\n",
    "    4. Estimate the Ratio of total_annual_reciepts_2023 to annual_donors_age_2023: ratio_reciept_donor_2023 = total_annual_reciepts_2023 / annual_donors_age_2023\n",
    "    5. Estimate the Ratio of total_annual_reciepts_2022 to annual_donors_age_2022: ratio_reciept_donor_2022 = total_annual_reciepts_2022 / annual_donors_age_2022\n",
    "- Then scale that back to work out however how many donors that is expected to be in 2024 and then using the historical age distribution in 2022/2023 just to break that down by age so that we can plug in those figures for 2024. So once calculated the number of donors in 2024, then need to find out of those donors what percentage would be aged 18 what percentage the age 19, 20, 21, ..., 106 based on the previous distribution so 2023 or 2022 and both years as well as the total number for receipts for 2022/2023. Then once you've got the total number of estimated donors for 2024 by considering 2022/2023 and we say how many donors were aged 18, how many were aged 19, how many were aged 20, … , etc (we should have all ages incremented by a year from 18 to 106. Then take those figures for 2024 and the plug come back in the age-specific number of annual donor demands. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Monte-Carlo simulation \n",
    "To ensure a future-proven forecasting model with much more reliable forecast outputs by applying uncertainty, \n",
    "especially when there are short-term volatilities in the average daily receipts in the pattern of data due to some short-term variation of external factors / drivers \n",
    "(e.g., advertisement), which has an impact on the short-term,  to capture these changes in the pattern of data in the short term and then apply the uncertainty related \n",
    "to this to a long-term forecasting of age-specific donor demands, e.g., as it is evident that the number of receipts changes in the short-term \n",
    "(e.g., from the range of 4000 to 7000 (increment by 100) in the drop-down list, \n",
    "so there is volatility in the short term and the range of the average daily receipts? Each time we run the model, the forecasting output  of age-specific donor demands changes. \n",
    "\n",
    "# Dealing with Uncertainty & data volatility\n",
    "THis is to introduce uncertainty into the model by simulating different scenarios for average daily receipts. \n",
    "This approach will capture the short-term volatility in donor receipts, leading to more reliable and robust long-term forecasts.\n",
    "\n",
    "## Set Up Monte Carlo Simulation Parameters\n",
    "set up the simulation to run multiple iterations, where each iteration randomly selects an average daily receipt value within \n",
    "a given range (e.g., 4000 to 7000). The model will then calculate the donor demand based on this value, \n",
    "and we'll aggregate the results to produce a distribution of possible outcomes.\n",
    "\n",
    "## Run the model\n",
    "- Run the Monte Carlo simulation for a specified number of iterations.\n",
    "- Randomly generate an average daily receipt within the specified range for each iteration.\n",
    "- Aggregate and analyse the results to provide a distribution of forecasted donor numbers.\n",
    "\n",
    "Monte Carlo Simulation Setup:\n",
    "\n",
    "The iterations variable defines how many times the simulation will run (in this example, 1000 iterations).\n",
    "lowerBound and upperBound set the range for possible average daily receipts, reflecting the volatility (from 4000 to 7000).\n",
    "Generating Random Average Daily Receipts:\n",
    "\n",
    "For each iteration, a random average daily receipt is selected from the specified range using Application.WorksheetFunction.RandBetween(lowerBound, upperBound).\n",
    "Running the Forecasting Model:\n",
    "\n",
    "For each random receipt value, the total receipts for 2024 are calculated.\n",
    "Using the ratios from 2022 and 2023, the estimated number of donors for 2024 is calculated for each iteration.\n",
    "Storing and Analyzing Results:\n",
    "\n",
    "The results of all iterations are stored in an array (monteCarloResults).\n",
    "The mean and standard deviation of the forecasted donor numbers for each age group are calculated across all iterations.\n",
    "Visualizations:\n",
    "\n",
    "Two charts are added to visualize the results:\n",
    "A clustered column chart showing the mean forecasted number of donors by age.\n",
    "A line chart showing the standard deviation of forecasted donors by age, indicating the uncertainty.\n",
    "Output:\n",
    "\n",
    "The final results are saved in the \"Forecast_2024\" sheet, and the charts are added for visual analysis.\n",
    "Running the Simulation:\n",
    "Each time you run the ForecastWithMonteCarlo macro, it will generate different results based on the random variation in average daily receipts. This randomness helps to account for short-term volatility, making the forecast more robust and reliable over the long term.\n",
    "Interpretation of Results:\n",
    "The mean values give an expected forecast for each age group based on the Monte Carlo simulation.\n",
    "The standard deviation indicates the level of uncertainty or volatility in the forecasted numbers. A higher standard deviation means more variability in the donor forecasts for that age group, suggesting that predictions for this group are more sensitive to changes in daily receipts.\n",
    "This approach ensures that the forecasting model accounts for potential short-term variations and provides a more nuanced understanding of the possible outcomes.\n",
    "\n",
    "## Additional Columns:\n",
    "\n",
    "Year: Added to specify the forecast year.\n",
    "AgeDistribution2022 & AgeDistribution2023: These columns store the age-specific distribution of donors for the years 2022 and 2023.\n",
    "AverageAgeDistribution: This column contains the average age distribution calculated from 2022 and 2023 data.\n",
    "RandomReceipt: Stores the random daily receipt value used in each iteration.\n",
    "MonteCarloResults: Holds the forecasted donor number for each iteration.\n",
    "Sum of Values and Sum of Squared Values: These are intermediate calculations needed to compute the mean and standard deviation for the forecasted donor numbers.\n",
    "Final Forecast (Mean) and Final Forecast (StdDev): The mean and standard deviation of the forecasted donor numbers after all iterations.\n",
    "Monte Carlo Simulation:\n",
    "\n",
    "Each iteration generates a random receipt value and calculates the forecasted donor numbers. The results are stored and used to compute the final forecast.\n",
    "Visualizations:\n",
    "\n",
    "Clustered Column Chart: Visualizes the mean forecasted donor numbers by age group.\n",
    "Line Chart: Shows the standard deviation (uncertainty) in the forecasted donor numbers for each age group.\n",
    "Interpretation:\n",
    "Year column gives context to the forecast year, which is 2024 in this scenario.\n",
    "Age Distribution Columns show how donor distributions are evolving over time.\n",
    "Random Receipt column illustrates the volatility and randomness considered in each iteration.\n",
    "Monte Carlo Results provide insight into the forecasted donor numbers for each random receipt value.\n",
    "Sum of Values and Sum of Squared Values are used to calculate the final forecast's mean and standard deviation, indicating the expected donor numbers and their uncertainty.\n",
    "The charts visually summarize the data, showing how different age groups' donor forecasts change under various scenarios and the associated uncertainties.\n",
    "This detailed output will help in analyzing the Monte Carlo simulation results in a more comprehensive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Uncertainty Ratio: average annual dornor demands and average annual reciepts:\n",
    "# Calculate the Ratio of Short-Term to Long-Term Demand:\n",
    "# Compute the ratio of the average short-term demand to the average long-term demand. \n",
    "# This ratio represents the relative impact of the short-term period on the long-term forecast.\n",
    "\n",
    "## -------------------\n",
    "# Instantiate the DataPreprocessor\n",
    "#data_preprocessor = DataPreprocessor(data_handler.combined_df, data_handler.snapshot_start, data_handler.snapshot_end)\n",
    "data_preprocessor = DataPreprocessor(data_handler.combined_df, '2007-01-01', data_handler.snapshot_end)\n",
    "data_preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the The total annual reciepts\n",
    "annual_receipts = data_preprocessor.calculate_annual_receipts()\n",
    "results = annual_receipts[['year', 'Yearly Receipt']]\n",
    "#print(f\"Total annual reciepts: {results}\")\n",
    "\n",
    "total_annual_reciepts_2022 = results['Yearly Receipt'].iloc[0]\n",
    "#print(f\"total_annual_reciepts_2022: {results['Yearly Receipt'].iloc[0]}\")\n",
    "\n",
    "total_annual_reciepts_2023 = results['Yearly Receipt'].iloc[1]\n",
    "#print(f\"total_annual_reciepts_2023: {results['Yearly Receipt'].iloc[1]}\")\n",
    "\n",
    "total_annual_reciepts_2024 = results['Yearly Receipt'].iloc[2]\n",
    "#print(f\"total_annual_reciepts_2024: {results['Yearly Receipt'].iloc[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_df_index = data_preprocessor.create_unique_identifier()\n",
    "monthly_unique_donors = data_preprocessor.calculate_unique_donors_count_monthly(lpa_df_index)\n",
    "daily_unique_donors = data_preprocessor.calculate_unique_donors_per_day(lpa_df_index)\n",
    "annual_donor_demands = data_preprocessor.calculate_unique_donors_count_daily(lpa_df_index)\n",
    "annual_unique_donors_age_specific = data_preprocessor.calculate_unique_donors_age_specific(lpa_df_index)\n",
    "annual_unique_donors = data_preprocessor.calculate_unique_donors_per_year(lpa_df_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Total annual donor demands based on 'unique_id'\n",
    "daily_unique_donors.sort_values(by=['year', 'age'])\n",
    "total_annual_donor = daily_unique_donors[['year', 'count']]\n",
    "total_annual_donor = total_annual_donor.groupby(['year']).sum()\n",
    "\n",
    "total_annual_donor_2022 = total_annual_donor.iloc[0]\n",
    "total_annual_donor_2023 = total_annual_donor.iloc[1]\n",
    "total_annual_donor_2024 = total_annual_donor.iloc[2]\n",
    "\n",
    "annual_unique_donors = annual_unique_donors.rename(columns={'count': 'demand'})\n",
    "#print(f\"Total annual donor demands: {total_annual_donor}\")\n",
    "#print(f\"Total annual donor demands for 2022: {total_annual_donor_2022}\")\n",
    "#print(f\"Total annual donor demands for 2023: {total_annual_donor_2023}\")\n",
    "#print(f\"Total annual donor demands for 2024: {total_annual_donor_2024}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in all columns based on the distribution of that particular age in previous years\n",
    "\n",
    "# Create a DataFrame with all ages from 18 to 27 for each year\n",
    "all_ages = pd.DataFrame([(year, age) for year in annual_unique_donors['year'].unique() for age in range(18, 107)], columns=['year', 'age'])\n",
    "\n",
    "# Merge the original DataFrame with the all_ages DataFrame\n",
    "df_full = pd.merge(all_ages, annual_unique_donors, on=['year', 'age'], how='left')\n",
    "\n",
    "# Fill missing values using the age distribution\n",
    "\n",
    "#pivot_table1 = pivot_table1.apply(lambda x: x.fillna(x.mean()), axis=1)\n",
    "#df_full['demand'] = df_full.groupby('year')['demand'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Fill missing values using the previous three ages' demand values or next three ages' demand values\n",
    "def fill_missing_values(group):\n",
    "    for i in range(len(group)):\n",
    "        if pd.isna(group.iloc[i]['demand']):\n",
    "            prev_values = group.iloc[max(0, i-3):i]['demand']\n",
    "            next_values = group.iloc[i+1:min(len(group), i+4)]['demand']\n",
    "            if not prev_values.isna().all():\n",
    "                group.at[i, 'demand'] = prev_values.mean()\n",
    "            elif not next_values.isna().all():\n",
    "                group.at[i, 'demand'] = next_values.mean()\n",
    "    return group\n",
    "\n",
    "# Handling Missing Data\n",
    "#pivot_tbl = pivot_tbl.fillna(0)\n",
    "df_full = df_full.groupby('year').apply(fill_missing_values).reset_index(drop=True)\n",
    "df_full = round(df_full.fillna(0), 0)\n",
    "# # Create a pivot table\n",
    "# pivot_table = df_full.pivot_table(index='year', columns='age', values='demand', aggfunc='sum')\n",
    "\n",
    "# # Add the column label 'year' in the first row and first column\n",
    "# pivot_table.index.name = 'age'\n",
    "# #pivot_table.reset_index(inplace=True)\n",
    "\n",
    "# donor_pivot_trns = pivot_table.transpose()\n",
    "# Print the pivot table\n",
    "#print(donor_pivot_trns)\n",
    "\n",
    "\n",
    "\n",
    "# Remove the age label in the first column and first row\n",
    "#pivot_table.columns.name = None\n",
    "#pivot_table.index.name = None\n",
    "\n",
    "# Reset index to make 'age' a column again\n",
    "#pivot_table.reset_index(inplace=True)\n",
    "\n",
    "#print(pivot_table)\n",
    "\n",
    "\n",
    "# # Create a pivot table\n",
    "# pivot_tbl = df_full.pivot_table(index='year', columns='age', values='demand', aggfunc='sum')\n",
    "\n",
    "# # Example operations\n",
    "# # 1. Aggregation\n",
    "# pivot_sum = pivot_tbl.sum()\n",
    "# pivot_mean = pivot_tbl.mean()\n",
    "\n",
    "# # 2. Filtering\n",
    "# filtered_pivot = pivot_tbl[pivot_tbl[22] > 10]\n",
    "\n",
    "# # 3. Grouping\n",
    "# grouped_pivot = df_full.groupby(['year', 'age']).sum().unstack()\n",
    "\n",
    "# # 4. Reshaping\n",
    "# stacked_pivot = pivot_tbl.stack()\n",
    "# unstacked_pivot = stacked_pivot.unstack()\n",
    "\n",
    "# # 5. Handling Missing Data\n",
    "# filled_pivot = pivot_tbl.fillna(0)\n",
    "\n",
    "# # 6. Sorting\n",
    "# # if 22 in pivot_tbl.columns:\n",
    "# #     sorted_pivot = pivot_tbl.sort_values(by=22, axis=1)\n",
    "# # else:\n",
    "# #     sorted_pivot = pivot_tbl\n",
    "\n",
    "# # 7. Applying Functions\n",
    "# applied_pivot = pivot_tbl.apply(np.log1p)\n",
    "\n",
    "# # 8. Pivot Table Customization\n",
    "# pivot_with_margins = df_full.pivot_table(index='year', columns='age', values='demand', aggfunc='sum', margins=True)\n",
    "\n",
    "# # Print examples\n",
    "# print(\"Sum:\\n\", pivot_sum)\n",
    "# print(\"Mean:\\n\", pivot_mean)\n",
    "# print(\"Filtered:\\n\", filtered_pivot)\n",
    "# print(\"Grouped:\\n\", grouped_pivot)\n",
    "# print(\"Stacked:\\n\", stacked_pivot)\n",
    "# print(\"Unstacked:\\n\", unstacked_pivot)\n",
    "# print(\"Filled:\\n\", filled_pivot)\n",
    "# #print(\"Sorted:\\n\", sorted_pivot)\n",
    "# print(\"Applied Function:\\n\", applied_pivot)\n",
    "# print(\"With Margins:\\n\", pivot_with_margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the pivot table\n",
    "df = df_full\n",
    "pivot_table = df.pivot_table(index='age', columns='year', values='demand', fill_value=0)\n",
    "#print(pivot_table)\n",
    "\n",
    "pivot_tbl = pivot_table\n",
    "# Reset index to make 'age' a column again\n",
    "pivot_tbl.reset_index(inplace=True)\n",
    "\n",
    "# Remove the second row\n",
    "pvt_tbl = pivot_tbl.drop(0)\n",
    "\n",
    "# Remove the second column (2007.0)\n",
    "pvt_tbl.drop(columns=[0.0], inplace=True)\n",
    "#pvt_tbl = pvt_tbl.pop(0.0)\n",
    "\n",
    "# Set a label to the first column\n",
    "pvt_tbl.rename(columns={'': 'Age Group'}, inplace=True)\n",
    "\n",
    "# Remove the index\n",
    "pvt_tbl.reset_index(drop=True, inplace=True)\n",
    "print(pvt_tbl)\n",
    "#pvt_df = pvt_tbl.pop('index')\n",
    "#pvt_df\n",
    "#pivot_annual_unique_donors = pvt_tbl.drop(columns=['year'], inplace=True)\n",
    "#pivot_annual_unique_donors\n",
    "\n",
    "\n",
    "# Remove the age label in the first column and first row\n",
    "#pivot_tbl.columns.name = None\n",
    "#pivot_tbl.index.name = None\n",
    "#print(pivot_tbl)\n",
    "\n",
    "#pvt_tbl = pivot_tbl.pop(1)\n",
    "#print(pvt_tbl)\n",
    "# Reorder the columns to move 'age' to the first position\n",
    "#pivot_tbl = pivot_tbl[\n",
    "# Insert 'age' as the first column\n",
    "#total_life_tbl.insert(0, 'age', first_column)\n",
    "\n",
    "pivot_annual_unique_donors = pvt_tbl # donor_pivot_trns\n",
    "#pivot_annual_unique_donors = pivot_annual_unique_donors[(pivot_annual_unique_donors['age'] >= 18) & (pivot_annual_unique_donors['age'] <= 106)]\n",
    "pivot_annual_unique_donors.to_csv('pivot_annual_unique_donors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file\n",
    "historical_data_df = df_full\n",
    "#historical_data_df = df_full[(df_full['age'] >= 18) & (df_full['age'] <= 106)]\n",
    "historical_data_df.to_csv('annual_unique_donors.csv', index=False)\n",
    "\n",
    "annual_receipts_historical = annual_receipts[['year', 'Yearly Receipt']]\n",
    "annual_receipts_historical.to_csv('annual_receipts.csv', index=False)\n",
    "annual_demands_historical = historical_data_df\n",
    "annual_unique_donors_age_specific = historical_data_df\n",
    "annual_demands_age_specific_historical = annual_unique_donors_age_specific\n",
    "annual_unique_donors_age_specific.to_csv('annual_unique_donors_age_specific.csv', index=False)\n",
    "\n",
    "monthly_unique_donors = monthly_unique_donors.rename(columns={'count': 'demand'})\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "historical_demand_monthly = monthly_unique_donors[(monthly_unique_donors['age'] >= 18) & (monthly_unique_donors['age'] <= 106)]\n",
    "historical_demand_monthly.to_csv('historical_demand_monthly.csv', index=False)\n",
    "\n",
    "daily_unique_donors = daily_unique_donors.rename(columns={'count': 'demand'})\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "historical_demand_daily = daily_unique_donors[(daily_unique_donors['age'] >= 18) & (daily_unique_donors['age'] <= 106)] \n",
    "historical_demand_daily.to_csv('historical_demand_daily.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'year' is 2023 or 2022\n",
    "filtered_annual_receipts = annual_receipts_historical #[annual_receipts_historical['year'].isin([2023, 2022, 2021, 2020])]\n",
    "#print(f\"annual_donor_receipts is: {filtered_annual_receipts}\")\n",
    "\n",
    "\n",
    "filtered_annual_demands = annual_demands_historical #[(annual_demands_historical.index == 2020) | (annual_demands_historical.index == 2021) | (annual_demands_historical.index == 2022) | (annual_demands_historical.index == 2023) | (annual_demands_historical.index == 2024)]\n",
    "#print(f\"annual_donor_demands is: {filtered_annual_demands}\")\n",
    "\n",
    "filtered_annual_demands_age_specific = annual_demands_age_specific_historical #[annual_demands_age_specific_historical['year'].isin([2023, 2022, 2021, 2020])]\n",
    "# Extract and save data into a csv file\n",
    "filtered_annual_demands_age_specific = filtered_annual_demands_age_specific.rename(columns={'count': 'demand'})\n",
    "\n",
    "#print(f\"annual_donor_demands_age_specific is: {filtered_annual_demands_age_specific}\") \n",
    "\n",
    "# Save to CSV file\n",
    "filtered_annual_demands_age_specific.to_csv('annual_demands_age_specific.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and Preprocess Data: Load the historical data and filter it for the age range 18-106.\n",
    "# Calculate Annual Receipts: Calculate the total annual receipts for 2022, 2023, and 2024 based on the provided daily averages and working days.\n",
    "# Estimate Ratios: Calculate the ratios of receipts to donors for 2022 and 2023.\n",
    "# Forecast Donors for 2024: Estimate the total number of donors for 2024 based on the historical ratios.\n",
    "# Age-Specific Distribution: Use historical age distributions from 2022 and 2023 to distribute the forecasted donors by age for 2024.\n",
    "# Combine Forecasts: Integrate these estimates into the final forecast for age-specific donor demands for the remaining months in 2024.\n",
    "\n",
    "# class to provide short-term forecast the rest of age-specific count of donor demands for the remaining months in 2024 based on a bunch of short-term drivers like Martin Lewis broadcast \n",
    "# As we have only first quarter of age-specific count of donor demands (annual_donors_age_2024), to short-term forecast the rest of quarters age-specific count of donor demands for the remaining months in 2024:\n",
    "# - Estimate the short-term forecasts for the remaining of 2024 by first, take the average number for receipts at working day across 2024 which currently is 5600 multiplied by the total number of working days in the year which is 256 give me the total number of expected receipts for the year (5600 * 256 = 1.433 million receipts across the whole of 2024). \n",
    "#     1. Calculate the number of receipts across the whole year (for the available data (only 6 months) on average are going to be for 2024 = average_daily_reciepts_2024\n",
    "#     2. Multiply (average_daily_reciepts_2024) to the Number of working days in 2024 (num_working_day_2024) = total_annual_reciepts_2024\n",
    "#     3. Estimate the Ratio of total_annual_reciepts_2024 to annual_donors_age_2024: ratio_reciept_donor_2024 = total_annual_reciepts_2024 / annual_donors_age_2024\n",
    "# - Once you have calculated the total number of receipts for 2024 then by looking at 2022/2023 historical data count how many receipts there were in 2022/2023 and how many donors were in 2022/2023 just to get the overall ratio. The starting point is just the total number for receipts so according to this that would be just over 1.4 million more receipts then scale that back based on total number for receipts 2022/2023 e.g., 70% then that would suggest that would be 1,000,000 donors roughly. E.g., just to keep it simple we consider the same overall ratio in 2022/2023 (e.g., 70%) should be use in 2024, as 2022 and 2023 are the nearest year to 2024. This will give us an estimate for the total number of donors that we might expect in 2024 based on what we're seeing about average receipts across the year in 2024.      \n",
    "#     1. Calculate the number of receipts across the whole year on average for 2023 = average_daily_reciepts_2023\n",
    "#     2. Multiply (average_daily_reciepts_2023) to the Number of working days in 2023 (num_working_day_2023) = total_annual_reciepts_2023\n",
    "#     3. Multiply (average_daily_reciepts_2022) to the Number of working days in 2022 (num_working_day_2022) = total_annual_reciepts_2022                                                                    \n",
    "#(Note: assume we have already calculated the above figures:  \n",
    "# total_annual_reciepts_2022: 751967.5346260389\n",
    "# total_annual_reciepts_2023: 970035.0282485875\n",
    "# total_annual_reciepts_2024: 1124615.1902439024                                                              \n",
    "# Total annual donor demands for 2022: count    675089\n",
    "# Total annual donor demands for 2023: count    852627\n",
    "# Total annual donor demands for 2024: count    568367  \n",
    "#     4. Estimate the Ratio of total_annual_reciepts_2023 to annual_donors_age_2023: ratio_reciept_donor_2023 = total_annual_reciepts_2023 / annual_donors_age_2023\n",
    "#     5. Estimate the Ratio of total_annual_reciepts_2022 to annual_donors_age_2022: ratio_reciept_donor_2022 = total_annual_reciepts_2022 / annual_donors_age_2022  \n",
    "# - Then scale that back to work out however how many donors that is expected to be in 2024 and then using the historical age distribution in 2022/2023 just to break that down by age so that we can plug in those figures for 2024. So once calculated the number of donors in 2024, then need to find out of those donors what percentage would be aged 18 what percentage the age 19, 20, 21, …, 106 based on the previous distribution so 2023 or 2022 and both years as well as the total number for receipts for 2022/2023. Then once you've got the total number of estimated donors for 2024 by considering 2022/2023 and we say how many donors were aged 18, how many were aged 19, how many were aged 20, … , etc \n",
    "# (we should have all ages incremented by a year from 18 to 106. Then take those figures for 2024 and the plug come back in the age-specific number of annual donor demands. based on the attached data?  \n",
    "\n",
    "# Load the historical data\n",
    "#historical_data_path = 'annual_unique_donors_22_23_24.csv'\n",
    "\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "filtered_data_df = historical_data_df[(historical_data_df['age'] >= 18) & (historical_data_df['age'] <= 106)]\n",
    "\n",
    "# # Add a column for the month (assuming the month is in the 'month' column in the dataset)\n",
    "# # If the dataset doesn't have month data, this step needs to be adjusted accordingly\n",
    "# # Here we assume that the dataset has a 'month' column with values from 1 to 12\n",
    "# filtered_data_df['month'] = pd.to_datetime(filtered_data_df['date']).dt.month\n",
    "\n",
    "# # Define a function to calculate quarters\n",
    "# def calculate_quarter(month):\n",
    "#     if 1 <= month <= 3:\n",
    "#         return 1\n",
    "#     elif 4 <= month <= 6:\n",
    "#         return 2\n",
    "#     elif 7 <= month <= 9:\n",
    "#         return 3\n",
    "#     elif 10 <= month <= 12:\n",
    "#         return 4\n",
    "\n",
    "# # Apply the function to add the 'quarter' column\n",
    "# filtered_data_df['quarter'] = filtered_data_df['month'].apply(calculate_quarter)\n",
    "\n",
    "# Calculate annual donor receipts and demands for the provided years\n",
    "annual_donor_demands = filtered_data_df.groupby('year')['demand'].sum()\n",
    "\n",
    "# Load the additional data provided in the task\n",
    "average_daily_receipts_2022 = total_annual_reciepts_2022 / 256\n",
    "average_daily_receipts_2023 = total_annual_reciepts_2023 / 256\n",
    "average_daily_receipts_2024 = 5600  # Given average daily receipts for 2024\n",
    "\n",
    "num_working_days_2022 = 256\n",
    "num_working_days_2023 = 256\n",
    "num_working_days_2024 = 256\n",
    "\n",
    "total_annual_receipts_2022 = round(average_daily_receipts_2022 * num_working_days_2022, 2)\n",
    "print(f\"The total number of receipts for 2022: {total_annual_receipts_2022}\")\n",
    "\n",
    "total_annual_receipts_2023 = round(average_daily_receipts_2023 * num_working_days_2023, 2)\n",
    "print(f\"The total number of receipts for 2023: {total_annual_receipts_2023}\")\n",
    "\n",
    "total_annual_receipts_2024 = round(average_daily_receipts_2024 * num_working_days_2024, 2)\n",
    "print(f\"The total number of receipts for 2024: {total_annual_receipts_2024}\")\n",
    "\n",
    "# Calculate ratios of receipts to donors for 2022 and 2023\n",
    "ratio_receipt_donor_2022 = round(total_annual_receipts_2022 / annual_donor_demands[2022], 2)\n",
    "print(f\"The Ratio of total number of receipt to donor demands for 2022: {ratio_receipt_donor_2022}\")\n",
    "\n",
    "ratio_receipt_donor_2023 = round(total_annual_receipts_2023 / annual_donor_demands[2023], 2)\n",
    "print(f\"The Ratio of total number of receipt to donor demands for 2023: {ratio_receipt_donor_2023}\")\n",
    "\n",
    "# Estimate the total number of donors for 2024 based on historical ratios\n",
    "estimated_donors_2024 = round(total_annual_receipts_2024 / ((ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2), 2)\n",
    "print(f\"The estimate total number of donors for 2024 based on historical ratios: {estimated_donors_2024}\")\n",
    "\n",
    "# Age-specific distribution based on 2022 and 2023\n",
    "age_distribution_2022 = filtered_data_df[filtered_data_df['year'] == 2022].groupby('age')['demand'].sum() / annual_donor_demands[2022]\n",
    "print(f\"Age-specific distribution based on 2022: {age_distribution_2022}\")\n",
    "\n",
    "age_distribution_2023 = filtered_data_df[filtered_data_df['year'] == 2023].groupby('age')['demand'].sum() / annual_donor_demands[2023]\n",
    "print(f\"Age-specific distribution based on 2023: {age_distribution_2023}\")\n",
    "\n",
    "# Average age distribution\n",
    "average_age_distribution = round((age_distribution_2022 + age_distribution_2023) / 2, 6)\n",
    "print(f\"Average age-specific distribution based on 2022/2023: {average_age_distribution}\")\n",
    "\n",
    "# Estimate the age-specific number of donors for 2024\n",
    "age_specific_donors_2024 = estimated_donors_2024 * average_age_distribution\n",
    "print(f\"Age-specific distribution for 2024: {age_specific_donors_2024}\")\n",
    "\n",
    "# Ask the user to specify the available quarters for 2024\n",
    "#available_quarters = input(\"Enter the quarters that data is available for 2024 (e.g., 1, 2): \")\n",
    "#available_quarters = list(map(int, available_quarters.split(',')))\n",
    "#available_quarters\n",
    "\n",
    "# Forecast the remaining months in 2024 based on the first quarter data\n",
    "first_quarter_data = filtered_data_df[(filtered_data_df['year'] == 2024)] #& (filtered_data_df['quarter'] == 1)]\n",
    "print(f\"The first quarter available data for 2024: {first_quarter_data}\")\n",
    "\n",
    "total_first_quarter_demand = first_quarter_data['demand'].sum()\n",
    "print(f\"The total first quarter available donor demands for 2024: {total_first_quarter_demand}\")\n",
    "\n",
    "remaining_demand_2024 = total_annual_receipts_2024 - total_first_quarter_demand\n",
    "print(f\"The remaining donor demands for 2024: {remaining_demand_2024}\")\n",
    "\n",
    "# Distribute the remaining demand across ages based on the average age distribution\n",
    "remaining_age_specific_donors_2024 = remaining_demand_2024 * average_age_distribution\n",
    "print(f\"The remaining age-specific donor demands for 2024: {remaining_age_specific_donors_2024}\")\n",
    "\n",
    "# Create a DataFrame to store the forecasted age-specific donors for the remaining months of 2024\n",
    "forecast_df = pd.DataFrame({\n",
    "    'age': average_age_distribution.index,\n",
    "    'forecasted_donors': remaining_age_specific_donors_2024\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"The age-specific donor demands for 2024:\")\n",
    "print(forecast_df)\n",
    "forecast_df.to_csv('estimated age-specific donor demands for 2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function in python that apply uncertainty to a short-term forecsasts of number of demands from April 2024 for 2 years \n",
    "# by multiplying the SARIMA forecasted values by two ratios: 1. annual_donor_receipts (average daily demnads per year) divided \n",
    "# by annual_donor_demands (average daily reciepts per year) and 2. (age-specific demnads ratio (claculated by estimating the percentage \n",
    "#                                                                                               of demands per year for each age from 18 to 106). \n",
    "#                                                                   Also if there are no demands in a specific age in the corresponding year then consider \n",
    "#                                                                   a zero demand for that age. \n",
    "# Here is the age specific count of demnds in 2022, 2023, and January 2024, February 2024 and March 2024.  \n",
    "# To accomplish this task, we need to:\n",
    "\n",
    "# Forecast the number of demands for the next two years using a SARIMA model.\n",
    "# Apply uncertainty by multiplying the forecasted values by the specified ratios:\n",
    "# The ratio of annual donor receipts to annual donor demands.\n",
    "# The age-specific demands ratio.\n",
    "# Here's a step-by-step Python function to achieve this:\n",
    "\n",
    "# Forecasting using SARIMA: I'll assume the SARIMA model is already built and forecasted values are available.\n",
    "# Ratio Calculation:\n",
    "# Calculate the ratio of annual donor receipts to annual donor demands.\n",
    "# Calculate age-specific demands ratio.\n",
    "# Apply Ratios: Adjust the forecasted values by these ratios.\n",
    "\n",
    "# 1. Forecasting the overall demand.\n",
    "# 2. Distributing the forecasted demand among different age groups using age-specific ratios.\n",
    "# 3. Adjusting these distributed forecasts using the month and age-specific ratios.\n",
    "\n",
    "\n",
    "# Load the historical data\n",
    "#historical_data_path = '/annual_unique_donors.csv'\n",
    "#pd.read_csv(historical_data_path)\n",
    "\n",
    "#historical_demand_daily['month'] = historical_demand_daily['month_year'].dt.month\n",
    "#historical_demand_daily['day'] = historical_demand_daily['receiptdate'].dt.day\n",
    "# Calculate annual donor receipts and demands\n",
    "# annual_donor_receipts = historical_data_df.groupby('year')['demand'].sum().reset_index(name='Yearly Receipt')\n",
    "# annual_donor_demands = historical_data_df.groupby('year')['demand'].sum()\n",
    "# Annual receipts and demands DataFrames\n",
    "annual_donor_receipts = filtered_annual_receipts  #pd.DataFrame({'year': [2022, 2023, 2024], 'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_donor_demands = filtered_annual_demands  #pd.Series({2022: 601254, 2023: 752898, 2024: 505219}, name='unique_key')\n",
    "\n",
    "# Age-specific demands DataFrame\n",
    "age_specific_demands = filtered_annual_demands_age_specific #pd.DataFrame({\n",
    "#     'year': [2022, 2022, 2022, 2023, 2023, 2023, 2024, 2024, 2024],\n",
    "#     'age': [18, 19, 20, 18, 19, 20, 18, 19, 20],\n",
    "#     'demand': [199, 286, 192, 249, 345, 243, 122, 267, 196]})\n",
    "\n",
    "# Calculate age-specific demands\n",
    "annual_donor_demands_age_specific = filtered_annual_demands_age_specific #historical_data_df.groupby(['year', 'age'])['demand'].sum().reset_index()\n",
    "\n",
    "# # Define a function to fit SARIMA model and forecast future demands\n",
    "# def fit_sarima_and_forecast(data, start_year, forecast_periods):\n",
    "#     model = sm.tsa.statespace.SARIMAX(data,\n",
    "#                                       order=(1, 1, 1),\n",
    "#                                       seasonal_order=(1, 1, 1, 12),\n",
    "#                                       enforce_stationarity=False,\n",
    "#                                       enforce_invertibility=False)\n",
    "#     results = model.fit(disp=False)\n",
    "#     forecast = results.get_forecast(steps=forecast_periods)\n",
    "#     forecast_values = forecast.predicted_mean\n",
    "#     forecast_index = pd.date_range(start=start_year, periods=forecast_periods, freq='MS')\n",
    "#     forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "#     return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2007\n",
    "end_ons_year = 2022 # The last avalilable year extracted mortality statistics from ONS\n",
    "final_year = 2024\n",
    "end_year = end_ons_year\n",
    "# Short term forecast extended years\n",
    "end_forecast_year = 2026\n",
    "\n",
    "# Long term forecast extended years\n",
    "year_forecast_long = 2039\n",
    "\n",
    "start_age = 18\n",
    "end_age = 106\n",
    "\n",
    "# Years from 2007 to 2022 (year_forecast_long the single life table is extracted from ONS and is available)\n",
    "years_ons = list(range(start_year, end_ons_year + 1))\n",
    "\n",
    "# Extend the table for years 2023 to 2026 (single life table is extracted from ONS and is NOT available) \n",
    "extended_years = list(range(end_ons_year+1, year_forecast_long + 1))\n",
    "\n",
    "# All years 2023 to 2026\n",
    "years = list(range(start_year, year_forecast_long + 1))\n",
    "\n",
    "# Ages from 18 to 100 (age in the single life table is extracted from ONS and is available)\n",
    "ages_100 = list(range(18, 101))\n",
    "\n",
    "# Extend ages from 100 to 106\n",
    "extended_ages = list(range(100, end_age+1))\n",
    "\n",
    "\n",
    "# Ages from 18 to 106\n",
    "age_range = range(18, end_age+1)\n",
    "\n",
    "ages = list(age_range)\n",
    "\n",
    "years_forecast_long = list(range(start_year, year_forecast_long+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Monte Carlo Simulation number of iterations\n",
    "iterations = 1000\n",
    "\n",
    "# Assumptions for the average range of reciepts\n",
    "lower_bound = 4000\n",
    "upper_bound = 7000\n",
    "\n",
    "# Number of working days in 2024\n",
    "num_working_days_2024 = 256\n",
    "\n",
    "# Fixed total receipts for 2022 and 2023\n",
    "total_receipts_2022 = 751967.534626039\n",
    "total_receipts_2023 = 970035.028248588\n",
    "\n",
    "lpa_demands = annual_donor_demands\n",
    "\n",
    "# Calculate total demands for 2022 and 2023\n",
    "# Filter the DataFrame for 2022 and 2023 data\n",
    "data_2022 = lpa_demands[lpa_demands['year'] == 2022]\n",
    "data_2023 = lpa_demands[lpa_demands['year'] == 2023]\n",
    "\n",
    "# Calculate total demands for 2022 and 2023\n",
    "total_demand_2022 = data_2022['demand'].sum()\n",
    "total_demand_2023 = data_2023['demand'].sum()\n",
    "\n",
    "# Aggregating age distribution: The age distributions for 2022 and 2023 are aggregated and normalised\n",
    "# Aggregate and normalise age distributions for 2022 and 2023\n",
    "age_distribution_2022 = data_2022.groupby('age')['demand'].sum().to_dict()\n",
    "age_distribution_2023 = data_2023.groupby('age')['demand'].sum().to_dict()\n",
    "\n",
    "for age in age_distribution_2022:\n",
    "    age_distribution_2022[age] /= total_demand_2022\n",
    "# print(age_distribution_2022)\n",
    "for age in age_distribution_2023:\n",
    "    age_distribution_2023[age] /= total_demand_2023\n",
    "# print(age_distribution_2023)\n",
    "\n",
    "# Average age distribution: Calculates the average across both years for shared age groups.\n",
    "# Average age distribution across 2022 and 2023\n",
    "average_age_distribution = {}\n",
    "for age in age_distribution_2022:\n",
    "    if age in age_distribution_2023:\n",
    "        average_age_distribution[age] = (age_distribution_2022[age] + age_distribution_2023[age]) / 2\n",
    "#print(average_age_distribution)\n",
    "\n",
    "# # Check for NaN values\n",
    "# has_nan = total_demand_2022.isna().any()\n",
    "# print(\"total_demand_2022 has NaN values:\", has_nan)\n",
    "# has_nan = total_demand_2023.isna().any()\n",
    "# print(\"total_demand_2023 has NaN values:\", has_nan)\n",
    "\n",
    "# # Check for NaN values\n",
    "# has_nan = age_distribution_2022.isna().any()\n",
    "# print(\"total_demand_2022 has NaN values:\", has_nan)\n",
    "# # Detect NA values\n",
    "# na_values = age_distribution_2022.isnull()\n",
    "# print(age_distribution_2022[na_values])\n",
    "# # Detect NA values using numpy.where()\n",
    "# na_indices = np.where(age_distribution_2022.isna())[0]\n",
    "# print(f\"Null values in age_distribution_2022: {na_indices}\")\n",
    "\n",
    "# has_nan = age_distribution_2023.isna().any()\n",
    "# print(\"total_demand_2023 has NaN values:\", has_nan)\n",
    "# # Detect NA values\n",
    "# na_values = age_distribution_2023.isnull()\n",
    "# print(age_distribution_2023[na_values])\n",
    "# # Detect NA values using numpy.where()\n",
    "# na_indices = np.where(age_distribution_2023.isna())[0]\n",
    "# print(f\"Null values in age_distribution_2023: {na_indices}\")\n",
    "\n",
    "# # NA fill \n",
    "# # Fill NA values with the mean of the Series\n",
    "# filled_series = series.fillna(series.mean())\n",
    "# # Forward fill NA values (propagate last valid observation forward)\n",
    "# filled_series = series.fillna(method='ffill')\n",
    "# # Backward fill NA values (propagate next valid observation backward)\n",
    "# filled_series = series.fillna(method='bfill')\n",
    "# print(filled_series)\n",
    "\n",
    "\n",
    "# reciept ratios for 2022 and 2023\n",
    "ratio_receipt_donor_2022 = total_receipts_2022 / total_demand_2022\n",
    "ratio_receipt_donor_2023 = total_receipts_2023 / total_demand_2023\n",
    "# Average reciept ratio\n",
    "average_reciept_ratio = (ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2\n",
    "\n",
    "\n",
    "# Monte Carlo simulation for 2024\n",
    "# Monte Carlo simulation results initialisation\n",
    "monte_carlo_results = np.random.uniform(lower_bound, upper_bound, iterations)\n",
    "#monte_carlo_results = []\n",
    "#monte_carlo_results = np.zeros(iterations)\n",
    "for i in range(iterations):\n",
    "    #random_receipt = random.randint(lower_bound, upper_bound)\n",
    "    random_receipt = np.random.uniform(lower_bound, upper_bound)\n",
    "    total_receipts_2024 = random_receipt * num_working_days_2024\n",
    "    \n",
    "    estimated_donors_2024 = total_receipts_2024 / average_reciept_ratio  ##    ???????? should be devided by the ratio or multiply by 1+ratio or multiply by ratio?????\n",
    "    #monte_carlo_results.append(estimated_donors_2024)\n",
    "    monte_carlo_results[i] = estimated_donors_2024\n",
    "#print(monte_carlo_results)\n",
    "\n",
    "\n",
    "##    ???????? should be devided by the ratio or multiply by 1+ratio or multiply by ratio?????\n",
    "\n",
    "\n",
    "\n",
    "# for age in average_age_distribution.index:\n",
    "#     sum_values = sum(monte_carlo_results[i] * average_age_distribution[age] for i in range(iterations))\n",
    "#     sum_squared_values = sum((monte_carlo_results[i] * average_age_distribution[age]) ** 2 for i in range(iterations))\n",
    "# Initialise an empty DataFrame for output\n",
    "output_data = []\n",
    "results = []\n",
    "\n",
    "# Add data for each age group for 2024\n",
    "for age_group in average_age_distribution.keys():\n",
    "    sum_values = 0\n",
    "    sum_squared_values = 0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        age_value = monte_carlo_results[i] * average_age_distribution[age_group]\n",
    "        sum_values += age_value\n",
    "        sum_squared_values += age_value ** 2\n",
    "\n",
    "    # Calculate mean and standard deviation for the forecast\n",
    "    forecasted_donors_mean = sum_values / iterations\n",
    "    forecasted_donors_stddev = np.sqrt(sum_squared_values / iterations - (sum_values / iterations) ** 2)\n",
    "\n",
    "    output_data.append([\n",
    "        2024, age_group, forecasted_donors_mean, forecasted_donors_stddev, \n",
    "        monte_carlo_results[i], age_distribution_2022[age_group], age_distribution_2023[age_group], \n",
    "        average_age_distribution[age_group], random_receipt\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame for display or saving\n",
    "output_df = pd.DataFrame(output_data, columns=[\n",
    "    'year', 'age', 'Forecasted Donors Mean', 'Forecasted Donors StdDev', \n",
    "    'monte_carlo_results', 'Age Distribution 2022', 'Age Distribution 2023',\n",
    "    'Average Age Distribution', 'Random Receipt'\n",
    "])\n",
    "  \n",
    "# Convert to DataFrame for further processing\n",
    "forecast_df = output_df\n",
    "\n",
    "# Print or save the output\n",
    "#print(forecast_df.head(5))\n",
    "forecast_df\n",
    "\n",
    "# # Plotting the Forecast\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.errorbar(df_output['age'], df_output['Forecast Mean'], \n",
    "#              yerr=df_output['Forecast StdDev'], fmt='o', label='Forecast')\n",
    "# plt.title(\"Long-Term Forecast Market Shape\")\n",
    "# plt.xlabel('age')\n",
    "# plt.ylabel('Forecasted Donors ')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Donor Estimates & Actuals\n",
    "\n",
    "lpa_donors = historical_data_df\n",
    "lpa_donors = lpa_donors.rename(columns={'year': 'year', 'age': 'age', 'demand': 'lx'})\n",
    "\n",
    "# Calculate 2024 estimate\n",
    "short_term_forecast_2024 = np.array(forecast_df['Forecasted Donors Mean'])\n",
    "\n",
    "# Replace the new estimate of 2024 based on short term forecast\n",
    "lpa_donors.loc[lpa_donors['year'] == 2024, 'lx'] = short_term_forecast_2024\n",
    "\n",
    "\n",
    "#annual_unique_donors.loc[(annual_unique_donors['year'] == 2017) & (annual_unique_donors['age'] == 18), 'demand']\n",
    "data = lpa_donors\n",
    "# Filter the data for the year 2024 to use as the forecast baseline\n",
    "data_2024 = data[data['year'] == 2024]\n",
    "\n",
    "# Only short term Naive forecast (2-year)\n",
    "forecast_years = range(2025, 2040)\n",
    "\n",
    "# Initialize forecast_lpa with the original data\n",
    "forecast_lpa = data.copy()\n",
    "\n",
    "# For each year in the forecast period, copy the demand from 2024 for each age\n",
    "for year in forecast_years:\n",
    "    # Create a new dataframe for the forecast year with the same 'age' and 'demand' as 2024\n",
    "    forecast_data = data_2024.copy()\n",
    "    forecast_data['year'] = year  # Update the year to the forecast year\n",
    "    \n",
    "    # Append the forecast data to the cumulative forecast_lpa dataframe\n",
    "    forecast_lpa = pd.concat([forecast_lpa, forecast_data])\n",
    "\n",
    "# Reset index and remove duplicates (if necessary)\n",
    "forecast_lpa.reset_index(drop=True, inplace=True)\n",
    "forecast_lpa_df = pd.DataFrame(forecast_lpa)\n",
    "\n",
    "# Display the forecast data\n",
    "print(forecast_lpa)\n",
    "\n",
    "#forecast_lpa_df = forecast_lpa_df.rename(columns={'year': 'year', 'age': 'Age', 'demand': 'lx'})\n",
    "print(forecast_lpa_df)\n",
    "\n",
    "\n",
    "# Create the pivot table\n",
    "df = forecast_lpa_df\n",
    "pivot_table = df.pivot_table(index='age', columns='year', values='lx', fill_value=0)\n",
    "#print(pivot_table)\n",
    "\n",
    "pivot_tbl = pivot_table\n",
    "# Reset index to make 'age' a column again\n",
    "pivot_tbl.reset_index(inplace=True)\n",
    "\n",
    "# Remove the second row\n",
    "pvt_tbl = pivot_tbl.drop(0)\n",
    "\n",
    "# Remove the second column (2007.0)\n",
    "pvt_tbl.drop(columns=[0.0], inplace=True)\n",
    "#pvt_tbl = pvt_tbl.pop(0.0)\n",
    "\n",
    "# Set a label to the first column\n",
    "pvt_tbl.rename(columns={'': 'Age Group'}, inplace=True)\n",
    "\n",
    "# Remove the index\n",
    "pvt_tbl.reset_index(drop=True, inplace=True)\n",
    "#print(pvt_tbl)\n",
    "\n",
    "Donor_Estimates_Actuals = pvt_tbl\n",
    "# df = Donor_Estimates_Actuals\n",
    "# df.set_index('year', inplace=True)\n",
    "# df = df.drop(df.index[0])\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# Donor_Estimates_Actuals = df\n",
    "\n",
    "# Save to CSV\n",
    "output_file_path = \"Donor_Estimates_Actuals.csv\"\n",
    "Donor_Estimates_Actuals.to_csv(output_file_path, index=False)\n",
    "\n",
    "Donor_Estimates_Actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Survival Rate\n",
    "- Calculate the survival rate for each year from 2007 to 2030 and for ages 18 to 106.\n",
    "- utilise the scikit-survival package:\n",
    "    1. Prepare the data: input the mortality rates (qx) as an array of probabilities for each age (18-106).\n",
    "    2. Initialise the number of donors for each year and age: This will include the actual LPA data for the years 2007-2023.\n",
    "    3. Calculate the survival rate for future years: Using the mortality statistics for males and females, compute the survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Forecast Mortality rates (qx) for ages 49 to 106:\n",
    "\n",
    "- Excel Formula: \n",
    "=10^@TREND(Log(average(mortality rate for Age=45:49)), (Age=49:94), (Age=90,Age^2=90^2)))\n",
    "\n",
    "0. Load the mortality rates (qx) from the CSV.\n",
    "\n",
    "1. The first step Compute the logarithm of these average mortality rates for age 49 to 94 - Log(average(mortality rate For Age from 49 to 94)):\n",
    "    - Calculate Calculate the average mortality rates for the specified age groups.\n",
    "    - Calculate the natural logarithm (base e) of the average mortality rate. \n",
    "\n",
    "2. Perform linear regression based on these values: \n",
    "    - The regression model uses ages 49 to 94 and their squares as independent variables. The Log(average(mortality rate for Age=45:49)) claculated in the first step is used as the independent variable in the TREND function.\n",
    "    - The logarithms of the mortality rates, are the dependent variable. It predicts the logarithm of the mortality rate for age 90 to 115.\n",
    "\n",
    "3. Predict the logarithm of mortality rates for ages 90 to 106: \n",
    "    - The model predicts the logarithm of the mortality rate for from 90 to 115 based on regression.\n",
    "    - This represents the new data point for which the prediction is needed. E.g., if the independent variables is for age=90, then calculate the square of age 90 (which is 8100).\n",
    "\n",
    "4. Apply Exponential Back-Transformation to get the predicted mortality rates on the original scale.\n",
    "    - Finally, raising 10 to the power of the predicted logarithm converts it back to the original mortality rate scale. The result of the TREND function is raised to the power of 10, effectively converting the logarithm back to the original scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "How to calculate the number of Living customers from year 2007 to 2040 for age from 18 to 106, by first computig the multiple years (2007 to 2040) Life tables, Cohort survival table, and finally Living customers tables?\n",
    "Given the follwoing numbers (mx, qx, Ix, dx, ex) from 2007 to 2022 for each age from 18 to 100 downloaded from the ONS statistics for England and Wales, \n",
    "and already calculated the number of customers as well as forecasted from 2007 till 2030 years for age 18 to 106, \n",
    "Where:\n",
    "- mx is the central rate of mortality, defined as the number of deaths at age x last birthday in the year to which the single year life table \n",
    "relates divided by the estimated population at that age over the same year.\n",
    "- qx is the mortality rate between age x and (x +1), that is the probability that a person aged x exactly will die before reaching age (x +1).\n",
    "- lx is the number of survivors to exact age x of 100000 live births of the same sex who are assumed to be subject throughout their lives to the \n",
    "mortality rates experienced in the year to which the single year life table relates.\n",
    "- dx is the number dying between exact age x and (x +1) described similarly to lx, that is dx=lx-lx+1.\n",
    "- ex is the average period expectation of life at exact age x, that is the average number of years that those aged x exact will live thereafter\n",
    "based on the mortality rates experienced in the year to which the single year life table relates.\n",
    "\n",
    "# Calculate the number of living customers from 2007 to 2040 for ages 18 to 106, using the life tables, cohort survival tables, and the living customers tables:\n",
    "\n",
    "1. **Life Tables Construction**\n",
    "   For each year (2007 to 2040) and each age (18 to 106), construct life tables. \n",
    "   Given already have mx, qx, lx, dx, and ex values from 2007 to 2022:\n",
    "\n",
    "   a. **Estimate Mortality Rates (qx) for Future Years (2023 to 2040)**\n",
    "      Given mx for the years 2023 to 2040, calculate qx using the formula:\n",
    "      $$\n",
    "      q_x = \\frac{m_x}{1 + 0.5 \\times m_x}\n",
    "      $$\n",
    "      * If mx is not available for future years, may need to project or assume future qx values based on historical trends or a forecasting model.\n",
    "\n",
    "   b. **Construct lx (Survivors)**\n",
    "      Start with an initial value for $l_{18}$ (typically 100,000 for a cohort of live births).\n",
    "      For each subsequent age and year:\n",
    "      $$\n",
    "      l_{x+1} = l_x \\times (1 - q_x)\n",
    "      $$\n",
    "      * This step should be done for each year and age.\n",
    "\n",
    "   c. **Calculate dx (Deaths)**\n",
    "      For each age and year:\n",
    "      $$\n",
    "      d_x = l_x - l_{x+1}\n",
    "      $$\n",
    "\n",
    "   d. **Calculate ex (Life Expectancy)**\n",
    "      Calculate the life expectancy $e_x$ using the formula:\n",
    "      $$\n",
    "      e_x = \\frac{L_x + L_{x+1} + \\ldots + L_{max\\ age}}{l_x}\n",
    "      $$\n",
    "      where $L_x$ is the number of person-years lived between ages $x$ and $x+1$, often approximated by:\n",
    "      $$\n",
    "      L_x = 0.5 \\times (l_x + l_{x+1})\n",
    "      $$\n",
    "\n",
    "2. **Cohort Survival Tables Construction**\n",
    "   To calculate cohort survival for each cohort (group of customers born in the same year):\n",
    "\n",
    "   a. **Determine the Initial Population for Each Cohort**\n",
    "      For each year and each age, determine the initial number of customers in the cohort.\n",
    "\n",
    "   b. **Apply Survival Rates**\n",
    "      Using the qx values calculated in the life tables, determine how many customers survive each year by multiplying the cohort population by $1 - q_x$.\n",
    "\n",
    "   c. **Project the Cohorts Over Time**\n",
    "      Continue this for each subsequent year, ensuring to track how each cohort diminishes over time due to mortality.\n",
    "\n",
    "3. **Living Customers Table Construction**\n",
    "   After calculating the cohort survival tables:\n",
    "\n",
    "   a. **Aggregate Living Customers by Year**\n",
    "      For each year from 2007 to 2040, sum up the number of living customers across all cohorts and ages to get the total number of living customers in each year.\n",
    "\n",
    "   b. **Tabulate the Results**\n",
    "      Create a table where each row corresponds to a year (2007 to 2040), and each column corresponds to an age (18 to 106). The entries in the table should be the number of living customers.\n",
    "\n",
    "4. **Example Steps for 2023**\n",
    "   - **Life Table for 2023**:\n",
    "     - Use the projected mx values to compute qx.\n",
    "     - Calculate lx for ages 18 to 106.\n",
    "     - Compute dx and ex.\n",
    "   - **Cohort Survival for 2023**:\n",
    "     - Start with the number of customers for each cohort at the beginning of 2023.\n",
    "     - Apply the survival probabilities to estimate how many customers survive through the year.\n",
    "   - **Living Customers in 2023**:\n",
    "     - Sum the surviving customers from all cohorts and ages to get the total number of living customers in 2023.\n",
    "\n",
    "5. **Repeat the Process for Each Year from 2024 to 2040**\n",
    "   By following these steps for each year, you will be able to calculate the number of living customers for each year from 2007 to 2040, \n",
    "    broken down by age from 18 to 106. \n",
    "This approach combines historical data, mortality projections, and cohort survival analysis to forecast the customer population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of living customers from 2007 to 2040 for ages 18 to 106:\n",
    "\n",
    "# Assumptions: have the necessary mortality data (mx, qx, lx, dx, ex) for the years 2007 to 2022 \n",
    "# and have forecasted / estimated data for subsequent years.\n",
    "\n",
    "end_ons_year = 2022 # The last avalilable year extracted mortality statistics from ONS\n",
    "\n",
    "# Load the life table data\n",
    "file_path = 'nltew198020221.xlsx'\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "\n",
    "years_all = re.findall(r'\\d{4}', file_path)\n",
    "if len(years_all) > 1:\n",
    "    final_year = int(years_all[1])\n",
    "    print(f\"The final year of the extracted data is: {end_ons_year}\")\n",
    "else:\n",
    "    print(\"Less than two years found in the filename.\")\n",
    "    \n",
    "# Initialise an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Load life tables from 2007 to 2022\n",
    "for year in range(start_year, end_ons_year+1):\n",
    "    sheet_name = str(year)\n",
    "    if sheet_name in xls.sheet_names:\n",
    "        df_male = pd.read_excel(xls, sheet_name=sheet_name, skiprows=range(0, 6), usecols=\"A:F\")\n",
    "        df_female = pd.read_excel(xls, sheet_name=sheet_name, skiprows=range(0, 6), usecols=\"H:M\")\n",
    "        df_male['year'] = year\n",
    "        df_female['year'] = year\n",
    "        df_male.columns = ['age', 'mx', 'qx', 'lx', 'dx', 'ex', 'year']\n",
    "        df_female.columns = ['age', 'mx', 'qx', 'lx', 'dx', 'ex', 'year']\n",
    "        df_combined = pd.merge(df_male, df_female, on=['age', 'year'], suffixes=('_male', '_female'))\n",
    "        df_combined['mx'] = (df_combined['mx_male'] + df_combined['mx_female']) / 2\n",
    "        df_combined['qx'] = (df_combined['qx_male'] + df_combined['qx_female']) / 2\n",
    "        df_combined['lx'] = (df_combined['lx_male'] + df_combined['lx_female']) / 2\n",
    "        df_combined['dx'] = (df_combined['dx_male'] + df_combined['dx_female']) / 2\n",
    "        df_combined['ex'] = (df_combined['ex_male'] + df_combined['ex_female']) / 2\n",
    "        df_combined = df_combined[['age', 'mx', 'qx', 'lx', 'dx', 'ex', 'year']]\n",
    "        dfs.append(df_combined)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "source_life_table = final_df[(final_df['age'] >= 18) & (final_df['age'] <= 106)]\n",
    "source_life_df = pd.DataFrame(source_life_table[['year', 'age', 'lx', 'qx']])\n",
    "\n",
    "\n",
    "\n",
    "# Function to add new rows\n",
    "def add_new_rows(df, start_year, end_year, start_age, end_age):\n",
    "    new_rows = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for age in range(start_age, end_age + 1):\n",
    "            if age > 100:  # Only add ages greater than 100\n",
    "                new_rows.append(\n",
    "                    {'year': year,\n",
    "                     'age': age,\n",
    "                     'lx': 0, \n",
    "                     'qx': 0})\n",
    "    return df.append(new_rows, ignore_index=True)\n",
    "\n",
    "# Create the initial DataFrame\n",
    "df = source_life_df\n",
    "\n",
    "# Add the new rows to the DataFrame\n",
    "new_life_tbl = add_new_rows(df, start_year, year_forecast_long, 18, 106)\n",
    "# Display the updated DataFrame\n",
    "#print(new_life_tbl)\n",
    "final_lpa_df = new_life_tbl\n",
    "final_lpa_df['qx'] = new_life_tbl['qx']\n",
    "#final_lpa_df   \n",
    "\n",
    "# Initialise a dictionary to hold starting population for each age in ages_100 and year in years_ons\n",
    "initial_pop_dict = {}\n",
    "\n",
    "# Starting population for each age and year \n",
    "for year in years_forecast_long:\n",
    "    #initial_population = forecast_lpa_df[forecast_lpa_df['year'] == year]['lx'].values\n",
    "    initial_population = final_lpa_df.loc[(final_lpa_df['year']==year), ['year', 'age', 'lx']]\n",
    "    \n",
    "    # Convert yearly data to DataFrame and set multi-index\n",
    "    initial_pop_dict[year] = pd.DataFrame(initial_population).set_index(['year', 'age'])\n",
    "#print(initial_pop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lpa donor actuals and forecasts for the source lx and update it\n",
    "\n",
    "df = pd.concat(initial_pop_dict.values(), axis=0)\n",
    "df.reset_index(inplace=True)\n",
    "df#.iloc[:,:-10,:]\n",
    "\n",
    "df_new_values = Donor_Estimates_Actuals.loc[:,2007:2039]\n",
    "df_new_values.reset_index(inplace=True)\n",
    "df_new_values = df_new_values.rename(columns={'index': 'age'})\n",
    "\n",
    "# Melt the new values DataFrame\n",
    "df_new_values = df_new_values.melt(id_vars=['age'], var_name='year', value_name='lx')\n",
    "df_new_values# = df_new_values[['year', 'age', 'lx']]\n",
    "#df_new_values['year'] = df_new_values['year'].str.extract('(\\d+)').astype(int)\n",
    "df_new_values\n",
    "\n",
    "# Merge the original DataFrame with the new values DataFrame\n",
    "df = df.merge(df_new_values, on=['year', 'age'], how='right')\n",
    "df['lx'] = df['lx_y']\n",
    "df.drop(columns=['lx_x', 'lx_y'], inplace=True)\n",
    "\n",
    "initial_donor_dict = {}\n",
    "\n",
    "for year in years_forecast_long:\n",
    "    df.loc[(df['year']==year), ['age']] = age_range\n",
    "    #df.loc[(df['year']==year), ['year', 'age', 'lx']].set_index(['year', 'age'])\n",
    "    initial_donor_dict[year] = df.loc[(\n",
    "        df['year']==year), ['year', 'age', 'lx']].set_index(['year', 'age'])\n",
    "#df.set_index(['year', 'age'])\n",
    "#print(df.loc[(df['year']==year), ['year', 'age', 'lx']])\n",
    "#initial_donor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_donor_dict\n",
    "#donor_df = pd.concat(initial_donor_dict.values(), axis=0) \n",
    "donor_df = df.set_index(['year', 'age'])\n",
    "#donor_df.loc[(year, range(18,107)), 'lx']\n",
    "#donor_df.loc[(year, age), 'lx']\n",
    "\n",
    "liftbl = pd.DataFrame()\n",
    "\n",
    "for year in years_forecast_long: #range(2007, end_ons_year + 1):\n",
    "    for age in ages:\n",
    "        # fill the qx values based on average of 4 previous ages for that age\n",
    "        #qx_values = np.array([source_life_df.loc[(source_life_df['year'] == 2007) & (source_life_df['age'] > age-6) & (source_life_df['age'] < age), 'qx'].mean()])\n",
    "        qx_cur = source_life_df.loc[(\n",
    "            source_life_df['year'] == year) & (\n",
    "            source_life_df['age'] > age-5) & (\n",
    "            source_life_df['age'] < age), 'qx'].mean() if year <= end_ons_year else np.nan\n",
    "        #lx_cur = source_life_df.loc[(source_life_df['year'] == year) & (source_life_df['age'] > age-6) & (source_life_df['age'] < age), 'lx'].mean() #(source_life_df['age'] == age), 'lx'].values[0]\n",
    "        #lx_cur = donor_df.loc[(year, age), 'lx']\n",
    "        lx_cur = donor_df.loc[(year, age), 'lx']\n",
    "        # If the result is valid (lx_next is not None), append it as a new row to source_life_df\n",
    "        if qx_cur is not None:\n",
    "            # Create a new row with the required values, adjust as necessary\n",
    "            new_row = pd.DataFrame({\n",
    "                'year': [year],  # next year, 2024 in this case\n",
    "                'age': [age],    # next age\n",
    "                'lx': [lx_cur],      # calculated value\n",
    "                'qx': [qx_cur]      # calculated value\n",
    "            })\n",
    "            \n",
    "\n",
    "            # Append the new row to source_life_df\n",
    "            liftbl = pd.concat([liftbl, new_row], ignore_index=True)\n",
    "source_life_df = liftbl.fillna(0)\n",
    "#source_life_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# for all years (2023 - 2039) and all age (18 - 106) calculate qx if we have qx (qx_prev) for all ages before and including 2022 (2007 - 2022) and we dont have qx (qx_cur) from 2023 onwards \n",
    "and should be calculated based on lx of the current year (lx_cur) and previous year lx (lx_prev) by using formula:  lx_cur = lx_prev * (1 - qx_cur), by using the attached data containing qx and lx, \n",
    "where qx=is the mortality rate between age x and (x +1), that is the probability that a person aged x exactly will die before reaching age (x +1). \n",
    "lx=is the number of survivors to exact age x of 100,000 live births of the same sex who are assumed to be subject throughout their lives to the mortality rates experienced in the year to which the single year life table relates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# population_forecast_df: Contains the forecasted population for each age group in 2023 and 2024.\n",
    "population_forecast = pd.read_csv('population_forecast.csv')\n",
    "# Convert the DataFrame to the desired format\n",
    "df_melted = population_forecast.melt(id_vars=['age'], var_name='year', value_name='population')\n",
    "population_forecast_df = pd.DataFrame(df_melted)\n",
    "\n",
    "pop_f = population_forecast_df#.set_index(['age', 'year'])\n",
    "pop_f['year'] = pd.to_numeric(pop_f['year'], errors='coerce')\n",
    "pop_f['age'] = pd.to_numeric(pop_f['age'], errors='coerce')\n",
    "\n",
    "# Sort the data by year and age for proper processing\n",
    "pop_f.sort_values(by=['year', 'age'], inplace=True)\n",
    "\n",
    "pop_f#pop_f[(pop_f['age'] == age) & (pop_f['year'] == year)]['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_life = source_life_df\n",
    "\n",
    "years_range = list(range(2023, 2040))  # Extend years range for future years\n",
    "ager = list(range(18, 107))  # Age range from 18 to 106 (inclusive)\n",
    "\n",
    "# Function to calculate qx based on lx (survival) values\n",
    "def calculate_qx_from_lx(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Calculate qx using lx values: qx = 1 - (lx+1 / lx)\n",
    "    Ensure qx is non-negative and that lx decreases with age.\n",
    "    \"\"\"\n",
    "    lx = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age), 'lx'].values\n",
    "    lx_next = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age + 1), 'lx'].values\n",
    "    \n",
    "    if len(lx) > 0 and len(lx_next) > 0 and lx[0] > 0:  # Ensure lx is valid and non-zero\n",
    "        qx = 1 - (lx_next[0] / lx[0])\n",
    "        # Ensure qx is not negative\n",
    "        return max(0, qx)  # Cap qx at a minimum of 0\n",
    "    else:\n",
    "        lx_prev = source_life.loc[(source_life['year'] == year-1) & (source_life['age'] == age), 'lx'].values\n",
    "        lx_cur = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age + 1), 'lx'].values if age < 106 else lx\n",
    "        qx = 1 - (lx_cur[0] / lx_prev[0])\n",
    "        return max(0, qx)  # Cap qx at a minimum of 0\n",
    "    return None  # Return None if lx is missing or invalid\n",
    "\n",
    "# Function to get the mean of the last valid qx values (up to 4)\n",
    "def get_previous_qx_mean(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Get the mean of the last valid qx values for a given age and year (up to 4).\n",
    "    \"\"\"\n",
    "    qx_values = []\n",
    "    for i in range(1, 5):  # Look back at the previous 4 age groups\n",
    "        qx_prev = source_life.loc[(source_life['year'] == year-1) & \n",
    "                                  (source_life['age'] == age - i), 'qx'].values\n",
    "        if len(qx_prev) > 0 and qx_prev[0] > 0:  # Ensure qx is valid and non-zero\n",
    "            qx_values.append(qx_prev[0])\n",
    "    \n",
    "    if len(qx_values) >= 2:  # Use at least 2 valid values\n",
    "        return np.mean(qx_values)\n",
    "    else:\n",
    "        return source_life.loc[(\n",
    "            source_life['year'] == year-1) & (\n",
    "            source_life['age'] == age - 1\n",
    "        ), 'qx'].values[0] if age > 18 else source_life.loc[(\n",
    "            source_life['year'] == year-1) & (\n",
    "            source_life['age'] == age), 'qx'].values[0]\n",
    "    return None  # Return None if there aren't enough valid values\n",
    "\n",
    "# Function to get the mean of the next valid qx values (up to 4)\n",
    "def get_next_qx_mean(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Get the mean of the next valid qx values for a given age and year (up to 4).\n",
    "    \"\"\"\n",
    "    qx_values = []\n",
    "    for i in range(1, 5):  # Look forward at the next 4 age groups\n",
    "        qx_next = source_life.loc[(source_life['year'] == year) & \n",
    "                                  (source_life['age'] == age + i), 'qx'].values\n",
    "        if len(qx_next) > 0 and qx_next[0] > 0:  # Ensure qx is valid and non-zero\n",
    "            qx_values.append(qx_next[0])\n",
    "    \n",
    "    if len(qx_values) >= 2:  # Use at least 2 valid values\n",
    "        return np.mean(qx_values)\n",
    "    else:\n",
    "        return source_life.loc[(\n",
    "            source_life['year'] == year-1) & (\n",
    "            source_life['age'] == age), 'qx'].values[0]\n",
    "    return None  # Return None if there aren't enough valid values\n",
    "\n",
    "# Function to get qx for previous years, considering missing values\n",
    "def get_previous_qx(source_life, year, age, lookback_years=10):\n",
    "    \"\"\"\n",
    "    Retrieves the most recent non-zero qx value for a given age\n",
    "    within a specified lookback period.\n",
    "    \"\"\"\n",
    "    for i in range(1, lookback_years+1):\n",
    "        qx_prev = source_life.loc[(source_life['year'] == year - i) & (\n",
    "            source_life['age'] == age), 'qx'].values\n",
    "        if len(qx_prev) > 0 and qx_prev[0] > 0:\n",
    "            return np.mean(qx_prev) #qx_prev[0]\n",
    "    return None  # No valid qx found in the lookback period\n",
    "\n",
    "\n",
    "# Iterate over each future year from 2023 to 2039 and replace invalid qx values\n",
    "for year in years_range:\n",
    "    for age in ages:\n",
    "        \n",
    "        # Get current qx value\n",
    "        qx_cur = source_life.loc[(source_life['year'] == year) & (\n",
    "            source_life['age'] == age), 'qx'].values[0]\n",
    "        \n",
    "        qx_cur = calculate_qx_from_lx(source_life, year, age)\n",
    "\n",
    "        source_life.loc[(source_life['year'] == year) & (\n",
    "            source_life['age'] == age), 'qx'] = qx_cur  \n",
    "    \n",
    "        # Replace if qx is negative or zero\n",
    "        if qx_cur <= 0:\n",
    "            if age < 21:\n",
    "                \n",
    "                qx_prev = get_previous_qx(source_life, year, age, lookback_years=5)\n",
    "                if qx_prev is not None:\n",
    "                    qx_cur = qx_prev\n",
    "                else:\n",
    "                    qx_cur = source_life.loc[(source_life['year'] == year-1) & (\n",
    "                        source_life['age'] == age), 'qx'].values[0]\n",
    "                    \n",
    "            elif (age > 21) & (age < 101):  # If age < 102, try to use the next valid values\n",
    "                qx_mean_next = get_next_qx_mean(source_life, year, age)\n",
    "                if qx_mean_next is not None:\n",
    "                    qx_cur = qx_mean_next\n",
    "                \n",
    "            elif (age >= 101) & (age < 107):  # If age > 21, try to use the previous valid values\n",
    "                qx_mean_prev = get_previous_qx_mean(source_life, year, age)\n",
    "                if qx_mean_prev is not None:\n",
    "                    qx_cur = qx_mean_prev\n",
    "        \n",
    "            source_life.loc[(source_life['year'] == year) & (\n",
    "                source_life['age'] == age), 'qx'] = qx_cur   \n",
    "        \n",
    "# Save the updated DataFrame to a new file\n",
    "output_file_path = 'updated_mortality_statistics.csv'\n",
    "source_life.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(source_life)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "To address the issue of having too many zeros in `qx` when calculating for future years (2023 and beyond), we can use a combination of the **survivors (`lx`)** data and the logic from the first code in my earlier response. This method will ensure that `qx` is calculated based on survival data, which can give a more reliable estimate for `qx`.\n",
    "\n",
    "### Strategy:\n",
    "1. **Use the `lx` (number of survivors) values**:  \n",
    "   If we have `lx` for all years before and after 2023, we can calculate `qx` using the relationship between survivors at age `x` and survivors at age `x+1`:\n",
    "   \\[\n",
    "   qx = 1 - \\frac{l_{x+1}}{l_x}\n",
    "   \\]\n",
    "   This formula will provide a more accurate estimate of the mortality rate based on the observed survival rates.\n",
    "\n",
    "2. **Fallback to the previous method**:  \n",
    "   If `lx` is missing or zero, we can still fallback on the averaging method from the previous years' `qx` values.\n",
    "\n",
    "### Improved Code:\n",
    "\n",
    "```python\n",
    "years_range = list(range(2023, 2040))  # Extend years range for future years\n",
    "ager = list(range(18, 21))  # Example age range (can extend this as needed)\n",
    "\n",
    "# Function to calculate qx based on lx (survival) values\n",
    "def calculate_qx_from_lx(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Calculate qx using lx values: qx = 1 - (lx+1 / lx)\n",
    "    \"\"\"\n",
    "    lx = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age), 'lx'].values\n",
    "    lx_next = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age + 1), 'lx'].values\n",
    "    \n",
    "    if len(lx) > 0 and len(lx_next) > 0 and lx[0] > 0:  # Ensure lx is valid and non-zero\n",
    "        return 1 - (lx_next[0] / lx[0])\n",
    "    return None\n",
    "\n",
    "# Function to get qx for previous years, considering missing values\n",
    "def get_previous_qx(source_life, year, age, lookback_years=3):\n",
    "    \"\"\"\n",
    "    Retrieves the most recent non-zero qx value for a given age\n",
    "    within a specified lookback period.\n",
    "    \"\"\"\n",
    "    for i in range(1, lookback_years+1):\n",
    "        qx_prev = source_life.loc[(source_life['year'] == year - i) & (\n",
    "            source_life['age'] == age), 'qx'].values\n",
    "        if len(qx_prev) > 0 and qx_prev[0] > 0:\n",
    "            return qx_prev[0]\n",
    "    return None  # No valid qx found in the lookback period\n",
    "\n",
    "# Iterate over each future year from 2023 to 2039 and calculate qx if missing\n",
    "for year in years_range:\n",
    "    # For each age group from 18 to 20 (you can extend this as needed)\n",
    "    for age in ager:\n",
    "        # Try to calculate qx using lx (survivor data)\n",
    "        qx_cur = calculate_qx_from_lx(source_life, year, age)\n",
    "        \n",
    "        # If lx calculation fails, fallback to previous qx method\n",
    "        if qx_cur is None:\n",
    "            qx_prev = get_previous_qx(source_life, year, age, lookback_years=3)\n",
    "            qx_prev2 = get_previous_qx(source_life, year-1, age, lookback_years=3)\n",
    "            \n",
    "            # If both previous years have valid qx, calculate average\n",
    "            if qx_prev is not None and qx_prev2 is not None:\n",
    "                qx_cur = (qx_prev + qx_prev2) / 2\n",
    "            elif qx_prev is not None:  # If only one previous year has qx, use that\n",
    "                qx_cur = qx_prev\n",
    "        \n",
    "        # Only update qx if the current value is zero or missing\n",
    "        if qx_cur is not None:\n",
    "            source_life.loc[(source_life['year'] == year) & \n",
    "                            (source_life['age'] == age) & \n",
    "                            (source_life['qx'] == 0), 'qx'] = qx_cur\n",
    "```\n",
    "\n",
    "### Key Changes:\n",
    "1. **Calculate `qx` from `lx`**:  \n",
    "   The function `calculate_qx_from_lx()` computes `qx` based on the survival rates (`lx`). This formula:\n",
    "   \\[\n",
    "   qx = 1 - \\frac{l_{x+1}}{l_x}\n",
    "   \\]\n",
    "   uses the number of survivors at age `x+1` and age `x` to calculate the mortality rate. This is the primary method for determining `qx` in this improved code.\n",
    "\n",
    "2. **Fallback to Previous Years' `qx`**:  \n",
    "   If the `lx` values are missing or zero (due to incomplete data), the code falls back to the previous method of using an average of the past years' `qx` values.\n",
    "\n",
    "3. **Handling Missing Data**:  \n",
    "   The code checks whether the `lx` values exist and are non-zero before performing any calculations, ensuring no division by zero or other issues.\n",
    "\n",
    "### How It Works:\n",
    "1. **Survival-Based Calculation (`lx`)**:  \n",
    "   For each future year and age group, the code first attempts to calculate `qx` using survival data. If successful, this ensures a reliable mortality rate based on real survival probabilities.\n",
    "\n",
    "2. **Fallback Mechanism**:  \n",
    "   If the `lx` data is unavailable or incomplete, it looks back at previous years' `qx` values to calculate an average or use the last known valid `qx`.\n",
    "\n",
    "3. **Replacing Zeros**:  \n",
    "   The code updates `qx` values for years where `qx` is initially 0 or missing, ensuring the calculated values are only applied where necessary.\n",
    "\n",
    "---\n",
    "\n",
    "### Output:\n",
    "After running this code, `source_life` will have the `qx` values calculated for 2023 and beyond. The use of survival (`lx`) data should minimize the number of zeros in the resulting `qx` values, producing more realistic estimates for future years.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "If you have `lx` data for the year 2023 and ages 18, 19, and 20, the formula will calculate the probability of dying between age `x` and `x+1` using the survivor data:\n",
    "- **For age 18** in 2023, `qx` will be calculated as:\n",
    "  \\[\n",
    "  qx_{18} = 1 - \\frac{l_{19}}{l_{18}}\n",
    "  \\]\n",
    "- **For age 19**, `qx` will similarly be calculated using survivors at age 19 and 20.\n",
    "\n",
    "If the `lx` data is missing for 2023, it will fallback to the previous years' `qx` values and calculate the average.\n",
    "\n",
    "Let me know if this addresses your issue or if you'd like further refinements!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "The issue of negative `qx` values arises because the formula for calculating `qx` using `lx` (survival values) can lead to negative results when the number of survivors at age `x+1` is greater than the number of survivors at age `x`. This scenario would imply a growth in the number of survivors, which is not realistic in the context of mortality rates.\n",
    "\n",
    "### Fixing the Issue:\n",
    "1. **Ensure non-negative `qx` values**:  \n",
    "   We need to ensure that `qx` values are never negative. The formula:\n",
    "   \\[\n",
    "   qx = 1 - \\frac{l_{x+1}}{l_x}\n",
    "   \\]\n",
    "   should be adjusted so that `qx` is capped at a minimum of 0. This can be done using `max(0, qx)` to avoid negative values.\n",
    "\n",
    "2. **Check `lx` Values**:  \n",
    "   The code will also verify that `lx` values are properly ordered (i.e., `l_{x+1} <= l_x`) before calculating `qx`. If `lx` values suggest an increase in survivors, the calculation will return `qx = 0`.\n",
    "\n",
    "### Updated Code:\n",
    "\n",
    "```python\n",
    "years_range = list(range(2023, 2040))  # Extend years range for future years\n",
    "ager = list(range(18, 21))  # Example age range (can extend this as needed)\n",
    "\n",
    "# Function to calculate qx based on lx (survival) values\n",
    "def calculate_qx_from_lx(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Calculate qx using lx values: qx = 1 - (lx+1 / lx)\n",
    "    Ensure qx is non-negative and that lx decreases with age.\n",
    "    \"\"\"\n",
    "    lx = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age), 'lx'].values\n",
    "    lx_next = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age + 1), 'lx'].values\n",
    "    \n",
    "    if len(lx) > 0 and len(lx_next) > 0 and lx[0] > 0:  # Ensure lx is valid and non-zero\n",
    "        qx = 1 - (lx_next[0] / lx[0])\n",
    "        # Ensure qx is not negative\n",
    "        return max(0, qx)  # Cap qx at a minimum of 0\n",
    "    return None  # Return None if lx is missing or invalid\n",
    "\n",
    "# Function to get qx for previous years, considering missing values\n",
    "def get_previous_qx(source_life, year, age, lookback_years=3):\n",
    "    \"\"\"\n",
    "    Retrieves the most recent non-zero qx value for a given age\n",
    "    within a specified lookback period.\n",
    "    \"\"\"\n",
    "    for i in range(1, lookback_years+1):\n",
    "        qx_prev = source_life.loc[(source_life['year'] == year - i) & (\n",
    "            source_life['age'] == age), 'qx'].values\n",
    "        if len(qx_prev) > 0 and qx_prev[0] > 0:\n",
    "            return qx_prev[0]\n",
    "    return None  # No valid qx found in the lookback period\n",
    "\n",
    "# Iterate over each future year from 2023 to 2039 and calculate qx if missing\n",
    "for year in years_range:\n",
    "    # For each age group from 18 to 20 (you can extend this as needed)\n",
    "    for age in ager:\n",
    "        # Try to calculate qx using lx (survivor data)\n",
    "        qx_cur = calculate_qx_from_lx(source_life, year, age)\n",
    "        \n",
    "        # If lx calculation fails, fallback to previous qx method\n",
    "        if qx_cur is None:\n",
    "            qx_prev = get_previous_qx(source_life, year, age, lookback_years=3)\n",
    "            qx_prev2 = get_previous_qx(source_life, year-1, age, lookback_years=3)\n",
    "            \n",
    "            # If both previous years have valid qx, calculate average\n",
    "            if qx_prev is not None and qx_prev2 is not None:\n",
    "                qx_cur = (qx_prev + qx_prev2) / 2\n",
    "            elif qx_prev is not None:  # If only one previous year has qx, use that\n",
    "                qx_cur = qx_prev\n",
    "        \n",
    "        # Only update qx if the current value is zero or missing\n",
    "        if qx_cur is not None:\n",
    "            source_life.loc[(source_life['year'] == year) & \n",
    "                            (source_life['age'] == age) & \n",
    "                            (source_life['qx'] == 0), 'qx'] = qx_cur\n",
    "```\n",
    "\n",
    "### Key Changes:\n",
    "1. **`max(0, qx)`**:  \n",
    "   This ensures that `qx` values never become negative. If the calculation yields a negative value, it is set to 0, indicating no mortality (in cases where the survivor count increases or remains the same).\n",
    "\n",
    "2. **Check Survivor (`lx`) Consistency**:  \n",
    "   The function now checks that `l_{x+1} <= l_x` before calculating `qx`. If this condition is violated (which would imply an increase in the number of survivors, which is unrealistic in a mortality table), it returns a `qx` of 0.\n",
    "\n",
    "3. **Fallback Mechanism for Missing `lx` Data**:  \n",
    "   If the `lx` data is missing or incomplete, the code falls back to the previous method of using historical `qx` values from previous years to estimate the current year's `qx`.\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works:\n",
    "- **Survivor-Based `qx` Calculation**:  \n",
    "  For each year and age, the function calculates `qx` based on the number of survivors (`lx`). It ensures that `qx` remains non-negative and that the number of survivors decreases as age increases.\n",
    "\n",
    "- **Fallback to Historical `qx`**:  \n",
    "  If `lx` values are missing or unreliable, the code looks at the previous years' `qx` values and calculates the current `qx` as an average of the last two valid values.\n",
    "\n",
    "- **Zero Replacement**:  \n",
    "  The calculated `qx` values are only applied to rows where `qx` is initially 0, ensuring that only missing or zero values are replaced.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "Let’s assume the following `lx` values for a given year and age group:\n",
    "\n",
    "| Age | Year | lx  | qx  |\n",
    "|-----|------|-----|-----|\n",
    "| 18  | 2023 | 1000 | 0   |\n",
    "| 19  | 2023 | 950  | 0   |\n",
    "| 20  | 2023 | 900  | 0   |\n",
    "\n",
    "For **age 18**, the `qx` value would be calculated as:\n",
    "\\[\n",
    "qx = 1 - \\frac{950}{1000} = 1 - 0.95 = 0.05\n",
    "\\]\n",
    "This result is non-negative and makes sense, as the number of survivors decreases from 1000 to 950 between ages 18 and 19.\n",
    "\n",
    "If the `lx` values showed an increase in survivors (e.g., 1000 to 1050), the formula would yield a negative `qx`, but `max(0, qx)` ensures that `qx` is set to 0 instead.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if this resolves the issue of negative `qx` values or if you need further modifications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Approach to Calculate Mortality Rates \\( q_x \\) for 2009\n",
    "\n",
    "To calculate mortality rates \\( q_x \\) for 2009 based on the given data, follow these steps:\n",
    "\n",
    "### **General Approach**\n",
    "\n",
    "1. **Estimate Deaths for 2009**:  \n",
    "   The estimated number of deaths \\( d_x \\) in 2009 can be calculated using the following formula:\n",
    "   \\[\n",
    "   d_x = \\text{Population}_{2009} \\times q_x\n",
    "   \\]\n",
    "   Since \\( q_x \\) for 2009 is unknown, we will estimate it using the data from 2007 and 2008.\n",
    "\n",
    "2. **Calculate the Average Mortality Rate \\( q_x \\) for Previous Years**:  \n",
    "   For each age, calculate an average \\( q_x \\) for 2007 and 2008 to use as a basis for estimating 2009 values:\n",
    "   \\[\n",
    "   q_x^{\\text{avg}} = \\frac{q_x^{2007} + q_x^{2008}}{2}\n",
    "   \\]\n",
    "   \n",
    "3. **Use the Formula to Calculate New \\( q_x \\) for 2009**:  \n",
    "   Using the survivor data \\( l_x \\) and estimated deaths \\( d_x \\), the mortality rate \\( q_x \\) for 2009 can be calculated as:\n",
    "   \\[\n",
    "   q_x = \\frac{d_x}{l_x}\n",
    "   \\]\n",
    "   where \\( l_x \\) is the number of survivors at age \\( x \\).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Calculation**\n",
    "\n",
    "1. **Average Mortality Rate for Previous Years**  \n",
    "   Calculate the average mortality rate \\( q_x \\) for 2007 and 2008 for each age group \\( x \\).\n",
    "\n",
    "   For example, for age 18:\n",
    "   \\[\n",
    "   q_{18}^{\\text{avg}} = \\frac{0.000000 + 0.000000}{2} = 0.000000\n",
    "   \\]\n",
    "   \n",
    "   You can repeat this calculation for other age groups.\n",
    "\n",
    "2. **Estimate Deaths for 2009**  \n",
    "   For age 18 in 2009:\n",
    "   \\[\n",
    "   d_{18}^{2009} = \\text{Population}_{2009, 18} \\times q_{18}^{\\text{avg}} = 734658 \\times 0.000000 = 0\n",
    "   \\]\n",
    "   \n",
    "   Repeat similar calculations for other age groups.\n",
    "\n",
    "3. **Calculate \\( q_x \\) for 2009**  \n",
    "   For age 18, since there are no deaths, the mortality rate remains 0. For other ages where deaths occur, use:\n",
    "   \\[\n",
    "   q_x^{2009} = \\frac{d_x^{2009}}{l_x^{2009}}\n",
    "   \\]\n",
    "\n",
    "\n",
    "### **Explanation of the Code**:\n",
    "\n",
    "1. **Input Data**:  \n",
    "   The code accepts data for survivors (`lx`) and mortality rates (`qx`) for 2007, 2008, and 2009, and population data for these years.\n",
    "\n",
    "2. **Average Mortality Rate**:  \n",
    "   It calculates the average mortality rate (`qx_avg`) for 2007 and 2008.\n",
    "\n",
    "3. **Deaths Calculation**:  \n",
    "   For each age group in 2009, the estimated number of deaths is calculated by multiplying the population for 2009 by the average mortality rate (`qx_avg`).\n",
    "\n",
    "4. **New Mortality Rate Calculation**:  \n",
    "   The mortality rate for 2009 (`qx_2009`) is calculated by dividing the estimated number of deaths by the number of survivors (`lx`).\n",
    "\n",
    "5. **Handling Missing Values**:  \n",
    "   If any missing or zero values appear in the data, the mortality rates are filled with 0 where necessary.\n",
    "\n",
    "This code will produce the mortality rates \\( q_x \\) for 2009 based on the input data. Let me know if you'd like further clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "To address the issue where some `qx` values are either negative or zero, we can implement a strategy that replaces these invalid values with the mean of the next or previous four valid `qx` values. Here's how the replacement will work:\n",
    "\n",
    "### Replacement Strategy:\n",
    "1. **For ages > 21**:  \n",
    "   Replace negative or zero `qx` values with the mean of the last four valid `qx` values from the **current and previous years**.\n",
    "   \n",
    "2. **For ages < 102**:  \n",
    "   Replace negative or zero `qx` values with the mean of the next four valid `qx` values from the **current and previous years**.\n",
    "\n",
    "### Approach:\n",
    "1. **Identify invalid `qx` values**:  \n",
    "   We’ll detect `qx` values that are either negative or zero.\n",
    "   \n",
    "2. **Calculate mean of neighboring values**:  \n",
    "   For ages greater than 21, we look for the previous four valid `qx` values. For ages below 102, we look for the next four valid `qx` values.\n",
    "\n",
    "3. **Replace invalid values**:  \n",
    "   If enough valid values are found, we replace the invalid `qx` with the mean of these values.\n",
    "\n",
    "### Updated Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "years_range = list(range(2023, 2040))  # Extend years range for future years\n",
    "ager = list(range(18, 103))  # Age range from 18 to 102 (inclusive)\n",
    "\n",
    "# Function to calculate qx based on lx (survival) values\n",
    "def calculate_qx_from_lx(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Calculate qx using lx values: qx = 1 - (lx+1 / lx)\n",
    "    Ensure qx is non-negative and that lx decreases with age.\n",
    "    \"\"\"\n",
    "    lx = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age), 'lx'].values\n",
    "    lx_next = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age + 1), 'lx'].values\n",
    "    \n",
    "    if len(lx) > 0 and len(lx_next) > 0 and lx[0] > 0:  # Ensure lx is valid and non-zero\n",
    "        qx = 1 - (lx_next[0] / lx[0])\n",
    "        # Ensure qx is not negative\n",
    "        return max(0, qx)  # Cap qx at a minimum of 0\n",
    "    return None  # Return None if lx is missing or invalid\n",
    "\n",
    "# Function to get the mean of the last four valid qx values\n",
    "def get_previous_qx_mean(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Get the mean of the last four valid qx values for a given age and year.\n",
    "    \"\"\"\n",
    "    qx_values = []\n",
    "    for i in range(4):  # Look back at the previous 4 age groups\n",
    "        qx_prev = source_life.loc[(source_life['year'] == year) & \n",
    "                                  (source_life['age'] == age - i), 'qx'].values\n",
    "        if len(qx_prev) > 0 and qx_prev[0] > 0:  # Ensure qx is valid and non-zero\n",
    "            qx_values.append(qx_prev[0])\n",
    "    \n",
    "    if len(qx_values) == 4:  # If we have 4 valid qx values, return their mean\n",
    "        return np.mean(qx_values)\n",
    "    return None  # Return None if there aren't enough valid values\n",
    "\n",
    "# Function to get the mean of the next four valid qx values\n",
    "def get_next_qx_mean(source_life, year, age):\n",
    "    \"\"\"\n",
    "    Get the mean of the next four valid qx values for a given age and year.\n",
    "    \"\"\"\n",
    "    qx_values = []\n",
    "    for i in range(1, 5):  # Look forward at the next 4 age groups\n",
    "        qx_next = source_life.loc[(source_life['year'] == year) & \n",
    "                                  (source_life['age'] == age + i), 'qx'].values\n",
    "        if len(qx_next) > 0 and qx_next[0] > 0:  # Ensure qx is valid and non-zero\n",
    "            qx_values.append(qx_next[0])\n",
    "    \n",
    "    if len(qx_values) == 4:  # If we have 4 valid qx values, return their mean\n",
    "        return np.mean(qx_values)\n",
    "    return None  # Return None if there aren't enough valid values\n",
    "\n",
    "# Iterate over each future year from 2023 to 2039 and replace invalid qx values\n",
    "for year in years_range:\n",
    "    for age in ager:\n",
    "        # Get current qx value\n",
    "        qx_cur = source_life.loc[(source_life['year'] == year) & (source_life['age'] == age), 'qx'].values\n",
    "        \n",
    "        if len(qx_cur) > 0:\n",
    "            qx_cur = qx_cur[0]\n",
    "            \n",
    "            # Replace if qx is negative or zero\n",
    "            if qx_cur <= 0:\n",
    "                if age > 21:  # If age > 21, use the previous 4 valid values\n",
    "                    qx_mean_prev = get_previous_qx_mean(source_life, year, age)\n",
    "                    if qx_mean_prev is not None:\n",
    "                        source_life.loc[(source_life['year'] == year) & \n",
    "                                        (source_life['age'] == age), 'qx'] = qx_mean_prev\n",
    "                \n",
    "                elif age < 102:  # If age < 102, use the next 4 valid values\n",
    "                    qx_mean_next = get_next_qx_mean(source_life, year, age)\n",
    "                    if qx_mean_next is not None:\n",
    "                        source_life.loc[(source_life['year'] == year) & \n",
    "                                        (source_life['age'] == age), 'qx'] = qx_mean_next\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Negative and Zero `qx` Detection**:\n",
    "   - The code checks if the current `qx` value is zero or negative, which are invalid.\n",
    "\n",
    "2. **Replacement for Ages > 21**:\n",
    "   - The `get_previous_qx_mean()` function looks back at the previous four valid `qx` values for the current year and age group, and it calculates their mean.\n",
    "   - If four valid values are found, the invalid `qx` is replaced with the mean.\n",
    "\n",
    "3. **Replacement for Ages < 102**:\n",
    "   - The `get_next_qx_mean()` function looks forward at the next four valid `qx` values and computes their mean.\n",
    "   - If four valid values are available, the invalid `qx` is replaced.\n",
    "\n",
    "4. **Edge Cases**:\n",
    "   - If fewer than four valid `qx` values are found, the function returns `None`, and the replacement is skipped.\n",
    "   - The function ensures that values are only replaced when valid neighboring data is available.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "If you have the following `qx` values for a given year and age:\n",
    "\n",
    "| Age | Year | qx  |\n",
    "|-----|------|-----|\n",
    "| 18  | 2023 | 0   |\n",
    "| 19  | 2023 | 0.005 |\n",
    "| 20  | 2023 | 0.006 |\n",
    "| 21  | 2023 | -0.002 |\n",
    "| 22  | 2023 | 0.007 |\n",
    "| 23  | 2023 | 0   |\n",
    "\n",
    "- **For age 18**, since `qx` is zero, the code will look for the next four values (`qx` for ages 19, 20, 21, and 22), calculate their mean, and replace `qx` for age 18 with that mean.\n",
    "  \n",
    "- **For age 21**, since `qx` is negative, it will look back at the previous four values and calculate their mean to replace the invalid value.\n",
    "\n",
    "---\n",
    "\n",
    "This approach should resolve issues with both negative and zero `qx` values, ensuring that all `qx` values are based on the neighboring valid data. Let me know if you need further adjustments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LPA SURVIVAL TABLES\n",
    "\n",
    "life_tbl_src = source_life\n",
    "#year_life_tbl = 2007\n",
    "first_column = []\n",
    "lpa_survival_tables_all = pd.DataFrame()\n",
    "lpa_survival_tables_all_vals = pd.DataFrame()\n",
    "lpa_survival_tables_all_aged = pd.DataFrame()\n",
    "total_lpa_surviving_donors_df = pd.DataFrame()\n",
    "#years = list(range(start_year, end_forecast_year + 1))\n",
    "\n",
    "# Initialise a dictionary to hold lpa_surviving_donors data for each year\n",
    "#lpa_surviving_donors_dict = {}\n",
    "#lpa_surviving_donors_dict_changed = {}\n",
    "lpa_surviving_donors_all_dict = {}\n",
    "total_lpa_surviving_donors_dict = {}\n",
    "total_life_tbl = pd.DataFrame()\n",
    "surviving_donors_lpa = {} #pd.DataFrame()\n",
    "summed_lx_dict_by_year = {}\n",
    "\n",
    "# Define the age groups\n",
    "age_groups = {\"age_groups\": age_range}\n",
    "age_groups_df = pd.DataFrame(age_groups)\n",
    "\n",
    "\n",
    "lpa_life_tbl_dict = {}\n",
    "qx_lpa_surviving_donors_all = pd.DataFrame() #{}\n",
    "\n",
    "\n",
    "# Extend life tables for all years:\n",
    "for year_life_tbl in years_forecast_long:  #list(range(2007, 2010)): #\n",
    "    \n",
    "     \n",
    "    lpa_surviving_donors = pd.DataFrame()\n",
    "    lpa_surviving_donors_df = pd.DataFrame()\n",
    "    lpa_surviving_donors_tbl = pd.DataFrame()\n",
    "    lpa_surviving_donors_all_df = pd.DataFrame()\n",
    "    lpa_surviving_donors_dict_changed = {}\n",
    "    lpa_surviving_donors_dict = {}\n",
    "    qx_lpa_surviving_donors_dict = {}\n",
    "    qx_lpa_surviving_donors_df = pd.DataFrame() \n",
    "    qx_lpa_surviving_donors = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_tbl = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_all_df = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_dict_changed = {}\n",
    "    qx_lpa_surviving_donors_dict = {}\n",
    "    \n",
    "    # Years from the year_life_tbl to end_forecast_year\n",
    "    years_life_tbls = list(range(year_life_tbl, year_forecast_long + 1))\n",
    "    \n",
    "    # Iterate over each year for which life table needs to be generated\n",
    "    for year in years_life_tbls: \n",
    "        \n",
    "        yearly_data = []\n",
    "        \n",
    "        for age in ages: \n",
    "            \n",
    "            qx_current_vals = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                life_tbl_src['age'] == age), 'qx'].values\n",
    "            \n",
    "            lx_current_vals = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                life_tbl_src['age'] == age), 'lx'].values\n",
    "            \n",
    "            # Calculate population for each age group, shifting cohorts forward each yea\n",
    "            if (year == year_life_tbl):  # Starting from the initial year\n",
    "                \n",
    "                # Calculate / Update the survivors (lx) based on the lpa donor data\n",
    "\n",
    "                if (age - (year - year_life_tbl) >= start_age): # for shifting for the next year and next age (age+1) \n",
    "\n",
    "                    qx = qx_current_vals[0] if len(qx_current_vals) > 0 else np.nan\n",
    "                    \n",
    "                    # Get lx for the current age and year  \n",
    "                    lx_current = lx_current_vals[0] if not np.isnan(lx_current_vals) else np.nan \n",
    "                    \n",
    "                    lx = lx_current# * (1 - qx) #if np.isnan(lx_current_vals) else 0 #np.nan\n",
    "                    \n",
    "                    #qx=life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'qx'].values[0]\n",
    "                    #lx = life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'lx'].values[0]\n",
    "                    #print(f\"NON-ZEROS: year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx:{lx}\")\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    lx = np.nan\n",
    "                    qx = np.nan\n",
    "                    #print(f\"ZEROS: year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx:{lx}\")\n",
    "                            \n",
    "            else: \n",
    "                # Access the data for the previous year (to calculate forward cohorts) \n",
    "                if (age - (year - year_life_tbl) >= start_age): # for shifting for the next year and next age (age+1) \n",
    "                    \n",
    "                    #qx_prev = life_tbl_src.loc[(life_tbl_src['year'] == year-1) & (\n",
    "                    #   life_tbl_src['age'] == age),'qx'].values[0] \n",
    "                    qx_cur = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                        life_tbl_src['age'] == age),'qx'].values[0] \n",
    "                    \n",
    "                    #lx_prev = lpa_surviving_donors.loc[(lpa_surviving_donors['year'] == year-1) & (\n",
    "                    #    lpa_surviving_donors['age'] == age-1)].values[0] \n",
    "                    lx_prev = lpa_surviving_donors_df.loc[(year-1, age-1), 'lx']\n",
    "                    #lpa_surviving_donors_df.loc[(year-1,  [age-4,age-3,age-2,age-1]), 'lx']\n",
    "                    #lx_cur = lpa_surviving_donors_dict_changed[year_life_tbl].iloc[age-start_age,0] if age < end_age else lpa_surviving_donors_dict_changed[year_life_tbl].iloc[age-start_age,0]\n",
    "#                     lx_cur = life_tbl_src.loc[(\n",
    "#                         life_tbl_src['year'] == year_life_tbl) & (\n",
    "#                         life_tbl_src['age'] == age-1),'lx'].values[0] if age < end_age else life_tbl_src.loc[(\n",
    "#                         life_tbl_src['year'] == year_life_tbl) & (\n",
    "#                         life_tbl_src['age'] == age),'lx'].values[0]\n",
    "                    \n",
    "                    #if (lx_cur > 0) & (qx_prev > 0): # & (age <= 100):# & (age < 106): #(len(qx_prev) > 0)\n",
    "\n",
    "                    qx = qx_cur\n",
    "\n",
    "                    #ex_qx = life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'qx'].values # qx_lpa_surviving_donors[year-1][age-start_age]\n",
    "                    #print(f\"year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx_cur:{lx_cur}, lx:{lx_cur * (1 - qx)}\")\n",
    "                    \n",
    "                    \n",
    "                    # Calculate current year's lx based on previous year's lx and previous qx\n",
    "#                     lx = lx_cur * (1 - qx) if not np.isnan(qx) else np.nan\n",
    "                    lx = lx_prev * (1 - qx) if not np.isnan(qx) else np.nan\n",
    "                                                       \n",
    "                else:\n",
    "                    lx = np.nan\n",
    "                    qx = np.nan\n",
    "\n",
    "                \n",
    "            # Append the data for the current age to the yearly data list\n",
    "            yearly_data.append({'year': year, 'age': age, 'lx': lx, 'qx': qx})\n",
    "\n",
    "        # Convert yearly data to a DataFrame and set multi-index for easy access\n",
    "        lpa_surviving_donors_df = pd.DataFrame(yearly_data).set_index(['year', 'age'])\n",
    "        #lpa_surviving_donors_inx = lpa_surviving_donors_df\n",
    "        #lpa_surviving_donors_tbl = lpa_surviving_donors_dict[year]\n",
    "        lpa_surviving_donors_dict[year] = lpa_surviving_donors_df[['lx']]\n",
    "        qx_lpa_surviving_donors_dict[year] = lpa_surviving_donors_df[['qx']]\n",
    "        #lpa_surviving_donors_dict[year].to_csv(f\"lpa_surviving_donors_{year}.csv\", index=False)\n",
    "        #print(f\"lpa_surviving_donors_dict({year}): {lpa_surviving_donors_dict[year]}\") \n",
    "         \n",
    "        lpa_surviving_donors = lpa_surviving_donors_df[['lx']]\n",
    "        lpa_surviving_donors = lpa_surviving_donors.reset_index() #pd.DataFrame(lpa_surviving_donors).reset_index()\n",
    "        lpa_surviving_donors = lpa_surviving_donors.rename(columns={'lx':year})  #, inplace=True)\n",
    "        #print(f\"year: {year} - lpa_surviving_donors: {lpa_surviving_donors}\")        \n",
    "        qx_lpa_surviving_donors = lpa_surviving_donors_df[['qx']]\n",
    "        qx_lpa_surviving_donors = qx_lpa_surviving_donors.reset_index() #pd.DataFrame(lpa_surviving_donors).reset_index()\n",
    "        qx_lpa_surviving_donors = qx_lpa_surviving_donors.rename(columns={'qx':year})  #, inplace=True)\n",
    "        \n",
    "        lpa_surviving_donors_tbl = lpa_surviving_donors #lpa_surviving_donors[['age', year]] \n",
    "        qx_lpa_surviving_donors_tbl = qx_lpa_surviving_donors #lpa_surviving_donors[['age', year]] \n",
    "        #lpa_surviving_donors_tbl = lpa_surviving_donors.assign(Age=pd.Series(range(18,107)).values)\n",
    "        lpa_surviving_donors_all_df = lpa_surviving_donors_tbl.set_index(['age'])\n",
    "        #print(f\"lpa_surviving_donors_all_df: {lpa_surviving_donors_all_df}\")\n",
    "        qx_lpa_surviving_donors_all_df = qx_lpa_surviving_donors_tbl.set_index(['age'])\n",
    "        lpa_surviving_donors_dict_changed[year] = lpa_surviving_donors_all_df[[year]]\n",
    "        qx_lpa_surviving_donors_dict_changed[year] = qx_lpa_surviving_donors_all_df[[year]]\n",
    "        #print(f\"year: {year} - lpa_surviving_donors_dict_changed: {lpa_surviving_donors_dict_changed[year]}\") \n",
    "    lpa_life_tbl_dict[year_life_tbl] = lpa_surviving_donors_df\n",
    "    #qx_lpa_life_tbl_dict[year_life_tbl] = lpa_surviving_donors_df\n",
    "    # Concatenate all yearly data into a single DataFrame\n",
    "    lpa_surviving_donors_all = pd.concat(lpa_surviving_donors_dict_changed.values(), axis=1)   \n",
    "    \n",
    "    qx_lpa_surviving_donors_all = pd.concat(qx_lpa_surviving_donors_dict_changed.values(), axis=1) \n",
    "     \n",
    "    #print(f\"lpa_surviving_donors_all from lpa_surviving_donors_dict_changed: {lpa_surviving_donors_all}\")\n",
    "    lpa_surviving_donors_all_vals = lpa_surviving_donors_all\n",
    "    qx_lpa_surviving_donors_all_vals = qx_lpa_surviving_donors_all\n",
    "    qx_lpa_surviving_donors_all = qx_lpa_surviving_donors_all.reset_index()\n",
    "    lpa_surviving_donors_all = lpa_surviving_donors_all.reset_index()\n",
    "    lpa_surviving_donors_all_vals = lpa_surviving_donors_all_vals.assign(age = pd.Series(age_range).values)\n",
    "    qx_lpa_surviving_donors_all_vals = qx_lpa_surviving_donors_all_vals.assign(age = pd.Series(age_range).values)\n",
    "    lpa_surviving_donors_all_dict[year_life_tbl] = lpa_surviving_donors_all_vals\n",
    "    lpa_surviving_donors_all_dict[year_life_tbl] = lpa_surviving_donors_all_vals\n",
    "    #print(f\"year_life_tbl in of the life_tbl: {year_life_tbl} - lpa_surviving_donors_all_vals: {lpa_surviving_donors_all_vals}\")\n",
    "    \n",
    "    # Ensure lpa_surviving_donors_all_dict[year_life_tbl] exists and has valid data\n",
    "    if year_life_tbl in lpa_surviving_donors_all_dict:\n",
    "        lpa_surviving_donors_all_aged = lpa_surviving_donors_all_dict[year_life_tbl]\n",
    "\n",
    "        # Ensure lpa_surviving_donors_all_aged is not None\n",
    "        if lpa_surviving_donors_all_aged is not None:\n",
    "            # Reorder the columns to move 'age' to the first position\n",
    "            first_column = lpa_surviving_donors_all_aged.pop('age')\n",
    "\n",
    "            # Insert 'age' as the first column\n",
    "            lpa_surviving_donors_all_aged.insert(0, 'age', first_column)\n",
    "\n",
    "            # Check the DataFrame before saving\n",
    "            #print(f\"Data for year of life table: {year_life_tbl}:\")\n",
    "            #print(lpa_surviving_donors_all_aged)\n",
    "\n",
    "            # Save to CSV\n",
    "            lpa_surviving_donors_all_aged.to_csv(f\"lpa_surviving_donors_{year_life_tbl}.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Error: lpa_surviving_donors_all_aged is None for year {year_life_tbl}.\")\n",
    "    else:\n",
    "        print(f\"Error: No data found for year {year_life_tbl} in lpa_surviving_donors_all_dict.\")\n",
    "    \n",
    "    # Calculate total living customers for each year by summing across ages\n",
    "    total_lpa_surviving_donors_df[year_life_tbl] = lpa_surviving_donors_all_aged.iloc[:, 1:].sum(axis=1) #(axis=1)\n",
    "    #total_lpa_surviving_donors['Total_lpa_surviving_donors'] = lpa_surviving_donors_all_aged.groupby('age')[year].sum().reset_index()\n",
    "    \n",
    "    surviving_donors_lpa[year_life_tbl] = lpa_surviving_donors_all_aged.iloc[:, 1:].sum(axis=1)\n",
    "    #print(f\"total_lpa_surviving_donors_df[{year_life_tbl}]: {total_lpa_surviving_donors_df[year_life_tbl]}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #total_lpa_surviving_donors_df['age'] = range(18, 107)  # range for ages 18-106\n",
    "    #total_lpa_surviving_donors_df.columns = [years_life_tbls, 'age']\n",
    "    #total_lpa_surviving_donors_df.columns = [year_life_tbl, 'age']\n",
    "    #print(f\"total_lpa_surviving_donors_df[year_life_tbl, 'age']: {total_lpa_surviving_donors_df[year_life_tbl, 'age']}\")\n",
    "    # Check the number of columns in the DataFrame\n",
    "    #print(f\"Columns before renaming: {total_lpa_surviving_donors_df.columns}\")\n",
    "\n",
    "    # Ensure 'age' is part of the DataFrame if needed\n",
    "    if 'age' not in total_lpa_surviving_donors_df.columns:\n",
    "        # If 'age' needs to be added, ensure it exists as a series\n",
    "        total_lpa_surviving_donors_df['age'] = age_range  # range for ages 18-106\n",
    "\n",
    "    # Check if the DataFrame has 2 columns now\n",
    "    if total_lpa_surviving_donors_df.shape[1] == 2:\n",
    "        total_lpa_surviving_donors_df.columns = [year_life_tbl, 'age']\n",
    "    else:\n",
    "        #print(f\"Warning: The DataFrame does not have 2 columns. It has {total_lpa_surviving_donors_df.shape[1]} columns.\")\n",
    "        #print(f\"Warning: The DataFrame has age column already.\")\n",
    "        total_lpa_surviving_donors_df = total_lpa_surviving_donors_df\n",
    "        \n",
    "    #Rename the column name by the year\n",
    "    total_lpa_surviving_donors_df.rename(columns={'Total_lpa_surviving_donors': year})  #, inplace=True)\n",
    "    \n",
    "    total_lpa_surviving_donors_dict[year_life_tbl] = total_lpa_surviving_donors_df.set_index(['age']) # pd.DataFrame(total_lpa_surviving_donors).set_index(['age'])\n",
    "    #print(f\"for year_life_tbl: {year_life_tbl} {total_lpa_surviving_donors_dict[year_life_tbl]}\")\n",
    "    total_lpa_surviving_donors_dict[year_life_tbl].iloc[:, :-1] = pd.NA\n",
    "    #print(f\"After NA applied to the prior years: for year_life_tbl: {year_life_tbl} {total_lpa_surviving_donors_dict[year_life_tbl]}\")\n",
    "    \n",
    "#Concatenate all yearly living customer tables into a single DataFrame\n",
    "total_life_tbl = pd.concat(total_lpa_surviving_donors_dict.values(), axis=0)\n",
    "#total_life_tbl = total_lpa_surviving_donors_dict[end_forecast_year]\n",
    "total_life_tbl = total_life_tbl.reset_index()\n",
    "# Reorder the columns to move 'age' to the first position\n",
    "total_life_tbl.pop('age')\n",
    "total_life_df = total_life_tbl\n",
    "# Insert 'age' as the first column\n",
    "#total_life_tbl.insert(0, 'age', first_column)\n",
    "print(f\"LPA LIFE TABLES : {total_life_df}\")\n",
    "total_life_df.to_csv('LPA_LIFE_TABLES.csv', index=False) \n",
    "LPA_LIFE_TABLES = total_life_df\n",
    "\n",
    "LPA_SURVIVAL_TABLES_individual_years_tables = pd.concat(lpa_surviving_donors_all_dict.values(), axis=0)\n",
    "print(f\"LPA SURVIVAL TABLES (for each individual year table): {total_life_df}\")\n",
    "LPA_SURVIVAL_TABLES_individual_years_tables.to_csv('LPA_SURVIVAL_TABLES_individual_years_tables.csv', index=False)\n",
    "\n",
    "surviving_donors_lpa_df = pd.concat(surviving_donors_lpa.values(), axis=1)\n",
    "# Rename the columns to years from 2007 to 2023\n",
    "surviving_donors_lpa_df.columns = [str(year) for year in years_forecast_long]\n",
    "print(f\"LPA SURVIVAL TABLES (TOTALS):\") # {surviving_donors_lpa_df}\")\n",
    "surviving_donors_lpa_df.to_csv('LPA_SURVIVAL_TABLES.csv', index=False)     \n",
    "LPA_SURVIVAL_TABLES_TOTALS = surviving_donors_lpa_df\n",
    "LPA_SURVIVAL_TABLES_TOTALS\n",
    "## ########################################################################################## ##        \n",
    "    # Sum based on number of years before year_index (e.g., year_index(2023) - year(2007) = 12)\n",
    "    # To calculate the sum of the 'lx' values for each year_life_tbl in lpa_surviving_donors_all_dict[year_life_tbl],\n",
    "    # iterate over each year_life_tbl, \n",
    "    # sum the values based on the conditions/assumptions provided, \n",
    "    # adjust the number of years that should be summed depending on whether the current year_life_tbl is less than or equal to year_index. \n",
    "\n",
    "    #             x = lpa_surviving_donors_dict_changed[2007]\n",
    "#             y = x.reset_index()\n",
    "#             #y.loc[y['age' == 18]]\n",
    "#             y.iloc[0,1] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Forecasting model\n",
    "\n",
    "## Previous Forecasting usig exponential smoothing:\n",
    "I have had a look now and the approach that I previously used is really quite simple, but may not work that well with the reduction in LPA demand following the pandemic.\n",
    "\n",
    "If X is the smoothing factor, and t the most recent year,  then a simple exponentially smoothed forecast is generated as follows\n",
    "\n",
    "(LPAs as a % of remaining customers)t * X + ((LPAs as a % of remaining customers)t + (LPAs as a % of remaining customers)t - (LPAs as a % of remaining customers)t-1) * (1-X)\n",
    "\n",
    "Ie it simply takes X% of the most recent value and adds onto it a proportion (1-X)% of the increase in LPAs as a % of remaining customers over the previous year. \n",
    "\n",
    "This is obviously quite simplistic but has worked well whilst these %s have increased from year to year. \n",
    "\n",
    "However this approach would not really work that well if we saw a sudden decrease in the %, over the course of the year, as this approach would only then allow for the trend to decrease. This may be the case for some of the age specific %’s following the pandemic, and may not be representative of the trend that was apparent before the pandemic. \n",
    "\n",
    "So what is probably needed really is a bit of  rethink about how best to do this so that the generated trend is not entirely dependant on the change in the % over the last 12 months .\n",
    "\n",
    "## New forecasting model\n",
    "I will leave you to have a think about how best to do this !!! but I guess some possibilities are \n",
    "•\tAveraging annual increases over more than one year \n",
    "•\tApplying a Bayesian approach to updating prior estimates .\n",
    "\n",
    "Fitting the model\n",
    "You can use a linear regression model to estimate the avocado price elasticity. The regression formula should be:\n",
    "\n",
    "Volume ~ Normal(beta0 + beta1 * price + beta2 * type_organic + sigma)\n",
    "\n",
    "Here, will be the price elasticity, that is the impact of price on sales. You will assume that the elasticity is the same for regular and organic avocados. You also expect it to be negative: the higher the price, the lower the sales, that's the case for most goods. To incorporate this prior knowledge into the model, you decide to use a normal distribution with mean -80 as the prior for price. How would you build such a model?\n",
    "\n",
    "NOTE: Recall that calling pm.sample() for the first time in a fresh Python session takes some time, as Python code is being compiled to C under the hood. To save you time, we only ask you to get the code right instead of executing it.\n",
    "\n",
    "Optimizing the price\n",
    "Great job on fitting and inspecting the model! Now, down to business: your boss asks you to provide the avocado price that would yield the largest profit, and to state what profit can be expected. Also, they want the price to be divisible by $0.25 so that the customers can easily pay with quarters.\n",
    "\n",
    "In this exercise, you will use your model to predict the volume and the profit for a couple of sensible prices. Next, you will visualize the predictive distributions to pick the optimal price. Finally, you will compute the credible interval for your profit prediction. Now go and optimize!\n",
    "\n",
    "Predicting Profit for Each Price:\n",
    "\n",
    "The code iterates over a list of potential prices: [0.5, 0.75, 1, 1.25].\n",
    "For each price, it calculates the predicted mean volume using a linear model: pred_mean = (intercept_mean + price_mean * price + organic_mean). This formula likely comes from a previously fitted Bayesian model where intercept_mean, price_mean, and organic_mean are the posterior means of the model parameters.\n",
    "It then simulates the predicted volume using a normal distribution centered around pred_mean with a standard deviation sd_mean, generating 1000 samples: volume_pred = np.random.normal(pred_mean, sd_mean, size=1000).\n",
    "The predicted profit for each price is calculated by multiplying the price by the predicted volume: profit_pred = price * volume_pred.\n",
    "These predicted profits are stored in a dictionary predicted_profit_per_price with the price as the key.\n",
    "Visualizing Predicted Profits:\n",
    "\n",
    "A forest plot is created using pm.forestplot(predicted_profit_per_price). This plot visualizes the distribution of predicted profits for each price, helping to identify which price might yield the highest profit.\n",
    "Calculating the Highest Posterior Density (HPD) Interval:\n",
    "\n",
    "The code calculates the HPD interval for the predicted profits at the optimal price, which is chosen as 0.75 in this solution. The HPD interval is a Bayesian credible interval that contains the most probable values of the parameter.\n",
    "The function az.hdi(predicted_profit_per_price[0.75], credible_interval=0.99) computes the 99% HPD interval for the predicted profits at the price of 0.75.\n",
    "Finally, it prints the HPD interval, which provides a range of values within which the true profit is likely to lie with 99% probability.\n",
    "This solution effectively uses Bayesian analysis to predict profits for different prices, visualizes these predictions, and calculates a credible interval for the optimal price, thus fulfilling the exercise's requirements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Hyperparameter tuning with Hyperopt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Linear regression formula\n",
    "formula = \"volume ~ price + type_organic\"\n",
    "\n",
    "# the MCMC model\n",
    "with pm.Model() as model:    \n",
    "    priors = {\"price\": pm.Normal.dist(mu=-5)}    \n",
    "    pm.GLM.from_formula(formula, data=avacado, priors=priors)    \n",
    "    trace = pm.sample(draws=1000, tune=500)\n",
    "\n",
    "\n",
    "# Draw a trace plot of trace\n",
    "pm.traceplot(trace)\n",
    "plt.show()\n",
    "\n",
    "# Print a summary of trace\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Get each parameter's posterior mean\n",
    "intercept_mean = np.mean(trace.get_values(\"Intercept\")) \n",
    "organic_mean = np.mean(trace.get_values(\"type_organic\")) \n",
    "price_mean = np.mean(trace.get_values(\"price\"))\n",
    "sd_mean = np.mean(trace.get_values(\"sd\"))\n",
    "\n",
    "# For each price, predict volume and use it to predict profit\n",
    "predicted_profit_per_price = {}\n",
    "for price in [0.5, 0.75, 1, 1.25]:\n",
    "    pred_mean = (intercept_mean + price_mean * price + organic_mean)\n",
    "    volume_pred = np.random.normal(pred_mean, sd_mean, size=1000)\n",
    "    profit_pred = price * volume_pred\n",
    "    predicted_profit_per_price.update({price: profit_pred})\n",
    "    \n",
    "# Draw a forest plot of predicted profit for all prices\n",
    "pm.forestplot(predicted_profit_per_price)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print HPD of predicted profit for the optimal price\n",
    "opt_hpd = az.hdi(predicted_profit_per_price[0.75], credible_interval=0.99)\n",
    "print(opt_hpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_source_life = source_life_df\n",
    "source_life_end_ons_year = source_life_df.loc[(source_life_df['year'] == end_ons_year)]\n",
    "\n",
    "# Iterate over each future year from 2023 to 2039 and replace invalid qx values\n",
    "for year in years_range:\n",
    "    for age in ages:\n",
    "        # Get current qx value\n",
    "        qx_end_ons_year = source_life_end_ons_year.loc[(source_life_end_ons_year['age'] == age), 'qx'].values[0]\n",
    "        # simplified mortalitility based on the previous year (last year qx was available:    \n",
    "        simplified_source_life.loc[(simplified_source_life['year'] == year) & (\n",
    "                simplified_source_life['age'] == age), 'qx'] = qx_end_ons_year\n",
    "        \n",
    "# Save the updated DataFrame to a new file\n",
    "simplified_file_path = 'simplified_mortality_statistics.csv'\n",
    "simplified_source_life.to_csv(simplified_file_path, index=False)\n",
    "\n",
    "#print(simplified_source_life)\n",
    "simplified_source_life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simplified LPA SURVIVAL TABLES\n",
    "\n",
    "life_tbl_src = simplified_source_life\n",
    "\n",
    "#year_life_tbl = 2007\n",
    "first_column = []\n",
    "lpa_survival_tables_all = pd.DataFrame()\n",
    "lpa_survival_tables_all_vals = pd.DataFrame()\n",
    "lpa_survival_tables_all_aged = pd.DataFrame()\n",
    "total_lpa_surviving_donors_df = pd.DataFrame()\n",
    "#years = list(range(start_year, end_forecast_year + 1))\n",
    "\n",
    "# Initialise a dictionary to hold lpa_surviving_donors data for each year\n",
    "#lpa_surviving_donors_dict = {}\n",
    "#lpa_surviving_donors_dict_changed = {}\n",
    "lpa_surviving_donors_all_dict = {}\n",
    "total_lpa_surviving_donors_dict = {}\n",
    "total_life_tbl = pd.DataFrame()\n",
    "surviving_donors_lpa = {} #pd.DataFrame()\n",
    "summed_lx_dict_by_year = {}\n",
    "\n",
    "# Define the age groups\n",
    "age_groups = {\"age_groups\": age_range}\n",
    "age_groups_df = pd.DataFrame(age_groups)\n",
    "\n",
    "\n",
    "lpa_life_tbl_dict = {}\n",
    "qx_lpa_surviving_donors_all = pd.DataFrame() #{}\n",
    "\n",
    "\n",
    "# Extend life tables for all years:\n",
    "for year_life_tbl in years_forecast_long:  #list(range(2007, 2010)): #\n",
    "    \n",
    "     \n",
    "    lpa_surviving_donors = pd.DataFrame()\n",
    "    lpa_surviving_donors_df = pd.DataFrame()\n",
    "    lpa_surviving_donors_tbl = pd.DataFrame()\n",
    "    lpa_surviving_donors_all_df = pd.DataFrame()\n",
    "    lpa_surviving_donors_dict_changed = {}\n",
    "    lpa_surviving_donors_dict = {}\n",
    "    qx_lpa_surviving_donors_dict = {}\n",
    "    qx_lpa_surviving_donors_df = pd.DataFrame() \n",
    "    qx_lpa_surviving_donors = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_tbl = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_all_df = pd.DataFrame()\n",
    "    qx_lpa_surviving_donors_dict_changed = {}\n",
    "    qx_lpa_surviving_donors_dict = {}\n",
    "    \n",
    "    # Years from the year_life_tbl to end_forecast_year\n",
    "    years_life_tbls = list(range(year_life_tbl, year_forecast_long + 1))\n",
    "    \n",
    "    # Iterate over each year for which life table needs to be generated\n",
    "    for year in years_life_tbls: \n",
    "        \n",
    "        yearly_data = []\n",
    "        \n",
    "        for age in ages: \n",
    "            \n",
    "            qx_current_vals = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                life_tbl_src['age'] == age), 'qx'].values\n",
    "            \n",
    "            lx_current_vals = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                life_tbl_src['age'] == age), 'lx'].values\n",
    "            \n",
    "            # Calculate population for each age group, shifting cohorts forward each yea\n",
    "            if (year == year_life_tbl):  # Starting from the initial year\n",
    "                \n",
    "                # Calculate / Update the survivors (lx) based on the lpa donor data\n",
    "\n",
    "                if (age - (year - year_life_tbl) >= start_age): # for shifting for the next year and next age (age+1) \n",
    "\n",
    "                    qx = qx_current_vals[0] if len(qx_current_vals) > 0 else np.nan\n",
    "                    \n",
    "                    # Get lx for the current age and year  \n",
    "                    lx_current = lx_current_vals[0] if not np.isnan(lx_current_vals) else np.nan \n",
    "                    \n",
    "                    lx = lx_current# * (1 - qx) #if np.isnan(lx_current_vals) else 0 #np.nan\n",
    "                    \n",
    "                    #qx=life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'qx'].values[0]\n",
    "                    #lx = life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'lx'].values[0]\n",
    "                    #print(f\"NON-ZEROS: year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx:{lx}\")\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    lx = np.nan\n",
    "                    qx = np.nan\n",
    "                    #print(f\"ZEROS: year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx:{lx}\")\n",
    "                            \n",
    "            else: \n",
    "                # Access the data for the previous year (to calculate forward cohorts) \n",
    "                if (age - (year - year_life_tbl) >= start_age): # for shifting for the next year and next age (age+1) \n",
    "                    \n",
    "                    #qx_prev = life_tbl_src.loc[(life_tbl_src['year'] == year-1) & (\n",
    "                    #   life_tbl_src['age'] == age),'qx'].values[0] \n",
    "                    qx_cur = life_tbl_src.loc[(life_tbl_src['year'] == year) & (\n",
    "                        life_tbl_src['age'] == age),'qx'].values[0] \n",
    "                    \n",
    "                    #lx_prev = lpa_surviving_donors.loc[(lpa_surviving_donors['year'] == year-1) & (\n",
    "                    #    lpa_surviving_donors['age'] == age-1)].values[0] \n",
    "                    lx_prev = lpa_surviving_donors_df.loc[(year-1, age-1), 'lx']\n",
    "                    #lpa_surviving_donors_df.loc[(year-1,  [age-4,age-3,age-2,age-1]), 'lx']\n",
    "                    #lx_cur = lpa_surviving_donors_dict_changed[year_life_tbl].iloc[age-start_age,0] if age < end_age else lpa_surviving_donors_dict_changed[year_life_tbl].iloc[age-start_age,0]\n",
    "#                     lx_cur = life_tbl_src.loc[(\n",
    "#                         life_tbl_src['year'] == year_life_tbl) & (\n",
    "#                         life_tbl_src['age'] == age-1),'lx'].values[0] if age < end_age else life_tbl_src.loc[(\n",
    "#                         life_tbl_src['year'] == year_life_tbl) & (\n",
    "#                         life_tbl_src['age'] == age),'lx'].values[0]\n",
    "                    \n",
    "                    #if (lx_cur > 0) & (qx_prev > 0): # & (age <= 100):# & (age < 106): #(len(qx_prev) > 0)\n",
    "\n",
    "                    qx = qx_cur\n",
    "\n",
    "                    #ex_qx = life_tbl_src.loc[(life_tbl_src['year'] == year) & (life_tbl_src['age'] == age),'qx'].values # qx_lpa_surviving_donors[year-1][age-start_age]\n",
    "                    #print(f\"year:{year} year_life_tbl:{year_life_tbl}, age:{age}, qx:{qx}, lx_cur:{lx_cur}, lx:{lx_cur * (1 - qx)}\")\n",
    "                    \n",
    "                    \n",
    "                    # Calculate current year's lx based on previous year's lx and previous qx\n",
    "#                     lx = lx_cur * (1 - qx) if not np.isnan(qx) else np.nan\n",
    "                    lx = lx_prev * (1 - qx) if not np.isnan(qx) else np.nan\n",
    "                                                       \n",
    "                else:\n",
    "                    lx = np.nan\n",
    "                    qx = np.nan\n",
    "\n",
    "                \n",
    "            # Append the data for the current age to the yearly data list\n",
    "            yearly_data.append({'year': year, 'age': age, 'lx': lx, 'qx': qx})\n",
    "\n",
    "        # Convert yearly data to a DataFrame and set multi-index for easy access\n",
    "        lpa_surviving_donors_df = pd.DataFrame(yearly_data).set_index(['year', 'age'])\n",
    "        #lpa_surviving_donors_inx = lpa_surviving_donors_df\n",
    "        #lpa_surviving_donors_tbl = lpa_surviving_donors_dict[year]\n",
    "        lpa_surviving_donors_dict[year] = lpa_surviving_donors_df[['lx']]\n",
    "        qx_lpa_surviving_donors_dict[year] = lpa_surviving_donors_df[['qx']]\n",
    "        #lpa_surviving_donors_dict[year].to_csv(f\"lpa_surviving_donors_{year}.csv\", index=False)\n",
    "        #print(f\"lpa_surviving_donors_dict({year}): {lpa_surviving_donors_dict[year]}\") \n",
    "         \n",
    "        lpa_surviving_donors = lpa_surviving_donors_df[['lx']]\n",
    "        lpa_surviving_donors = lpa_surviving_donors.reset_index() #pd.DataFrame(lpa_surviving_donors).reset_index()\n",
    "        lpa_surviving_donors = lpa_surviving_donors.rename(columns={'lx':year})  #, inplace=True)\n",
    "        #print(f\"year: {year} - lpa_surviving_donors: {lpa_surviving_donors}\")        \n",
    "        qx_lpa_surviving_donors = lpa_surviving_donors_df[['qx']]\n",
    "        qx_lpa_surviving_donors = qx_lpa_surviving_donors.reset_index() #pd.DataFrame(lpa_surviving_donors).reset_index()\n",
    "        qx_lpa_surviving_donors = qx_lpa_surviving_donors.rename(columns={'qx':year})  #, inplace=True)\n",
    "        \n",
    "        lpa_surviving_donors_tbl = lpa_surviving_donors #lpa_surviving_donors[['age', year]] \n",
    "        qx_lpa_surviving_donors_tbl = qx_lpa_surviving_donors #lpa_surviving_donors[['age', year]] \n",
    "        #lpa_surviving_donors_tbl = lpa_surviving_donors.assign(Age=pd.Series(range(18,107)).values)\n",
    "        lpa_surviving_donors_all_df = lpa_surviving_donors_tbl.set_index(['age'])\n",
    "        #print(f\"lpa_surviving_donors_all_df: {lpa_surviving_donors_all_df}\")\n",
    "        qx_lpa_surviving_donors_all_df = qx_lpa_surviving_donors_tbl.set_index(['age'])\n",
    "        lpa_surviving_donors_dict_changed[year] = lpa_surviving_donors_all_df[[year]]\n",
    "        qx_lpa_surviving_donors_dict_changed[year] = qx_lpa_surviving_donors_all_df[[year]]\n",
    "        #print(f\"year: {year} - lpa_surviving_donors_dict_changed: {lpa_surviving_donors_dict_changed[year]}\") \n",
    "    lpa_life_tbl_dict[year_life_tbl] = lpa_surviving_donors_df\n",
    "    #qx_lpa_life_tbl_dict[year_life_tbl] = lpa_surviving_donors_df\n",
    "    # Concatenate all yearly data into a single DataFrame\n",
    "    lpa_surviving_donors_all = pd.concat(lpa_surviving_donors_dict_changed.values(), axis=1)   \n",
    "    \n",
    "    qx_lpa_surviving_donors_all = pd.concat(qx_lpa_surviving_donors_dict_changed.values(), axis=1) \n",
    "     \n",
    "    #print(f\"lpa_surviving_donors_all from lpa_surviving_donors_dict_changed: {lpa_surviving_donors_all}\")\n",
    "    lpa_surviving_donors_all_vals = lpa_surviving_donors_all\n",
    "    qx_lpa_surviving_donors_all_vals = qx_lpa_surviving_donors_all\n",
    "    qx_lpa_surviving_donors_all = qx_lpa_surviving_donors_all.reset_index()\n",
    "    lpa_surviving_donors_all = lpa_surviving_donors_all.reset_index()\n",
    "    lpa_surviving_donors_all_vals = lpa_surviving_donors_all_vals.assign(age = pd.Series(age_range).values)\n",
    "    qx_lpa_surviving_donors_all_vals = qx_lpa_surviving_donors_all_vals.assign(age = pd.Series(age_range).values)\n",
    "    lpa_surviving_donors_all_dict[year_life_tbl] = lpa_surviving_donors_all_vals\n",
    "    lpa_surviving_donors_all_dict[year_life_tbl] = lpa_surviving_donors_all_vals\n",
    "    #print(f\"year_life_tbl in of the life_tbl: {year_life_tbl} - lpa_surviving_donors_all_vals: {lpa_surviving_donors_all_vals}\")\n",
    "    \n",
    "    # Ensure lpa_surviving_donors_all_dict[year_life_tbl] exists and has valid data\n",
    "    if year_life_tbl in lpa_surviving_donors_all_dict:\n",
    "        lpa_surviving_donors_all_aged = lpa_surviving_donors_all_dict[year_life_tbl]\n",
    "\n",
    "        # Ensure lpa_surviving_donors_all_aged is not None\n",
    "        if lpa_surviving_donors_all_aged is not None:\n",
    "            # Reorder the columns to move 'age' to the first position\n",
    "            first_column = lpa_surviving_donors_all_aged.pop('age')\n",
    "\n",
    "            # Insert 'age' as the first column\n",
    "            lpa_surviving_donors_all_aged.insert(0, 'age', first_column)\n",
    "\n",
    "            # Check the DataFrame before saving\n",
    "            #print(f\"Data for year of life table: {year_life_tbl}:\")\n",
    "            #print(lpa_surviving_donors_all_aged)\n",
    "\n",
    "            # Save to CSV\n",
    "#             lpa_surviving_donors_all_aged.to_csv(f\"sim_lpa_surviving_donors_{year_life_tbl}.csv\", index=False)\n",
    "        else:\n",
    "            print(f\"Error: lpa_surviving_donors_all_aged is None for year {year_life_tbl}.\")\n",
    "    else:\n",
    "        print(f\"Error: No data found for year {year_life_tbl} in lpa_surviving_donors_all_dict.\")\n",
    "    \n",
    "    # Calculate total living customers for each year by summing across ages\n",
    "    total_lpa_surviving_donors_df[year_life_tbl] = lpa_surviving_donors_all_aged.iloc[:, 1:].sum(axis=1) #(axis=1)\n",
    "    #total_lpa_surviving_donors['Total_lpa_surviving_donors'] = lpa_surviving_donors_all_aged.groupby('age')[year].sum().reset_index()\n",
    "    \n",
    "    surviving_donors_lpa[year_life_tbl] = lpa_surviving_donors_all_aged.iloc[:, 1:].sum(axis=1)\n",
    "    #print(f\"total_lpa_surviving_donors_df[{year_life_tbl}]: {total_lpa_surviving_donors_df[year_life_tbl]}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #total_lpa_surviving_donors_df['age'] = range(18, 107)  # range for ages 18-106\n",
    "    #total_lpa_surviving_donors_df.columns = [years_life_tbls, 'age']\n",
    "    #total_lpa_surviving_donors_df.columns = [year_life_tbl, 'age']\n",
    "    #print(f\"total_lpa_surviving_donors_df[year_life_tbl, 'age']: {total_lpa_surviving_donors_df[year_life_tbl, 'age']}\")\n",
    "    # Check the number of columns in the DataFrame\n",
    "    #print(f\"Columns before renaming: {total_lpa_surviving_donors_df.columns}\")\n",
    "\n",
    "    # Ensure 'age' is part of the DataFrame if needed\n",
    "    if 'age' not in total_lpa_surviving_donors_df.columns:\n",
    "        # If 'age' needs to be added, ensure it exists as a series\n",
    "        total_lpa_surviving_donors_df['age'] = age_range  # range for ages 18-106\n",
    "\n",
    "    # Check if the DataFrame has 2 columns now\n",
    "    if total_lpa_surviving_donors_df.shape[1] == 2:\n",
    "        total_lpa_surviving_donors_df.columns = [year_life_tbl, 'age']\n",
    "    else:\n",
    "        #print(f\"Warning: The DataFrame does not have 2 columns. It has {total_lpa_surviving_donors_df.shape[1]} columns.\")\n",
    "        #print(f\"Warning: The DataFrame has age column already.\")\n",
    "        total_lpa_surviving_donors_df = total_lpa_surviving_donors_df\n",
    "        \n",
    "    #Rename the column name by the year\n",
    "    total_lpa_surviving_donors_df.rename(columns={'Total_lpa_surviving_donors': year})  #, inplace=True)\n",
    "    \n",
    "    total_lpa_surviving_donors_dict[year_life_tbl] = total_lpa_surviving_donors_df.set_index(['age']) # pd.DataFrame(total_lpa_surviving_donors).set_index(['age'])\n",
    "    #print(f\"for year_life_tbl: {year_life_tbl} {total_lpa_surviving_donors_dict[year_life_tbl]}\")\n",
    "    total_lpa_surviving_donors_dict[year_life_tbl].iloc[:, :-1] = pd.NA\n",
    "    #print(f\"After NA applied to the prior years: for year_life_tbl: {year_life_tbl} {total_lpa_surviving_donors_dict[year_life_tbl]}\")\n",
    "    \n",
    "#Concatenate all yearly living customer tables into a single DataFrame\n",
    "total_life_tbl = pd.concat(total_lpa_surviving_donors_dict.values(), axis=0)\n",
    "#total_life_tbl = total_lpa_surviving_donors_dict[end_forecast_year]\n",
    "total_life_tbl = total_life_tbl.reset_index()\n",
    "# Reorder the columns to move 'age' to the first position\n",
    "total_life_tbl.pop('age')\n",
    "total_life_df = total_life_tbl\n",
    "# Insert 'age' as the first column\n",
    "#total_life_tbl.insert(0, 'age', first_column)\n",
    "print(f\"Simplified LPA LIFE TABLES : {total_life_df}\")\n",
    "total_life_df.to_csv('Simplified LPA_LIFE_TABLES.csv', index=False) \n",
    "LPA_LIFE_TABLES = total_life_df\n",
    "\n",
    "LPA_SURVIVAL_TABLES_individual_years_tables = pd.concat(lpa_surviving_donors_all_dict.values(), axis=0)\n",
    "print(f\"Simplified LPA SURVIVAL TABLES (for each individual year table): {total_life_df}\")\n",
    "LPA_SURVIVAL_TABLES_individual_years_tables.to_csv('Simplified_LPA_SURVIVAL_TABLES_individual_years_tables.csv', index=False)\n",
    "\n",
    "surviving_donors_lpa_df = pd.concat(surviving_donors_lpa.values(), axis=1)\n",
    "# Rename the columns to years from 2007 to 2023\n",
    "surviving_donors_lpa_df.columns = [str(year) for year in years_forecast_long]\n",
    "print(f\"Simplified LPA SURVIVAL TABLES (TOTALS):\") # {surviving_donors_lpa_df}\")\n",
    "surviving_donors_lpa_df.to_csv('Simplified_LPA_SURVIVAL_TABLES.csv', index=False)     \n",
    "Simplified_LPA_SURVIVAL_TABLES_TOTALS = surviving_donors_lpa_df\n",
    "Simplified_LPA_SURVIVAL_TABLES_TOTALS\n",
    "## ########################################################################################## ##        \n",
    "    # Sum based on number of years before year_index (e.g., year_index(2023) - year(2007) = 12)\n",
    "    # To calculate the sum of the 'lx' values for each year_life_tbl in lpa_surviving_donors_all_dict[year_life_tbl],\n",
    "    # iterate over each year_life_tbl, \n",
    "    # sum the values based on the conditions/assumptions provided, \n",
    "    # adjust the number of years that should be summed depending on whether the current year_life_tbl is less than or equal to year_index. \n",
    "\n",
    "    #             x = lpa_surviving_donors_dict_changed[2007]\n",
    "#             y = x.reset_index()\n",
    "#             #y.loc[y['age' == 18]]\n",
    "#             y.iloc[0,1] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Survival Rates: The code now considers the survival rates across different ages (from 18 to 106). \n",
    "The survival rate is factored into how the cohort sizes decrease year by year.\n",
    "\n",
    "Forecasting: For each iteration in the Monte Carlo simulation, the number of donors is estimated dynamically, considering the varying age-specific survival rates.\n",
    "\n",
    "Market Shape: The assumedMarketShape is calculated based on the specific age group’s donor population compared to the total population. \n",
    "The assumedPotentialMarketShape is normalized to a 0-100 scale.\n",
    "\n",
    "This approach allows for a more accurate long-term forecast of customer/donor behavior by integrating demographic aging and survival rates into the market model.\n",
    "\n",
    "# To extend the lpa_surviving_donors calculation for ages from 18 to 106 and integrate it into the long-term cohort survival forecasting, we need to make sure that the cohort survival rates are applied dynamically across the forecasted years, adjusting for demographic aging. Below is a refined explanation and code modification to include this requirement in your existing VBA code.\n",
    "\n",
    "Step 1: Extend lpa_surviving_donors Calculation\n",
    "To extend the lpa_surviving_donors calculation from ages 18 to 106, you'll first need to calculate survival rates for each age group. This can be done using the life table that provides qx values (the probability of dying within one year).\n",
    "\n",
    "Assumption: The life table's qx values are already calculated for all age groups from 18 to 106.\n",
    "\n",
    "Step 2: Modify VBA Code for Cohort Survival Forecasting\n",
    "Below is the modified code segment that integrates the survival rates into the cohort-based forecasting model:\n",
    "    \n",
    "Step 3: Integration and Testing\n",
    "After implementing this code:\n",
    "Test the modified code using the existing life table and demographic data.\n",
    "Verify the accuracy by comparing the results with known historical data or through validation with external models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "lpa_demands = historical_data_df\n",
    "\n",
    "# Get the last row in column A\n",
    "#last_row = ws.max_row\n",
    "\n",
    "# donors_df: Contains donor data for 2022 and 2023, including year, age, and demand (number of donors per age group).\n",
    "donors_df = annual_donor_demands_age_specific\n",
    "\n",
    "# # Sample data for donors_df\n",
    "# donors_data = {\n",
    "#     'year': [2022, 2022, 2023, 2023],\n",
    "#     'age': [30, 50, 30, 50],\n",
    "#     'demand': [500, 300, 550, 320]\n",
    "# }\n",
    "# donors_df = pd.DataFrame(donors_data)\n",
    "\n",
    "# population_forecast_df: Contains the forecasted population for each age group in 2023 and 2024.\n",
    "\n",
    "# population_forecast_df: Contains the forecasted population for each age group in 2023 and 2024.\n",
    "population_forecast = pd.read_csv('population_forecast.csv')\n",
    "# Convert the DataFrame to the desired format\n",
    "df_melted = population_forecast.melt(id_vars=['age'], var_name='year', value_name='population')\n",
    "population_forecast_df = pd.DataFrame(df_melted)\n",
    "\n",
    "pop_f = population_forecast_df#.set_index(['age', 'year'])\n",
    "pop_f['year'] = pd.to_numeric(pop_f['year'], errors='coerce')\n",
    "pop_f['age'] = pd.to_numeric(pop_f['age'], errors='coerce')\n",
    "\n",
    "# Sort the data by year and age for proper processing\n",
    "pop_f.sort_values(by=['year', 'age'], inplace=True)\n",
    "population_forecast_df = pop_f\n",
    "pop_f#pop_f[(pop_f['age'] == age) & (pop_f['year'] == year)]['population']\n",
    "#population_forecast_df[(population_forecast_df['age'] == age) & \n",
    "#                                              (population_forecast_df['year'] == 2023)]['population']\n",
    "# # Sample data for population_forecast_df\n",
    "# population_forecast_data = {\n",
    "#     'year': [2023, 2023, 2024, 2024],\n",
    "#     'age': [30, 50, 30, 50],\n",
    "#     'population': [10000, 8000, 10500, 8200]\n",
    "# }\n",
    "# population_forecast_df = pd.DataFrame(population_forecast_data)\n",
    "\n",
    "# survival_rate_df: Contains survival rates for each age group for future years.\n",
    "surviving_lpa = LPA_SURVIVAL_TABLES_TOTALS\n",
    "survival_tbl = surviving_lpa.reset_index()\n",
    "survival_tbl = survival_tbl.rename(columns={'age':'age'})\n",
    "# Convert the DataFrame to the desired format\n",
    "survival_melted = survival_tbl.melt(id_vars=['age'], var_name='year', value_name='survived')\n",
    "survival_df = pd.DataFrame(survival_melted)\n",
    "\n",
    "# # Sample data for survival_rate_df\n",
    "# survival_rate_data = {\n",
    "#     'age': [30, 50],\n",
    "#     'year': [2025, 2025],\n",
    "#     'survival_rate': [0.95, 0.93]\n",
    "# }\n",
    "# survival_rate_df = pd.DataFrame(survival_rate_data)\n",
    "\n",
    "\n",
    "# Merge the DataFrames on 'year' and 'age'\n",
    "#merged_df = pd.merge(survival_df, pop_f, on=['year', 'age'], how='inner')\n",
    "merged_df = survival_df\n",
    "# Calculate the demand/population ratio\n",
    "#merged_df['survival_rate'] = merged_df['survived'] / merged_df['population']\n",
    "merged_df['survival_rate'] = survival_df['survived'] / pop_f['population']\n",
    "\n",
    "survival_rate_df = merged_df[['age', 'year', 'survival_rate']]\n",
    "survival_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Prompt user to ask regarding control assumption to apply the market shape or not\n",
    "# ## Automating the input dates to forecast\n",
    "\n",
    "# p = getpass.getpass(prompt='Do you want to apply the market shape for forecasting? (Choose Yes=Y OR No=N)')\n",
    " \n",
    "# if (p.lower() == 'n') | (p.lower() == ''):\n",
    "#     # The market shape = 100%\n",
    "#     print('You have not choosen to apply the market shape.')\n",
    "    \n",
    "# else:    \n",
    "#     # Apply the market shape based on the ONS population forecast\n",
    "#     print('You have choosen to apply the market shape.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Additional forecast for future years (2025-2029) can be added similarly using previous years' data and survival rates.\n",
    "# handling age-specific market data\n",
    "# Dictionary to store results\n",
    "total_population_age_specific = {}\n",
    "total_donors_age_specific = {}\n",
    "assumed_market_shape = {}\n",
    "max_market_estimate = {}\n",
    "assumed_potential_market_shape = {}\n",
    "total_surviving_age_specific = {}\n",
    "total_survival_rate_age_specific = {}\n",
    "assumed_potential_survival_rate = {}\n",
    "assumed_survival_rate = {}\n",
    "max_survival_estimate = {}\n",
    "avg_survival_rate = {}\n",
    "assumed_potential_avg_survival_rate = {}\n",
    "max_avg_survival_estimate = {}\n",
    "# Create arrays for total population and donors (106 age groups, assuming 0-105 years)\n",
    "#total_population_age_specific = np.zeros(106)\n",
    "#total_donors_age_specific = np.zeros(106)\n",
    "#assumed_market_shape = np.zeros(106)\n",
    "#assumed_potential_market_shape = np.zeros(106)\n",
    "\n",
    "\n",
    "# for age in range(18, 107):\n",
    "#     population_2023 = population_forecast_df[(population_forecast_df['age'] == age) & \n",
    "#                                              (population_forecast_df['year'] == 2023)]['population'].sum()\n",
    "#     population_2024 = population_forecast_df[(population_forecast_df['age'] == age) & \n",
    "#                                              (population_forecast_df['year'] == 2024)]['population'].sum()\n",
    "#     total_population_age_specific[age] = population_2023 + population_2024\n",
    "#     donors_2023 = df_donors[(df_donors['year'] == 2023) & (df_donors['age'] == age)]['Demand'].sum()\n",
    "#     forecasted_donors_2024 = df_output[df_output['age'] == age]['Forecasted_Donors_Mean'].sum()\n",
    "#     total_donors_age_specific[age] = donors_2023 + forecasted_donors_2024\n",
    "    \n",
    "    \n",
    "# Iterate over age range\n",
    "for age in ages:\n",
    "\n",
    "    # Ensure 'age' and 'year' columns are integers\n",
    "    population_forecast_df['age'] = population_forecast_df['age'].astype(int)\n",
    "    population_forecast_df['year'] = population_forecast_df['year'].astype(int)\n",
    "\n",
    "    # Check if the age and year exist in the DataFrame\n",
    "    #print(population_forecast_df[population_forecast_df['year'] == 2023].head())\n",
    "    #print(population_forecast_df[population_forecast_df['age'] == age].head())\n",
    "\n",
    "    # Calculate total population age-specific for 2023 and 2024 (current and last year)\n",
    "    total_population_age_specific[age] = population_forecast_df[\n",
    "        ((population_forecast_df['age'] == age) & (population_forecast_df['year'] == 2023)) |\n",
    "        ((population_forecast_df['age'] == age) & (population_forecast_df['year'] == 2024))\n",
    "    ]['population'].sum()\n",
    "    \n",
    "    # Calculate total donors age-specific for 2023 and 2024 (current and last year)\n",
    "    total_donors_age_specific[age] = (donors_df[\n",
    "        ((donors_df['year'] == 2023) & (donors_df['age'] == age)) |\n",
    "        ((donors_df['year'] == 2024) & (donors_df['age'] == age))\n",
    "    ]['demand'].sum())\n",
    "\n",
    "    # Ensure 'age' and 'year' columns are integers\n",
    "    survival_df['age'] = survival_df['age'].astype(int)\n",
    "    survival_df['year'] = survival_df['year'].astype(int)\n",
    "\n",
    "    # Check if the age and year exist in the DataFrame\n",
    "    #print(survival_df[survival_df['year'] == 2023].head())\n",
    "    #print(survival_df[survival_df['age'] == age].head())\n",
    "    \n",
    "    # Calculate total surviving customers age-specific for 2023 and 2024 (current and last year)\n",
    "    total_surviving_age_specific[age] = (survival_df[\n",
    "        ((survival_df['year'] == 2023) & (survival_df['age'] == age)) |\n",
    "        ((survival_df['year'] == 2024) & (survival_df['age'] == age))\n",
    "    ]['survived'].sum())\n",
    "    \n",
    "    # Ensure 'age' and 'year' columns are integers\n",
    "    survival_rate_df['age'] = survival_rate_df['age'].astype(int)\n",
    "    survival_rate_df['year'] = survival_rate_df['year'].astype(int)\n",
    "\n",
    "    # Check if the age and year exist in the DataFrame\n",
    "    #print(survival_df[survival_df['year'] == 2023].head())\n",
    "    #print(survival_df[survival_df['age'] == age].head())\n",
    "    \n",
    "    # Calculate total survival rate age-specific for 2023 and 2024 (current and last year)\n",
    "    total_survival_rate_age_specific[age] = (survival_rate_df[\n",
    "        ((survival_rate_df['year'] == 2023) & (survival_rate_df['age'] == age)) |\n",
    "        ((survival_rate_df['year'] == 2024) & (survival_rate_df['age'] == age))\n",
    "    ]['survival_rate'].sum())\n",
    "    \n",
    "    # Calculate assumed market shape \n",
    "    assumed_survival_rate[age] = total_surviving_age_specific[age] / total_population_age_specific[age] if total_population_age_specific[age] > 0 else 0\n",
    "\n",
    "    # Calculate survival rate\n",
    "    assumed_market_shape[age] = total_donors_age_specific[age] / total_population_age_specific[age] if total_population_age_specific[age] > 0 else 0\n",
    "    \n",
    "    #Calculate Average survival rate\n",
    "    avg_survival_rate[age] = survival_rate_df[\n",
    "        ((survival_rate_df['year'] == 2023) & (survival_rate_df['age'] == age)) |\n",
    "        ((survival_rate_df['year'] == 2024) & (survival_rate_df['age'] == age))\n",
    "    ]['survival_rate'].mean()\n",
    "    \n",
    "    \n",
    "# Normilisation:\n",
    "# Find max assumed market shape\n",
    "max_assumed_market_shape = max(assumed_market_shape.values())\n",
    "print(f\"Maximum of Assuming Market Shapes: {max_assumed_market_shape}\")\n",
    "\n",
    "# Find max survival rate\n",
    "max_assumed_survival_rate = max(assumed_survival_rate.values())\n",
    "print(f\"Maximum of Assumed Survival Rate: {max_assumed_survival_rate}\")\n",
    "\n",
    "# Find max average survival rate\n",
    "max_avg_survival_rate = max(avg_survival_rate.values())\n",
    "print(f\"Maximum of Assumed Average Survival Rate: {max_avg_survival_rate}\")\n",
    "\n",
    "# # Assuming market shapes based on a certain distribution\n",
    "# max_assumed_market_shape = np.max(assumed_market_shape)\n",
    "\n",
    "# Calculate assumed potential market shape and survival rate\n",
    "for age in ages:\n",
    "    assumed_potential_market_shape[age] = (assumed_market_shape[age] / max_assumed_market_shape) #* 100\n",
    "    \n",
    "    assumed_potential_survival_rate[age] = (assumed_survival_rate[age] / max_assumed_survival_rate) #* 100\n",
    "    \n",
    "    assumed_potential_avg_survival_rate[age] = (avg_survival_rate[age] / max_avg_survival_rate) #* 100\n",
    "\n",
    "    \n",
    "for age in ages:\n",
    "\n",
    "    max_market_estimate[age] = total_population_age_specific[age] * max_assumed_market_shape\n",
    "\n",
    "    max_survival_estimate[age] = total_population_age_specific[age] * max_assumed_survival_rate\n",
    "\n",
    "    max_avg_survival_estimate[age] = total_population_age_specific[age] * max_avg_survival_rate\n",
    "\n",
    "    \n",
    "# LPA MARKET SHAPE    \n",
    "# LPAs as % of Population Totals = Assumed Market \"Shape\"\n",
    "Assumed_Market_Shape = pd.DataFrame()\n",
    "Assumed_Market_Shape['age'] = pd.DataFrame(assumed_market_shape.keys())\n",
    "Assumed_Market_Shape['market_shape'] = pd.DataFrame(assumed_market_shape.values())\n",
    "LPA_MARKET_SHAPE = Assumed_Market_Shape['market_shape']\n",
    "print(Assumed_Market_Shape)\n",
    "\n",
    "Assumed_Potential_Maximum_Market = pd.DataFrame()\n",
    "Assumed_Potential_Maximum_Market['age'] = pd.DataFrame(assumed_potential_market_shape.keys())\n",
    "Assumed_Potential_Maximum_Market['market_shape'] = pd.DataFrame(assumed_potential_market_shape.values())\n",
    "print(Assumed_Potential_Maximum_Market)\n",
    "\n",
    "\n",
    "# Dictionary for cohort survival rate\n",
    "survival_rate_dict = {(row['age'], row['year']): row['survival_rate'] for _, row in survival_rate_df.iterrows()}\n",
    "\n",
    "\n",
    "# print(len(total_population_age_specific))  # Should be 89\n",
    "# print(len(total_donors_age_specific))      # Should be 89\n",
    "# print(len(assumed_market_shape))           # Should be 89\n",
    "\n",
    "# Output the final forecast and results\n",
    "output_market_data = {\n",
    "    'age': list(range(18,107)),\n",
    "    'Total Population': total_population_age_specific.values(),\n",
    "    'Total Donors': total_donors_age_specific.values(),\n",
    "    'Assumed Market Shape': LPA_MARKET_SHAPE,\n",
    "    'Assumed Potential Market Shape': Assumed_Potential_Maximum_Market['market_shape'],\n",
    "    'Total Surviving Customers': total_surviving_age_specific.values(),\n",
    "    'Max Market estimates': max_market_estimate.values(),\n",
    "    'Max Assumed Market Shape': [max_assumed_market_shape] * 89,\n",
    "    'Assumed Survival Rate': assumed_survival_rate.values(),\n",
    "    'Assumed Potential Survival Rate': assumed_potential_survival_rate.values(),\n",
    "    'Max Survival estimates': max_survival_estimate.values(),\n",
    "    'Max Assumed Survival Rate': [max_assumed_survival_rate] * 89,\n",
    "    'Average Survival Rate': avg_survival_rate.values(),\n",
    "    'Total Survival Rate': total_survival_rate_age_specific.values()\n",
    "}\n",
    "\n",
    "output_market_df = pd.DataFrame(output_market_data)\n",
    "\n",
    "# save to csv\n",
    "output_market_df.to_csv('output_market_data.csv', index=False)\n",
    "\n",
    "print(output_market_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_forecast_long = 2039\n",
    "years_forecast_long = list(range(start_year, year_forecast_long+1))\n",
    "\n",
    "\n",
    "# MAX MARKET ESTIMATES\n",
    "\n",
    "MAX_MARKET_ESTIMATES = pd.DataFrame()\n",
    "MAX_MARKET_ESTIMATES['age'] = output_market_df[['age']] #pd.DataFrame(Assumed_Potential_Maximum_Market.keys())\n",
    "\n",
    "# Calculate max market estimates in long term (till 2039)\n",
    "for year in years_forecast_long:\n",
    "    \n",
    "    max_market_estimate ={}\n",
    "    market_shape_percentage = {}\n",
    "    pop_forecast_ons = 0\n",
    "    \n",
    "    for age in range(18, 107):\n",
    "        \n",
    "        # Fill the missing pop_forecast_ons for age > 104      ??????????????\n",
    "        \n",
    "        pop_forecast_ons = population_forecast_df[((population_forecast_df['age'] == age) & (population_forecast_df['year'] == year))]['population'].values[0]\n",
    "        market_shape_percentage[age] = (Assumed_Potential_Maximum_Market[Assumed_Potential_Maximum_Market['age'] == age]['market_shape']).values[0]\n",
    "        max_market_estimate[age] = pop_forecast_ons * market_shape_percentage[age]\n",
    "    \n",
    "    # MAX MARKET ESTIMATES\n",
    "    MAX_MARKET_ESTIMATES[year] = pd.DataFrame(max_market_estimate.values())\n",
    "\n",
    "print(f\"MAX MARKET ESTIMATES\") #: {MAX_MARKET_ESTIMATES}\")\n",
    "MAX_MARKET_ESTIMATES.to_csv('MAX_MARKET_ESTIMATES.csv', index=False)     \n",
    "MAX_MARKET_ESTIMATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMAINING CUSTOMERS\n",
    "\n",
    "# For 2007 (the starting year): MAX_MARKET_ESTIMATES[year]\n",
    "# For year > 2007: = MAX(0, MAX_MARKET_ESTIMATES - LPA SURVIVAL TABLES)\n",
    "\n",
    "LPA_SURVIVAL_TABLES = surviving_donors_lpa_df\n",
    "LPA_SURVIVAL_TABLES = LPA_SURVIVAL_TABLES.reset_index()\n",
    "\n",
    "# List of old and new column names\n",
    "old_columns = LPA_SURVIVAL_TABLES.columns\n",
    "new_columns = years\n",
    "\n",
    "# Creating a renaming dictionary\n",
    "rename_dict = {old: new for old, new in zip(old_columns, new_columns)}\n",
    "\n",
    "# Renaming columns\n",
    "LPA_SURVIVAL_TABLES.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "remaining_lpa = {}\n",
    "remaining_customers = pd.DataFrame()\n",
    "\n",
    "# Calculate the emaining customers based on MAX_MARKET_ESTIMATES and LPA_SURVIVAL_TABLES\n",
    "for year in years:\n",
    "    if year == start_year: # for 2007\n",
    "        remaining_lpa[year] = MAX_MARKET_ESTIMATES[year]\n",
    "    else: # year > 2007\n",
    "        yearly_data = []\n",
    "        remaining = 0\n",
    "        for a in range(len(ages)):\n",
    "            # REMAINING CUSTOMERS: MAX(0, MAX_MARKET_ESTIMATES - LPA_SURVIVAL_TABLES)\n",
    "            remaining = MAX_MARKET_ESTIMATES[year][a] - LPA_SURVIVAL_TABLES[year][a] if MAX_MARKET_ESTIMATES[year][a] - LPA_SURVIVAL_TABLES[year][a] else 0\n",
    "            yearly_data.append(remaining) \n",
    "        \n",
    "        #print(yearly_data)\n",
    "        remaining_lpa[year] = pd.Series(yearly_data)\n",
    "    \n",
    "remaining_customers = pd.concat(remaining_lpa.values(), axis=1)              \n",
    "\n",
    "# If 'age' needs to be added, ensure it exists as a series\n",
    "remaining_customers['age'] = range(18, 107)  # range for ages 18-106       \n",
    "\n",
    "# List of old and new column names\n",
    "old_columns = remaining_customers.columns[:-1]\n",
    "new_columns = years\n",
    "\n",
    "# Creating a renaming dictionary\n",
    "rename_dict = {old: new for old, new in zip(old_columns, new_columns)}\n",
    "\n",
    "# Renaming columns\n",
    "remaining_customers.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "\n",
    "#remaining_customers = remaining_customers.reset_index()\n",
    "# Reorder the columns to move 'age' to the first position\n",
    "first_column = remaining_customers.pop('age')\n",
    "# Insert 'age' as the first column\n",
    "remaining_customers.insert(0, 'age', first_column)\n",
    "print(f\"REMAINING CUSTOMERS\") #: {remaining_customers}\")\n",
    "remaining_customers.to_csv('REMAINING_CUSTOMERS.csv', index=False) \n",
    "REMAINING_CUSTOMERS = remaining_customers\n",
    "REMAINING_CUSTOMERS\n",
    "#     pd.DataFrame(yearly_data).set_index(['year', 'age'])        \n",
    "#     # Concatenate all yearly data into a single DataFrame\n",
    "#     lpa_surviving_donors_all = pd.concat(lpa_surviving_donors_dict_changed.values(), axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPA_LIFE_TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast for the next 5 years (2025-2029)\n",
    "forecasted_results = []\n",
    "iterations = 1000  # example number of iterations\n",
    "\n",
    "for year in range(2025, 2030):\n",
    "    for age in range(18, 107):\n",
    "        cohort_survival_rate = survival_rate_dict.get((age, year), 0)\n",
    "        \n",
    "        # Retrieve mean from last two years\n",
    "        last_year_mean = population_forecast_df[\n",
    "            (population_forecast_df['year'] == year - 1) & (population_forecast_df['age'] == age)\n",
    "        ]['Donors'].mean()\n",
    "        \n",
    "        second_last_year_mean = population_forecast_df[\n",
    "            (population_forecast_df['year'] == year - 2) & (population_forecast_df['age'] == age)\n",
    "        ]['Donors'].mean()\n",
    "        \n",
    "        prev_year_mean = (last_year_mean + second_last_year_mean) / 2 if pd.notnull(last_year_mean) and pd.notnull(second_last_year_mean) else 0\n",
    "        \n",
    "        # Monte Carlo simulation for forecasting donors\n",
    "        forecasted_donors = []\n",
    "        for _ in range(iterations):\n",
    "            forecasted_value = prev_year_mean * (cohort_survival_rate * max_market_estimate[age])\n",
    "            forecasted_donors.append(forecasted_value)\n",
    "        \n",
    "        forecasted_donors_mean = np.mean(forecasted_donors)\n",
    "        forecasted_donors_stddev = np.std(forecasted_donors)\n",
    "        \n",
    "        forecasted_results.append({\n",
    "            \"Year\": year,\n",
    "            \"Age\": age,\n",
    "            \"ForecastedDonorsMean\": forecasted_donors_mean,\n",
    "            \"ForecastedDonorsStdDev\": forecasted_donors_stddev\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame for analysis or saving\n",
    "forecasted_results_df = pd.DataFrame(forecasted_results)\n",
    "\n",
    "# Save forecasted results to Excel\n",
    "forecasted_results_df.to_excel(\"ForecastedDonors.xlsx\", index=False)\n",
    "\n",
    "# Visualization using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(forecast_df['Age Group'], forecast_df['Forecast Mean'], label='Forecasted Donors Mean')\n",
    "plt.fill_between(forecast_df['Age Group'], forecast_df['Forecast Mean'] - forecast_df['Forecast StdDev'], \n",
    "                 forecast_df['Forecast Mean'] + forecast_df['Forecast StdDev'], color='lightblue', alpha=0.5)\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Donors')\n",
    "plt.title('Forecasted Donors for 2024')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialise the class with the sample data\n",
    "forecast_model = LongTermForecastLPA(donors_df, population_forecast_df, survival_rate_df)\n",
    "\n",
    "# Run the forecast\n",
    "forecast_result = forecast_model.run_forecast()\n",
    "\n",
    "# Output the forecast result\n",
    "print(forecast_result)\n",
    "\n",
    "# The forecast will generate estimated donor counts for 2024 based on the Monte Carlo simulation, \n",
    "# and then extend the forecast for the years 2025-2029 using the cohort survival model. \n",
    "# The forecast_result will contain the forecasted values for each age group and year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class LongTermForecastLPA:\n",
    "    def __init__(self, donors_df, population_forecast_df, survival_rate_df):\n",
    "        # Initialize dataframes\n",
    "        self.donors_df = donors_df\n",
    "        self.population_forecast_df = population_forecast_df\n",
    "        self.survival_rate_df = survival_rate_df\n",
    "\n",
    "        # Fixed variables\n",
    "        self.iterations = 1000\n",
    "        self.lower_bound = 4000\n",
    "        self.upper_bound = 7000\n",
    "        self.num_working_days_2024 = 256\n",
    "\n",
    "        # Fixed total receipts for 2022 and 2023\n",
    "        self.total_receipts_2022 = 751967.534626039\n",
    "        self.total_receipts_2023 = 970035.028248588\n",
    "\n",
    "        # Initialize variables\n",
    "        self.total_population_age_specific = np.zeros(107)\n",
    "        self.total_donors_age_specific = np.zeros(107)\n",
    "        self.assumed_market_shape = np.zeros(107)\n",
    "        self.assumed_potential_market_shape = np.zeros(107)\n",
    "\n",
    "    def run_forecast(self):\n",
    "        # Calculate total demands for 2022 and 2023\n",
    "        total_demand_2022 = self.calculate_total_demand(2022)\n",
    "        total_demand_2023 = self.calculate_total_demand(2023)\n",
    "\n",
    "        # Aggregate age distributions for 2022 and 2023\n",
    "        age_distribution_2022 = self.calculate_age_distribution(2022, total_demand_2022)\n",
    "        age_distribution_2023 = self.calculate_age_distribution(2023, total_demand_2023)\n",
    "\n",
    "        # Average age distribution across 2022 and 2023\n",
    "        average_age_distribution = self.calculate_average_age_distribution(age_distribution_2022, age_distribution_2023)\n",
    "\n",
    "        # Monte Carlo Simulation for 2024\n",
    "        monte_carlo_results = self.monte_carlo_simulation(average_age_distribution, total_demand_2022, total_demand_2023)\n",
    "\n",
    "        # Output the results to a DataFrame\n",
    "        result_df = self.output_results(monte_carlo_results, average_age_distribution)\n",
    "\n",
    "        # Calculate total population and total donors age-specific for 2023 and 2024\n",
    "        self.calculate_total_population_and_donors()\n",
    "\n",
    "        # Extend forecast to the next 5 years (2025-2029) using cohort model\n",
    "        extended_forecast_df = self.extend_forecast(result_df)\n",
    "\n",
    "        # Combine all results\n",
    "        final_result_df = pd.concat([result_df, extended_forecast_df], ignore_index=True)\n",
    "\n",
    "        return final_result_df\n",
    "\n",
    "    def calculate_total_demand(self, year):\n",
    "        return self.donors_df[self.donors_df['year'] == year]['demand'].sum()\n",
    "\n",
    "    def calculate_age_distribution(self, year, total_demand):\n",
    "        age_distribution = self.donors_df[self.donors_df['year'] == year].groupby('age')['demand'].sum()\n",
    "        return age_distribution / total_demand\n",
    "\n",
    "    def calculate_average_age_distribution(self, dist_2022, dist_2023):\n",
    "        common_ages = dist_2022.index.intersection(dist_2023.index)\n",
    "        return (dist_2022[common_ages] + dist_2023[common_ages]) / 2\n",
    "\n",
    "    def monte_carlo_simulation(self, average_age_distribution, total_demand_2022, total_demand_2023):\n",
    "        monte_carlo_results = []\n",
    "        ratio_receipt_donor_2022 = self.total_receipts_2022 / total_demand_2022\n",
    "        ratio_receipt_donor_2023 = self.total_receipts_2023 / total_demand_2023\n",
    "        avg_ratio = (ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            random_receipt = np.random.randint(self.lower_bound, self.upper_bound)\n",
    "            total_receipts_2024 = random_receipt * self.num_working_days_2024\n",
    "            estimated_donors_2024 = total_receipts_2024 / avg_ratio\n",
    "            monte_carlo_results.append(estimated_donors_2024)\n",
    "\n",
    "        return monte_carlo_results\n",
    "\n",
    "    def output_results(self, monte_carlo_results, average_age_distribution):\n",
    "        result_df = pd.DataFrame(columns=[\"Year\", \"Age Group\", \"Forecast (Mean)\", \"Forecast (StdDev)\"])\n",
    "        \n",
    "        for age in average_age_distribution.index:\n",
    "            sum_values = np.sum(np.array(monte_carlo_results) * average_age_distribution[age])\n",
    "            sum_squared_values = np.sum((np.array(monte_carlo_results) * average_age_distribution[age]) ** 2)\n",
    "\n",
    "            forecast_mean = sum_values / self.iterations\n",
    "            variance = sum_squared_values / self.iterations - (forecast_mean ** 2)\n",
    "            forecast_stddev = np.sqrt(variance) if variance >= 0 else 0\n",
    "\n",
    "            result_df = result_df.append({\n",
    "                \"Year\": 2024,\n",
    "                \"Age Group\": age,\n",
    "                \"Forecast (Mean)\": forecast_mean,\n",
    "                \"Forecast (StdDev)\": forecast_stddev\n",
    "            }, ignore_index=True)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def calculate_total_population_and_donors(self):\n",
    "        for age in range(18, 107):\n",
    "            population_2023 = self.population_forecast_df[(self.population_forecast_df['year'] == 2023) & (self.population_forecast_df['age'] == age)]['population'].sum()\n",
    "            population_2024 = self.population_forecast_df[(self.population_forecast_df['year'] == 2024) & (self.population_forecast_df['age'] == age)]['population'].sum()\n",
    "\n",
    "            total_population = population_2023 + population_2024\n",
    "            total_donors = self.donors_df[(self.donors_df['year'] == 2023) & (self.donors_df['age'] == age)]['demand'].sum()\n",
    "\n",
    "            self.total_population_age_specific[age] = total_population\n",
    "            self.total_donors_age_specific[age] = total_donors\n",
    "\n",
    "            self.assumed_market_shape[age] = total_donors / total_population if total_population > 0 else 0\n",
    "\n",
    "        max_market_shape = np.max(self.assumed_market_shape)\n",
    "        self.assumed_potential_market_shape = (self.assumed_market_shape / max_market_shape) * 100\n",
    "\n",
    "    def extend_forecast(self, result_df):\n",
    "        extended_forecast_df = pd.DataFrame(columns=[\"Year\", \"Age Group\", \"Forecast (Mean)\", \"Forecast (StdDev)\"])\n",
    "\n",
    "        for year in range(2025, 2030):\n",
    "            for age in range(18, 107):\n",
    "                survival_rate = self.get_survival_rate(age, year)\n",
    "                previous_year_mean = result_df[(result_df['Year'] == 2024) & (result_df['Age Group'] == age)][\"Forecast (Mean)\"].mean()\n",
    "\n",
    "                forecast_mean = previous_year_mean * survival_rate\n",
    "                forecast_stddev = np.std(forecast_mean)  # Approximation for stddev\n",
    "\n",
    "                extended_forecast_df = extended_forecast_df.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Age Group\": age,\n",
    "                    \"Forecast (Mean)\": forecast_mean,\n",
    "                    \"Forecast (StdDev)\": forecast_stddev\n",
    "                }, ignore_index=True)\n",
    "\n",
    "        return extended_forecast_df\n",
    "\n",
    "    def get_survival_rate(self, age, year):\n",
    "        survival_rate = self.survival_rate_df[(self.survival_rate_df['age'] == age) & (self.survival_rate_df['year'] == year)]['rate']\n",
    "        return survival_rate.iloc[0] if not survival_rate.empty else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for survival_rate_df\n",
    "survival_rate_data = {\n",
    "    'age': [30, 50],\n",
    "    'year': [2025, 2025],\n",
    "    'survival_rate': [0.95, 0.93]\n",
    "}\n",
    "survival_rate_df = pd.DataFrame(survival_rate_data)\n",
    "survival_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_forecast = pd.read_csv('population_forecast.csv')\n",
    "# Convert the DataFrame to the desired format\n",
    "df_melted = population_forecast.melt(id_vars=['age'], var_name='year', value_name='population')\n",
    "population_forecast_df = pd.DataFrame(df_melted)\n",
    "population_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_lpa = remaining_lpa_df\n",
    "survival_tbl = remaining_lpa.reset_index()\n",
    "survival_tbl = survival_tbl.rename(columns={'age':'age'})\n",
    "# Convert the DataFrame to the desired format\n",
    "df_melted = survival_tbl.melt(id_vars=['age'], var_name='year', value_name='remaining')\n",
    "survival_df = pd.DataFrame(df_melted)\n",
    "survival_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_forecast_df = pd.read_csv('population_forecast.csv')\n",
    "population_forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_rate_df = remaining_lpa_df.reset_index()\n",
    "survival_rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub LongTermForecast_Market_Survival()\n",
    "    ' Define variables\n",
    "    Dim ws As Worksheet\n",
    "    Set ws = ThisWorkbook.Sheets(\"annual_unique_donors (2)\")\n",
    "    Dim lastRow As Long\n",
    "    lastRow = ws.Cells(ws.Rows.count, \"A\").End(xlUp).row\n",
    "    Dim iterations As Integer\n",
    "    iterations = 1000 ' Number of iterations for Monte Carlo simulation\n",
    "    Dim lowerBound As Double, upperBound As Double\n",
    "    lowerBound = 4000\n",
    "    upperBound = 7000\n",
    "    Dim i As Long, j As Long, row As Long\n",
    "    Dim randomReceipt As Double\n",
    "    Dim estimatedDonors2024 As Double\n",
    "    Dim monteCarloResults() As Double\n",
    "    ReDim monteCarloResults(1 To iterations)\n",
    "    Dim ageDistribution2022 As Object, ageDistribution2023 As Object, averageAgeDistribution As Object\n",
    "    Dim totalDemand2022 As Double, totalDemand2023 As Double\n",
    "    Dim totalReceipts2022 As Double, totalReceipts2023 As Double\n",
    "    Dim totalReceipts2024 As Double\n",
    "    Dim ratioReceiptDonor2022 As Double, ratioReceiptDonor2023 As Double\n",
    "    Dim numWorkingDays2024 As Long\n",
    "    Dim totalPopulationAgeSpecific(106) As Double, totalDonorsAgeSpecific(106) As Double\n",
    "    Dim assumedMarketShape(106) As Double, assumedPotentialMarketShape(106) As Double\n",
    "    Dim maxAssumedMarketShape As Double\n",
    "    Dim prevYearsPop(4) As Double\n",
    "    numWorkingDays2024 = 256\n",
    "    ' Fixed total receipts for 2022 and 2023\n",
    "    totalReceipts2022 = 751967.534626039\n",
    "    totalReceipts2023 = 970035.028248588\n",
    "    ' Calculate total demands for 2022 and 2023\n",
    "    totalDemand2022 = Application.WorksheetFunction.SumIf(ws.Range(\"A2:A\" & lastRow), 2022, ws.Range(\"C2:C\" & lastRow))\n",
    "    totalDemand2023 = Application.WorksheetFunction.SumIf(ws.Range(\"A2:A\" & lastRow), 2023, ws.Range(\"C2:C\" & lastRow))\n",
    "    ' Aggregate age distributions for 2022 and 2023\n",
    "    Set ageDistribution2022 = CreateObject(\"Scripting.Dictionary\")\n",
    "    Set ageDistribution2023 = CreateObject(\"Scripting.Dictionary\")\n",
    "    For i = 2 To lastRow\n",
    "        If ws.Cells(i, 1).Value = 2022 Then\n",
    "            If ageDistribution2022.Exists(ws.Cells(i, 2).Value) Then\n",
    "                ageDistribution2022(ws.Cells(i, 2).Value) = ageDistribution2022(ws.Cells(i, 2).Value) + ws.Cells(i, 3).Value\n",
    "            Else\n",
    "                ageDistribution2022.Add ws.Cells(i, 2).Value, ws.Cells(i, 3).Value\n",
    "            End If\n",
    "        ElseIf ws.Cells(i, 1).Value = 2023 Then\n",
    "            If ageDistribution2023.Exists(ws.Cells(i, 2).Value) Then\n",
    "                ageDistribution2023(ws.Cells(i, 2).Value) = ageDistribution2023(ws.Cells(i, 2).Value) + ws.Cells(i, 3).Value\n",
    "            Else\n",
    "                ageDistribution2023.Add ws.Cells(i, 2).Value, ws.Cells(i, 3).Value\n",
    "            End If\n",
    "        End If\n",
    "    Next i\n",
    "    ' Normalize age distribution\n",
    "    For Each age In ageDistribution2022.Keys\n",
    "        ageDistribution2022(age) = ageDistribution2022(age) / totalDemand2022\n",
    "    Next age\n",
    "    For Each age In ageDistribution2023.Keys\n",
    "        ageDistribution2023(age) = ageDistribution2023(age) / totalDemand2023\n",
    "    Next age\n",
    "    ' Average age distribution across 2022 and 2023\n",
    "    Set averageAgeDistribution = CreateObject(\"Scripting.Dictionary\")\n",
    "    For Each age In ageDistribution2022.Keys\n",
    "        If ageDistribution2023.Exists(age) Then\n",
    "            averageAgeDistribution.Add age, (ageDistribution2022(age) + ageDistribution2023(age)) / 2\n",
    "        End If\n",
    "    Next age\n",
    "    ' Monte Carlo Simulation for 2024\n",
    "    For i = 1 To iterations\n",
    "        randomReceipt = Application.WorksheetFunction.RandBetween(lowerBound, upperBound)\n",
    "        totalReceipts2024 = randomReceipt * numWorkingDays2024\n",
    "        ratioReceiptDonor2022 = totalReceipts2022 / totalDemand2022\n",
    "        ratioReceiptDonor2023 = totalReceipts2023 / totalDemand2023\n",
    "        estimatedDonors2024 = totalReceipts2024 / ((ratioReceiptDonor2022 + ratioReceiptDonor2023) / 2)\n",
    "        monteCarloResults(i) = estimatedDonors2024\n",
    "    Next i \n",
    "    Dim outputWs As Worksheet\n",
    "    ' Output the results to the \"LongTermForecast_market\" sheet\n",
    "    On Error Resume Next\n",
    "    Set outputWs = ThisWorkbook.Sheets(\"LongTermForecastMarket\")\n",
    "    If Not outputWs Is Nothing Then\n",
    "        outputWs.Cells.Clear\n",
    "        For Each chartObj In outputWs.ChartObjects\n",
    "            chartObj.Delete\n",
    "        Next chartObj\n",
    "    Else\n",
    "        Set outputWs = ThisWorkbook.Sheets.Add(After:=ThisWorkbook.Sheets(ThisWorkbook.Sheets.count))\n",
    "        outputWs.Name = \"LongTermForecastMarket\"\n",
    "    End If\n",
    "    On Error GoTo 0\n",
    "    ' Output column headers\n",
    "    outputWs.Cells(1, 1).Value = \"Year\"\n",
    "    outputWs.Cells(1, 2).Value = \"Age Group\"\n",
    "    outputWs.Cells(1, 3).Value = \"Age Distribution 2022\"\n",
    "    outputWs.Cells(1, 4).Value = \"Age Distribution 2023\"\n",
    "    outputWs.Cells(1, 5).Value = \"Random Receipt\"\n",
    "    outputWs.Cells(1, 6).Value = \"Final Forecast (Mean)\"\n",
    "    outputWs.Cells(1, 7).Value = \"Final Forecast (StdDev)\"\n",
    "    ' Add data for each age group for 2024\n",
    "    row = 2\n",
    "    For Each age In averageAgeDistribution.Keys\n",
    "        sumValues = 0\n",
    "        sumSquaredValues = 0\n",
    "        For i = 1 To iterations\n",
    "            sumValues = sumValues + monteCarloResults(i) * averageAgeDistribution(age)\n",
    "            sumSquaredValues = sumSquaredValues + (monteCarloResults(i) * averageAgeDistribution(age)) ^ 2\n",
    "        Next i\n",
    "        ' Calculate mean and standard deviation for the final forecast\n",
    "        forecastedDonorsMean = sumValues / iterations\n",
    "        forecastedDonorsStdDev = Sqr(sumSquaredValues / iterations - (sumValues / iterations) ^ 2)\n",
    "        ' Output the data for the current age group\n",
    "        outputWs.Cells(row, 1).Value = 2024\n",
    "        outputWs.Cells(row, 2).Value = age\n",
    "        outputWs.Cells(row, 3).Value = ageDistribution2022(age)\n",
    "        outputWs.Cells(row, 4).Value = ageDistribution2023(age)\n",
    "        outputWs.Cells(row, 5).Value = randomReceipt ' Random Receipt output only once per age group\n",
    "        outputWs.Cells(row, 6).Value = forecastedDonorsMean\n",
    "        outputWs.Cells(row, 7).Value = forecastedDonorsStdDev\n",
    "        row = row + 1\n",
    "    Next age\n",
    "    finalYearLastRow = outputWs.Cells(outputWs.Rows.count, \"A\").End(xlUp).row\n",
    "    ' Calculate total population and total donors age-specific for 2023 and 2024\n",
    "    Dim populationForecastWs As Worksheet\n",
    "    Set populationForecastWs = ThisWorkbook.Sheets(\"UnpivotPopulationForecast\")\n",
    "    Dim popLastRow As Long\n",
    "    popLastRow = populationForecastWs.Cells(populationForecastWs.Rows.count, \"A\").End(xlUp).row \n",
    "    For age = 18 To 106\n",
    "        totalPopulationAgeSpecific(age) = Application.WorksheetFunction.SumIfs(populationForecastWs.Range(\"C2:C\" & popLastRow), _\n",
    "            populationForecastWs.Range(\"B2:B\" & popLastRow), age, populationForecastWs.Range(\"A2:A\" & popLastRow), 2023) + _\n",
    "            Application.WorksheetFunction.SumIfs(populationForecastWs.Range(\"C2:C\" & popLastRow), _\n",
    "            populationForecastWs.Range(\"B2:B\" & popLastRow), age, populationForecastWs.Range(\"A2:A\" & popLastRow), 2024)\n",
    "            \n",
    "        totalDonorsAgeSpecific(age) = Application.WorksheetFunction.SumIf(ws.Range(\"A2:A\" & lastRow), 2023, ws.Range(\"C2:C\" & lastRow)) + _\n",
    "                              Application.WorksheetFunction.SumIf(outputWs.Range(\"A2:A\" & finalYearLastRow), 2024, outputWs.Range(\"F2:F\" & finalYearLastRow))     \n",
    "        assumedMarketShape(age) = totalDonorsAgeSpecific(age) / totalPopulationAgeSpecific(age)\n",
    "    Next age\n",
    "    ' Find the max assumed market shape and corresponding age\n",
    "    maxAssumedMarketShape = Application.WorksheetFunction.Max(assumedMarketShape)\n",
    "    ' Calculate assumed potential market shape\n",
    "    For age = 18 To 106\n",
    "        assumedPotentialMarketShape(age) = assumedMarketShape(age) / maxAssumedMarketShape * 100\n",
    "    Next age\n",
    "    ' Calculate MAX MARKET ESTIMATES:\n",
    "    'Calculate maxMarketEstimate by multiplying totalPopulationAgeSpecific(age) by assumedPotentialMarketShape(age) for each age\n",
    "    For age = 18 To 106\n",
    "        maxMarketEstimate(age) = totalPopulationAgeSpecific(age) * maxAssumedMarketShape\n",
    "    Next age\n",
    "    ' LPA SURVIVAL TABLES (BY YEAR OF APPLICATION):\n",
    "    \n",
    "    ' Extend forecast to the next 5 years (2025-2029) using cohort model\n",
    "    Dim year As Long\n",
    "    Dim cohortSurvivalRate As Double\n",
    "    Dim survivalRateWs As Worksheet\n",
    "    Set survivalRateWs = ThisWorkbook.Sheets(\"UnpivotSurvivalRate\")\n",
    "    Dim srLastRow As Long\n",
    "    srLastRow = survivalRateWs.Cells(survivalRateWs.Rows.count, \"A\").End(xlUp).row    \n",
    "    Dim dict As Object\n",
    "    Set dict = CreateObject(\"Scripting.Dictionary\")    \n",
    "    ' Load data into the dictionary\n",
    "    For i = 2 To srLastRow\n",
    "        Key = survivalRateWs.Cells(i, 1).Value & \"-\" & survivalRateWs.Cells(i, 2).Value\n",
    "        Value = survivalRateWs.Cells(i, 3).Value\n",
    "        dict(Key) = Value\n",
    "    Next i    \n",
    "    For year = 2025 To 2029\n",
    "        For age = 18 To 106\n",
    "            sumValues = 0\n",
    "            sumSquaredValues = 0    \n",
    "            ' Retrieve the survival rate\n",
    "            Key = age & \"-\" & year\n",
    "            If dict.Exists(Key) Then\n",
    "                cohortSurvivalRate = dict(Key)\n",
    "            Else\n",
    "                cohortSurvivalRate = 0\n",
    "            End If    \n",
    "            ' Calculate prevYearMean as the average of the values from the last two years\n",
    "            Dim lastYearMean As Double, secondLastYearMean As Double\n",
    "            Dim lastYearRow As Range, secondLastYearRow As Range    \n",
    "            ' Find the row for the last year (year - 1) for the current age\n",
    "            Set lastYearRow = outputWs.Columns(2).Find(What:=age, After:=outputWs.Cells(1, 2), LookIn:=xlValues, LookAt:=xlWhole, SearchOrder:=xlByRows, SearchDirection:=xlPrevious, MatchCase:=False)\n",
    "            If Not lastYearRow Is Nothing Then\n",
    "                lastYearMean = lastYearRow.Offset(0, 4).Value\n",
    "            Else\n",
    "                lastYearMean = 0\n",
    "            End If    \n",
    "            ' Find the row for the second last year (year - 2) for the current age\n",
    "            Set secondLastYearRow = outputWs.Columns(2).Find(What:=age, After:=lastYearRow, LookIn:=xlValues, LookAt:=xlWhole, SearchOrder:=xlByRows, SearchDirection:=xlPrevious, MatchCase:=False)\n",
    "            If Not secondLastYearRow Is Nothing Then\n",
    "                secondLastYearMean = secondLastYearRow.Offset(0, 4).Value\n",
    "            Else\n",
    "                secondLastYearMean = 0\n",
    "            End If    \n",
    "            ' Calculate the average of the last two years\n",
    "            prevYearMean = (lastYearMean + secondLastYearMean) / 2    \n",
    "            ' Apply assumedPotentialMarketShape and cohortSurvivalRate in the forecast\n",
    "            For i = 1 To iterations\n",
    "                ' Apply cohort survival rate and assumed potential market shape\n",
    "                forecastedDonors = prevYearMean * (cohortSurvivalRate * maxMarketEstimate(age)))   \n",
    "                sumValues = sumValues + forecastedDonors\n",
    "                sumSquaredValues = sumSquaredValues + forecastedDonors ^ 2\n",
    "            Next i   \n",
    "            ' Calculate mean and standard deviation for the forecasted donors\n",
    "            forecastedDonorsMean = sumValues / iterations\n",
    "            Dim variance As Double\n",
    "            variance = sumSquaredValues / iterations - (sumValues / iterations) ^ 2   \n",
    "            If variance >= 0 Then\n",
    "                forecastedDonorsStdDev = Sqr(variance)\n",
    "            Else\n",
    "                forecastedDonorsStdDev = 0\n",
    "            End If    \n",
    "            ' Output the data for the current year and age group\n",
    "            outputWs.Cells(row, 1).Value = year\n",
    "            outputWs.Cells(row, 2).Value = age\n",
    "            outputWs.Cells(row, 3).Value = \"N/A\"\n",
    "            outputWs.Cells(row, 4).Value = \"N/A\"\n",
    "            outputWs.Cells(row, 5).Value = randomReceipt\n",
    "            outputWs.Cells(row, 6).Value = forecastedDonorsMean\n",
    "            outputWs.Cells(row, 7).Value = forecastedDonorsStdDev\n",
    "            row = row + 1\n",
    "        Next age\n",
    "    Next year \n",
    "    ' Virtulisation\n",
    "    'Dim chartObj As ChartObject\n",
    "    'Dim ws As Worksheet\n",
    "    'Set outputWs = ThisWorkbook.Sheets(\"LongTermForecastMarket\")\n",
    "    ' Clear any existing charts\n",
    "    For Each chartObj In outputWs.ChartObjects\n",
    "        chartObj.Delete\n",
    "    Next chartObj\n",
    "    ' Define the last row for the data\n",
    "    'Dim lastRow As Long\n",
    "    lastRow = outputWs.Cells(outputWs.Rows.count, 1).End(xlUp).row\n",
    "    ' 1. Line Chart: Forecasted Donors Over Time\n",
    "    Set chartObj = outputWs.ChartObjects.Add(Left:=50, Width:=500, Top:=50, Height:=300)\n",
    "    With chartObj.chart\n",
    "        .SetSourceData Source:=outputWs.Range(\"A1:A\" & lastRow & \", F1:F\" & lastRow)\n",
    "        .ChartType = xlLine\n",
    "        .HasTitle = True\n",
    "        .ChartTitle.Text = \"Forecasted Donors Over Time\"\n",
    "        .Axes(xlCategory, xlPrimary).HasTitle = True\n",
    "        .Axes(xlCategory, xlPrimary).AxisTitle.Text = \"Year\"\n",
    "        .Axes(xlValue, xlPrimary).HasTitle = True\n",
    "        .Axes(xlValue, xlPrimary).AxisTitle.Text = \"Number of Donors\"\n",
    "    End With\n",
    "    ' 2. Bar Chart: Age Distribution 2022 and 2023\n",
    "    Set chartObj = outputWs.ChartObjects.Add(Left:=600, Width:=500, Top:=50, Height:=300)\n",
    "    With chartObj.chart\n",
    "        .SetSourceData Source:=outputWs.Range(\"B1:B\" & lastRow & \", C1:D\" & lastRow)\n",
    "        .ChartType = xlColumnClustered\n",
    "        .HasTitle = True\n",
    "        .ChartTitle.Text = \"Age Distribution 2022 vs 2023\"\n",
    "        .Axes(xlCategory, xlPrimary).HasTitle = True\n",
    "        .Axes(xlCategory, xlPrimary).AxisTitle.Text = \"Age Group\"\n",
    "        .Axes(xlValue, xlPrimary).HasTitle = True\n",
    "        .Axes(xlValue, xlPrimary).AxisTitle.Text = \"Distribution\"\n",
    "    End With\n",
    "    ' 3. Cluster Chart: Comparing Forecasts Across Different Years\n",
    "    Set chartObj = outputWs.ChartObjects.Add(Left:=50, Width:=500, Top:=400, Height:=300)\n",
    "    With chartObj.chart\n",
    "        .SetSourceData Source:=outputWs.Range(\"A1:A\" & lastRow & \", F1:F\" & lastRow)\n",
    "        .ChartType = xlColumnClustered\n",
    "        .HasTitle = True\n",
    "        .ChartTitle.Text = \"Forecasted Donors Comparison\"\n",
    "        .Axes(xlCategory, xlPrimary).HasTitle = True\n",
    "        .Axes(xlCategory, xlPrimary).AxisTitle.Text = \"Year\"\n",
    "        .Axes(xlValue, xlPrimary).HasTitle = True\n",
    "        .Axes(xlValue, xlPrimary).AxisTitle.Text = \"Number of Donors\"\n",
    "    End With\n",
    "    ' 4. Heatmap: Assumed Market Shape by Age\n",
    "    ' Create a new sheet for the heatmap\n",
    "    Dim heatmapWs As Worksheet\n",
    "    On Error Resume Next\n",
    "    Set heatmapWs = ThisWorkbook.Sheets(\"MarketShapeHeatmap\")\n",
    "    If heatmapWs Is Nothing Then\n",
    "        Set heatmapWs = ThisWorkbook.Sheets.Add(After:=ThisWorkbook.Sheets(ThisWorkbook.Sheets.count))\n",
    "        heatmapWs.Name = \"MarketShapeHeatmap\"\n",
    "    End If\n",
    "    On Error GoTo 0\n",
    "    ' Populate the heatmap data\n",
    "    heatmapWs.Cells.Clear\n",
    "    heatmapWs.Cells(1, 1).Value = \"Age Group\"\n",
    "    heatmapWs.Cells(1, 2).Value = \"Market Shape (%)\"\n",
    "    For age = 18 To 106\n",
    "        heatmapWs.Cells(age - 16, 1).Value = age\n",
    "        heatmapWs.Cells(age - 16, 2).Value = assumedPotentialMarketShape(age)\n",
    "    Next age\n",
    "    ' Add conditional formatting to create a heatmap\n",
    "    With heatmapWs.Range(\"B2:B91\")\n",
    "        .FormatConditions.AddColorScale ColorScaleType:=3\n",
    "        .FormatConditions(1).ColorScaleCriteria(1).Type = xlConditionValueLowestValue\n",
    "        .FormatConditions(1).ColorScaleCriteria(1).FormatColor.Color = RGB(255, 255, 255)\n",
    "        .FormatConditions(1).ColorScaleCriteria(2).Type = xlConditionValuePercentile\n",
    "        .FormatConditions(1).ColorScaleCriteria(2).Value = 50\n",
    "        .FormatConditions(1).ColorScaleCriteria(2).FormatColor.Color = RGB(255, 165, 0)\n",
    "        .FormatConditions(1).ColorScaleCriteria(3).Type = xlConditionValueHighestValue\n",
    "        .FormatConditions(1).ColorScaleCriteria(3).FormatColor.Color = RGB(255, 0, 0)\n",
    "    End With\n",
    "    \n",
    "    ' Optional: Automatically resize columns for better readability\n",
    "    heatmapWs.Columns(\"A:B\").AutoFit\n",
    "End Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# This script is designed to be modular, allowing you to call specific methods to perform different parts of the analysis.\n",
    "# split the code into three separate classes:\n",
    "\n",
    "# DataHandler: For handling file operations and initial data loading.\n",
    "# DataPreprocessor: For preprocessing the data and performing calculations on the data.\n",
    "# DataAnalyzer: For analyzing the data and Bayesian modeling.\n",
    "\n",
    "# Load and Preprocess Data:\n",
    "\n",
    "# Extract relevant columns.\n",
    "# Handle missing values.\n",
    "# Calculate age from the date of birth and receipt date.\n",
    "# Filter data by year and age range.\n",
    "# Calculate Age-Specific Demand:\n",
    "\n",
    "# Group data by year, gender, and age.\n",
    "# Calculate the number of unique donors.\n",
    "# Calculate Annual Demands Ratio:\n",
    "\n",
    "# Use the annual average daily application receipts.\n",
    "# Apply the annual demands ratio to incorporate uncertainty.\n",
    "# Forecast Age-Specific Demand:\n",
    "\n",
    "# Use the Bayesian model to forecast future demands.\n",
    "# Adjust the model to account for age-specific data.\n",
    "\n",
    "# use the Pymc Python package and Bayesian criteria while using Monte Carlo simulation for time series forecasting of donor application demands to \n",
    "# account for uncertainty and make more robust predictions, especially in scenarios with significant disruptions like post-COVID impacts after March 2021, \n",
    "# by having age-specific demand data (column names: year, gender, age, number of unique donors) from 2006 to 2024? Also, how do you make sure that, \n",
    "# from the actual data, you choose the right prior based on the distribution of donor demands per year and fluctuation before and after COVID? \n",
    "# to learn from the pre-COVID data and post-COVID data to decide which distribution should be used for the priors for pre-COVID and post-COVID parameters? \n",
    "# In addition, imagine we already have calculated average annual daily application receipts and then you can use average annual daily application receipts \n",
    "# and annual demands ratio (without considering age) to deal with uncertainty to improve long term forecasting of  donor application demands?\n",
    "\n",
    "\n",
    "## -------------------\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "## -------------------\n",
    "#%%\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "#%%\n",
    "## ------------------Step 3: DataAnalyzer Class-------------------- ##\n",
    "\n",
    "class DataAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def exploratory_data_analysis(self, data):\n",
    "        data.reset_index()\n",
    "        data.set_index('month_year', inplace=True)\n",
    "        data['demand'].plot(figsize=(14, 7))\n",
    "        plt.title('Donor Application Demands')\n",
    "        plt.xlabel('Month-Year')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        pre_covid = data.loc[:'Mar-21', 'demand']\n",
    "        post_covid = data.loc['Mar-21':, 'demand']\n",
    "\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        sns.histplot(pre_covid, kde=True, label='Pre-COVID', color='blue', bins=50)\n",
    "        sns.histplot(post_covid, kde=True, label='Post-COVID', color='red', bins=50)\n",
    "        plt.legend()\n",
    "        plt.title('Distribution of Donor Application Demands')\n",
    "        plt.xlabel('Demand')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "    def determine_priors(self, pre_covid, post_covid):\n",
    "        def test_distribution(data, dist, *args):\n",
    "            return kstest(data, dist, args=args)\n",
    "\n",
    "        print(\"Pre-COVID Data:\")\n",
    "        print(\"Normal:\", test_distribution(pre_covid, 'norm', np.mean(pre_covid), np.std(pre_covid)))\n",
    "        print(\"Log-Normal:\", test_distribution(pre_covid, 'lognorm', np.std(np.log(pre_covid[pre_covid > 0])), 0, np.exp(np.mean(np.log(pre_covid[pre_covid > 0])))))\n",
    "        print(\"Student's t:\", test_distribution(pre_covid, 't', len(pre_covid)-1, np.mean(pre_covid), np.std(pre_covid)))\n",
    "\n",
    "        print(\"\\nPost-COVID Data:\")\n",
    "        print(\"Normal:\", test_distribution(post_covid, 'norm', np.mean(post_covid), np.std(post_covid)))\n",
    "        print(\"Log-Normal:\", test_distribution(post_covid, 'lognorm', np.std(np.log(post_covid[post_covid > 0])), 0, np.exp(np.mean(np.log(post_covid[post_covid > 0])))))\n",
    "        print(\"Student's t:\", test_distribution(post_covid, 't', len(post_covid)-1, np.mean(post_covid), np.std(post_covid)))\n",
    "\n",
    "    def bayesian_modeling(self, pre_covid, post_covid):\n",
    "        model = pm.Model()\n",
    "        with model:\n",
    "            pre_covid_mean = pm.Normal('pre_covid_mean', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "            pre_covid_sd = pm.HalfNormal('pre_covid_sd', sigma=1)\n",
    "            post_covid_mean = pm.Normal('post_covid_mean', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "            post_covid_sd = pm.HalfNormal('post_covid_sd', sigma=1)\n",
    "\n",
    "            pre_covid_likelihood = pm.Normal('pre_covid_likelihood', mu=pre_covid_mean, sigma=pre_covid_sd, observed=pre_covid)\n",
    "            post_covid_likelihood = pm.Normal('post_covid_likelihood', mu=post_covid_mean, sigma=post_covid_sd, observed=post_covid)\n",
    "\n",
    "            trace = pm.sample(1000, tune=2000, return_inferencedata=True)\n",
    "        \n",
    "        az.plot_trace(trace)\n",
    "        plt.show()\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "\n",
    "data = lpa_data\n",
    "print(data.head(2))\n",
    "# Instantiate the DataAnalyzer\n",
    "data_analyzer = DataAnalyzer(data)\n",
    "data_analyzer.exploratory_data_analysis(data)\n",
    "pre_covid, post_covid = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "data_analyzer.determine_priors(pre_covid, post_covid)\n",
    "trace= data_analyzer.bayesian_modeling(pre_covid, post_covid)\n",
    "## ------------------\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "## ------------------Step 4: forecasting-------------------- ##\n",
    "post_covid_data = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "\n",
    "\n",
    "\n",
    "## ------------------\n",
    "\n",
    "    \n",
    "# %%\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "model = pm.Model()\n",
    "with model:\n",
    "    pre_covid_mean = pm.Normal('pre_covid_mean', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "    pre_covid_sd = pm.HalfNormal('pre_covid_sd', sigma=1)\n",
    "    post_covid_mean = pm.Normal('post_covid_mean', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "    post_covid_sd = pm.HalfNormal('post_covid_sd', sigma=1)\n",
    "\n",
    "    pre_covid_likelihood = pm.Normal('pre_covid_likelihood', mu=pre_covid_mean, sigma=pre_covid_sd, observed=pre_covid)\n",
    "    post_covid_likelihood = pm.Normal('post_covid_likelihood', mu=post_covid_mean, sigma=post_covid_sd, observed=post_covid)\n",
    "\n",
    "    trace = pm.sample(1000, tune=2000, return_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True, random_seed=rng)\n",
    "    \n",
    "print(trace.posterior_predictive)   #\n",
    "\n",
    "az.plot_ppc(trace, num_pp_samples=100); \n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "## ------------------Step 5: Monte Carlo simulations for forecasting-------------------- ##\n",
    "pre_covid_data, post_covid_data = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "\n",
    "trace = data_analyzer.bayesian_modeling(pre_covid_data, post_covid_data)\n",
    "pre_covid_data, post_covid_data = pre_covid.reset_index(), post_covid.reset_index() \n",
    "#trace = data_analyzer.bayesian_modeling(pre_covid_data, post_covid_data)\n",
    "trace['pre_covid_pred'], trace['post_covid_pred'] = pre_covid_likelihood, post_covid_likelihood\n",
    "\n",
    "with pm.Model() as model:\n",
    "    post_pred = pm.sample_posterior_predictive(trace, var_names=['pre_covid_pred', 'post_covid_pred'])\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "axes[0].plot(pre_covid_data['month_year'], pre_covid_data['demand'], label='Observed Pre-COVID')\n",
    "axes[0].plot(pre_covid_data['month_year'], post_pred['pre_covid_pred'].mean(axis=0), label='Predicted Pre-COVID Mean')\n",
    "axes[0].fill_between(pre_covid_data['month_year'], np.percentile(post_pred['pre_covid_pred'], 5, axis=0), \n",
    "                     np.percentile(post_pred['pre_covid_pred'], 95, axis=0), alpha=0.2, label='95% CI')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Pre-COVID Predictions')\n",
    "\n",
    "axes[1].plot(post_covid_data['month_year'], post_covid_data['demand'], label='Observed Post-COVID')\n",
    "axes[1].plot(post_covid_data['month_year'], post_pred['post_covid_pred'].mean(axis=0), label='Predicted Post-COVID Mean')\n",
    "axes[1].fill_between(post_covid_data['month_year'], np.percentile(post_pred['post_covid_pred'], 5, axis=0), \n",
    "                     np.percentile(post_pred['post_covid_pred'], 95, axis=0), alpha=0.2, label='95% CI')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Post-COVID Predictions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "## ------------------\n",
    "## ------------------\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "## ------------------Step 6: Specify the Model with PyMC-------------------- ##\n",
    "\n",
    "# Convert data to numpy array for PyMC\n",
    "demand_data = data['demand'].values\n",
    "\n",
    "# Define a Bayesian model with potential structural break after March 2021\n",
    "with pm.Model() as model:\n",
    "    # Priors for pre-COVID parameters (Normal distribution)\n",
    "    mu_pre = pm.Normal('mu_pre', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "    sigma_pre = pm.HalfNormal('sigma_pre', sigma=np.std(pre_covid))\n",
    "    \n",
    "    # Priors for post-COVID parameters (Normal distribution)\n",
    "    mu_post = pm.Normal('mu_post', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "    sigma_post = pm.HalfNormal('sigma_post', sigma=np.std(post_covid))\n",
    "    \n",
    "    # Indicator for structural break\n",
    "    switchpoint = len(pre_covid)\n",
    "    idx = np.arange(len(demand_data))\n",
    "    \n",
    "    # Likelihood\n",
    "    mu = pm.math.switch(idx < switchpoint, mu_pre, mu_post)\n",
    "    sigma = pm.math.switch(idx < switchpoint, sigma_pre, sigma_post)\n",
    "    \n",
    "    y = pm.Normal('y', mu=mu, sigma=sigma, observed=demand_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "## ------------------Step 5: Fit the Model Using MCMC-------------------- ##\n",
    "\n",
    "with model:\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True)\n",
    "\n",
    "# Inspect the trace\n",
    "az.plot_trace(trace)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "\n",
    "## ------------------Step 6: Posterior Predictive Checks-------------------- ##\n",
    "\n",
    "with model:\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['y'])\n",
    "\n",
    "# Simulate future demands\n",
    "n_future = 365  # Simulate for one year\n",
    "future_simulations = []\n",
    "\n",
    "for sample in ppc['y']:\n",
    "    future_path = np.concatenate([demand_data, np.zeros(n_future)])\n",
    "    for t in range(len(demand_data), len(demand_data) + n_future):\n",
    "        future_path[t] = sample[t - len(demand_data)] + future_path[t - 1]\n",
    "    future_simulations.append(future_path[-n_future:])\n",
    "\n",
    "future_simulations = np.array(future_simulations)\n",
    "\n",
    "# Analyze future simulations\n",
    "mean_forecast = np.mean(future_simulations, axis=0)\n",
    "cred_interval = np.percentile(future_simulations, [2.5, 97.5], axis=0)\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "## ------------------Step 7: Analyse and Visualize Results-------------------- ##\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, demand_data, label='Historical Data')\n",
    "plt.plot(pd.date_range(data.index[-1], periods=n_future, freq='D'), mean_forecast, label='Mean Forecast')\n",
    "plt.fill_between(pd.date_range(data.index[-1], periods=n_future, freq='D'), cred_interval[0], cred_interval[1], color='gray', alpha=0.5, label='95% Credible Interval')\n",
    "plt.axvline(data.index[switchpoint], color='r', linestyle='--', label='Post-COVID Impact')\n",
    "plt.legend()\n",
    "plt.title('Forecast of Daily Application Demands')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## -----------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LPAForecast:\n",
    "    def __init__(self, post_covid_data, covid_data, historical_data): #, economic_data):\n",
    "        self.post_covid_data = post_covid_data\n",
    "        self.covid_data = covid_data\n",
    "        #self.economic_data = economic_data\n",
    "        self.historical_data = historical_data\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        # Merge historical data with COVID-19 impact data and economic data\n",
    "        self.data = historical_data #pd.merge(self.post_covid_data, self.covid_data, on='date', how='left')\n",
    "        #self.data = pd.merge(self.data, self.economic_data, on='date', how='left')\n",
    "        self.data.fillna(0, inplace=True)\n",
    "\n",
    "    def short_term_forecast(self, order=(5,1,0)):\n",
    "        # Split data into training and testing sets\n",
    "        train, test = train_test_split(self.data, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        # Fit ARIMA model\n",
    "        model = ARIMA(train['demand'], order=order, exog=train[['covid_impact']]) #, 'economic_indicator']])\n",
    "        self.model_fit = model.fit()\n",
    "        \n",
    "        # Forecast\n",
    "        self.short_term_predictions = self.model_fit.forecast(steps=len(test), exog=test[['covid_impact']]) #, 'economic_indicator']])\n",
    "        #baseline_forecast = self.model_fit.forecast(steps=24)  # Assuming 2 years monthly forecast\n",
    "        self.test = test\n",
    "\n",
    "    def quantify_uncertainty(self):\n",
    "        # Calculate confidence intervals\n",
    "        self.conf_int = self.model_fit.get_forecast(steps=len(self.test), exog=self.test[['covid_impact']]).conf_int() #, 'economic_indicator']]).conf_int()\n",
    "        #self.conf_int = self.model_fit.get_forecast(steps=len(self.test)).conf_int()\n",
    "        \n",
    "    def long_term_forecast(self, adjustment_factor=1.2):\n",
    "        # Baseline forecast using historical trend\n",
    "        #future_economic_data = self.economic_data.tail(24)  # Assuming 2 years monthly forecast\n",
    "        baseline_forecast = self.model_fit.forecast(steps=24, exog=future_economic_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "        #baseline_forecast = self.model_fit.forecast(steps=24)  # Assuming 2 years monthly forecast\n",
    "        \n",
    "        # Adjust for COVID-19 impact\n",
    "        self.long_term_predictions = baseline_forecast * adjustment_factor\n",
    "\n",
    "        \n",
    "# Write a function to apply exponential smoothing applied to the age-specific short-term forecasts to incorporate covid impact and do sentivitity tests \n",
    "# follow the excel formula in LPA model and control assumption:\n",
    "# =GB9*'LPA Control Assumptions'!$B$123+(1-'LPA Control Assumptions'!$B$123)*(GB9-GA9+GB9)\n",
    "    #def age_specific_uncertainty(self)\n",
    "    \n",
    "    \n",
    "    def forecast_by_age_group(self, age_groups):\n",
    "        self.age_group_forecasts = {}\n",
    "        for age_group in age_groups:\n",
    "            # Filter data for the age group\n",
    "            age_group_data = self.data[self.data['age_group'] == age_group]\n",
    "            \n",
    "            # Fit ARIMA model\n",
    "            model = ARIMA(age_group_data['demand'], order=(5,1,0), exog=age_group_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            # Forecast\n",
    "            forecast = model_fit.forecast(steps=24, exog=future_economic_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "            self.age_group_forecasts[age_group] = forecast\n",
    "#         for age_group in age_groups:\n",
    "#             # Filter data for the age group\n",
    "#             age_group_data = self.data[self.data['age_group'] == age_group]\n",
    "#             # Fit ARIMA model\n",
    "#             model = ARIMA(age_group_data['registrations'], order=(5,1,0))\n",
    "#             model_fit = model.fit()\n",
    "#             # Forecast\n",
    "#             forecast = model_fit.forecast(steps=24)\n",
    "#             self.age_group_forecasts[age_group] = forecast\n",
    "    def validate_model(self):\n",
    "        # Compare predictions with actual values\n",
    "        self.validation_results = self.test['demand'] - self.short_term_predictions\n",
    "\n",
    "    def aggregate_by_age_group(self, bins, labels):\n",
    "        # Create a new column 'AgeGroup' with the age bins\n",
    "        self.data['AgeGroup'] = pd.cut(self.data['age'], bins=bins, labels=labels, right=False)\n",
    "        \n",
    "        # Aggregate data within each age group\n",
    "        aggregated_data = self.data.groupby('AgeGroup').agg({\n",
    "            'demand': 'sum',\n",
    "            'name': 'count'\n",
    "        }).rename(columns={'name': 'count'})\n",
    "        \n",
    "        return aggregated_data\n",
    "\n",
    "    def run_forecast(self, age_groups, bins, labels):\n",
    "        self.preprocess_data()\n",
    "        self.short_term_forecast()\n",
    "        self.quantify_uncertainty()\n",
    "        self.long_term_forecast()\n",
    "        self.forecast_by_age_group(age_groups)\n",
    "        self.validate_model()\n",
    "        return self.aggregate_by_age_group(bins, labels)\n",
    "\n",
    "# usage\n",
    "#historical_data = pd.read_csv('historical_data.csv')  # Replace with actual data source\n",
    "#covid_data = pd.read_csv('covid_data.csv')  # Replace with actual data source\n",
    "#economic_data = pd.read_csv('economic_data.csv')  # Replace with actual data source\n",
    "age_groups = ['18-20', '21-25', '26-30', '31-35', '36-40','41-45','46-50', '51-55', '56-60', '61-65', '66-70', '71+']\n",
    "bins = [18, 20, 30, 40, 50, 60, 70, 100]\n",
    "labels = ['18-20', '21-25', '26-30', '31-35', '36-40','41-45','46-50', '51-55', '56-60', '61-65', '66-70', '71+']\n",
    "\n",
    "forecast = LPAForecast(post_covid_data, covid_data, historical_data)# , economic_data)\n",
    "aggregated_data = forecast.run_forecast(age_groups, bins, labels)\n",
    "\n",
    "print(aggregated_data)\n",
    "\n",
    "#age_groups = ['18-30', '31-50', '51-70', '71+']\n",
    "\n",
    "#forecast = LPAForecast(post_covid_data, covid_data)\n",
    "#forecast.run_forecast(age_groups)\n",
    "#print(forecast.long_term_predictions)\n",
    "#print(forecast.age_group_forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = {'Column1': [1, 2, 3],\n",
    "        'Column2': ['A', 'B', 'C']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a custom function to combine columns\n",
    "def combine_columns(row):\n",
    "    return str(row['Column1']) + row['Column2']\n",
    "\n",
    "# Apply the custom function to create a new column 'Combined'\n",
    "df['Combined'] = df.apply(combine_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to compare the distribution\n",
    "pivot_annual_unique_donors = pd.pivot_table(annual_unique_donors, \n",
    "                             values='demand', \n",
    "                             index=['year'])#, # ['Age Group 2017', 'Age Group Today'],\n",
    "                             #aggfunc='sum') # count\n",
    "\n",
    "pivot_annual_unique_donors.reset_index(inplace=True)\n",
    "pivot_annual_unique_donors.columns = ['year', 'age'] # 'Age Group 2017', 'Age Group Today', 'Number of Individuals']\n",
    "\n",
    "pivot_annual_unique_donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        lx = life_table.loc[(life_table['year'] == year) & (life_table['age'] == age), 'lx'].values[0]\n",
    "        initial_customers = customers_df.loc[customers_df['year'] == cohort_year, 'Age 18'].values[0]\n",
    "        lpa_surviving_donors_age = initial_customers * (lx / initial_lx)\n",
    "        lpa_surviving_donors_year[f'Age {age}'] = lpa_surviving_donors_age\n",
    "        total_lpa_surviving_donors += lpa_surviving_donors_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Mortality rates for ages 45 to 49 (example values)\n",
    "qx_45_49 = qx.iloc['age' in range(45,50),:]\n",
    "mortality_rates_45_49 = qx_45_49['qx'] #np.array([rate_45, rate_46, rate_47, rate_48, rate_49])\n",
    "mortality_rates_45_49\n",
    "\n",
    "# Step 1: Calculate the logarithm of the average mortality rate for ages 45-49\n",
    "log_avg_mortality = np.log(np.mean(mortality_rates_45_49))\n",
    "log_avg_mortality\n",
    "\n",
    "# Ages and their corresponding logarithms of mortality rates (example values)\n",
    "ages = np.array([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94])\n",
    "log_mortality_rates = np.array([...])  # Fill in the logarithms of mortality rates for these ages\n",
    "log_mortality_rates\n",
    "\n",
    "# Step 1: Load the qx.csv file\n",
    "file_path = 'qx.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Define the age groups\n",
    "age_groups = {\n",
    "    \"45-49\": range(45, 50),\n",
    "    \"50-54\": range(50, 55),\n",
    "    \"55-59\": range(55, 60),\n",
    "    \"60-64\": range(60, 65),\n",
    "    \"65-69\": range(65, 70),\n",
    "    \"70-74\": range(70, 75),\n",
    "    \"75-79\": range(75, 80),\n",
    "    \"80-84\": range(80, 85),\n",
    "    \"85-89\": range(85, 90),\n",
    "}\n",
    "\n",
    "# Step 3: Calculate the average mortality rates for each age group\n",
    "average_mortality_rates = {}\n",
    "for group, ages in age_groups.items():\n",
    "    average_mortality_rates[group] = df[df['age'].isin(ages)]['qx'].mean()\n",
    "\n",
    "# Step 4: Calculate the logarithm of the average mortality rates\n",
    "log_avg_mortality_rates = {group: np.log(rate) for group, rate in average_mortality_rates.items()}\n",
    "\n",
    "# Use the midpoints of the age groups as representative ages for regression\n",
    "midpoints = {\n",
    "    \"45-49\": 47,\n",
    "    \"50-54\": 52,\n",
    "    \"55-59\": 57,\n",
    "    \"60-64\": 62,\n",
    "    \"65-69\": 67,\n",
    "    \"70-74\": 72,\n",
    "    \"75-79\": 77,\n",
    "    \"80-84\": 82,\n",
    "    \"85-89\": 87,\n",
    "}\n",
    "\n",
    "# Convert midpoints and log mortality rates into lists for regression\n",
    "ages_for_regression = np.array(list(midpoints.values()))\n",
    "log_mortality_for_regression = np.array(list(log_avg_mortality_rates.values()))\n",
    "\n",
    "# Step 5: Prepare the data for linear regression\n",
    "X = np.column_stack((ages_for_regression, ages_for_regression**2))\n",
    "\n",
    "# Add a constant to the model for the intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 6: Perform linear regression\n",
    "model = sm.OLS(log_mortality_for_regression, X)\n",
    "results = model.fit()\n",
    "coefficients = results.params\n",
    "\n",
    "# Step 7: Predict the logarithm of mortality rates for ages 90 to 106\n",
    "predicted_log_mortality = {}\n",
    "age_prediction_groups = {\n",
    "    \"90-94\": range(90, 95),\n",
    "    \"95-99\": range(95, 100),\n",
    "    \"100-104\": range(100, 105),\n",
    "    \"105+\": range(105, 107)\n",
    "}\n",
    "\n",
    "for group, ages in age_prediction_groups.items():\n",
    "    predictions = []\n",
    "    for age in ages:\n",
    "        log_mortality = coefficients[0] + coefficients[1] * age + coefficients[2] * age**2\n",
    "        predictions.append(log_mortality)\n",
    "    predicted_log_mortality[group] = np.mean(predictions)\n",
    "\n",
    "# Step 8: Apply exponential back-transformation\n",
    "predicted_mortality_rates = {group: 10 ** log_mortality for group, log_mortality in predicted_log_mortality.items()}\n",
    "\n",
    "# Display the results\n",
    "print(\"Predicted mortality rates (original scale):\")\n",
    "for group, rate in predicted_mortality_rates.items():\n",
    "    print(f\"{group}: {rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Step 1: Load the qx.csv file\n",
    "file_path = 'qx.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Define the age groups\n",
    "age_groups = {\n",
    "    \"45-49\": range(45, 50),\n",
    "    \"50-54\": range(50, 55),\n",
    "    \"55-59\": range(55, 60),\n",
    "    \"60-64\": range(60, 65),\n",
    "    \"65-69\": range(65, 70),\n",
    "    \"70-74\": range(70, 75),\n",
    "    \"75-79\": range(75, 80),\n",
    "    \"80-84\": range(80, 85),\n",
    "    \"85-89\": range(85, 90),\n",
    "}\n",
    "\n",
    "# Step 3: Calculate the average mortality rates for each age group\n",
    "average_mortality_rates = {}\n",
    "for group, ages in age_groups.items():\n",
    "    average_mortality_rates[group] = df[df['age'].isin(ages)]['qx'].mean()\n",
    "\n",
    "# Step 4: Calculate the logarithm of the average mortality rates\n",
    "log_avg_mortality_rates = {group: np.log(rate) for group, rate in average_mortality_rates.items()}\n",
    "\n",
    "# Step 5: Perform linear regression based on these values\n",
    "ages_for_regression = np.array(list(range(49, 95)))\n",
    "X = np.column_stack((ages_for_regression, ages_for_regression**2))\n",
    "y = np.array([log_avg_mortality_rates['45-49'], log_avg_mortality_rates['50-54'], \n",
    "              log_avg_mortality_rates['55-59'], log_avg_mortality_rates['60-64'], \n",
    "              log_avg_mortality_rates['65-69'], log_avg_mortality_rates['70-74'], \n",
    "              log_avg_mortality_rates['75-79'], log_avg_mortality_rates['80-84'], \n",
    "              log_avg_mortality_rates['85-89']])\n",
    "\n",
    "# Fit the linear model\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "coefficients = results.params\n",
    "\n",
    "# Step 6: Predict the logarithm of mortality rates for ages 90 to 106\n",
    "predicted_log_mortality = {}\n",
    "age_prediction_groups = {\n",
    "    \"90-94\": range(90, 95),\n",
    "    \"95-99\": range(95, 100),\n",
    "    \"100-104\": range(100, 105),\n",
    "    \"105+\": range(105, 107)\n",
    "}\n",
    "\n",
    "for group, ages in age_prediction_groups.items():\n",
    "    predictions = []\n",
    "    for age in ages:\n",
    "        log_mortality = coefficients[0] * age + coefficients[1] * age**2\n",
    "        predictions.append(log_mortality)\n",
    "    predicted_log_mortality[group] = np.mean(predictions)\n",
    "\n",
    "# Step 7: Apply exponential back-transformation\n",
    "predicted_mortality_rates = {group: 10 ** log_mortality for group, log_mortality in predicted_log_mortality.items()}\n",
    "\n",
    "# Display the results\n",
    "print(\"Predicted mortality rates (original scale):\")\n",
    "for group, rate in predicted_mortality_rates.items():\n",
    "    print(f\"{group}: {rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Prepare the data for linear regression\n",
    "X = np.column_stack((ages, ages**2))  # Include age and age^2 as independent variables\n",
    "\n",
    "# Step 3: Perform linear regression\n",
    "coefficients, _, _, _ = np.linalg.lstsq(X, log_mortality_rates, rcond=None)\n",
    "\n",
    "# Step 4: Predict the log mortality rate for age 90\n",
    "age_90 = 90\n",
    "predicted_log_mortality = coefficients[0] * age_90 + coefficients[1] * age_90**2\n",
    "\n",
    "# Step 5: Convert the predicted log mortality rate back to the original scale\n",
    "predicted_mortality = 10 ** predicted_log_mortality\n",
    "\n",
    "print(predicted_mortality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "# Cohort model to calculate Survival rate based on Demographic Ageing \n",
    "\n",
    "Initialize the Input Data:\n",
    "\n",
    "Mortality rates (qx) for ages 18 to 106.\n",
    "LPA data (e.g., donor demands) for years 2007 to 2023.\n",
    "Mortality statistics for males and females.\n",
    "\n",
    "Forecasted donor demands for years 2024 to 2030.\n",
    "Create Survival Tables:\n",
    "\n",
    "For each year (2007-2023), generate a survival table corresponding to that year using the actual donor demands.\n",
    "Estimate Age-Specific Survival:\n",
    "\n",
    "Use the mortality rates (qx) to create tables for estimated age-specific survival for both males and females.\n",
    "Forecast Donors for Future Years:\n",
    "\n",
    "Use the survival rates to forecast the number of donors for future years (2024-2030).\n",
    "Aggregate Data into a Final Table:\n",
    "\n",
    "Aggregate the data from the survival tables into a single table that tracks the total survival over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example LPA data for years 2007 to 2023 (random data for illustration)\n",
    "lpa_data = pd.DataFrame(np.random.randint(100, 1000, size=(89, 17)), \n",
    "                        index=np.arange(18, 107), \n",
    "                        columns=np.arange(2007, 2024))  # Replace with actual LPA data\n",
    "\n",
    "# Example mortality statistics for males and females (random data for illustration)\n",
    "survival_male = np.random.random((89, 89))  # Replace with actual male survival rates\n",
    "survival_female = np.random.random((89, 89))  # Replace with actual female survival rates\n",
    "\n",
    "# Example forecasted donor demands for years 2024 to 2030 (random data for illustration)\n",
    "forecast_data = pd.DataFrame(np.random.randint(100, 1000, size=(89, 7)), \n",
    "                             index=np.arange(18, 107), \n",
    "                             columns=np.arange(2024, 2031))  # Replace with actual forecast data\n",
    "\n",
    "# Control assumption for gender\n",
    "control_assumption_gender = 1  # 1 for male, 0 for female\n",
    "\n",
    "# Step 2: Create survival tables for each year from 2007 to 2023\n",
    "\n",
    "def create_survival_table(year):\n",
    "    survival_table = pd.DataFrame(index=np.arange(18, 107), columns=[year])\n",
    "    survival_table[year] = lpa_data[year]\n",
    "    return survival_table\n",
    "\n",
    "survival_tables = {year: create_survival_table(year) for year in range(2007, 2024)}\n",
    "\n",
    "# Step 3: Estimate Age-Specific Survival for future years based on survival rates\n",
    "\n",
    "def estimate_age_specific_survival(age, prior_year, current_year, gender):\n",
    "    prior_number_of_year = current_year - 2007\n",
    "    if gender == 1:  # Male\n",
    "        survival_rate = survival_male[age - prior_number_of_year - 18, prior_year]\n",
    "    else:  # Female\n",
    "        survival_rate = survival_female[age - prior_number_of_year - 18, prior_year]\n",
    "    return survival_rate\n",
    "\n",
    "# Step 4: Forecast Donors for Future Years\n",
    "\n",
    "def forecast_donors_for_year(year):\n",
    "    prior_year_data = survival_tables[year - 1]\n",
    "    forecasted_table = pd.DataFrame(index=np.arange(18, 107), columns=[year])\n",
    "\n",
    "    for age in range(18, 107):\n",
    "        prior_age = age - (year - 2007)\n",
    "        if prior_age >= 18:\n",
    "            survival_rate = estimate_age_specific_survival(age, year - 2007, year, control_assumption_gender)\n",
    "            forecasted_table.at[age, year] = prior_year_data.at[prior_age, year - 1] * survival_rate\n",
    "        else:\n",
    "            forecasted_table.at[age, year] = 0\n",
    "\n",
    "    return forecasted_table\n",
    "\n",
    "for year in range(2024, 2031):\n",
    "    if year in forecast_data.columns:\n",
    "        survival_tables[year] = forecast_data[year]\n",
    "    else:\n",
    "        survival_tables[year] = forecast_donors_for_year(year)\n",
    "\n",
    "# Step 5: Aggregate all survival tables into a single table\n",
    "\n",
    "total_lpa_survival_table = pd.DataFrame(index=np.arange(18, 107), columns=np.arange(2007, 2031))\n",
    "\n",
    "for year in range(2007, 2031):\n",
    "    total_lpa_survival_table[year] = survival_tables[year].sum(axis=1)\n",
    "\n",
    "# Example output of the total LPA Survival Table\n",
    "print(total_lpa_survival_table)\n",
    "\n",
    "# Step 6: Save or manipulate the final output as needed (e.g., export to Excel, further analysis, etc.)\n",
    "# total_lpa_survival_table.to_excel(\"Total_LPA_Survival_Tables.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "year=range(2007,2023)\n",
    "print(create_survival_table(year))\n",
    "\n",
    "age= 19 #range(18,107)\n",
    "prior_year= 0 # This can be from 0 to 89 (aging from 18 to 106 years old)\n",
    "current_year=2023\n",
    "gender=1\n",
    "print(estimate_age_specific_survival(age, prior_year, current_year, gender))\n",
    "#print(forecast_donors_for_year(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# Dynamic Micro-simulation\n",
    "\n",
    "Initialization:\n",
    "\n",
    "We start by initializing a simulated population with random ages between 18 and 106 and assigning genders.\n",
    "The population size (population_size) is chosen as 10,000 for this example, but it can be adjusted.\n",
    "Simulating Life Paths:\n",
    "\n",
    "For each individual, we simulate their life path year by year using mortality rates (qx).\n",
    "The function simulate_life_path updates each individual's age and determines if they survive each year based on the given mortality rates.\n",
    "Aggregating Results:\n",
    "\n",
    "The survival status of each individual is tracked, and these are aggregated into a survival_table that records the number of survivors for each year and age group.\n",
    "Incorporating Forecasts:\n",
    "\n",
    "For years beyond 2023, we replace the survival counts with forecasted donor demands.\n",
    "Output:\n",
    "\n",
    "The final survival_table contains the simulated survival data, which can be saved or further analyzed.\n",
    "Important Notes:\n",
    "The mortality rates (qx), initial population attributes, and forecast data must be realistic and based on actual data.\n",
    "The size of the population (population_size) can significantly impact the accuracy of the simulation.\n",
    "This code provides a flexible framework that can be extended or modified based on specific needs or additional demographic factors.\n",
    "This dynamic micro-simulation model provides a powerful tool to simulate demographic processes and forecast the survival rates of a population over time, accounting for individual-level variability and dynamic changes in the population structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Initialize the Population\n",
    "\n",
    "# Parameters\n",
    "start_year = 2007\n",
    "end_year = 2030\n",
    "initial_age = 18\n",
    "max_age = 106\n",
    "population_size = 10000  # Number of individuals to simulate\n",
    "\n",
    "# Generate initial cohort\n",
    "np.random.seed(42)\n",
    "initial_population = pd.DataFrame({\n",
    "    'age': np.random.randint(initial_age, max_age, population_size),\n",
    "    'gender': np.random.choice(['male', 'female'], population_size, p=[0.5, 0.5])\n",
    "})\n",
    "\n",
    "# Step 2: Simulate Individual Life Paths\n",
    "\n",
    "def simulate_life_path(individual, start_year, end_year, mortality_rates):\n",
    "    life_path = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        current_age = individual['age'] + (year - start_year)\n",
    "        if current_age > max_age:\n",
    "            break\n",
    "        if np.random.rand() < mortality_rates[individual['gender']][current_age - initial_age]:\n",
    "            life_path[year] = 0  # Individual has died\n",
    "            break\n",
    "        life_path[year] = 1  # Individual survives this year\n",
    "    return life_path\n",
    "\n",
    "# Example mortality rates (random for illustration)\n",
    "mortality_rates = {\n",
    "    'male': np.random.rand(max_age - initial_age + 1),\n",
    "    'female': np.random.rand(max_age - initial_age + 1)\n",
    "}\n",
    "\n",
    "# Simulate life paths for the entire population\n",
    "life_paths = initial_population.apply(lambda ind: simulate_life_path(ind, start_year, end_year, mortality_rates), axis=1)\n",
    "\n",
    "# Step 3: Aggregate Results\n",
    "\n",
    "# Initialize an empty DataFrame to store survival counts for each year and age\n",
    "survival_table = pd.DataFrame(0, index=np.arange(initial_age, max_age + 1), columns=np.arange(start_year, end_year + 1))\n",
    "\n",
    "# Aggregate individual life paths into the survival table\n",
    "for path in life_paths:\n",
    "    for year, status in path.items():\n",
    "        age = initial_age + (year - start_year)\n",
    "        survival_table.at[age, year] += status\n",
    "\n",
    "# Step 4: Incorporate Forecasts (For years 2024 to 2030)\n",
    "\n",
    "# Example forecasted data for donor demands (random for illustration)\n",
    "forecasted_donors = pd.DataFrame(np.random.randint(100, 1000, size=(max_age - initial_age + 1, end_year - 2023)),\n",
    "                                 index=np.arange(initial_age, max_age + 1), \n",
    "                                 columns=np.arange(2024, end_year + 1))\n",
    "\n",
    "# Replace survival table data for forecast years with the forecasted data\n",
    "for year in range(2024, end_year + 1):\n",
    "    survival_table[year] = forecasted_donors[year]\n",
    "\n",
    "# Step 5: Output the Results\n",
    "\n",
    "# The final survival table contains the simulated survival counts for each year and age\n",
    "print(survival_table)\n",
    "\n",
    "# Optionally, save the results to an Excel file or further manipulate the data\n",
    "# survival_table.to_excel(\"Simulated_LPA_Survival_Tables.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming qx is the mortality rate array for ages 18 to 106\n",
    "# Example: qx = np.array([...]) # 89 elements corresponding to ages 18 to 106\n",
    "qx = np.random.random(89)  # This should be replaced with actual mortality rates\n",
    "\n",
    "# Assuming we have actual LPA data in a dataframe, with years as columns and ages 18-106 as rows\n",
    "# Example: lpa_data = pd.DataFrame([...], index=np.arange(18, 107), columns=np.arange(2007, 2024))\n",
    "lpa_data = pd.DataFrame(np.random.randint(100, 1000, size=(89, 17)), \n",
    "                        index=np.arange(18, 107), index\n",
    "                        columns=np.arange(2007, 2024))  # Replace with actual LPA data\n",
    "\n",
    "# Placeholder for male and female survival tables\n",
    "# Example: survival_male = np.array([...]) # Male survival rates\n",
    "# Example: survival_female = np.array([...]) # Female survival rates\n",
    "survival_male = np.random.random((89, 89))  # Replace with actual survival rates\n",
    "survival_female = np.random.random((89, 89))  # Replace with actual survival rates\n",
    "\n",
    "# Control assumptions for gender (1 = Male, 0 = Female)\n",
    "control_assumption_gender = 1  # Example value, should be set based on the control assumptions\n",
    "\n",
    "# Initialize dataframe to hold the forecast data\n",
    "forecast_years = np.arange(2024, 2031)\n",
    "forecast_data = pd.DataFrame(index=np.arange(18, 107), columns=forecast_years)\n",
    "\n",
    "# Copy actual LPA data to forecast data for years 2007-2023\n",
    "all_data = lpa_data.copy()\n",
    "\n",
    "x=17 # start age -1\n",
    "# Iterate through years from 2007 to 2030\n",
    "for year in range(2007, 2031):\n",
    "    if year > 2023:\n",
    "        # Forecast years - use the previous year's data and survival rates\n",
    "        prior_year = year - 2007\n",
    "        for age in range(18, 107):\n",
    "            if age - prior_year >= 18:  # Ensure valid age after subtracting years\n",
    "                if control_assumption_gender == 1:\n",
    "                    # Use male survival rates\n",
    "                    survival_rate = survival_male[age - prior_year - 18, prior_year]\n",
    "                else:\n",
    "                    # Use female survival rates\n",
    "                    survival_rate = survival_female[age - prior_year - 18, prior_year]\n",
    "\n",
    "                # Estimate donors\n",
    "                #num_donors = all_data.at[age - prior_year, year - 1] * survival_rate\n",
    "                num_donors = all_data.iloc[age - prior_year - 1, prior_year - 1] * survival_rate\n",
    "                print(prior_year)\n",
    "                print(year)\n",
    "                print(age)\n",
    "                forecast_data.at[age, year] = num_donors\n",
    "            else:\n",
    "                forecast_data.at[age, year] = 0  # No data available for this combination of year and age\n",
    "    else:\n",
    "        # Use actual LPA data for years up to 2023\n",
    "        forecast_data[year] = all_data[year]\n",
    "\n",
    "# Append forecasted data to the full dataset\n",
    "all_data = pd.concat([all_data, forecast_data], axis=1)\n",
    "\n",
    "# Example: output the full dataset (could be written to an Excel or CSV file)\n",
    "print(all_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# Calculate Total Numeber of Demands:\n",
    "calculate_total_demand() sums up the values based on the year.\n",
    "\n",
    "# Calculate Age Distribution:\n",
    "calculate_age_distribution() aggregates and normalizes the age distribution data.\n",
    "\n",
    "# Monte Carlo Simulation:\n",
    "monte_carlo_simulation() runs the simulation for 2024, generating multiple forecasts.\n",
    "\n",
    "# Output Results:\n",
    "output_results() writes the results to a new or existing worksheet.\n",
    "\n",
    "# Calculate Population and Donors:\n",
    "calculate_total_population_and_donors() computes total population and donors age-specific.\n",
    "\n",
    "# Extend Forecast:\n",
    "extend_forecast() continues the forecast for 2025-2029 using the cohort survival model.\n",
    "\n",
    "# Finding Values for Previous Years:\n",
    "Use Find to locate the corresponding rows for the current age group in the last two years.\n",
    "lastYearRow corresponds to the row in the worksheet for the previous year (year - 1).\n",
    "secondLastYearRow corresponds to the row in the worksheet for the year before the previous year (year - 2).\n",
    "\n",
    "# Calculating prevYearMean:\n",
    "The mean of the forecasts from the last two years is calculated using the values found from lastYearMean and secondLastYearMean.\n",
    "This average is then used as prevYearMean in the forecast calculations.\n",
    "\n",
    "# Using prevYearMean in Forecast:\n",
    "The prevYearMean is multiplied by the cohort survival rate to get the forecasted donors for the current year and age group.\n",
    "This method ensures that the forecast for each year is informed by the trends observed in the previous two years, providing a more stable and potentially more accurate prediction.\n",
    "To apply the assumedPotentialMarketShape for each age into the long-term forecast along with the cohortSurvivalRate, we can modify the calculation of forecastedDonors by multiplying the prevYearMean (the average of the forecasts from the last two years) by both the cohortSurvivalRate and the assumedPotentialMarketShape for the specific age.\n",
    "\n",
    "# Multiplying by assumedPotentialMarketShape:\n",
    "The forecastedDonors calculation is modified to include assumedPotentialMarketShape(age) / 100. This converts the percentage value into a multiplier.\n",
    "By applying this adjustment, the forecasted number of donors for each age group is scaled according to the assumed potential market shape for that age group.\n",
    "\n",
    "# Integrating assumedPotentialMarketShape:\n",
    "The potential market shape is used to adjust the number of forecasted donors, reflecting the varying market potential across different age groups.\n",
    "\n",
    "# Impact on the Forecast:\n",
    "This approach ensures that the forecast not only considers the survival rate but also adjusts based on the market potential for each age group, providing a more nuanced and potentially more accurate prediction.\n",
    "By incorporating both the cohortSurvivalRate and assumedPotentialMarketShape, the forecast becomes more refined, taking into account both demographic survival probabilities and market potential variations by age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class LongTermForecastLPA:\n",
    "    def __init__(self, donors_df, population_forecast_df, survival_rate_df):\n",
    "        # Initialize dataframes\n",
    "        self.donors_df = donors_df\n",
    "        self.population_forecast_df = population_forecast_df\n",
    "        self.survival_rate_df = survival_rate_df\n",
    "\n",
    "        # Fixed variables\n",
    "        self.iterations = 1000\n",
    "        self.lower_bound = 4000\n",
    "        self.upper_bound = 7000\n",
    "        self.num_working_days_2024 = 256\n",
    "\n",
    "        # Fixed total receipts for 2022 and 2023\n",
    "        self.total_receipts_2022 = 751967.534626039\n",
    "        self.total_receipts_2023 = 970035.028248588\n",
    "\n",
    "        # Initialize variables\n",
    "        self.total_population_age_specific = np.zeros(107)\n",
    "        self.total_donors_age_specific = np.zeros(107)\n",
    "        self.assumed_market_shape = np.zeros(107)\n",
    "        self.assumed_potential_market_shape = np.zeros(107)\n",
    "\n",
    "    def run_forecast(self):\n",
    "        # Calculate total demands for 2022 and 2023\n",
    "        total_demand_2022 = self.calculate_total_demand(2022)\n",
    "        total_demand_2023 = self.calculate_total_demand(2023)\n",
    "\n",
    "        # Aggregate age distributions for 2022 and 2023\n",
    "        age_distribution_2022 = self.calculate_age_distribution(2022, total_demand_2022)\n",
    "        age_distribution_2023 = self.calculate_age_distribution(2023, total_demand_2023)\n",
    "\n",
    "        # Average age distribution across 2022 and 2023\n",
    "        average_age_distribution = self.calculate_average_age_distribution(age_distribution_2022, age_distribution_2023)\n",
    "\n",
    "        # Monte Carlo Simulation for 2024\n",
    "        monte_carlo_results = self.monte_carlo_simulation(average_age_distribution, total_demand_2022, total_demand_2023)\n",
    "\n",
    "        # Output the results to a DataFrame\n",
    "        result_df = self.output_results(monte_carlo_results, average_age_distribution)\n",
    "\n",
    "        # Calculate total population and total donors age-specific for 2023 and 2024\n",
    "        self.calculate_total_population_and_donors()\n",
    "\n",
    "        # Extend forecast to the next 5 years (2025-2029) using cohort model\n",
    "        extended_forecast_df = self.extend_forecast(result_df)\n",
    "\n",
    "        # Combine all results\n",
    "        final_result_df = pd.concat([result_df, extended_forecast_df], ignore_index=True)\n",
    "\n",
    "        return final_result_df\n",
    "\n",
    "    def calculate_total_demand(self, year):\n",
    "        return self.donors_df[self.donors_df['year'] == year]['demand'].sum()\n",
    "\n",
    "    def calculate_age_distribution(self, year, total_demand):\n",
    "        age_distribution = self.donors_df[self.donors_df['year'] == year].groupby('age')['demand'].sum()\n",
    "        return age_distribution / total_demand\n",
    "\n",
    "    def calculate_average_age_distribution(self, dist_2022, dist_2023):\n",
    "        common_ages = dist_2022.index.intersection(dist_2023.index)\n",
    "        return (dist_2022[common_ages] + dist_2023[common_ages]) / 2\n",
    "\n",
    "    def monte_carlo_simulation(self, average_age_distribution, total_demand_2022, total_demand_2023):\n",
    "        monte_carlo_results = []\n",
    "        for _ in range(self.iterations):\n",
    "            random_receipt = np.random.randint(self.lower_bound, self.upper_bound)\n",
    "            total_receipts_2024 = random_receipt * self.num_working_days_2024\n",
    "            ratio_receipt_donor_2022 = self.total_receipts_2022 / total_demand_2022\n",
    "            ratio_receipt_donor_2023 = self.total_receipts_2023 / total_demand_2023\n",
    "            estimated_donors_2024 = total_receipts_2024 / ((ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2)\n",
    "            monte_carlo_results.append(estimated_donors_2024)\n",
    "        return np.array(monte_carlo_results)\n",
    "\n",
    "    def output_results(self, monte_carlo_results, average_age_distribution):\n",
    "        result_data = []\n",
    "\n",
    "        for age in average_age_distribution.index:\n",
    "            sum_values = np.sum(monte_carlo_results * average_age_distribution[age])\n",
    "            sum_squared_values = np.sum((monte_carlo_results * average_age_distribution[age]) ** 2)\n",
    "            forecasted_donors_mean = sum_values / self.iterations\n",
    "            forecasted_donors_std_dev = np.sqrt(sum_squared_values / self.iterations - (forecasted_donors_mean ** 2))\n",
    "\n",
    "            result_data.append({\n",
    "                'year': 2024,\n",
    "                'Age Group': age,\n",
    "                'Age Distribution 2022': average_age_distribution[age],\n",
    "                'Age Distribution 2023': 'N/A',\n",
    "                'Random Receipt': np.mean(monte_carlo_results),\n",
    "                'Final Forecast (Mean)': forecasted_donors_mean,\n",
    "                'Final Forecast (StdDev)': forecasted_donors_std_dev\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(result_data)\n",
    "\n",
    "    def calculate_total_population_and_donors(self):\n",
    "        for age in range(18, 107):\n",
    "            total_population = self.population_forecast_df[(self.population_forecast_df['age'] == age) & \n",
    "                                                           (self.population_forecast_df['year'].isin([2023, 2024]))]['PopulationForecastInput'].sum()\n",
    "            total_donors = self.total_population_age_specific[age] + self.total_donors_age_specific[age]\n",
    "            self.assumed_market_shape[age] = total_donors / total_population\n",
    "        self.max_assumed_market_shape = np.max(self.assumed_market_shape)\n",
    "\n",
    "        for age in range(18, 107):\n",
    "            self.assumed_potential_market_shape[age] = self.assumed_market_shape[age] / self.max_assumed_market_shape * 100\n",
    "\n",
    "    def extend_forecast(self, result_df):\n",
    "        extended_result_data = []\n",
    "        survival_dict = self.survival_rate_df.set_index(['age', 'year'])['SurvivalRate'].to_dict()\n",
    "\n",
    "        for year in range(2025, 2030):\n",
    "            for age in range(18, 107):\n",
    "                key = (age, year)\n",
    "                cohort_survival_rate = survival_dict.get(key, 0)\n",
    "                prev_year_mean = result_df.loc[(result_df['year'] == year - 1) & (result_df['Age Group'] == age), 'Final Forecast (Mean)'].values[0]\n",
    "                forecasted_donors_mean = prev_year_mean * cohort_survival_rate\n",
    "                variance = np.var([forecasted_donors_mean for _ in range(self.iterations)])\n",
    "                forecasted_donors_std_dev = np.sqrt(variance) if variance >= 0 else 0\n",
    "\n",
    "                extended_result_data.append({\n",
    "                    'year': year,\n",
    "                    'Age Group': age,\n",
    "                    'Age Distribution 2022': 'N/A',\n",
    "                    'Age Distribution 2023': 'N/A',\n",
    "                    'Random Receipt': 'N/A',\n",
    "                    'Final Forecast (Mean)': forecasted_donors_mean,\n",
    "                    'Final Forecast (StdDev)': forecasted_donors_std_dev\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(extended_result_data)\n",
    "\n",
    "# Assuming you have loaded your data into pandas DataFrames:\n",
    "donors_df = pd.read_csv('annual_unique_donors.csv')  # Replace with your DataFrame\n",
    "population_forecast_df = pd.read_csv('UnpivotPopulationForecast.csv')  # Replace with your DataFrame\n",
    "survival_rate_df = pd.read_csv('UnpivotSurvivalRate.csv')  # Replace with your DataFrame\n",
    "\n",
    "# Initialize the forecast class\n",
    "forecast = LongTermForecastLPA(donors_df, population_forecast_df, survival_rate_df)\n",
    "\n",
    "# Run the forecast\n",
    "result_df = forecast.run_forecast()\n",
    "\n",
    "# Save the result to an Excel file\n",
    "result_df.to_excel('long_term_forecast_results.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to perform Naïve extrapolation\n",
    "def naive_extrapolation(data, forecast_periods, freq='Y'):\n",
    "    last_observed_value = data.iloc[-1]\n",
    "    forecast_values = np.repeat(last_observed_value, forecast_periods)\n",
    "    #data.set_index('year', inplace=True)\n",
    "    #forecast_index = pd.date_range(start=f\"{data.index[-1].year + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "    last_year = data.index[-1] #data['year'].iloc[-1] #\n",
    "    \n",
    "    # Modified to generate forecasts for different frequencies (Y, M, D).\n",
    "    if freq == 'Y': \n",
    "        forecast_index = pd.date_range(start=f\"{last_year + 1}\", periods=forecast_periods, freq='YS')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y'), periods=forecast_periods, freq='YS')\n",
    "        \n",
    "    elif freq == 'M': \n",
    "        tup = data.index[-1]\n",
    "        first, *middle, last = tup\n",
    "        middle = last\n",
    "        last = 1\n",
    "        # Calculate the date 6 months from today's date and print it in ISO 8601 format\n",
    "        #print((dt.date.today() + dt.timedelta(1 * 365 / 12)).isoformat())\n",
    "        forecast_index = pd.date_range(start=f\"{(dt.date(first, middle, last) + dt.timedelta((1 * 365 / 12)+1)).isoformat()}\", periods=forecast_periods, freq='MS')\n",
    "        #forecast_index = pd.date_range(start=f\"{last_year}-01\", periods=forecast_periods, freq='MS')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y-%m'), periods=forecast_periods, freq='MS')\n",
    "    elif freq == 'D':\n",
    "        tup = data.index[-1]\n",
    "        first, middle, last = tup \n",
    "        forecast_index = pd.date_range(start=f\"{(dt.date(first, middle, last) + dt.timedelta(3)).isoformat()}\", periods=forecast_periods, freq='D')\n",
    "        #forecast_index = pd.date_range(start=f\"{last_year}-01-01\", periods=forecast_periods, freq='D')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y-%m-%d'), periods=forecast_periods, freq='D')\n",
    "        \n",
    "    forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast demand using SARIMA\n",
    "#start_year = '2024-04'\n",
    "#forecast_periods = 2 #24\n",
    "# Forecast overall demand using Naïve extrapolation\n",
    "forecast_periods_annual = 5  # 2 years of forecast\n",
    "forecast_periods_monthly = 24  # 24 months of forecast (2 years)\n",
    "forecast_periods_daily = 730  # 730 days of forecast (2 years)\n",
    "\n",
    "# Annual forecast\n",
    "historical_demand = historical_data_df.groupby('year')['demand'].sum()\n",
    "forecast_df_annual = naive_extrapolation(historical_demand, forecast_periods_annual, freq='Y')\n",
    "\n",
    "# Monthly forecast\n",
    "historical_demand_mon = historical_demand_monthly.reset_index()\n",
    "historical_demand_mon = historical_demand_monthly.groupby(['year', 'month'])['demand'].sum()\n",
    "forecast_df_monthly = naive_extrapolation(historical_demand_mon, forecast_periods_monthly, freq='M')\n",
    "\n",
    "\n",
    "# Daily forecast\n",
    "historical_demand_day = historical_demand_daily.reset_index()\n",
    "historical_demand_day = historical_demand_day.groupby(['year', 'month', 'day'])['demand'].sum() #.groupby(['year', 'month', 'day'])['demand'].sum()\n",
    "forecast_df_daily = naive_extrapolation(historical_demand_day, forecast_periods_daily, freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#forecast_df = fit_sarima_and_forecast(historical_data_df.set_index('year')['demand'], start_year, forecast_periods)\n",
    "#forecast_df = fit_sarima_and_forecast(historical_demand, start_year, forecast_periods)\n",
    "#forecast_df = naive_extrapolation(historical_demand, forecast_periods)\n",
    "\n",
    "# Calculate age-specific demand ratios\n",
    "age_specific_ratios = {}\n",
    "for year in historical_data_df['year'].unique():\n",
    "    print(f\"year: {year}\")\n",
    "    age_demand = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'] == year]\n",
    "    #print(f\"age_demand: {age_demand}\")\n",
    "    total_demand = age_demand['demand'].sum()\n",
    "    #print(f\"total_demand: {total_demand}\")\n",
    "    if total_demand > 0:\n",
    "        age_specific_ratios[year] = age_demand.set_index('age')['demand'] / total_demand\n",
    "        #print(f\"age_specific_ratios[year]: {age_specific_ratios[year]}\")\n",
    "    else:\n",
    "        age_specific_ratios[year] = pd.Series(0, index=range(18, 107))\n",
    "        #print(f\" Zero age: age_specific_ratios[year]: {pd.Series(0, index=range(18, 107))}\")\n",
    "# Function to apply uncertainty adjustments to the forecasts\n",
    "def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year, freq='Y'):\n",
    "#def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year):\n",
    "    # Filter Ages: We filter the data to include only ages between 18 and 106.\n",
    "    #adjusted_forecast = forecast_df.copy()\n",
    "    adjusted_forecast = pd.DataFrame(index=forecast_df.index, columns=range(18, 107))\n",
    "    \n",
    "    start_year = pd.to_datetime(forecast_start_year).year -1\n",
    "    \n",
    "    month_ratio_list = []#list()\n",
    "    \n",
    "    for i in range(len(forecast_df)):\n",
    "        if freq == 'Y':\n",
    "            forecast_year = start_year - i\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "        elif freq == 'M':\n",
    "            forecast_year = start_year - (i // 12)\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "        elif freq == 'D':\n",
    "            forecast_year = start_year - (i // 365)\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "    # Forecasting: We fit the SARIMA model to the historical data and obtain the overall forecast.\n",
    "#         Check Year Existence: Before calculating the month_ratio, we check if the forecast_year exists in both annual_donor_receipts and annual_donor_demands.\n",
    "#         Assign Zero Demand: If the year does not exist in either DataFrame, we assign zero demand for that period.\n",
    "        if forecast_year in annual_donor_receipts['year'].values and forecast_year in annual_donor_demands.index:\n",
    "            print(f\"## ------------------- ##\")\n",
    "            #print(f\"## ------------------- ##\")\n",
    "            #print(f\"## ------------------- ##\")\n",
    "            #print(f\"forecast_year for receipts: {annual_donor_receipts['year'].values}\")\n",
    "            #print(f\"forecast_year for donors: {annual_donor_demands.index}\")\n",
    "            #print(f\"forecast_year: {forecast_year}\")\n",
    "            month_ratio = round((annual_donor_receipts[annual_donor_receipts['year'] == forecast_year]['Yearly Receipt'].values[0] / ##annual_donor_receipts[annual_donor_receipts['year'] == 2023]['Yearly Receipt'].values[0] / annual_donor_demands[2023] \n",
    "                           annual_donor_demands[forecast_year]), 2)\n",
    "            #print(f\"month_ratio: {month_ratio}\")\n",
    "            \n",
    "            # Age-Specific Ratios: We calculate the demand ratios for each age group.\n",
    "            #age_specific_ratio = age_specific_ratios.get(year, pd.Series(0, index=range(18, 107)))\n",
    "            for age in range(18, 107):\n",
    "                age_specific_ratio = age_specific_ratios.get(forecast_year, pd.Series(0, index=range(18, 107)))\n",
    "                #print(f\"age_specific_ratio: {age_specific_ratio}\")\n",
    "                # Adjusting the Forecast:\n",
    "                # Initialize an empty DataFrame to hold the adjusted forecast values.\n",
    "                # For each forecasted period, calculate the monthly ratio.\n",
    "                if age in age_specific_ratio:\n",
    "                     # Distribute the forecasted demand among different age groups using the calculated age-specific ratios.\n",
    "                    #month_ratio_list = month_ratio_list.append(month_ratio) \n",
    "                    adjusted_forecast.iloc[i, age - 18] = (forecast_df.iloc[i]['Forecast'] * month_ratio * age_specific_ratio[age])\n",
    "                    print(f\" for i: {i}, year: {forecast_year}, age: {age} ==> month_ratio = {month_ratio}, age_specific_ratio[age]: {age_specific_ratio[age]}, adjusted_forecast: {adjusted_forecast.iloc[i, age - 18]}\")\n",
    "#                     if age not in dict:\n",
    "#                         dict[age] = []\n",
    "#                         dict[age].append(month_ratio)\n",
    "#                         print(dict)\n",
    "                   \n",
    "                    #.to_csv(f\"month_ratio_year{forecast_year}_age{age}.csv\", index=False)\n",
    "                    #age_specific_ratio[age].to_csv(f\"age_specific_ratio_year{forecast_year}_age{age}.csv\", index=False)\n",
    "                else: # If a specific age has no data, we assign a zero demand.\n",
    "                    adjusted_forecast.iloc[i, age - 18] = 0   \n",
    "        else:\n",
    "            # If the year is not found, assign zero demand\n",
    "            adjusted_forecast.iloc[i, :] = 0\n",
    "        \n",
    "        #adjusted_forecast.iloc[i] = adjusted_forecast.iloc[i] * month_ratio * age_specific_ratio.values\n",
    "        #forecast_value = adjusted_forecast.iloc[i]['Forecast']\n",
    "        #adjusted_values = forecast_value * month_ratio * age_specific_ratio.values\n",
    "        #adjusted_forecast.iloc[i]['Forecast'] = adjusted_values.sum()\n",
    "    return adjusted_forecast #, month_ratio_list)\n",
    "\n",
    "# Apply the uncertainty adjustments to the forecasts\n",
    "#adjusted_forecast_df = apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year)\n",
    "\n",
    "# Apply the uncertainty adjustments to the forecasts\n",
    "\n",
    "start_year = dt.date.today() #2024\n",
    "forecast_start_year = start_year\n",
    "pd.to_datetime(forecast_start_year).year -1\n",
    "\n",
    "# Adjusted annual forecast\n",
    "adjusted_forecast_annual_df = apply_uncertainty_adjustments(forecast_df_annual, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='Y')\n",
    "adjusted_forecast_annual_df.to_csv(f\"adjusted_forecast_annual.csv\", index=False)\n",
    "\n",
    "# Adjusted monthly forecast\n",
    "#adjusted_forecast_monthly_df = apply_uncertainty_adjustments(forecast_df_monthly, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='M')\n",
    "#adjusted_forecast_monthly_df.to_csv(f\"adjusted_forecast_monthly.csv\", index=False)\n",
    "\n",
    "# Adjusted daily forecast\n",
    "#adjusted_forecast_daily_df = apply_uncertainty_adjustments(forecast_df_daily, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='D')\n",
    "#adjusted_forecast_daily_df.to_csv(f\"adjusted_forecast_daily.csv\", index=False)\n",
    "\n",
    "# Display the adjusted forecasts\n",
    "print(\"Adjusted Annual Forecast:\")\n",
    "print(adjusted_forecast_annual_df.head())\n",
    "\n",
    "#print(\"Adjusted Monthly Forecast:\")\n",
    "#print(adjusted_forecast_monthly_df.head())\n",
    "\n",
    "#print(\"Adjusted Daily Forecast:\")\n",
    "#print(adjusted_forecast_daily_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical data\n",
    "historical_data_df = annual_unique_donors\n",
    "\n",
    "\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "filtered_data_df = historical_data_df[(historical_data_df['age'] >= 18) & (historical_data_df['age'] <= 106)]\n",
    "\n",
    "# Calculate annual donor receipts and demands\n",
    "annual_donor_receipts = filtered_data_df.groupby('year')['demand'].sum().reset_index(name='Yearly Receipt')\n",
    "annual_donor_demands = filtered_data_df.groupby('year')['demand'].sum()\n",
    "\n",
    "# Calculate age-specific demands\n",
    "annual_donor_demands_age_specific = filtered_data_df.groupby(['year', 'age'])['demand'].sum().reset_index()\n",
    "\n",
    "# Define a function to perform Naïve extrapolation\n",
    "def naive_extrapolation(data, forecast_periods):\n",
    "    last_observed_value = data.iloc[-1]\n",
    "    forecast_values = np.repeat(last_observed_value, forecast_periods)\n",
    "    #forecast_index = pd.date_range(start=f\"{data.index[-1].year + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "    forecast_index = pd.date_range(start=f\"{data.index[-1] + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "\n",
    "    forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "    return forecast_df\n",
    "\n",
    "# Forecast overall demand using Naïve extrapolation\n",
    "forecast_periods = 2  # 2 years of forecast\n",
    "historical_demand = filtered_data_df.groupby('year')['demand'].sum()\n",
    "historical_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_df = naive_extrapolation(historical_demand, forecast_periods)\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Calculate age-specific demand ratios\n",
    "# age_specific_ratios = {}\n",
    "# for year in filtered_data_df['year'].unique():\n",
    "#     age_demand = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'] == year]\n",
    "#     total_demand = age_demand['demand'].sum()\n",
    "#     if total_demand > 0:\n",
    "#         age_specific_ratios[year] = age_demand.set_index('age')['demand'] / total_demand\n",
    "#     else:\n",
    "#         age_specific_ratios[year] = pd.Series(0, index=range(18, 107))\n",
    "\n",
    "# # Function to apply uncertainty adjustments to the forecasts\n",
    "# def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year):\n",
    "#     adjusted_forecast = pd.DataFrame(index=forecast_df.index, columns=range(18, 107))\n",
    "#     start_year = pd.to_datetime(forecast_start_year).year\n",
    "#     for i in range(len(forecast_df)):\n",
    "#         forecast_year = start_year + i\n",
    "#         # Check if the year exists in both DataFrames\n",
    "#         if forecast_year in annual_donor_receipts['year'].values and forecast_year in annual_donor_demands.index:\n",
    "#             month_ratio = (annual_donor_receipts[annual_donor_receipts['year'] == forecast_year]['Yearly Receipt'].values[0] /\n",
    "#                            annual_donor_demands[forecast_year])\n",
    "#             for age in range(18, 107):\n",
    "#                 age_specific_ratio = age_specific_ratios.get(forecast_year, pd.Series(0, index=range(18, 107)))\n",
    "#                 if age in age_specific_ratio:\n",
    "#                     adjusted_forecast.iloc[i, age - 18] = (forecast_df.iloc[i]['Forecast'] * month_ratio * age_specific_ratio[age])\n",
    "#                 else:\n",
    "#                     adjusted_forecast.iloc[i, age - 18] = 0\n",
    "#         else:\n",
    "#             # If the year is not found, assign zero demand\n",
    "#             adjusted_forecast.iloc[i, :] = 0\n",
    "#     return adjusted_forecast\n",
    "\n",
    "# # Apply the uncertainty adjustments to the forecasts\n",
    "# start_year = 2024\n",
    "# adjusted_forecast_df = apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year)\n",
    "\n",
    "# # Display the adjusted forecast\n",
    "# print(adjusted_forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Calculates the growth rate for each age cohort.\n",
    "# Computes the average growth rate for each age cohort.\n",
    "# Uses the last year’s data to forecast the next year’s demand.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Calculates the growth rate for each age cohort.\n",
    "# Computes the average growth rate for each age cohort.\n",
    "# Uses the last year’s data to forecast the next year’s demand.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Applies seasonal decomposition to separate the trend and seasonal components.\n",
    "# Calculates the average growth rate for the trend component.\n",
    "# Forecasts the next year’s trend component and combines it with the seasonal component.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "def cohort_analysis_forecast(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "df = annual_donor_demands\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast(df)\n",
    "print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_uncertainty(forecast, annual_donor_receipts, annual_donor_demands, age_specific_demands):\n",
    "#     # Calculate the annual ratios\n",
    "#     annual_ratios = annual_donor_receipts['Yearly Receipt'] / annual_donor_demands\n",
    "\n",
    "#     # Calculate the age-specific demand ratios\n",
    "#     age_specific_ratios = age_specific_demands.groupby('age')['demand'].sum() / age_specific_demands['demand'].sum()\n",
    "\n",
    "#     # Create a DataFrame to store the adjusted forecast\n",
    "#     adjusted_forecast = pd.DataFrame(index=forecast.index, columns=forecast.columns)\n",
    "\n",
    "#     for year in range(2024, 2026):\n",
    "#         # Get the annual ratio for the current year\n",
    "#         annual_ratio = annual_ratios.loc[year]\n",
    "\n",
    "#         for age in range(18, 107):\n",
    "#             # Get the age-specific ratio for the current age\n",
    "#             age_ratio = age_specific_ratios.get(age, 0)\n",
    "\n",
    "#             # Apply the uncertainty to the forecast\n",
    "#             adjusted_forecast.loc[(forecast.index.year == year) & (forecast.columns == age), age] = (\n",
    "#                 forecast.loc[(forecast.index.year == year) & (forecast.columns == age), age] * annual_ratio * age_ratio\n",
    "#             )\n",
    "\n",
    "#     # Fill NaN values with 0\n",
    "#     adjusted_forecast = adjusted_forecast.fillna(0)\n",
    "\n",
    "#     return adjusted_forecast\n",
    "\n",
    "\n",
    "# def cohort_analysis_forecast_with_seasonality(df):\n",
    "#     # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "#     pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "#     # Initialize a DataFrame to store the forecast\n",
    "#     forecast_df = pd.DataFrame(index=pivot.index)\n",
    "    \n",
    "#     # Loop through each age cohort to apply seasonal decomposition and forecast\n",
    "#     for age in pivot.index:\n",
    "#         # Get the time series for the current age cohort\n",
    "#         ts = pivot.loc[age].dropna()\n",
    "        \n",
    "#         # Apply seasonal decomposition\n",
    "#         decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
    "        \n",
    "#         # Extract the trend and seasonal components\n",
    "#         trend = decomposition.trend.dropna()\n",
    "#         seasonal = decomposition.seasonal.dropna()\n",
    "        \n",
    "#         # Calculate the average growth rate for the trend component\n",
    "#         growth_rate = trend.pct_change().mean()\n",
    "        \n",
    "#         # Forecast the next year's trend component\n",
    "#         last_trend_value = trend.iloc[-1]\n",
    "#         forecast_trend = last_trend_value * (1 + growth_rate)\n",
    "        \n",
    "#         # Get the seasonal component for the next period (assuming seasonality repeats)\n",
    "#         next_seasonal_value = seasonal.iloc[-12 % len(seasonal)]\n",
    "        \n",
    "#         # Combine the forecasted trend and seasonal components\n",
    "#         forecast_value = forecast_trend * next_seasonal_value\n",
    "        \n",
    "#         # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "#         uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "#         forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "#         # Store the forecast in the DataFrame\n",
    "#         forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "#     # Return the forecast DataFrame\n",
    "#     return forecast_df\n",
    "\n",
    "# # Call the function and print the forecast\n",
    "# forecast = cohort_analysis_forecast_with_seasonality(df)\n",
    "# print(forecast)\n",
    "\n",
    "\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Applies STL decomposition to separate the trend and seasonal components.\n",
    "# Calculates the average growth rate for the trend component.\n",
    "# Forecasts the next year’s trend component and combines it with the seasonal component.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "# import pandas as pd\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# # Assuming the dataframe has a 'year' column and a 'demand' column\n",
    "# df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "# df.set_index('year', inplace=True)\n",
    "\n",
    "# # Decompose the time series to observe seasonal patterns\n",
    "# decomposition = seasonal_decompose(df['demand'], model='additive', period=1)\n",
    "\n",
    "# # Fit the TSL model with seasonal components\n",
    "# model = ExponentialSmoothing(df['demand'], trend='add', seasonal='add', seasonal_periods=1)\n",
    "# fit_model = model.fit()\n",
    "\n",
    "# # Forecast the next period\n",
    "# forecast = fit_model.forecast(1)\n",
    "\n",
    "# # Add the forecast to the original function\n",
    "# def cohort_analysis_forecast(df, forecast_value):\n",
    "#     # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "#     pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "#     # Calculate the growth rate for each age cohort\n",
    "#     growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "#     # Calculate the average growth rate for each age cohort\n",
    "#     avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "#     # Get the last year of data for each age cohort\n",
    "#     last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "#     # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "#     forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "#     # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "#     # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "#     uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "#     forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "#     # Add the TSL forecast value\n",
    "#     forecast_with_uncertainty['TSL_Forecast'] = forecast_value\n",
    "    \n",
    "#     # Return the forecast with uncertainty\n",
    "#     return forecast_with_uncertainty\n",
    "\n",
    "# # Call the function and print the forecast with TSL seasonal forecasting\n",
    "# forecast_with_tsl = cohort_analysis_forecast(df, forecast.values[0])\n",
    "# print(forecast_with_tsl)\n",
    "\n",
    "# This code integrates STL seasonal forecasting into your existing cohort analysis forecast function. \n",
    "# It uses the STL decomposition from the statsmodels library to decompose the time series data and \n",
    "# then applies the Holt-Winters method for forecasting. \n",
    "# The forecast value is then adjusted by the age-specific Uncertainty_Ratio.\n",
    "\n",
    "# import pandas as pd\n",
    "# from statsmodels.tsa.seasonal import STL\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# # Assuming the dataframe has 'year' and 'age' columns and a 'demand' column\n",
    "# df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "# df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# # Function to apply STL and forecast\n",
    "# def cohort_analysis_forecast_with_stl(df):\n",
    "#     # Initialize a DataFrame to store the forecast\n",
    "#     forecast_df = pd.DataFrame()\n",
    "\n",
    "#     # Loop through each age cohort to apply STL and forecast\n",
    "#     for age in df.index.get_level_values(0).unique():\n",
    "#         # Get the time series for the current age cohort\n",
    "#         ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "#         # Apply STL decomposition\n",
    "#         stl = STL(ts, seasonal=13)\n",
    "#         result = stl.fit()\n",
    "        \n",
    "#         # Forecast the next year's demand using Holt-Winters method\n",
    "#         model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#         fit_model = model.fit()\n",
    "#         forecast_value = fit_model.forecast(1).iloc[0]\n",
    "        \n",
    "#         # Get the corresponding 'Uncertainty_Ratio' for the specific age and year\n",
    "#         uncertainty_ratio = df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        \n",
    "#         # Multiply the forecast value by the 'Uncertainty_Ratio'\n",
    "#         forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "#         # Store the forecast in the DataFrame\n",
    "#         forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "#     # Return the forecast DataFrame\n",
    "#     return forecast_df\n",
    "\n",
    "# # Call the function and print the forecast\n",
    "# forecast = cohort_analysis_forecast_with_stl(df)\n",
    "# print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "class DemandForecasting:\n",
    "    def __init__(self, file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "        self.df = self.df[self.df['year'].isin([2020, 2021, 2022, 2023])]\n",
    "        self.df.set_index(['age', 'year'], inplace=True)\n",
    "        self.variability_measures = None\n",
    "        self.forecast_df = None\n",
    "\n",
    "    def calculate_variability_measures(self):\n",
    "        measures = pd.DataFrame()\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "            std_dev = ts.std()\n",
    "            variance = ts.var()\n",
    "            range_val = ts.max() - ts.min()\n",
    "            iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "            cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "            mad = ts.mad()\n",
    "            qd = iqr / 2\n",
    "            measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "            measures.loc[age, 'Variance'] = variance\n",
    "            measures.loc[age, 'Range'] = range_val\n",
    "            measures.loc[age, 'IQR'] = iqr\n",
    "            measures.loc[age, 'CV'] = cv\n",
    "            measures.loc[age, 'MAD'] = mad\n",
    "            measures.loc[age, 'QD'] = qd\n",
    "        self.variability_measures = measures\n",
    "        return measures\n",
    "\n",
    "    def cohort_analysis_forecast_with_stl(self):\n",
    "        forecast_df = pd.DataFrame()\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            print(f\"age: {age}\")\n",
    "            ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "            # Ensure that the time series has a frequency for the STL decomposition\n",
    "            if not ts.index.inferred_freq:\n",
    "                ts = ts.asfreq('Y')\n",
    "            stl = STL(endog=ts, period=None, seasonal=13)\n",
    "            result = stl.fit()\n",
    "            model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "            fit_model = model.fit()\n",
    "            forecast_value = fit_model.forecast(1).iloc[0]\n",
    "            uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "            forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "            forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "        self.forecast_df = forecast_df\n",
    "        return forecast_df\n",
    "\n",
    "    def visualize_forecast_with_uncertainty(self):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            ts = self.df.xs(age, level='age')['demand']\n",
    "            plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "        for age in self.forecast_df.index:\n",
    "            plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "        for age in self.forecast_df.index:\n",
    "            adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "            plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_variability_measures(self):\n",
    "        # Reset index to use 'age' as a column for the boxplot\n",
    "        df_reset = self.df.reset_index()\n",
    "        \n",
    "        # Check if there are any NaN values in 'age' or 'demand' columns\n",
    "        if df_reset['age'].isnull().any() or df_reset['demand'].isnull().any():\n",
    "            # Drop rows with NaN values in 'age' or 'demand' columns\n",
    "            df_reset = df_reset.dropna(subset=['age', 'demand'])\n",
    "        \n",
    "        # Check if there are enough data points to create a boxplot\n",
    "        if len(df_reset) > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(x='age', y='demand', data=df_reset)\n",
    "            plt.title('Box Plot of Demand by Age')\n",
    "            plt.xlabel('age')\n",
    "            plt.ylabel('Demand')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough data to create a boxplot.\")\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "        plt.title('Histogram of Demand')\n",
    "        plt.xlabel('Demand')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "        plt.title('Violin Plot of Demand by Age')\n",
    "        plt.xlabel('age')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "        std_demand = self.df.groupby('age')['demand'].std()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "        plt.title('Mean Demand with Standard Deviation by Age')\n",
    "        plt.xlabel('age')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "        plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('age')\n",
    "        plt.show()\n",
    "\n",
    "    def apply_uncertainty_to_forecast(self,start_period,end_period,average_annual_receipts,total_annual_donors,annual_donor_demands_age_specific):\n",
    "        # Load additional data\n",
    "        average_annual_receipts = average_annual_receipts\n",
    "        total_annual_donors = total_annual_donors \n",
    "        annual_donor_demands_age_specific = annual_donor_demands_age_specific\n",
    "\n",
    "        # Calculate the ratios\n",
    "        ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "        ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "        # Naive extrapolation for the specified period\n",
    "        forecast_dates = pd.date_range(start=start_period, end=end_period, freq='D')\n",
    "        last_known_value = self.df['demand'].iloc[-1]\n",
    "        forecast_values = pd.Series(last_known_value, index=forecast_dates)\n",
    "\n",
    "        # Apply the ratios to the forecasted values\n",
    "        forecast_with_uncertainty = forecast_values.copy()\n",
    "        for date in forecast_dates:\n",
    "            year = date.year\n",
    "            age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0] if 'age' in self.df.columns else None\n",
    "            ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "            ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "            forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "\n",
    "        # Return the forecast with applied uncertainty\n",
    "        return forecast_with_uncertainty\n",
    "    \n",
    "# Calculate variability measures\n",
    "variability_measures = forecasting.calculate_variability_measures()\n",
    "print(variability_measures)\n",
    "\n",
    "# Perform cohort analysis forecast with STL\n",
    "forecast = forecasting.cohort_analysis_forecast_with_stl()\n",
    "print(forecast)\n",
    "\n",
    "# Visualize the forecast with uncertainty\n",
    "forecasting.visualize_forecast_with_uncertainty()\n",
    "\n",
    "# Visualize variability measures\n",
    "#forecasting.visualize_variability_measures()\n",
    "\n",
    "file_path = 'annual_unique_donors.csv'\n",
    "forecasting = DemandForecasting(file_path)\n",
    "\n",
    "# Apply uncertainty to forecast using naive extrapolation\n",
    "start_period = pd.Timestamp('2024-04-01')\n",
    "end_period = pd.Timestamp('2026-03-31')\n",
    "\n",
    "annual_donor_receipts = pd.read_csv('annual_receipts.csv')\n",
    "average_annual_receipts = annual_donor_receipts.rename(columns={'Yearly Receipt': 'demand'})\n",
    "average_annual_receipts = average_annual_receipts[average_annual_receipts['year'].isin([2020, 2021, 2022, 2023])]\n",
    "average_annual_receipts.set_index('year', inplace=True)\n",
    "#pd.DataFrame({'year': [2022, 2023, 2024],'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_donor_demands = pd.read_csv('annual_unique_donors.csv') #pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "total_annual_donors = annual_donor_demands\n",
    "total_annual_donors = total_annual_donors[total_annual_donors['year'].isin([2020, 2021, 2022, 2023])]\n",
    "total_annual_donors = total_annual_donors.groupby('year')['demand'].sum()\n",
    "\n",
    "annual_donor_demands_age_specific = pd.read_csv('annual_demands_age_specific.csv') #pd.DataFrame({})\n",
    "annual_donor_demands_age_specific = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific)\n",
    "print(forecast_with_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands.xs(18, level='age')['demand'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands['demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.df = pd.read_csv(file_path)\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df = self.df[self.df['year'].isin([2020, 2021, 2022, 2023])]\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             print(f\"age: {age}\")\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "#     def apply_uncertainty_to_forecast(\n",
    "#         self, sarima_order, seasonal_order, start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific):\n",
    "#         # Load additional data\n",
    "#         average_annual_receipts = average_annual_receipts\n",
    "#         total_annual_donors = total_annual_donors \n",
    "#         annual_donor_demands_age_specific = annual_donor_demands_age_specific\n",
    "\n",
    "#         # Calculate the ratios\n",
    "#         ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "#         ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "#         # Fit SARIMA model\n",
    "#         sarima_model = SARIMAX(self.df['demand'], order=sarima_order, seasonal_order=seasonal_order)\n",
    "#         sarima_results = sarima_model.fit()\n",
    "\n",
    "#         # Forecast for the specified period\n",
    "#         #forecast = sarima_results.get_forecast(steps=(end_period - start_period).days)\n",
    "#         forecast_dates = pd.date_range(start=start_period, end=end_period, freq='D')\n",
    "#         forecast = sarima_results.get_forecast(steps=len(forecast_dates))\n",
    "#         forecast_values = forecast.predicted_mean\n",
    "\n",
    "#         # Apply the ratios to the forecasted values\n",
    "#         forecast_with_uncertainty = forecast_values.copy()\n",
    "#         for date in forecast_dates: #forecast_values.index:\n",
    "#             year = date.year\n",
    "#             print(f\"For year: {year}\")\n",
    "#             age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0] if 'age' in self.df.columns else None\n",
    "#             ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#             forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "#             print(f\"\"\"For year: {year}, the ratio_receipts_to_demands is: {ratio_1} \n",
    "#             and the ratio_receipts_to_demands is: {ratio_2}\"\"\")           \n",
    "#             #age = self.df.loc[date, 'age'] if 'age' in self.df.columns else None\n",
    "#             #age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0]\n",
    "#             #ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             #ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].demand #.year\n",
    "#             #ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "\n",
    "#         # Return the forecast with applied uncertainty\n",
    "#         return forecast_with_uncertainty\n",
    "\n",
    "# # Example usage\n",
    "# file_path = 'annual_unique_donors.csv'\n",
    "# forecasting = DemandForecasting(file_path)\n",
    "# sarima_order = (1, 1, 1)\n",
    "# seasonal_order = (1, 1, 1, 12)\n",
    "# start_period = pd.Timestamp('2024-01-01')  #('2024-04-01')\n",
    "# end_period = pd.Timestamp('2026-01-01')\n",
    "# annual_donor_receipts = pd.read_csv('annual_receipts.csv')\n",
    "# average_annual_receipts = annual_donor_receipts.rename(columns={'Yearly Receipt': 'demand'})\n",
    "# average_annual_receipts = average_annual_receipts[average_annual_receipts['year'].isin([2020, 2021, 2022, 2023])]\n",
    "# average_annual_receipts.set_index('year', inplace=True)\n",
    "# #pd.DataFrame({'year': [2022, 2023, 2024],'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "# annual_donor_demands = pd.read_csv('annual_unique_donors.csv') #pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "# total_annual_donors = annual_donor_demands\n",
    "# total_annual_donors = total_annual_donors[total_annual_donors['year'].isin([2020, 2021, 2022, 2023])]\n",
    "# total_annual_donors = total_annual_donors.groupby('year')['demand'].sum()\n",
    "\n",
    "# annual_donor_demands_age_specific = pd.read_csv('annual_demands_age_specific.csv') #pd.DataFrame({})\n",
    "# annual_donor_demands_age_specific = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "# forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(\n",
    "#     sarima_order, seasonal_order, start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific)\n",
    "# print(forecast_with_uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "#ratio_receipts_to_demands.reset_index()\n",
    "#ratio_receipts_to_demands.loc['year']\n",
    "#ratio_receipts_to_demands.reset_index()\n",
    "ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].year #ratio_receipts_to_demands.loc[year]\n",
    "ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].year\n",
    "\n",
    "#ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "#ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_receipts_to_demands.loc[2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start=start_period, end=end_period, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.df = pd.read_csv(file_path)\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "#     def apply_uncertainty_to_forecast(self, sarima_order, seasonal_order, start_period, end_period):\n",
    "#         # Load additional data\n",
    "#         annual_donor_receipts = pd.DataFrame({\n",
    "#             'year': [2022, 2023, 2024],\n",
    "#             'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]\n",
    "#         })\n",
    "#         annual_donor_demands = pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "#         annual_donor_demands_age_specific = pd.DataFrame({\n",
    "#             # Assuming this DataFrame contains the age-specific demand data as shown in the context\n",
    "#         })\n",
    "\n",
    "#         # Calculate the ratios\n",
    "#         ratio_receipts_to_demands = annual_donor_receipts['Yearly Receipt'] / annual_donor_demands\n",
    "#         ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "#         # Fit SARIMA model\n",
    "#         sarima_model = SARIMAX(self.df['demand'], order=sarima_order, seasonal_order=seasonal_order)\n",
    "#         sarima_results = sarima_model.fit()\n",
    "\n",
    "#         # Forecast for the specified period\n",
    "#         forecast = sarima_results.get_forecast(steps=(end_period - start_period).days)\n",
    "#         forecast_values = forecast.predicted_mean\n",
    "\n",
    "#         # Apply the ratios to the forecasted values\n",
    "#         forecast_with_uncertainty = forecast_values.copy()\n",
    "#         for date in forecast_values.index:\n",
    "#             year = date.year\n",
    "#             age = self.df.loc[date, 'age'] if 'age' in self.df.columns else None\n",
    "#             ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#             forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "\n",
    "#         # Return the forecast with applied uncertainty\n",
    "#         return forecast_with_uncertainty\n",
    "\n",
    "# # Example usage\n",
    "# file_path = 'annual_unique_donors.csv'\n",
    "# forecasting = DemandForecasting(file_path)\n",
    "# sarima_order = (1, 1, 1)\n",
    "# seasonal_order = (1, 1, 1, 12)\n",
    "# start_period = pd.Timestamp('2024-04-01')\n",
    "# end_period = pd.Timestamp('2026-03-31')\n",
    "# forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(sarima_order, seasonal_order, start_period, end_period)\n",
    "# print(forecast_with_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explanation\n",
    "# # Class Initialization:\n",
    "# # Loads the dataset and sets up the DataFrame.\n",
    "# # Calculate Variability Measures:\n",
    "# # Computes various measures of variability for each age cohort.\n",
    "# # Cohort Analysis Forecast with STL:\n",
    "# # Applies STL decomposition and Holt-Winters forecasting, adjusting the forecast with the uncertainty ratio.\n",
    "# # Visualize Forecast with Uncertainty:\n",
    "# # Plots the original demand, forecasted demand, and adjusted forecast with uncertainty.\n",
    "# # Visualize Variability Measures:\n",
    "# # Creates various plots (box plot, histogram, violin plot, scatter plot with error bars, and heatmap) to visualize the variability measures.\n",
    "# # You can use this class to load your data, perform the analysis, and visualize the results. Feel free to run the code and let me know if you need any further assistance!\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from statsmodels.tsa.seasonal import STL\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, historical_data):\n",
    "#         self.df = historical_data\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# historical_data = annual_unique_donors\n",
    "# forecasting = DemandForecasting(historical_data)\n",
    "# variability_measures = forecasting.calculate_variability_measures()\n",
    "# forecast = forecasting.cohort_analysis_forecast_with_stl()\n",
    "# forecasting.visualize_forecast_with_uncertainty()\n",
    "# forecasting.visualize_variability_measures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "can you add TSL seasonal forecasting to the code below based on the attched data?\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add TSL seasonal forecasting to the code based on the attached data\n",
    "\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "can you add TSL seasonal forecasting to the code below based on the attched data? def cohort_analysis_forecast(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast(df)\n",
    "print(forecast)\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add TSL seasonal forecasting to the code based on the attached data\n",
    "\n",
    "\n",
    "Sent by Copilot:\n",
    "It looks like there was an issue with the code execution because the dataset does not contain a ‘Date’ column. Let’s adjust the code to add TSL seasonal forecasting based on the data you provided.\n",
    "\n",
    "Here’s the updated code:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has a 'year' column and a 'demand' column\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index('year', inplace=True)\n",
    "\n",
    "# Decompose the time series to observe seasonal patterns\n",
    "decomposition = seasonal_decompose(df['demand'], model='additive', period=1)\n",
    "\n",
    "# Fit the TSL model with seasonal components\n",
    "model = ExponentialSmoothing(df['demand'], trend='add', seasonal='add', seasonal_periods=1)\n",
    "fit_model = model.fit()\n",
    "\n",
    "# Forecast the next period\n",
    "forecast = fit_model.forecast(1)\n",
    "\n",
    "# Add the forecast to the original function\n",
    "def cohort_analysis_forecast(df, forecast_value):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Add the TSL forecast value\n",
    "    forecast_with_uncertainty['TSL_Forecast'] = forecast_value\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "# Call the function and print the forecast with TSL seasonal forecasting\n",
    "forecast_with_tsl = cohort_analysis_forecast(df, forecast.values[0])\n",
    "print(forecast_with_tsl)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code integrates TSL seasonal forecasting into your existing cohort analysis forecast function. It uses the ExponentialSmoothing model from the statsmodels library to forecast the next period based on the seasonal decomposition of the demand data. The forecast value is then incorporated into the final forecast with uncertainty.\n",
    "\n",
    "Feel free to run this code and let me know if you encounter any issues or need further adjustments!\n",
    "\n",
    "Learn more\n",
    "\n",
    "1\n",
    "\n",
    "annual_unique_donors.csv\n",
    "You\n",
    "Sent by you:\n",
    "How can I visualize the forecast results?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "You can visualize the forecast results using various plotting libraries in Python, such as matplotlib or seaborn. Here’s an example of how you can visualize the forecast results using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'forecast_with_tsl' is the DataFrame returned by the cohort_analysis_forecast function\n",
    "# and it includes the 'TSL_Forecast' column\n",
    "\n",
    "def visualize_forecast(df, forecast_with_tsl):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index, df['demand'], label='Original Demand', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    plt.plot(forecast_with_tsl.index, forecast_with_tsl, label='Forecasted Demand', marker='x')\n",
    "    \n",
    "    # Highlight the TSL forecast\n",
    "    plt.axvline(x=forecast_with_tsl.index[-1], color='r', linestyle='--', label='TSL Forecast')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with TSL Seasonal Forecasting')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast(df, forecast_with_tsl)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data and the forecasted demand, with a vertical line highlighting the TSL forecast. You can customize the plot further by adding more details or adjusting the style to suit your needs.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "can you add STL for forecasting time series data forecasting model and adjust and change the above code to ensure that multiplying the forecast value for a specific age in a specific year to be corresponded to the related age and year when choosing age_specific Uncertainty_Ratio to the code below based on the attched data? # Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')                                                                                                         def cohort_analysis_forecast_with_seasonality(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Initialize a DataFrame to store the forecast\n",
    "    forecast_df = pd.DataFrame(index=pivot.index)\n",
    "    \n",
    "    # Loop through each age cohort to apply seasonal decomposition and forecast\n",
    "    for age in pivot.index:\n",
    "        # Get the time series for the current age cohort\n",
    "        ts = pivot.loc[age].dropna()\n",
    "        \n",
    "        # Apply seasonal decomposition\n",
    "        decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
    "        \n",
    "        # Extract the trend and seasonal components\n",
    "        trend = decomposition.trend.dropna()\n",
    "        seasonal = decomposition.seasonal.dropna()\n",
    "        \n",
    "        # Calculate the average growth rate for the trend component\n",
    "        growth_rate = trend.pct_change().mean()\n",
    "        \n",
    "        # Forecast the next year's trend component\n",
    "        last_trend_value = trend.iloc[-1]\n",
    "        forecast_trend = last_trend_value * (1 + growth_rate)\n",
    "        \n",
    "        # Get the seasonal component for the next period (assuming seasonality repeats)\n",
    "        next_seasonal_value = seasonal.iloc[-12 % len(seasonal)]\n",
    "        \n",
    "        # Combine the forecasted trend and seasonal components\n",
    "        forecast_value = forecast_trend * next_seasonal_value\n",
    "        \n",
    "        # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "        uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "        # Store the forecast in the DataFrame\n",
    "        forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "    # Return the forecast DataFrame\n",
    "    return forecast_df\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast_with_seasonality(df)\n",
    "print(forecast)\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add STL for forecasting time series data forecasting model and adjust and change the code to ensure that multiplying the forecast value for a specific age in a specific year to be corresponded to the related age and year when choosing age_specific Uncertainty_Ratio to the code based on the attached data\n",
    "\n",
    "\n",
    "Sent by Copilot:\n",
    "It looks like there was an issue with the code execution because the dataset does not contain a ‘Date’ column. Let’s adjust the code to add STL seasonal forecasting based on the data you provided.\n",
    "\n",
    "Here’s the updated code:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year' and 'age' columns and a 'demand' column\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to apply STL and forecast\n",
    "def cohort_analysis_forecast_with_stl(df):\n",
    "    # Initialize a DataFrame to store the forecast\n",
    "    forecast_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each age cohort to apply STL and forecast\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        # Get the time series for the current age cohort\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Apply STL decomposition\n",
    "        stl = STL(ts, seasonal=13)\n",
    "        result = stl.fit()\n",
    "        \n",
    "        # Forecast the next year's demand using Holt-Winters method\n",
    "        model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "        fit_model = model.fit()\n",
    "        forecast_value = fit_model.forecast(1).iloc[0]\n",
    "        \n",
    "        # Get the corresponding 'Uncertainty_Ratio' for the specific age and year\n",
    "        uncertainty_ratio = df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        \n",
    "        # Multiply the forecast value by the 'Uncertainty_Ratio'\n",
    "        forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "        # Store the forecast in the DataFrame\n",
    "        forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "    # Return the forecast DataFrame\n",
    "    return forecast_df\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast_with_stl(df)\n",
    "print(forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code integrates STL seasonal forecasting into your existing cohort analysis forecast function. It uses the STL decomposition from the statsmodels library to decompose the time series data and then applies the Holt-Winters method for forecasting. The forecast value is then adjusted by the age-specific Uncertainty_Ratio.\n",
    "\n",
    "Feel free to run this code and let me know if you encounter any issues or need further adjustments!\n",
    "\n",
    "Learn more\n",
    "\n",
    "1\n",
    "\n",
    "annual_unique_donors.csv\n",
    "You\n",
    "Sent by you:\n",
    "How can I interpret the forecast results?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Interpreting the forecast results involves understanding the different components and what they represent. Here’s a breakdown of how to interpret the forecast results from the code provided:\n",
    "\n",
    "Original Demand Data:\n",
    "This represents the historical demand data for each age cohort over the years. It’s the baseline data used for forecasting.\n",
    "STL Decomposition:\n",
    "Seasonal Component: This shows the repeating patterns or cycles in the data, such as yearly seasonality.\n",
    "Trend Component: This indicates the long-term progression of the data, showing whether the demand is generally increasing or decreasing over time.\n",
    "Residual Component: This represents the random noise or irregular fluctuations in the data that are not explained by the trend or seasonal components.\n",
    "Forecasted Demand:\n",
    "This is the predicted demand for the next period based on the historical data and the STL decomposition. It combines the trend and seasonal components to project future demand.\n",
    "Uncertainty Ratio:\n",
    "This factor adjusts the forecasted demand to account for uncertainty. It can vary by age and year, reflecting the variability in the data.\n",
    "Forecast with Uncertainty:\n",
    "This is the final forecasted demand after adjusting for uncertainty. It provides a more realistic prediction by incorporating potential variations.\n",
    "Example Interpretation\n",
    "Let’s say you have the following forecast results for a specific age cohort:\n",
    "\n",
    "Original Demand Data: Shows an increasing trend over the past 5 years.\n",
    "Seasonal Component: Indicates higher demand during certain months of the year.\n",
    "Trend Component: Shows a steady upward trend.\n",
    "Residual Component: Contains some random fluctuations but no significant outliers.\n",
    "Forecasted Demand: Predicts an increase in demand for the next year.\n",
    "Uncertainty Ratio: Adjusts the forecast slightly higher due to observed variability.\n",
    "Visualization\n",
    "To visualize these results, you can plot the original demand data, the decomposed components (seasonal, trend, residual), and the forecasted demand. This will help you see how the forecast is derived and how the different components contribute to the final prediction.\n",
    "\n",
    "Here’s an example of how to visualize the forecast results using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast(df, forecast_df):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with STL Seasonal Forecasting')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast(df, forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data and the forecasted demand for each age cohort. You can customize the plot further to highlight specific components or add more details.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How do I interpret the uncertainty ratio?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "The uncertainty ratio is a factor used to adjust the forecasted demand to account for variability and potential errors in the prediction. Here’s how you can interpret it:\n",
    "\n",
    "Understanding the Uncertainty Ratio\n",
    "Purpose:\n",
    "The uncertainty ratio is used to incorporate the inherent uncertainty in the forecast. It adjusts the forecasted values to reflect the possible range of outcomes, considering the variability in the historical data.\n",
    "Calculation:\n",
    "In your code, the uncertainty ratio is calculated as the mean of the ‘Uncertainty_Ratio’ column for each specific age cohort. If this column is not present, a default value of 1 is used, indicating no adjustment.\n",
    "Impact on Forecast:\n",
    "The forecasted demand is multiplied by the uncertainty ratio. If the uncertainty ratio is greater than 1, it increases the forecasted value, indicating higher variability and potential for greater demand. If it is less than 1, it decreases the forecasted value, indicating lower variability and potential for lesser demand.\n",
    "Example Interpretation\n",
    "Let’s say you have a forecasted demand of 100 units for a specific age cohort, and the uncertainty ratio for that cohort is 1.2. The adjusted forecast would be:\n",
    "\n",
    "[ \\text{Adjusted Forecast} = \\text{Forecasted Demand} \\times \\text{Uncertainty Ratio} ] [ \\text{Adjusted Forecast} = 100 \\times 1.2 = 120 ]\n",
    "\n",
    "This means that, considering the variability in the data, the forecasted demand is adjusted to 120 units.\n",
    "\n",
    "Practical Use\n",
    "Higher Uncertainty Ratio: Indicates more variability in the historical data, suggesting that the forecasted demand could be higher than initially predicted.\n",
    "Lower Uncertainty Ratio: Indicates less variability, suggesting that the forecasted demand could be lower or more stable.\n",
    "Visualization\n",
    "To visualize the impact of the uncertainty ratio, you can plot the original forecasted values and the adjusted values side by side. This will help you see how the uncertainty ratio modifies the forecast.\n",
    "\n",
    "Here’s an example of how to visualize this using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast_with_uncertainty(df, forecast_df):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    # Highlight the adjusted forecast with uncertainty\n",
    "    for age in forecast_df.index:\n",
    "        adjusted_forecast = forecast_df.loc[age] * df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "        plt.plot(forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast_with_uncertainty(df, forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data, the forecasted demand, and the adjusted forecast with uncertainty for each age cohort. This visualization helps in understanding how the uncertainty ratio affects the forecasted values.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I calculate the uncertainty ratio for my specific data?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "To calculate the uncertainty ratio for your specific data, you need to quantify the variability or uncertainty in your historical demand data. This can be done using statistical measures such as the standard deviation or variance. Here’s a step-by-step guide on how to calculate the uncertainty ratio:\n",
    "\n",
    "Step-by-Step Guide\n",
    "Load Your Data: Ensure your data is loaded into a DataFrame and properly formatted.\n",
    "Calculate the Standard Deviation: Compute the standard deviation of the demand for each age cohort. The standard deviation measures the amount of variation or dispersion in the data.\n",
    "Calculate the Mean Demand: Compute the mean (average) demand for each age cohort.\n",
    "Calculate the Uncertainty Ratio: The uncertainty ratio can be calculated as the ratio of the standard deviation to the mean demand. This gives a relative measure of variability.\n",
    "Example Code\n",
    "Here’s an example of how you can calculate the uncertainty ratio for each age cohort in your dataset:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Calculate the uncertainty ratio for each age cohort\n",
    "def calculate_uncertainty_ratio(df):\n",
    "    # Initialize a DataFrame to store the uncertainty ratios\n",
    "    uncertainty_ratios = pd.DataFrame()\n",
    "\n",
    "    # Loop through each age cohort\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        # Get the demand time series for the current age cohort\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate the standard deviation and mean demand\n",
    "        std_dev = ts.std()\n",
    "        mean_demand = ts.mean()\n",
    "        \n",
    "        # Calculate the uncertainty ratio\n",
    "        uncertainty_ratio = std_dev / mean_demand if mean_demand != 0 else 0\n",
    "        \n",
    "        # Store the uncertainty ratio in the DataFrame\n",
    "        uncertainty_ratios.loc[age, 'Uncertainty_Ratio'] = uncertainty_ratio\n",
    "    \n",
    "    return uncertainty_ratios\n",
    "\n",
    "# Call the function and print the uncertainty ratios\n",
    "uncertainty_ratios = calculate_uncertainty_ratio(df)\n",
    "print(uncertainty_ratios)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Explanation\n",
    "Standard Deviation (std_dev): Measures the spread of the demand values around the mean. A higher standard deviation indicates more variability.\n",
    "Mean Demand (mean_demand): The average demand for the age cohort.\n",
    "Uncertainty Ratio (uncertainty_ratio): The ratio of the standard deviation to the mean demand. This provides a relative measure of the variability in the demand data.\n",
    "Using the Uncertainty Ratio\n",
    "Once you have calculated the uncertainty ratios, you can use them to adjust your forecasted demand values. This will help you account for the variability in the historical data and provide a more realistic forecast.\n",
    "\n",
    "Feel free to run this code with your data and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I interpret the uncertainty ratio in my specific context?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Interpreting the uncertainty ratio in your specific context involves understanding how it reflects the variability and reliability of your forecasted demand. Here’s a detailed guide to help you interpret it:\n",
    "\n",
    "What the Uncertainty Ratio Represents\n",
    "Variability in Historical Data:\n",
    "The uncertainty ratio is a measure of how much the demand has varied historically for a specific age cohort. A higher ratio indicates more variability, while a lower ratio indicates more stability.\n",
    "Adjustment to Forecast:\n",
    "The ratio adjusts the forecasted demand to account for this variability. It helps in providing a range of possible outcomes rather than a single point estimate, making the forecast more realistic.\n",
    "Interpreting Different Values\n",
    "High Uncertainty Ratio (> 1):\n",
    "Implication: There is significant variability in the historical demand data.\n",
    "Interpretation: The forecasted demand is adjusted upwards to account for potential higher demand. This suggests that the future demand could be more volatile and less predictable.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 1.5, the adjusted forecast would be 150 units.\n",
    "Low Uncertainty Ratio (< 1):\n",
    "Implication: There is less variability in the historical demand data.\n",
    "Interpretation: The forecasted demand is adjusted downwards, indicating more stable and predictable future demand.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 0.8, the adjusted forecast would be 80 units.\n",
    "Uncertainty Ratio = 1:\n",
    "Implication: The variability in the historical data is average or negligible.\n",
    "Interpretation: The forecasted demand remains unchanged, suggesting that the historical data is a good predictor of future demand without significant adjustments.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 1, the adjusted forecast remains 100 units.\n",
    "Practical Application\n",
    "Decision Making: Use the adjusted forecast to make informed decisions about inventory, resource allocation, and planning. A higher uncertainty ratio might prompt you to prepare for a wider range of outcomes.\n",
    "Risk Management: Understand the potential risks associated with high variability. A higher uncertainty ratio indicates a need for contingency plans to handle unexpected changes in demand.\n",
    "Performance Evaluation: Evaluate the performance of your forecasting model by comparing the adjusted forecasts with actual outcomes. This can help in refining the model and improving accuracy.\n",
    "Visualization\n",
    "Visualizing the impact of the uncertainty ratio can help in better understanding its effect on the forecast. Here’s an example of how to visualize the original forecast and the adjusted forecast:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast_with_uncertainty(df, forecast_df, uncertainty_ratios):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    for age in forecast_df.index:\n",
    "        adjusted_forecast = forecast_df.loc[age] * uncertainty_ratios.loc[age, 'Uncertainty_Ratio']\n",
    "        plt.plot(forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'uncertainty_ratios' is the DataFrame containing the calculated uncertainty ratios\n",
    "visualize_forecast_with_uncertainty(df, forecast, uncertainty_ratios)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This visualization will help you see how the uncertainty ratio modifies the forecasted values and provides a clearer picture of potential future demand.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "What other statistical measures can help assess variability?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "In addition to the standard deviation and mean, several other statistical measures can help assess variability in your data. Here are some key measures:\n",
    "\n",
    "1. Variance\n",
    "Definition: Variance is the average of the squared differences from the mean. It provides a measure of how much the data points differ from the mean.\n",
    "Formula:\n",
    "Variance\n",
    "(\n",
    "σ\n",
    "2\n",
    ")\n",
    "=\n",
    "∑\n",
    "(\n",
    "x\n",
    "i\n",
    "−\n",
    "μ\n",
    ")\n",
    "2\n",
    "N\n",
    "Variance(σ2)=N∑(xi​−μ)2​\n",
    "\n",
    "Interpretation: A higher variance indicates more spread out data points.\n",
    "2. Range\n",
    "Definition: The range is the difference between the maximum and minimum values in the dataset.\n",
    "Formula:\n",
    "Range\n",
    "=\n",
    "Max\n",
    "−\n",
    "Min\n",
    "Range=Max−Min\n",
    "\n",
    "Interpretation: A larger range indicates a wider spread of data points.\n",
    "3. Interquartile Range (IQR)\n",
    "Definition: The IQR is the range between the first quartile (Q1) and the third quartile (Q3). It measures the spread of the middle 50% of the data.\n",
    "Formula:\n",
    "IQR\n",
    "=\n",
    "Q\n",
    "3\n",
    "−\n",
    "Q\n",
    "1\n",
    "IQR=Q3−Q1\n",
    "\n",
    "Interpretation: A larger IQR indicates more variability in the middle 50% of the data.\n",
    "4. Coefficient of Variation (CV)\n",
    "Definition: The CV is the ratio of the standard deviation to the mean, expressed as a percentage. It provides a standardized measure of dispersion.\n",
    "Formula:\n",
    "CV\n",
    "=\n",
    "σ\n",
    "μ\n",
    "×\n",
    "100\n",
    "CV=μσ​×100\n",
    "\n",
    "Interpretation: A higher CV indicates greater relative variability.\n",
    "5. Mean Absolute Deviation (MAD)\n",
    "Definition: MAD is the average of the absolute differences between each data point and the mean.\n",
    "Formula:\n",
    "MAD\n",
    "=\n",
    "∑\n",
    "∣\n",
    "x\n",
    "i\n",
    "−\n",
    "μ\n",
    "∣\n",
    "N\n",
    "MAD=N∑∣xi​−μ∣​\n",
    "\n",
    "Interpretation: A higher MAD indicates more variability.\n",
    "6. Quartile Deviation (QD)\n",
    "Definition: QD is half of the IQR and provides a measure of the spread of the middle 50% of the data.\n",
    "Formula:\n",
    "QD\n",
    "=\n",
    "Q\n",
    "3\n",
    "−\n",
    "Q\n",
    "1\n",
    "2\n",
    "QD=2Q3−Q1​\n",
    "\n",
    "Interpretation: A larger QD indicates more variability in the middle 50% of the data.\n",
    "Example Code to Calculate These Measures\n",
    "Here’s an example of how you can calculate these measures using Python:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to calculate variability measures\n",
    "def calculate_variability_measures(df):\n",
    "    variability_measures = pd.DataFrame()\n",
    "\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate measures\n",
    "        std_dev = ts.std()\n",
    "        variance = ts.var()\n",
    "        range_val = ts.max() - ts.min()\n",
    "        iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "        cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "        mad = ts.mad()\n",
    "        qd = iqr / 2\n",
    "        \n",
    "        # Store measures in DataFrame\n",
    "        variability_measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "        variability_measures.loc[age, 'Variance'] = variance\n",
    "        variability_measures.loc[age, 'Range'] = range_val\n",
    "        variability_measures.loc[age, 'IQR'] = iqr\n",
    "        variability_measures.loc[age, 'CV'] = cv\n",
    "        variability_measures.loc[age, 'MAD'] = mad\n",
    "        variability_measures.loc[age, 'QD'] = qd\n",
    "    \n",
    "    return variability_measures\n",
    "\n",
    "# Call the function and print the variability measures\n",
    "variability_measures = calculate_variability_measures(df)\n",
    "print(variability_measures)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Interpretation of Results\n",
    "Standard Deviation and Variance: Indicate the overall spread of the data.\n",
    "Range and IQR: Provide insights into the spread of the data, with IQR focusing on the middle 50%.\n",
    "Coefficient of Variation: Standardizes the measure of dispersion, making it easier to compare across different datasets.\n",
    "Mean Absolute Deviation and Quartile Deviation: Offer alternative measures of variability that are less sensitive to outliers.\n",
    "These measures can help you better understand the variability in your data and make more informed decisions based on the forecasted demand.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I choose the most appropriate variability measure for my specific analysis?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Choosing the most appropriate variability measure for your specific analysis depends on several factors, including the nature of your data, the goals of your analysis, and the specific characteristics you want to capture. Here are some guidelines to help you make an informed decision:\n",
    "\n",
    "1. Nature of the Data\n",
    "Continuous Data: Measures like standard deviation, variance, and coefficient of variation are suitable for continuous data, as they provide insights into the spread and relative variability.\n",
    "Categorical Data: For categorical data, measures like range and interquartile range (IQR) might be more appropriate, as they can highlight the spread of categories.\n",
    "2. Goals of the Analysis\n",
    "Understanding Overall Spread: If your goal is to understand the overall spread of the data, standard deviation and variance are good choices. They provide a comprehensive measure of variability.\n",
    "Comparing Relative Variability: If you need to compare the variability of different datasets or groups, the coefficient of variation (CV) is useful. It standardizes the measure of dispersion, making it easier to compare across different scales.\n",
    "Identifying Outliers: If you are interested in identifying outliers or understanding the spread of the middle 50% of the data, the interquartile range (IQR) and mean absolute deviation (MAD) are helpful.\n",
    "3. Specific Characteristics\n",
    "Sensitivity to Outliers: Standard deviation and variance are sensitive to outliers, which can skew the results. If your data contains outliers, you might prefer measures like IQR or MAD, which are less affected by extreme values.\n",
    "Ease of Interpretation: Some measures are easier to interpret than others. For example, the range is straightforward and easy to understand, while the coefficient of variation provides a relative measure that can be more informative in certain contexts.\n",
    "Practical Examples\n",
    "Standard Deviation and Variance:\n",
    "Use When: You want to understand the overall spread of continuous data.\n",
    "Example: Analyzing the variability in monthly sales figures.\n",
    "Coefficient of Variation (CV):\n",
    "Use When: You need to compare the relative variability of different datasets.\n",
    "Example: Comparing the variability of sales figures across different regions.\n",
    "Interquartile Range (IQR):\n",
    "Use When: You want to focus on the spread of the middle 50% of the data and identify potential outliers.\n",
    "Example: Analyzing the distribution of test scores to identify students who are performing significantly above or below the median.\n",
    "Mean Absolute Deviation (MAD):\n",
    "Use When: You need a measure of variability that is less sensitive to outliers.\n",
    "Example: Assessing the consistency of delivery times for a logistics company.\n",
    "Example Code to Calculate and Compare Measures\n",
    "Here’s an example of how you can calculate and compare different variability measures using Python:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to calculate and compare variability measures\n",
    "def compare_variability_measures(df):\n",
    "    measures = pd.DataFrame()\n",
    "\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate measures\n",
    "        std_dev = ts.std()\n",
    "        variance = ts.var()\n",
    "        range_val = ts.max() - ts.min()\n",
    "        iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "        cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "        mad = ts.mad()\n",
    "        \n",
    "        # Store measures in DataFrame\n",
    "        measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "        measures.loc[age, 'Variance'] = variance\n",
    "        measures.loc[age, 'Range'] = range_val\n",
    "        measures.loc[age, 'IQR'] = iqr\n",
    "        measures.loc[age, 'CV'] = cv\n",
    "        measures.loc[age, 'MAD'] = mad\n",
    "    \n",
    "    return measures\n",
    "\n",
    "# Call the function and print the measures\n",
    "variability_measures = compare_variability_measures(df)\n",
    "print(variability_measures)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Summary\n",
    "Standard Deviation and Variance: Best for understanding overall spread.\n",
    "Coefficient of Variation (CV): Ideal for comparing relative variability.\n",
    "Interquartile Range (IQR) and Mean Absolute Deviation (MAD): Useful for identifying outliers and understanding the spread of the middle 50% of the data.\n",
    "By considering these factors, you can choose the most appropriate variability measure for your specific analysis, ensuring that your insights are accurate and meaningful. If you have any specific questions or need further assistance, feel free to ask!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I visualize different variability measures for better insights?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Visualizing different variability measures can provide a clearer understanding of the data’s spread and help identify patterns or outliers. Here are some common ways to visualize these measures using Python’s matplotlib and seaborn libraries:\n",
    "\n",
    "1. Box Plot\n",
    "A box plot (or whisker plot) is useful for visualizing the distribution of data and highlighting the interquartile range (IQR), median, and potential outliers.\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='age', y='demand', data=df)\n",
    "plt.title('Box Plot of Demand by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "2. Histogram\n",
    "A histogram shows the frequency distribution of the data, which helps in understanding the spread and central tendency.\n",
    "\n",
    "Python\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['demand'], bins=20, kde=True)\n",
    "plt.title('Histogram of Demand')\n",
    "plt.xlabel('Demand')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "3. Violin Plot\n",
    "A violin plot combines aspects of a box plot and a kernel density plot. It shows the distribution of the data across different categories.\n",
    "\n",
    "Python\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='age', y='demand', data=df)\n",
    "plt.title('Violin Plot of Demand by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "4. Scatter Plot with Error Bars\n",
    "A scatter plot with error bars can show the mean demand and the variability (e.g., standard deviation) for each age cohort.\n",
    "\n",
    "Python\n",
    "\n",
    "# Calculate mean and standard deviation for each age cohort\n",
    "mean_demand = df.groupby('age')['demand'].mean()\n",
    "std_demand = df.groupby('age')['demand'].std()\n",
    "\n",
    "# Create a scatter plot with error bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "plt.title('Mean Demand with Standard Deviation by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "5. Heatmap\n",
    "A heatmap can visualize the variability measures across different age cohorts and years.\n",
    "\n",
    "Python\n",
    "\n",
    "# Pivot the data to create a matrix for the heatmap\n",
    "pivot_table = df.pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Summary\n",
    "Box Plot: Visualizes the distribution, IQR, median, and outliers.\n",
    "Histogram: Shows the frequency distribution of the data.\n",
    "Violin Plot: Combines box plot and kernel density plot features.\n",
    "Scatter Plot with Error Bars: Displays mean demand with variability.\n",
    "Heatmap: Visualizes variability measures across different categories.\n",
    "These visualizations can help you gain better insights into the variability of your data and make more informed decisions based on the analysis. Feel free to run these examples with your data and let me know if you need any further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "# Suppress warnings from statsmodels\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def apply_uncertainty_to_forecast(forecast, annual_receipts, annual_demands, age_specific_demands):\n",
    "    # Calculate the annual donor receipt to demand ratio for each year\n",
    "    annual_ratio = annual_receipts['Yearly Receipt'] / annual_demands\n",
    "    \n",
    "    # Calculate the age-specific demands ratio\n",
    "    age_specific_ratio = age_specific_demands.groupby(['year', 'age']).sum().reset_index()\n",
    "    age_specific_ratio['total_demands'] = age_specific_ratio.groupby('year')['demand'].transform('sum')\n",
    "    age_specific_ratio['age_ratio'] = age_specific_ratio['demand'] / age_specific_ratio['total_demands']\n",
    "    \n",
    "    # Create an empty DataFrame to hold the adjusted forecast\n",
    "    adjusted_forecast = pd.DataFrame(columns=['date', 'age', 'adjusted_forecast'])\n",
    "    \n",
    "    # Apply the ratios to the forecasted values\n",
    "    for index, row in forecast.iterrows():\n",
    "        year = row['date'].year\n",
    "        age = row['age']\n",
    "        forecast_value = row['forecast']\n",
    "\n",
    "        # Calculate the adjusted forecast value\n",
    "        if year in annual_ratio.index and year in age_specific_ratio['year'].unique():\n",
    "            age_ratio = age_specific_ratio[(age_specific_ratio['year'] == year) & (age_specific_ratio['age'] == age)]\n",
    "            if not age_ratio.empty:\n",
    "                age_ratio_value = age_ratio['age_ratio'].values[0]\n",
    "            else:\n",
    "                age_ratio_value = 0\n",
    "            adjusted_value = forecast_value * annual_ratio.loc[year] * age_ratio_value\n",
    "        else:\n",
    "            adjusted_value = 0\n",
    "        \n",
    "        # Append the adjusted value to the DataFrame\n",
    "        adjusted_forecast = adjusted_forecast.append({'date': row['date'], 'age': age, 'adjusted_forecast': adjusted_value}, ignore_index=True)\n",
    "    \n",
    "    return adjusted_forecast\n",
    "\n",
    "def forecast_demand_with_sarima(historical_data, steps, seasonal_order=(1,1,1,12)):\n",
    "    # Fit a SARIMA model\n",
    "    model = SARIMAX(historical_data, order=(1,1,1), seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    \n",
    "    # Forecast future values\n",
    "    forecast = model_fit.forecast(steps=steps)\n",
    "    return forecast\n",
    "\n",
    "# Lpa historical data for fitting SARIMA\n",
    "historical_data = pd.Series(np.random.randint(100, 1000, 36), \n",
    "                            index=pd.date_range(start='2021-01-01', periods=36, freq='M'))\n",
    "\n",
    "# Forecast for the next 24 months (2 years)\n",
    "sarima_forecast = forecast_demand_with_sarima(historical_data, steps=24)\n",
    "\n",
    "# Prepare the forecast DataFrame for the next 24 months for ages 18 to 106\n",
    "forecast_dates = pd.date_range(start='2024-04-01', periods=24, freq='M')\n",
    "forecast_ages = np.random.randint(18, 106, 24)\n",
    "forecast_df = pd.DataFrame({'date': forecast_dates, 'age': forecast_ages, 'forecast': sarima_forecast})\n",
    "\n",
    "# Annual receipts and demands DataFrames\n",
    "annual_receipts = annual_donor_receipts  #pd.DataFrame({'year': [2022, 2023, 2024], 'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_demands = annual_donor_demands  #pd.Series({2022: 601254, 2023: 752898, 2024: 505219}, name='unique_key')\n",
    "\n",
    "# Age-specific demands DataFrame\n",
    "age_specific_demands = annual_donor_demands_age_specific #pd.DataFrame({\n",
    "#     'year': [2022, 2022, 2022, 2023, 2023, 2023, 2024, 2024, 2024],\n",
    "#     'age': [18, 19, 20, 18, 19, 20, 18, 19, 20],\n",
    "#     'demand': [199, 286, 192, 249, 345, 243, 122, 267, 196]})\n",
    "\n",
    "# Apply uncertainty to the SARIMA forecast\n",
    "adjusted_forecast = apply_uncertainty_to_forecast(forecast_df, annual_receipts, annual_demands, age_specific_demands)\n",
    "\n",
    "print(adjusted_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def uncertainty_ratio(self, lpa_df_index, month_year):\n",
    "\n",
    "\n",
    "# Estimate the Uncertainty:\n",
    "\n",
    "\n",
    "#covid_impact_ratio = pre_covid_mean_demand / post_covid_mean_demand\n",
    "impact_ratio = filtered_annual_demands / filtered_annual_receipts \n",
    "\n",
    "# Apply the Uncertainty to Future Long-Term Forecasts:\n",
    "# Multiply the future long-term forecasts by the estimated uncertainty to incorporate the impact of the short-term period.\n",
    "\n",
    "print(f\"\"\"The ratio of {impact_ratio} indicates that the short-term demand during COVID \n",
    "        was {impact_ratio * 100}% higher than the long-term average.\"\"\")\n",
    "\n",
    "# # Apply the Uncertainty:\n",
    "# Adjusted_Long-Term_Forecast = Future_Long_Term_Forecast * covid_impact_ratio\n",
    "\n",
    "   \n",
    "# Extract and save data into a csv file\n",
    "lpa_data = monthly_unique_donors.rename(columns={'count': 'demand'})\n",
    "\n",
    "print(lpa_data.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
