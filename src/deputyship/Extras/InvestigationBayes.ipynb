{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pydbtools\n",
    "# !pip install awswrangler\n",
    "# !pip install pandas --upgrade\n",
    "# !pip install time\n",
    "# !pip install numpy --upgrade\n",
    "# !pip install jinja2\n",
    "# !pip install lovely_logger \n",
    "\n",
    "# import pydbtools\n",
    "# import awswrangler as wr\n",
    "# import model_stages.stage1_get_invest_data as stage1\n",
    "# import model_stages.stage2_prepare_invests_for_merging as stage2\n",
    "# import model_stages.stage3_merge_with_POA_data as stage3\n",
    "\n",
    "\n",
    "# ## Config\n",
    "\n",
    "# date_cols = ['date_received_in_investigations', 'date_allocated_to_team',\n",
    "#                   'date_allocated_to_current_investigator', 'pg_sign_off_date',\n",
    "#                   'closure_date',\n",
    "#                   'date_received_in_opg', 'legal_approval_date_clean',\n",
    "#                  'receiptdate', 'registrationdate']\n",
    "\n",
    "# cols_to_keep = ['unique_id', \n",
    "#                 # 'client_donor_title',\n",
    "#                 # 'client_donor_forename', 'client_donor_surname', 'client_donor_dob',\n",
    "#                 'case_type', 'concern_type', 'status', 'sub_status',\n",
    "#                 'date_received_in_opg', 'multiple_id', 'lead_case',\n",
    "#                 'days_to_pg_sign_off', 'closure_date', 'case_uid', 'receiptdate', 'registrationdate',\n",
    "#                 'case_status', 'poa_case_type', 'casesubtype', 'poas_involved',\n",
    "#                 'order_involved', 'legal_approval_date_clean', 'invest_concluded',\n",
    "#                 'year_concluded', 'case_type_agg']\n",
    "# first_date = '01/01/2019'\n",
    "# last_date = '31/12/2024'\n",
    "\n",
    "# min_LPA_receiptdate = '2017-01-01'\n",
    "# max_LPA_receiptdate = '2024-12-31'\n",
    "# sample_size = '1000000'\n",
    "\n",
    "\n",
    "# ## Read/Link Data\n",
    "\n",
    "# # Read Investigations Data\n",
    "# df_inv_data = stage1.main(date_cols, first_date, last_date, cols_to_keep)\n",
    "\n",
    "# # Expand Investigations Data\n",
    "# expanded_df = stage2.main(df_inv_data)\n",
    "\n",
    "# # Link to LPA Data\n",
    "# linked_df = stage3.main(expanded_df, \n",
    "#                         min_LPA_receiptdate, \n",
    "#                         max_LPA_receiptdate, \n",
    "#                         sample_size)\n",
    "\n",
    "# # print(linked_df)\n",
    "\n",
    "# linked_Investigation_LPA_data = linked_df\n",
    "# linked_Investigation_LPA_data.to_csv('linked_Investigation_LPA_data.csv', index=False)\n",
    "\n",
    "# linked_df\n",
    "\n",
    "# inv = linked_df.loc[linked_df['investigator'].notnull()]\n",
    "# inv.to_csv('linked_Investigation_LPA_inv.csv', index=False)\n",
    "\n",
    "# inv_linked_lpa = linked_df[['uid','donor_id','lpa_reg_date','lpa_status','lpa_rec_date','poa_type','unique_id','case_no','client_donor_dob','case_type','concern_type','date_received_in_opg','status','mojap_extract_date','poa_case_type','casesubtype','poa_rec_to_invest_rec','year_concluded','link_id','uid_to_link']]\n",
    "# inv_linked_lpa\n",
    "# inv_linked_lpa_data = inv_linked_lpa\n",
    "# inv_linked_lpa_data.to_csv('inv_linked_lpa_data.csv', index=False)\n",
    "\n",
    "# pydbtools.read_sql_query(\"SELECT DISTINCT(mojap_extract_date) FROM opg_investigations_prod.investigations ORDER BY mojap_extract_date DESC\")\n",
    "# lpa_dashboard = pydbtools.read_sql_query(\"SELECT * FROM sirius_derived.opg_lpa_dashboard LIMIT 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "How to explain the drivers and factors that caused a step reduction in the investigation cases for Lasting Power of Attorney (LPA) demands from Office of Public Guardian (OPG)? To achieve this, basically we linked Investigation and LPA dataset which resulted a data frame in Python with the following variables (columns): linked_df[['uid','donor_id','lpa_reg_date','lpa_status','lpa_rec_date','poa_type','unique_id','case_no','client_donor_dob','case_type','concern_type','date_received_in_opg','status','mojap_extract_date','poa_case_type','casesubtype','poa_rec_to_invest_rec','year_concluded','link_id','uid_to_link']].   Regarding these, can you explain what machine learning and statistical techniques is useful and how to implement them to show 1. How to investigate the age distribution (based on the dob of donor ('client_donor_dob') at the investigation ('date_received_in_opg') changes before and after pandemic that might be the reason for the step reduction in investigation of LPA cases? 2. How to show that different 'casesubtype' and 'case_type' changes influenced this step reduction in the investigation of LPA cases? 3. investigate whether: •\tIt suggests that the downward trend in the investigations rate for Health and Welfare cases or where investigations have included both Health and Welfare AND Property and Finance concerns have been gradual since 2016 rather than a step reduction associated with the pandemic. Having said that the rate of investigations particularly for Health and Welfare cases levelled off after the pandemic.\n",
    "•\tThere isn’t any evidence of a gradual decline in Finance and Property cases, but instead the pattern that we have discussed before of a sustained stepped reduction following the pandemic.\n",
    "•\tThe gradual decline in Health and Welfare and combined concerns from 2016 is interesting because it also coincides with what I believe was an operational decision at that time to remove the triage process for LPA investigations. This had the immediate effect of increasing the number of concerns accepted for investigation, which can be seen in the attached charts, followed by a gradual decline.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "!pip install --upgrade numpy\n",
    "# !pip uninstall numpy\n",
    "# !pip install numpy\n",
    "import numpy as np\n",
    "# print(np.__version__)\n",
    "# print(np.__path__)\n",
    "linked_df = pd.read_csv('inv_linked_lpa_data.csv')\n",
    "linked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "1. Investigating Age Distribution Changes Pre- and Post-Pandemic\n",
    "To check whether changes in donor age at the time of investigation contributed to the reduction:\n",
    "\n",
    "Techniques:\n",
    "Descriptive Statistics & Visualization: Calculate mean, median, and IQR of donor age pre- and post-pandemic.\n",
    "\n",
    "Kernel Density Estimation (KDE) & Histograms: Compare the age distributions before and after the pandemic.\n",
    "\n",
    "Kolmogorov-Smirnov (KS) Test: Check if the distribution of ages significantly changed.\n",
    "\n",
    "Causal Inference (Difference-in-Differences - DiD): Compare the mean age before and after the pandemic with a control period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade scipy matplotlib\n",
    "#!pip install matplotlib\n",
    "# !pip uninstall seaborn\n",
    "# !pip install seaborn\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install --upgrade seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Convert to datetime\n",
    "linked_df['client_donor_dob'] = pd.to_datetime(linked_df['client_donor_dob'],\n",
    "                                               errors='coerce', dayfirst=True)\n",
    "\n",
    "linked_df['date_received_in_opg'] = pd.to_datetime(linked_df['date_received_in_opg'])\n",
    "\n",
    "# Calculate donor age at investigation\n",
    "linked_df['donor_age_at_investigation'] = (linked_df['date_received_in_opg'] - linked_df['client_donor_dob']).dt.days / 365.25\n",
    "\n",
    "# Split pre- and post-pandemic (assuming March 2020 as pandemic start)\n",
    "pre_pandemic = linked_df[linked_df['date_received_in_opg'] < '2020-03-01']\n",
    "post_pandemic = linked_df[linked_df['date_received_in_opg'] >= '2020-03-01']\n",
    "\n",
    "# Plot KDE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(pre_pandemic['donor_age_at_investigation'], label='Pre-Pandemic', shade=True)\n",
    "sns.kdeplot(post_pandemic['donor_age_at_investigation'], label='Post-Pandemic', shade=True)\n",
    "plt.legend()\n",
    "plt.title('Age Distribution of Donors at Investigation')\n",
    "plt.show()\n",
    "\n",
    "# Perform KS test\n",
    "ks_stat, p_value = ks_2samp(pre_pandemic['donor_age_at_investigation'], post_pandemic['donor_age_at_investigation'])\n",
    "print(f\"KS Statistic: {ks_stat}, P-Value: {p_value}\")\n",
    "\n",
    "# If the KS test p-value is low, the distributions are significantly different.\n",
    "\n",
    "# If the post-pandemic mean is significantly lower, \n",
    "# older donors may have been investigated less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "1. Investigating Age Distribution Changes Pre- and Post-Pandemic\n",
    "Refinement: Bayesian Analysis & Causal Inference\n",
    "Rather than just comparing distributions, we can:\n",
    "\n",
    "Use a Bayesian model to estimate how much the mean donor age changed.\n",
    "\n",
    "Apply Causal Impact Analysis (Google’s CausalImpact package) to check if the change was due to the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress warnings from statsmodels\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!pip install --upgrade pymc3\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip uninstall pymc3\n",
    "#!pip install git+https://github.com/pymc-devs/pymc3\n",
    "# !git clone https://github.com/pymc-devs/pymc3\n",
    "# !cd pymc3\n",
    "# !pip install -r requirements.txt\n",
    "# !python setup.py install\n",
    "# !python setup.py develop\n",
    "# !python -m pip install --upgrade pip\n",
    "#!pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A. Bayesian Estimation of Age Differences\n",
    "#!pip install pymc3\n",
    "\n",
    "\n",
    "\n",
    "# Define Bayesian Model\n",
    "with pm.Model():\n",
    "    mu_pre = pm.Normal(\"mu_pre\", mu=70, sigma=10)  # Prior for Pre-Pandemic Age Mean\n",
    "    mu_post = pm.Normal(\"mu_post\", mu=70, sigma=10)  # Prior for Post-Pandemic Age Mean\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "    # Likelihood\n",
    "    age_pre = pm.Normal(\"age_pre\", mu=mu_pre, sigma=sigma, observed=pre_pandemic['donor_age_at_investigation'])\n",
    "    age_post = pm.Normal(\"age_post\", mu=mu_post, sigma=sigma, observed=post_pandemic['donor_age_at_investigation'])\n",
    "\n",
    "    # Difference\n",
    "    diff = pm.Deterministic(\"diff\", mu_post - mu_pre)\n",
    "\n",
    "    trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "# Plot Posterior Distribution of Age Difference\n",
    "az.plot_posterior(trace, var_names=[\"diff\"])\n",
    "\n",
    "# This approach gives a probability distribution of the change in age, rather than a simple p-value.\n",
    "\n",
    "# If most of the posterior distribution is negative, it means donor age at investigation decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B. Causal Impact Analysis\n",
    "\n",
    "from causalimpact import CausalImpact\n",
    "\n",
    "# Convert to time series\n",
    "age_ts = linked_df.groupby('year_received')['donor_age_at_investigation'].mean()\n",
    "\n",
    "# Define pre/post intervention periods\n",
    "pre_period = [0, len(age_ts[age_ts.index < 2020])-1]\n",
    "post_period = [len(age_ts[age_ts.index < 2020]), len(age_ts)-1]\n",
    "\n",
    "# Run Causal Impact\n",
    "impact = CausalImpact(age_ts, pre_period, post_period)\n",
    "impact.plot()\n",
    "print(impact.summary())\n",
    "print(impact.summary(output='report'))\n",
    "\n",
    "# This quantifies the causal effect of the pandemic on donor age at investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "1. Investigating Age Distribution Changes Before and After the Pandemic\n",
    "To investigate how the age distribution of donors at the time of investigation changed before and after the pandemic, you can use the following steps:\n",
    "\n",
    "Techniques:\n",
    "Descriptive Statistics: Calculate summary statistics (mean, median, standard deviation) for the age of donors before and after the pandemic.\n",
    "Visualization: Use histograms, box plots, and density plots to visualize the age distribution.\n",
    "Hypothesis Testing: Perform statistical tests (e.g., t-test, Mann-Whitney U test) to determine if there are significant differences in age distribution before and after the pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Assuming linked_df is your DataFrame\n",
    "linked_df['age_at_investigation'] = (pd.to_datetime(linked_df['date_received_in_opg']) - pd.to_datetime(linked_df['client_donor_dob'])).dt.days / 365.25\n",
    "\n",
    "# Split data into before and after pandemic\n",
    "before_pandemic = linked_df[linked_df['date_received_in_opg'] < '2020-03-01']\n",
    "after_pandemic = linked_df[linked_df['date_received_in_opg'] >= '2020-03-01']\n",
    "\n",
    "# Descriptive statistics\n",
    "print(before_pandemic['age_at_investigation'].describe())\n",
    "print(after_pandemic['age_at_investigation'].describe())\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(before_pandemic['age_at_investigation'], color='blue', label='Before Pandemic', kde=True)\n",
    "sns.histplot(after_pandemic['age_at_investigation'], color='red', label='After Pandemic', kde=True)\n",
    "plt.legend()\n",
    "plt.title('Age Distribution of Donors at Investigation')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Hypothesis testing\n",
    "t_stat, p_value = ttest_ind(before_pandemic['age_at_investigation'], after_pandemic['age_at_investigation'])\n",
    "print(f'T-test: t_stat={t_stat}, p_value={p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "2. Analysing Changes in Case Types (‘casesubtype’ and ‘case_type’)\n",
    "To assess whether shifts in case types contributed to the reduction:\n",
    "\n",
    "Techniques:\n",
    "Time Series Analysis: Visualizing case types over time.\n",
    "\n",
    "Chi-Square Test: Checking if case distributions changed pre- and post-pandemic.\n",
    "\n",
    "Logistic Regression: Predicting investigation likelihood based on case type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Aggregate case types by year\n",
    "linked_df['year_received'] = linked_df['date_received_in_opg'].dt.year\n",
    "case_type_counts = linked_df.groupby(['year_received', 'case_type']).size().unstack()\n",
    "\n",
    "# Plot trends\n",
    "case_type_counts.plot(kind='line', figsize=(10,5), title=\"Case Type Trends Over Time\")\n",
    "plt.show()\n",
    "\n",
    "# Chi-square test\n",
    "pre_post_pivot = linked_df.pivot_table(index='case_type', columns=linked_df['date_received_in_opg'] >= '2020-03-01', aggfunc='size', fill_value=0)\n",
    "chi2, p, dof, ex = chi2_contingency(pre_post_pivot)\n",
    "print(f\"Chi-Square Statistic: {chi2}, P-Value: {p}\")\n",
    "\n",
    "# Logistic Regression - Predicting Investigation Likelihood\n",
    "linked_df['post_pandemic'] = linked_df['date_received_in_opg'] >= '2020-03-01'\n",
    "model = smf.logit(\"post_pandemic ~ C(case_type) + C(casesubtype)\", data=linked_df).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# If chi-square p-value is low, case type proportions changed.\n",
    "\n",
    "# Logistic regression shows which case types were more/less likely to be investigated post-pandemic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "2. Analyzing Changes in Case Types (‘casesubtype’ and ‘case_type’)\n",
    "Refinement: NLP & Clustering\n",
    "If there are text-based ‘concern_type’ descriptions, we can use NLP-based topic modeling to group similar concerns over time.\n",
    "\n",
    "Clustering (K-Means, DBSCAN) can group case subtypes to reveal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A. Topic Modeling for Case Subtypes\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Convert case types into TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(linked_df['casesubtype'].astype(str))\n",
    "\n",
    "# Apply LDA\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "topics = lda.fit_transform(X)\n",
    "\n",
    "# Display top words in each topic\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {i}: {[vectorizer.get_feature_names_out()[j] for j in topic.argsort()[-5:]]}\")\n",
    "\n",
    "# Helps identify case subtype patterns that may have changed pre/post-pandemic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B. Clustering Subtypes Over Time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Convert categorical case subtypes into numeric representations\n",
    "linked_df['casesubtype_encoded'] = linked_df['casesubtype'].astype('category').cat.codes\n",
    "\n",
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "linked_df['cluster'] = kmeans.fit_predict(linked_df[['casesubtype_encoded', 'year_received']])\n",
    "\n",
    "# Visualize Changes in Clusters Over Time\n",
    "sns.lineplot(data=linked_df, x='year_received', y='cluster', hue='casesubtype', marker='o')\n",
    "plt.title('Case Subtype Clustering Over Time')\n",
    "plt.show()\n",
    "\n",
    "# If certain clusters disappear or emerge post-pandemic, they could explain the step reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "2. Showing Influence of 'casesubtype' and 'case_type' Changes\n",
    "To show how different 'casesubtype' and 'case_type' changes influenced the step reduction in investigation cases, you can use:\n",
    "\n",
    "Techniques:\n",
    "Categorical Analysis: Analyze the frequency and distribution of different case subtypes and types before and after the pandemic.\n",
    "Chi-Square Test: Perform chi-square tests to determine if there are significant differences in the distribution of case subtypes and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Frequency distribution\n",
    "case_subtype_counts_before = before_pandemic['casesubtype'].value_counts()\n",
    "case_subtype_counts_after = after_pandemic['casesubtype'].value_counts()\n",
    "\n",
    "case_type_counts_before = before_pandemic['case_type'].value_counts()\n",
    "case_type_counts_after = after_pandemic['case_type'].value_counts()\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=case_subtype_counts_before.index, y=case_subtype_counts_before.values, color='blue', label='Before Pandemic')\n",
    "sns.barplot(x=case_subtype_counts_after.index, y=case_subtype_counts_after.values, color='red', label='After Pandemic')\n",
    "plt.legend()\n",
    "plt.title('Case Subtype Distribution Before and After Pandemic')\n",
    "plt.xlabel('Case Subtype')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=case_type_counts_before.index, y=case_type_counts_before.values, color='blue', label='Before Pandemic')\n",
    "sns.barplot(x=case_type_counts_after.index, y=case_type_counts_after.values, color='red', label='After Pandemic')\n",
    "plt.legend()\n",
    "plt.title('Case Type Distribution Before and After Pandemic')\n",
    "plt.xlabel('Case Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Chi-square test\n",
    "contingency_table_subtype = pd.crosstab(linked_df['casesubtype'], linked_df['date_received_in_opg'] >= '2020-03-01')\n",
    "chi2_stat_subtype, p_val_subtype, dof_subtype, ex_subtype = chi2_contingency(contingency_table_subtype)\n",
    "print(f'Chi-square test for case subtype: chi2_stat={chi2_stat_subtype}, p_value={p_val_subtype}')\n",
    "\n",
    "contingency_table_type = pd.crosstab(linked_df['case_type'], linked_df['date_received_in_opg'] >= '2020-03-01')\n",
    "chi2_stat_type, p_val_type, dof_type, ex_type = chi2_contingency(contingency_table_type)\n",
    "print(f'Chi-square test for case type: chi2_stat={chi2_stat_type}, p_value={p_val_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "3. Investigating Gradual vs. Step Decline in Investigation Cases (2016 Onwards)\n",
    "To determine if the decline was gradual (since 2016) or a sharp step drop post-pandemic:\n",
    "\n",
    "Techniques:\n",
    "Time Series Decomposition: Breaking down long-term trends and seasonality.\n",
    "\n",
    "Change Point Detection: Identifying structural breaks in investigation rates.\n",
    "\n",
    "Interrupted Time Series Analysis (ITSA): Evaluating the impact of pandemic on investigation trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import ruptures as rpt\n",
    "\n",
    "# Aggregate investigation counts by year\n",
    "investigations_by_year = linked_df.groupby('year_received').size()\n",
    "\n",
    "# Time Series Decomposition\n",
    "decomposed = seasonal_decompose(investigations_by_year, model='additive', period=1)\n",
    "decomposed.plot()\n",
    "plt.show()\n",
    "\n",
    "# Change Point Detection\n",
    "algo = rpt.Pelt(model=\"rbf\").fit(investigations_by_year.values.reshape(-1, 1))\n",
    "breakpoints = algo.predict(pen=10)\n",
    "print(\"Change Points Detected at Years:\", [list(investigations_by_year.index)[bp] for bp in breakpoints[:-1]])\n",
    "\n",
    "# ITSA - Comparing Pre/Post Pandemic Trends\n",
    "linked_df['post_pandemic'] = (linked_df['year_received'] >= 2020).astype(int)\n",
    "model = smf.ols(\"casesubtype ~ year_received + post_pandemic\", data=linked_df).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Change point detection helps confirm whether the drop was gradual or sudden.\n",
    "\n",
    "# ITSA helps quantify the impact of the pandemic on investigation trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Findings to Look for:\n",
    "Age Analysis: If older donors were investigated less post-pandemic, it may explain some of the decline.\n",
    "\n",
    "Case Type Shifts: A significant drop in certain cases (e.g., Health & Welfare) might suggest policy changes.\n",
    "\n",
    "Trend Analysis: If Finance & Property cases show a step decline while Health & Welfare cases decline gradually, it supports the operational decision hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "3. Investigating Gradual vs. Step Decline in Investigation Cases (2016 Onwards)\n",
    "Refinement: Structural Breaks & Granger Causality\n",
    "To determine if the step reduction aligns with operational decisions, we can:\n",
    "\n",
    "Detect breakpoints in investigation rates using Bayesian Change Point Detection.\n",
    "\n",
    "Apply Granger Causality to test whether operational changes caused case volume reductions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Bayesian Change Point Detection\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "# Convert investigation counts to numpy array\n",
    "y = investigations_by_year.values\n",
    "\n",
    "# Define Model\n",
    "with pm.Model():\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=len(y)-1)\n",
    "    mu1 = pm.Normal(\"mu1\", mu=np.mean(y[:len(y)//2]), sigma=np.std(y))\n",
    "    mu2 = pm.Normal(\"mu2\", mu=np.mean(y[len(y)//2:]), sigma=np.std(y))\n",
    "    \n",
    "    # Likelihood\n",
    "    idx = np.arange(len(y))\n",
    "    mu = pm.math.switch(tau > idx, mu1, mu2)\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=np.std(y), observed=y)\n",
    "\n",
    "    trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "# Plot Posterior Distribution of Breakpoint\n",
    "az.plot_posterior(trace, var_names=[\"tau\"])\n",
    "\n",
    "# If the posterior distribution of tau (change point) aligns with 2016 or the pandemic, it suggests a structural change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Granger Causality for Triage Removal vs. Investigation Decline\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Creating a DataFrame with lagged operational decisions\n",
    "df_granger = linked_df[['year_received', 'case_type']].pivot_table(index='year_received', columns='case_type', aggfunc='size', fill_value=0)\n",
    "df_granger['triage_removed'] = (df_granger.index >= 2016).astype(int)\n",
    "\n",
    "# Running Granger Causality Test\n",
    "grangercausalitytests(df_granger[['case_type', 'triage_removed']], maxlag=5)\n",
    "\n",
    "# If triage removal Granger-causes the decline in investigations, we have strong causal evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "3. Investigating Trends in Investigation Rates\n",
    "To investigate trends in investigation rates for different case types and subtypes, you can use:\n",
    "\n",
    "Techniques:\n",
    "Time Series Analysis: Analyze the trends over time using line plots and statistical tests.\n",
    "Regression Analysis: Use regression models to identify trends and changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Group by year and case type/subtype\n",
    "yearly_counts = linked_df.groupby(['year_concluded', 'case_type']).size().unstack().fillna(0)\n",
    "yearly_counts_subtype = linked_df.groupby(['year_concluded', 'casesubtype']).size().unstack().fillna(0)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "yearly_counts.plot(kind='line', marker='o')\n",
    "plt.title('Yearly Investigation Counts by Case Type')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Investigations')\n",
    "plt.legend(title='Case Type')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "yearly_counts_subtype.plot(kind='line', marker='o')\n",
    "plt.title('Yearly Investigation Counts by Case Subtype')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Investigations')\n",
    "plt.legend(title='Case Subtype')\n",
    "plt.show()\n",
    "\n",
    "# Time series decomposition\n",
    "for case_type in yearly_counts.columns:\n",
    "    result = seasonal_decompose(yearly_counts[case_type], model='additive', period=1)\n",
    "    result.plot()\n",
    "    plt.title(f'Time Series Decomposition for {case_type}')\n",
    "    plt.show()\n",
    "\n",
    "# Regression analysis\n",
    "\n",
    "X = yearly_counts.index.values.reshape(-1, 1)\n",
    "for case_type in yearly_counts.columns:\n",
    "    y = yearly_counts[case_type].values\n",
    "    model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "    print(f'Regression analysis for {case_type}:')\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Next Steps\n",
    "Deep Dive into Outliers\n",
    "\n",
    "If we find an anomaly in 2016 or 2020, investigate if it aligns with internal reports or policy changes.\n",
    "\n",
    "Interactive Dashboards\n",
    "\n",
    "Use Plotly or Dash to create an interactive visualization for stakeholders.\n",
    "\n",
    "Predictive Modeling for Future Investigations\n",
    "\n",
    "Use XGBoost or Random Forest to predict the number of investigations based on past trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "A dashboard will help OPG stakeholders visualize the trends, analyze case distributions, and interactively explore insights. I'll create a Plotly Dash application that includes:\n",
    "\n",
    "Age Distribution Analysis – A histogram/KDE plot comparing pre- and post-pandemic donor ages.\n",
    "\n",
    "Case Type Trends Over Time – A time-series line chart showing case subtypes from 2016 onward.\n",
    "\n",
    "Investigation Volume & Structural Changes – A bar chart with annotations marking key events (e.g., triage removal in 2016, pandemic in 2020).\n",
    "\n",
    "Case Type Breakdown (Pie Chart) – To compare case distributions over different periods.\n",
    "\n",
    "Changepoint Detection & Forecasting – Structural break analysis visualized dynamically.\n",
    "\n",
    "This Plotly Dash app provides an interactive dashboard for OPG stakeholders to explore:\n",
    "\n",
    "Donor Age Distribution before and after the pandemic.\n",
    "\n",
    "Case Type Trends Over Time (line chart).\n",
    "\n",
    "Investigation Volume Changes with key events like triage removal in 2016.\n",
    "\n",
    "Case Type Breakdown (pie chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess data\n",
    "linked_df['date_received_in_opg'] = pd.to_datetime(linked_df['date_received_in_opg'])\n",
    "linked_df['year_received'] = linked_df['date_received_in_opg'].dt.year\n",
    "linked_df['donor_age'] = (linked_df['date_received_in_opg'] - pd.to_datetime(linked_df['client_donor_dob'])).dt.days / 365.25\n",
    "\n",
    "# Aggregate data\n",
    "case_type_trend = linked_df.groupby(['year_received', 'case_type']).size().reset_index(name='count')\n",
    "\n",
    "# Dash App\n",
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"OPG Investigation Dashboard\"),\n",
    "    \n",
    "    # Age Distribution Comparison\n",
    "    dcc.Graph(\n",
    "        figure=px.histogram(linked_df, x='donor_age', color=(linked_df['year_received'] >= 2020),\n",
    "                            nbins=50, title=\"Donor Age Distribution: Pre vs. Post Pandemic\")\n",
    "    ),\n",
    "    \n",
    "    # Case Type Trends\n",
    "    dcc.Graph(\n",
    "        figure=px.line(case_type_trend, x='year_received', y='count', color='case_type',\n",
    "                       title=\"Trends in Case Types Over Time\")\n",
    "    ),\n",
    "    \n",
    "    # Investigation Volume with Key Events\n",
    "    dcc.Graph(\n",
    "        figure=px.bar(linked_df.groupby('year_received').size().reset_index(name='count'), x='year_received', y='count',\n",
    "                      title=\"Annual Investigation Volume\").add_vline(x=2016, line_dash='dash', annotation_text='Triage Removed')\n",
    "    ),\n",
    "    \n",
    "    # Case Type Breakdown (Pie Chart)\n",
    "    dcc.Graph(\n",
    "        figure=px.pie(linked_df, names='case_type', title=\"Case Type Distribution\")\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "additional features, such as changepoint detection visualizations or predictive modeling? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
