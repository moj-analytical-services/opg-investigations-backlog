{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "\n",
    "!pip install xlsxwriter\n",
    "import xlsxwriter\n",
    "#from scipy.stats import kstest, probplot\n",
    "\n",
    "#import pymc as pm\n",
    "#import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------Step 1: DataHandler Class-------------------- ##\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, bucket_name, folder_path):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.folder_path = folder_path\n",
    "        self.s3_client = boto3.client('s3')\n",
    "        self.selected_columns = [\"receiptdate\", \"cases_glueexporteddate\", \"uid\", \"type\", \"casesubtype\", \"status\", \"donor_dob\", \"donor_postcode\", \"donor_gender\"]\n",
    "        self.combined_df = None\n",
    "        self.snapshot_start = '2021-12-31'#'2006-12-31'\n",
    "        self.snapshot_end = None #'2023-12-31' #\n",
    "\n",
    "    def list_files(self):\n",
    "        response = self.s3_client.list_objects_v2(Bucket=self.bucket_name, Prefix=self.folder_path)\n",
    "        file_keys = [obj['Key'] for obj in response.get('Contents', [])]\n",
    "        non_none_file_keys = [key for key in file_keys if key is not None]\n",
    "        file_names = [os.path.basename(key) for key in non_none_file_keys]\n",
    "        csv_extension = '.csv'\n",
    "        filtered_file_names = [fn for fn in file_names if fn.lower().endswith(csv_extension)]\n",
    "        return filtered_file_names\n",
    "\n",
    "    def read_csv_files(self, file_names):\n",
    "        dfs = {}\n",
    "        for file_name in file_names:\n",
    "            s3_path = f's3://{self.bucket_name}/{file_name}'\n",
    "            try:\n",
    "                csv_obj = self.s3_client.get_object(Bucket=self.bucket_name, Key=f'{self.folder_path}/{file_name}')\n",
    "                csv_string = csv_obj['Body'].read().decode('utf-8')\n",
    "                df = pd.read_csv(StringIO(csv_string))\n",
    "                df_selected = df[self.selected_columns]\n",
    "                dfs[file_name] = df_selected\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_name}: {e}\")\n",
    "        return dfs\n",
    "\n",
    "    def concatenate_dataframes(self, dataframes):\n",
    "        self.combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "\n",
    "    def set_dates(self, start_date=None, end_date=None):\n",
    "        self.snapshot_start = start_date if start_date else '2021-12-31' \n",
    "        if end_date:\n",
    "            self.snapshot_end = end_date\n",
    "        else:\n",
    "            first_csv_file_name = self.list_files()[1]\n",
    "            self.snapshot_end = first_csv_file_name.split('opg-analytical_cases_P')[1].lstrip().split('_S')[0] #'2023-12-31' # \n",
    "\n",
    "## -------------------\n",
    "\n",
    "# Enter the corresponding S3 bucket name\n",
    "bucketName = \"alpha-opg-analytical\"\n",
    "\n",
    "# Select the corresponding folder includes new LPA data in S3 bucket:\n",
    "folderPath = \"sirius_data_cuts_3\"\n",
    "\n",
    "# Instantiate the DataHandler\n",
    "data_handler = DataHandler(bucket_name=bucketName, folder_path=folderPath)\n",
    "file_names = data_handler.list_files()\n",
    "dataframes = data_handler.read_csv_files(file_names)\n",
    "data_handler.concatenate_dataframes(dataframes)\n",
    "data_handler.set_dates()\n",
    "\n",
    "\n",
    "print(data_handler.combined_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, combined_df, snapshot_start, snapshot_end):\n",
    "        self.combined_df = combined_df\n",
    "        self.snapshot_start = snapshot_start\n",
    "        self.snapshot_end = snapshot_end\n",
    "        self.lpa_data_sample_imputed = None\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        df_filtered = self.combined_df\n",
    "        df_filtered['receiptdate'] = pd.to_datetime(df_filtered['receiptdate'], errors='coerce')\n",
    "        df_filtered = df_filtered.loc[(df_filtered['receiptdate'] > pd.to_datetime(self.snapshot_start))]\n",
    "        df_filtered = df_filtered.loc[(df_filtered['receiptdate'] < pd.to_datetime(self.snapshot_end))]\n",
    "        df_filtered = df_filtered.loc[(df_filtered['type'] == 'lpa')]\n",
    "        df = df_filtered[[\"receiptdate\", \"uid\", \"casesubtype\", \"status\", \"donor_dob\", \"donor_postcode\", \"donor_gender\"]]\n",
    "        lpa_df = df.dropna()\n",
    "        lpa_df['age'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce').dt.year - pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.year\n",
    "        lpa_df['donor_dob'] = pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.date\n",
    "        lpa_df['receiptdate'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce')\n",
    "        lpa_df['year'] = lpa_df['receiptdate'].dt.year\n",
    "        lpa_data_sample_imputed = lpa_df\n",
    "\n",
    "        criteria = lpa_data_sample_imputed[(lpa_data_sample_imputed['age'] < 0) | (lpa_data_sample_imputed['age'] > 126)]\n",
    "        lpa_data_sample_imputed.loc[criteria.index, 'age'] = np.nan\n",
    "\n",
    "        most_common_age = lpa_data_sample_imputed.groupby('year')['age'].apply(lambda x: x.mode().iloc[0])\n",
    "        lpa_data_sample_imputed['age'] = lpa_data_sample_imputed.apply(lambda row: most_common_age[row['year']] if pd.isna(row['age']) else row['age'], axis=1)\n",
    "\n",
    "        # Ensure all ages from 18 to 106 are present\n",
    "        all_ages = pd.DataFrame({'age': range(18, 107)})\n",
    "        lpa_data_sample_imputed = lpa_data_sample_imputed.merge(all_ages, on='age', how='right')\n",
    "\n",
    "        # Impute missing values in all columns based on the distribution of that particular age in previous years\n",
    "        for column in lpa_data_sample_imputed.columns:\n",
    "            if column not in ['age', 'year']:\n",
    "                lpa_data_sample_imputed[column] = lpa_data_sample_imputed.groupby('age')[column].transform(lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else x.mean()))\n",
    "\n",
    "        self.lpa_data_sample_imputed = lpa_data_sample_imputed\n",
    "\n",
    "    def calculate_annual_receipts(self):\n",
    "        df = self.lpa_data_sample_imputed\n",
    "\n",
    "        def count_working_days(year):\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-31'\n",
    "            date_range = pd.date_range(start_date, end_date, freq='B')\n",
    "            return len(date_range)\n",
    "\n",
    "        results = {\n",
    "            'year': [],\n",
    "            'Average Daily Reciept': [],\n",
    "            'Yearly Receipt': [],\n",
    "            'Standard Deviation Daily Reciept': [],\n",
    "            'Yearly Standard Deviation': []\n",
    "        }\n",
    "\n",
    "        for year in df['year'].unique():\n",
    "            df_year = df[df['year'] == year]\n",
    "            daily_reciept = df_year.groupby('receiptdate').size()\n",
    "            average_daily_reciept = daily_reciept.mean()\n",
    "            std_dev_daily_reciept = daily_reciept.std()\n",
    "            working_days = count_working_days(year)\n",
    "            yearly_reciept = average_daily_reciept * working_days\n",
    "            yearly_std_dev = average_daily_reciept * working_days\n",
    "\n",
    "            results['year'].append(year)\n",
    "            results['Average Daily Reciept'].append(average_daily_reciept)\n",
    "            results['Yearly Receipt'].append(yearly_reciept)\n",
    "            results['Standard Deviation Daily Reciept'].append(std_dev_daily_reciept)\n",
    "            results['Yearly Standard Deviation'].append(yearly_std_dev)\n",
    "\n",
    "        annual_receipts = pd.DataFrame(results)\n",
    "        annual_receipts = annual_receipts.sort_values(by=['year'])\n",
    "\n",
    "        return annual_receipts\n",
    "\n",
    "    def create_unique_identifier(self):\n",
    "        lpa_unique = self.lpa_data_sample_imputed\n",
    "        lpa_unique['donor_postcode'] = lpa_unique['donor_postcode'].str.strip().str.replace(' ', '')\n",
    "        lpa_unique['unique_key'] = lpa_unique['donor_dob'].astype(str) + lpa_unique['donor_gender'] + lpa_unique['donor_postcode']\n",
    "\n",
    "        duplicate_mask = lpa_unique.duplicated('unique_key', keep=False)\n",
    "        lpa_unique = pd.concat([lpa_unique.loc[duplicate_mask & lpa_unique[['age', 'donor_gender', 'donor_postcode']].ne(0).any(axis=1)], \n",
    "                                lpa_unique[~duplicate_mask]])\n",
    "\n",
    "        lpa_unique['month_year'] = lpa_unique['receiptdate'].dt.strftime('%b-%y')\n",
    "        lpa_unique = lpa_unique.sort_values(by=['receiptdate'])\n",
    "        return lpa_unique\n",
    "\n",
    "    def calculate_unique_donors_per_year(self, lpa_df_index):\n",
    "        lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "        annual_unique_donors = lpa_df_index.groupby(['year', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        annual_unique_donors = annual_unique_donors.sort_values(by=['year', 'age'])\n",
    "        return annual_unique_donors\n",
    "\n",
    "    def calculate_unique_donors_count_monthly(self, lpa_df_index):\n",
    "        lpa_df_no_index = lpa_df_index.reset_index()\n",
    "        lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "        monthly_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        monthly_unique_donors = monthly_unique_donors.sort_values(by=['year', 'month', 'donor_gender', 'age'])\n",
    "        return monthly_unique_donors\n",
    "\n",
    "    def calculate_unique_donors_per_day(self, lpa_df_index):     \n",
    "        lpa_df_no_index = lpa_df_index.reset_index()\n",
    "        lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "        lpa_df_no_index['day'] = lpa_df_no_index['receiptdate'].dt.day\n",
    "        daily_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'day', 'receiptdate', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        daily_unique_donors = daily_unique_donors.sort_values(by=['receiptdate', 'year', 'month', 'day', 'donor_gender', 'age'])\n",
    "        return daily_unique_donors    \n",
    "    \n",
    "    def calculate_unique_donors_age_specific(self, lpa_df_index):\n",
    "       #lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "        annual_unique_donors_age_specific = lpa_df_index.groupby(['year', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "        annual_unique_donors_age_specific = annual_unique_donors_age_specific.sort_values(by=['year', 'age'])\n",
    "        return annual_unique_donors_age_specific\n",
    "        \n",
    "    def calculate_unique_donors_count_daily(self, lpa_df_index):\n",
    "        #daily_unique_donors = lpa_df_index.groupby(['year'])['unique_key'].nunique().reset_index(name='count')\n",
    "        #daily_unique_donors = daily_unique_donors.sort_values(by=['year'])\n",
    "        # Group by 'year' and count unique 'unique_id'\n",
    "        annual_unique_counts = lpa_df_index.groupby(lpa_df_index['year'])['unique_key'].nunique()    \n",
    "        return annual_unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ------------------Step 2: DataPreprocessor Class-------------------- ##\n",
    "\n",
    "# class DataPreprocessor:\n",
    "#     def __init__(self, combined_df, snapshot_start, snapshot_end):\n",
    "#         self.combined_df = combined_df\n",
    "#         self.snapshot_start = snapshot_start\n",
    "#         self.snapshot_end = snapshot_end\n",
    "#         self.lpa_data_sample_imputed = None\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         df_filtered = self.combined_df\n",
    "#         df_filtered['receiptdate'] = pd.to_datetime(df_filtered['receiptdate'], errors='coerce')\n",
    "#         df_filtered = df_filtered.loc[(df_filtered['receiptdate'] > pd.to_datetime(self.snapshot_start))]\n",
    "#         df_filtered = df_filtered.loc[(df_filtered['receiptdate'] < pd.to_datetime(self.snapshot_end))]\n",
    "#         df_filtered = df_filtered.loc[(df_filtered['type'] == 'lpa')]\n",
    "#         df = df_filtered[[\"receiptdate\", \"uid\", \"casesubtype\", \"status\", \"donor_dob\", \"donor_postcode\", \"donor_gender\"]]\n",
    "#         lpa_df = df.dropna()\n",
    "#         lpa_df['age'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce').dt.year - pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.year\n",
    "#         lpa_df['donor_dob'] = pd.to_datetime(lpa_df['donor_dob'], errors='coerce').dt.date\n",
    "#         lpa_df['receiptdate'] = pd.to_datetime(lpa_df['receiptdate'], errors='coerce')\n",
    "#         lpa_df['year'] = lpa_df['receiptdate'].dt.year\n",
    "#         lpa_data_sample_imputed = lpa_df\n",
    "\n",
    "#         criteria = lpa_data_sample_imputed[(lpa_data_sample_imputed['age'] < 0) | (lpa_data_sample_imputed['age'] > 126)]\n",
    "#         lpa_data_sample_imputed.loc[criteria.index, 'age'] = np.nan\n",
    "\n",
    "#         most_common_age = lpa_data_sample_imputed.groupby('year')['age'].apply(lambda x: x.mode().iloc[0])\n",
    "#         lpa_data_sample_imputed['age'] = lpa_data_sample_imputed.apply(lambda row: most_common_age[row['year']] if pd.isna(row['age']) else row['age'], axis=1)\n",
    "\n",
    "#         self.lpa_data_sample_imputed = lpa_data_sample_imputed\n",
    "\n",
    "#     def calculate_annual_receipts(self):\n",
    "#         df = self.lpa_data_sample_imputed\n",
    "\n",
    "#         def count_working_days(year):\n",
    "#             start_date = f'{year}-01-01'\n",
    "#             end_date = f'{year}-12-31'\n",
    "#             date_range = pd.date_range(start_date, end_date, freq='B')\n",
    "#             return len(date_range)\n",
    "\n",
    "#         results = {\n",
    "#             'year': [],\n",
    "#             'Average Daily Reciept': [],\n",
    "#             'Yearly Receipt': [],\n",
    "#             'Standard Deviation Daily Reciept': [],\n",
    "#             'Yearly Standard Deviation': []\n",
    "#         }\n",
    "\n",
    "#         for year in df['year'].unique():\n",
    "#             df_year = df[df['year'] == year]\n",
    "#             daily_reciept = df_year.groupby('receiptdate').size()\n",
    "#             average_daily_reciept = daily_reciept.mean()\n",
    "#             std_dev_daily_reciept = daily_reciept.std()\n",
    "#             working_days = count_working_days(year)\n",
    "#             yearly_reciept = average_daily_reciept * working_days\n",
    "#             yearly_std_dev = average_daily_reciept * working_days\n",
    "\n",
    "#             results['year'].append(year)\n",
    "#             results['Average Daily Reciept'].append(average_daily_reciept)\n",
    "#             results['Yearly Receipt'].append(yearly_reciept)\n",
    "#             results['Standard Deviation Daily Reciept'].append(std_dev_daily_reciept)\n",
    "#             results['Yearly Standard Deviation'].append(yearly_std_dev)\n",
    "\n",
    "#         annual_receipts = pd.DataFrame(results)\n",
    "#         annual_receipts = annual_receipts.sort_values(by=['year'])\n",
    "\n",
    "#         return annual_receipts\n",
    "\n",
    "#     def create_unique_identifier(self):\n",
    "#         lpa_unique = self.lpa_data_sample_imputed\n",
    "#         lpa_unique['donor_postcode'] = lpa_unique['donor_postcode'].str.strip().str.replace(' ', '')\n",
    "#         lpa_unique['unique_key'] = lpa_unique['donor_dob'].astype(str) + lpa_unique['donor_gender'] + lpa_unique['donor_postcode']\n",
    "\n",
    "#         duplicate_mask = lpa_unique.duplicated('unique_key', keep=False)\n",
    "#         lpa_unique = pd.concat([lpa_unique.loc[duplicate_mask & lpa_unique[['age', 'donor_gender', 'donor_postcode']].ne(0).any(axis=1)], \n",
    "#                                 lpa_unique[~duplicate_mask]])\n",
    "\n",
    "#         lpa_unique['month_year'] = lpa_unique['receiptdate'].dt.strftime('%b-%y')\n",
    "#         lpa_unique = lpa_unique.sort_values(by=['receiptdate'])\n",
    "#         return lpa_unique\n",
    "\n",
    "#     def calculate_unique_donors_per_year(self, lpa_df_index):\n",
    "#         lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "#         annual_unique_donors = lpa_df_index.groupby(['year', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "#         annual_unique_donors = annual_unique_donors.sort_values(by=['year', 'donor_gender', 'age'])\n",
    "#         return annual_unique_donors\n",
    "\n",
    "#     def calculate_unique_donors_count_monthly(self, lpa_df_index):\n",
    "#         lpa_df_no_index = lpa_df_index.reset_index()\n",
    "#         lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "#         monthly_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "#         monthly_unique_donors = monthly_unique_donors.sort_values(by=['year', 'month', 'donor_gender', 'age'])\n",
    "#         return monthly_unique_donors\n",
    "\n",
    "#     def calculate_unique_donors_per_day(self, lpa_df_index):     \n",
    "#         lpa_df_no_index = lpa_df_index.reset_index()\n",
    "#         lpa_df_no_index['month'] = lpa_df_no_index['receiptdate'].dt.month\n",
    "#         lpa_df_no_index['day'] = lpa_df_no_index['receiptdate'].dt.day\n",
    "#         daily_unique_donors = lpa_df_no_index.groupby(['year', 'month', 'day', 'receiptdate', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "#         daily_unique_donors = daily_unique_donors.sort_values(by=['receiptdate', 'year', 'month', 'day', 'donor_gender', 'age'])\n",
    "#         return daily_unique_donors    \n",
    "    \n",
    "#     def calculate_unique_donors_age_specific(self, lpa_df_index):\n",
    "#        #lpa_df_index.set_index('receiptdate', inplace=True)\n",
    "#         annual_unique_donors_age_specific = lpa_df_index.groupby(['year', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "#         annual_unique_donors_age_specific = annual_unique_donors_age_specific.sort_values(by=['year', 'age'])\n",
    "#         return annual_unique_donors_age_specific\n",
    "        \n",
    "#     def calculate_unique_donors_count_daily(self, lpa_df_index):\n",
    "#         #daily_unique_donors = lpa_df_index.groupby(['year'])['unique_key'].nunique().reset_index(name='count')\n",
    "#         #daily_unique_donors = daily_unique_donors.sort_values(by=['year'])\n",
    "#         # Group by 'year' and count unique 'unique_id'\n",
    "#         annual_unique_counts = lpa_df_index.groupby(lpa_df_index['year'])['unique_key'].nunique()    \n",
    "#         return annual_unique_counts\n",
    "    \n",
    "#     # def aggregate_by_age_group(self, bins, labels):\n",
    "        \n",
    "#     #     daily_unique_donors = lpa_df_index.groupby(['year', 'month_year', 'donor_gender', 'age'])['unique_key'].nunique().reset_index(name='count')\n",
    "\n",
    "#     #     # Create age groups\n",
    "#     #     bins = list(range(18, 106))\n",
    "#     #     labels = [str(i) for i in range(18, 107)]\n",
    "        \n",
    "#     #     # Create a new column 'AgeGroup' with the age bins\n",
    "#     #     self.data['AgeGroup'] = pd.cut(self.data['age'], bins=bins, labels=labels, right=False)\n",
    "        \n",
    "#     #     # Aggregate data within each age group\n",
    "#     #     aggregated_data = self.data.groupby('AgeGroup').agg({\n",
    "#     #         'demand': 'sum',\n",
    "#     #         'name': 'count'\n",
    "#     #     }).rename(columns={'name': 'count'})\n",
    "        \n",
    "#     #     return aggregated_data    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# short-term forecast the rest of age-specific count of donor demands for the remaining months in 2024 based on a bunch of short-term drivers like Martin Lewis broadcast \n",
    "As we have only first quarter of age-specific count of donor demands (annual_donors_age_2024), to short-term forecast the rest of quarters age-specific count of donor demands for the remaining months in 2024:\n",
    "- Estimate the short-term forecasts for the remaining of 2024 by first, take the average number for receipts at working day across 2024 which currently is 5600 multiplied by the total number of working days in the year which is 256 give me the total number of expected receipts for the year (5600 * 256 = 1.433 million receipts across the whole of 2024). \n",
    "    1. Calculate the number of reciepts across the whole year (for the available data (only 6 months) on average are going to be for 2024 = average_daily_reciepts_2024\n",
    "    2. Muliply (average_daily_reciepts_2024) to the Number of working days in 2024 (num_working_day_2024) = total_annual_reciepts_2024\n",
    "    3. Estimate the Ratio of total_annual_reciepts_2024 to annual_donors_age_2024: ratio_reciept_donor_2024 = total_annual_reciepts_2024 / annual_donors_age_2024\n",
    "- Once you have calculated the total number of receipts for 2024 then by looking at 2022/2023 historical data count how many receipts there were in 2022/2023 and how many donors were in 2022/2023 just to get the overall ratio. The starting point is just the total number for receipts so according to this that would be just over 1.4 million more receipts then scale that back based on total number for receipts 2022/2023 e.g., 70% then that would suggest that would be 1,000,000 donors roughly. E.g., just to keep it simple we consider the same overall ratio in 2022/2023 (e.g., 70%) should be use in 2024, as 2022 and 2023 are the nearest year to 2024. This will give us an estimate for the total number of donors that we might expect in 2024 based on what we're seeing about average receipts across the year in 2024.      \n",
    "    1. Calculate the number of reciepts across the whole year on average for 2023 = average_daily_reciepts_2023\n",
    "    2. Muliply (average_daily_reciepts_2023) to the Number of working days in 2023 (num_working_day_2023) = total_annual_reciepts_2023\n",
    "    3. Muliply (average_daily_reciepts_2022) to the Number of working days in 2022 (num_working_day_2022) = total_annual_reciepts_2022\n",
    "    4. Estimate the Ratio of total_annual_reciepts_2023 to annual_donors_age_2023: ratio_reciept_donor_2023 = total_annual_reciepts_2023 / annual_donors_age_2023\n",
    "    5. Estimate the Ratio of total_annual_reciepts_2022 to annual_donors_age_2022: ratio_reciept_donor_2022 = total_annual_reciepts_2022 / annual_donors_age_2022\n",
    "- Then scale that back to work out however how many donors that is expected to be in 2024 and then using the historical age distribution in 2022/2023 just to break that down by age so that we can plug in those figures for 2024. So once calculated the number of donors in 2024, then need to find out of those donors what percentage would be aged 18 what percentage the age 19, 20, 21, ..., 106 based on the previous distribution so 2023 or 2022 and both years as well as the total number for receipts for 2022/2023. Then once you've got the total number of estimated donors for 2024 by considering 2022/2023 and we say how many donors were aged 18, how many were aged 19, how many were aged 20, … , etc (we should have all ages incremented by a year from 18 to 106. Then take those figures for 2024 and the plug come back in the age-specific number of annual donor demands. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Monte-Carlo simulation \n",
    "To ensure a future-proven forecasting model with much more reliable forecast outputs by applying uncertainty, \n",
    "especially when there are short-term volatilities in the average daily receipts in the pattern of data due to some short-term variation of external factors / drivers \n",
    "(e.g., advertisement), which has an impact on the short-term,  to capture these changes in the pattern of data in the short term and then apply the uncertainty related \n",
    "to this to a long-term forecasting of age-specific donor demands, e.g., as it is evident that the number of receipts changes in the short-term \n",
    "(e.g., from the range of 4000 to 7000 (increment by 100) in the drop-down list, \n",
    "so there is volatility in the short term and the range of the average daily receipts? Each time we run the model, the forecasting output  of age-specific donor demands changes. \n",
    "\n",
    "# Dealing with Uncertanty & data volatility\n",
    "THis is to introduce uncertainty into the model by simulating different scenarios for average daily receipts. \n",
    "This approach will capture the short-term volatility in donor receipts, leading to more reliable and robust long-term forecasts.\n",
    "\n",
    "## Set Up Monte Carlo Simulation Parameters\n",
    "set up the simulation to run multiple iterations, where each iteration randomly selects an average daily receipt value within \n",
    "a given range (e.g., 4000 to 7000). The model will then calculate the donor demand based on this value, \n",
    "and we'll aggregate the results to produce a distribution of possible outcomes.\n",
    "\n",
    "## Run the model\n",
    "- Run the Monte Carlo simulation for a specified number of iterations.\n",
    "- Randomly generate an average daily receipt within the specified range for each iteration.\n",
    "- Aggregate and analyse the results to provide a distribution of forecasted donor numbers.\n",
    "\n",
    "Monte Carlo Simulation Setup:\n",
    "\n",
    "The iterations variable defines how many times the simulation will run (in this example, 1000 iterations).\n",
    "lowerBound and upperBound set the range for possible average daily receipts, reflecting the volatility (from 4000 to 7000).\n",
    "Generating Random Average Daily Receipts:\n",
    "\n",
    "For each iteration, a random average daily receipt is selected from the specified range using Application.WorksheetFunction.RandBetween(lowerBound, upperBound).\n",
    "Running the Forecasting Model:\n",
    "\n",
    "For each random receipt value, the total receipts for 2024 are calculated.\n",
    "Using the ratios from 2022 and 2023, the estimated number of donors for 2024 is calculated for each iteration.\n",
    "Storing and Analyzing Results:\n",
    "\n",
    "The results of all iterations are stored in an array (monteCarloResults).\n",
    "The mean and standard deviation of the forecasted donor numbers for each age group are calculated across all iterations.\n",
    "Visualizations:\n",
    "\n",
    "Two charts are added to visualize the results:\n",
    "A clustered column chart showing the mean forecasted number of donors by age.\n",
    "A line chart showing the standard deviation of forecasted donors by age, indicating the uncertainty.\n",
    "Output:\n",
    "\n",
    "The final results are saved in the \"Forecast_2024\" sheet, and the charts are added for visual analysis.\n",
    "Running the Simulation:\n",
    "Each time you run the ForecastWithMonteCarlo macro, it will generate different results based on the random variation in average daily receipts. This randomness helps to account for short-term volatility, making the forecast more robust and reliable over the long term.\n",
    "Interpretation of Results:\n",
    "The mean values give an expected forecast for each age group based on the Monte Carlo simulation.\n",
    "The standard deviation indicates the level of uncertainty or volatility in the forecasted numbers. A higher standard deviation means more variability in the donor forecasts for that age group, suggesting that predictions for this group are more sensitive to changes in daily receipts.\n",
    "This approach ensures that the forecasting model accounts for potential short-term variations and provides a more nuanced understanding of the possible outcomes.\n",
    "\n",
    "## Additional Columns:\n",
    "\n",
    "Year: Added to specify the forecast year.\n",
    "AgeDistribution2022 & AgeDistribution2023: These columns store the age-specific distribution of donors for the years 2022 and 2023.\n",
    "AverageAgeDistribution: This column contains the average age distribution calculated from 2022 and 2023 data.\n",
    "RandomReceipt: Stores the random daily receipt value used in each iteration.\n",
    "MonteCarloResults: Holds the forecasted donor number for each iteration.\n",
    "Sum of Values and Sum of Squared Values: These are intermediate calculations needed to compute the mean and standard deviation for the forecasted donor numbers.\n",
    "Final Forecast (Mean) and Final Forecast (StdDev): The mean and standard deviation of the forecasted donor numbers after all iterations.\n",
    "Monte Carlo Simulation:\n",
    "\n",
    "Each iteration generates a random receipt value and calculates the forecasted donor numbers. The results are stored and used to compute the final forecast.\n",
    "Visualizations:\n",
    "\n",
    "Clustered Column Chart: Visualizes the mean forecasted donor numbers by age group.\n",
    "Line Chart: Shows the standard deviation (uncertainty) in the forecasted donor numbers for each age group.\n",
    "Interpretation:\n",
    "Year column gives context to the forecast year, which is 2024 in this scenario.\n",
    "Age Distribution Columns show how donor distributions are evolving over time.\n",
    "Random Receipt column illustrates the volatility and randomness considered in each iteration.\n",
    "Monte Carlo Results provide insight into the forecasted donor numbers for each random receipt value.\n",
    "Sum of Values and Sum of Squared Values are used to calculate the final forecast's mean and standard deviation, indicating the expected donor numbers and their uncertainty.\n",
    "The charts visually summarize the data, showing how different age groups' donor forecasts change under various scenarios and the associated uncertainties.\n",
    "This detailed output will help in analyzing the Monte Carlo simulation results in a more comprehensive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Uncertainty Ratio: average annual dornor demands and average annual reciepts:\n",
    "# Calculate the Ratio of Short-Term to Long-Term Demand:\n",
    "# Compute the ratio of the average short-term demand to the average long-term demand. \n",
    "# This ratio represents the relative impact of the short-term period on the long-term forecast.\n",
    "\n",
    "## -------------------\n",
    "# Instantiate the DataPreprocessor\n",
    "data_preprocessor = DataPreprocessor(data_handler.combined_df, data_handler.snapshot_start, data_handler.snapshot_end)\n",
    "data_preprocessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the The total annual reciepts\n",
    "annual_receipts = data_preprocessor.calculate_annual_receipts()\n",
    "results = annual_receipts[['year', 'Yearly Receipt']]\n",
    "\n",
    "print(f\"Total annual reciepts: {results}\")\n",
    "\n",
    "total_annual_reciepts_2022 = results['Yearly Receipt'].iloc[0]\n",
    "print(f\"total_annual_reciepts_2022: {results['Yearly Receipt'].iloc[0]}\")\n",
    "\n",
    "total_annual_reciepts_2023 = results['Yearly Receipt'].iloc[1]\n",
    "print(f\"total_annual_reciepts_2023: {results['Yearly Receipt'].iloc[1]}\")\n",
    "\n",
    "total_annual_reciepts_2024 = results['Yearly Receipt'].iloc[2]\n",
    "print(f\"total_annual_reciepts_2024: {results['Yearly Receipt'].iloc[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpa_df_index = data_preprocessor.create_unique_identifier()\n",
    "\n",
    "monthly_unique_donors = data_preprocessor.calculate_unique_donors_count_monthly(lpa_df_index)\n",
    "daily_unique_donors = data_preprocessor.calculate_unique_donors_per_day(lpa_df_index)\n",
    "annual_donor_demands = data_preprocessor.calculate_unique_donors_count_daily(lpa_df_index)\n",
    "annual_unique_donors_age_specific = data_preprocessor.calculate_unique_donors_age_specific(lpa_df_index)\n",
    "annual_unique_donors = data_preprocessor.calculate_unique_donors_per_year(lpa_df_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Total annual donor demands based on 'unique_id'\n",
    "daily_unique_donors.sort_values(by=['year', 'age'])\n",
    "total_annual_donor = daily_unique_donors[['year', 'count']]\n",
    "total_annual_donor = total_annual_donor.groupby(['year']).sum()\n",
    "\n",
    "total_annual_donor_2022 = total_annual_donor.iloc[0]\n",
    "total_annual_donor_2023 = total_annual_donor.iloc[1]\n",
    "total_annual_donor_2024 = total_annual_donor.iloc[2]\n",
    "\n",
    "print(f\"Total annual donor demands: {total_annual_donor}\")\n",
    "\n",
    "print(f\"Total annual donor demands for 2022: {total_annual_donor_2022}\")\n",
    "print(f\"Total annual donor demands for 2023: {total_annual_donor_2023}\")\n",
    "print(f\"Total annual donor demands for 2024: {total_annual_donor_2024}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to include only ages from 18 to 106\n",
    "annual_unique_donors = annual_unique_donors.rename(columns={'count': 'demand'})\n",
    "historical_data_df = annual_unique_donors[(annual_unique_donors['age'] >= 18) & (annual_unique_donors['age'] <= 106)]\n",
    "historical_data_df.to_csv('annual_unique_donors.csv', index=False)\n",
    "\n",
    "monthly_unique_donors = monthly_unique_donors.rename(columns={'count': 'demand'})\n",
    "historical_demand_monthly = monthly_unique_donors[(monthly_unique_donors['age'] >= 18) & (monthly_unique_donors['age'] <= 106)]\n",
    "historical_demand_monthly.to_csv('historical_demand_monthly.csv', index=False)\n",
    "\n",
    "daily_unique_donors = daily_unique_donors.rename(columns={'count': 'demand'})\n",
    "historical_demand_daily = daily_unique_donors[(daily_unique_donors['age'] >= 18) & (daily_unique_donors['age'] <= 106)] \n",
    "historical_demand_daily.to_csv('historical_demand_daily.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annual_receipts_historical = annual_receipts[['year', 'Yearly Receipt']]\n",
    "# Save to CSV file\n",
    "annual_receipts_historical.to_csv('annual_receipts.csv', index=False)\n",
    "annual_demands_historical = annual_donor_demands\n",
    "annual_demands_age_specific_historical = annual_unique_donors_age_specific\n",
    "annual_unique_donors_age_specific.to_csv('annual_unique_donors_age_specific.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'year' is 2023 or 2022\n",
    "filtered_annual_receipts = annual_receipts_historical #[annual_receipts_historical['year'].isin([2023, 2022, 2021, 2020])]\n",
    "print(f\"annual_donor_receipts is: {filtered_annual_receipts}\")\n",
    "\n",
    "\n",
    "filtered_annual_demands = annual_demands_historical #[(annual_demands_historical.index == 2020) | (annual_demands_historical.index == 2021) | (annual_demands_historical.index == 2022) | (annual_demands_historical.index == 2023) | (annual_demands_historical.index == 2024)]\n",
    "print(f\"annual_donor_demands is: {filtered_annual_demands}\")\n",
    "\n",
    "filtered_annual_demands_age_specific = annual_demands_age_specific_historical #[annual_demands_age_specific_historical['year'].isin([2023, 2022, 2021, 2020])]\n",
    "# Extract and save data into a csv file\n",
    "filtered_annual_demands_age_specific = filtered_annual_demands_age_specific.rename(columns={'count': 'demand'})\n",
    "\n",
    "print(f\"annual_donor_demands_age_specific is: {filtered_annual_demands_age_specific}\") \n",
    "\n",
    "# Save to CSV file\n",
    "filtered_annual_demands_age_specific.to_csv('annual_demands_age_specific.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and Preprocess Data: Load the historical data and filter it for the age range 18-106.\n",
    "# Calculate Annual Receipts: Calculate the total annual receipts for 2022, 2023, and 2024 based on the provided daily averages and working days.\n",
    "# Estimate Ratios: Calculate the ratios of receipts to donors for 2022 and 2023.\n",
    "# Forecast Donors for 2024: Estimate the total number of donors for 2024 based on the historical ratios.\n",
    "# Age-Specific Distribution: Use historical age distributions from 2022 and 2023 to distribute the forecasted donors by age for 2024.\n",
    "# Combine Forecasts: Integrate these estimates into the final forecast for age-specific donor demands for the remaining months in 2024.\n",
    "\n",
    "# class to provide short-term forecast the rest of age-specific count of donor demands for the remaining months in 2024 based on a bunch of short-term drivers like Martin Lewis broadcast \n",
    "# As we have only first quarter of age-specific count of donor demands (annual_donors_age_2024), to short-term forecast the rest of quarters age-specific count of donor demands for the remaining months in 2024:\n",
    "# - Estimate the short-term forecasts for the remaining of 2024 by first, take the average number for receipts at working day across 2024 which currently is 5600 multiplied by the total number of working days in the year which is 256 give me the total number of expected receipts for the year (5600 * 256 = 1.433 million receipts across the whole of 2024). \n",
    "#     1. Calculate the number of receipts across the whole year (for the available data (only 6 months) on average are going to be for 2024 = average_daily_reciepts_2024\n",
    "#     2. Multiply (average_daily_reciepts_2024) to the Number of working days in 2024 (num_working_day_2024) = total_annual_reciepts_2024\n",
    "#     3. Estimate the Ratio of total_annual_reciepts_2024 to annual_donors_age_2024: ratio_reciept_donor_2024 = total_annual_reciepts_2024 / annual_donors_age_2024\n",
    "# - Once you have calculated the total number of receipts for 2024 then by looking at 2022/2023 historical data count how many receipts there were in 2022/2023 and how many donors were in 2022/2023 just to get the overall ratio. The starting point is just the total number for receipts so according to this that would be just over 1.4 million more receipts then scale that back based on total number for receipts 2022/2023 e.g., 70% then that would suggest that would be 1,000,000 donors roughly. E.g., just to keep it simple we consider the same overall ratio in 2022/2023 (e.g., 70%) should be use in 2024, as 2022 and 2023 are the nearest year to 2024. This will give us an estimate for the total number of donors that we might expect in 2024 based on what we're seeing about average receipts across the year in 2024.      \n",
    "#     1. Calculate the number of receipts across the whole year on average for 2023 = average_daily_reciepts_2023\n",
    "#     2. Multiply (average_daily_reciepts_2023) to the Number of working days in 2023 (num_working_day_2023) = total_annual_reciepts_2023\n",
    "#     3. Multiply (average_daily_reciepts_2022) to the Number of working days in 2022 (num_working_day_2022) = total_annual_reciepts_2022                                                                    \n",
    "#(Note: assume we have already calculated the above figures:  \n",
    "# total_annual_reciepts_2022: 751967.5346260389\n",
    "# total_annual_reciepts_2023: 970035.0282485875\n",
    "# total_annual_reciepts_2024: 1124615.1902439024                                                              \n",
    "# Total annual donor demands for 2022: count    675089\n",
    "# Total annual donor demands for 2023: count    852627\n",
    "# Total annual donor demands for 2024: count    568367  \n",
    "#     4. Estimate the Ratio of total_annual_reciepts_2023 to annual_donors_age_2023: ratio_reciept_donor_2023 = total_annual_reciepts_2023 / annual_donors_age_2023\n",
    "#     5. Estimate the Ratio of total_annual_reciepts_2022 to annual_donors_age_2022: ratio_reciept_donor_2022 = total_annual_reciepts_2022 / annual_donors_age_2022  \n",
    "# - Then scale that back to work out however how many donors that is expected to be in 2024 and then using the historical age distribution in 2022/2023 just to break that down by age so that we can plug in those figures for 2024. So once calculated the number of donors in 2024, then need to find out of those donors what percentage would be aged 18 what percentage the age 19, 20, 21, …, 106 based on the previous distribution so 2023 or 2022 and both years as well as the total number for receipts for 2022/2023. Then once you've got the total number of estimated donors for 2024 by considering 2022/2023 and we say how many donors were aged 18, how many were aged 19, how many were aged 20, … , etc \n",
    "# (we should have all ages incremented by a year from 18 to 106. Then take those figures for 2024 and the plug come back in the age-specific number of annual donor demands. based on the attached data?  \n",
    "\n",
    "# Load the historical data\n",
    "#historical_data_path = 'annual_unique_donors_22_23_24.csv'\n",
    "historical_data_df = annual_unique_donors\n",
    "\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "filtered_data_df = historical_data_df[(historical_data_df['age'] >= 18) & (historical_data_df['age'] <= 106)]\n",
    "\n",
    "# # Add a column for the month (assuming the month is in the 'month' column in the dataset)\n",
    "# # If the dataset doesn't have month data, this step needs to be adjusted accordingly\n",
    "# # Here we assume that the dataset has a 'month' column with values from 1 to 12\n",
    "# filtered_data_df['month'] = pd.to_datetime(filtered_data_df['date']).dt.month\n",
    "\n",
    "# # Define a function to calculate quarters\n",
    "# def calculate_quarter(month):\n",
    "#     if 1 <= month <= 3:\n",
    "#         return 1\n",
    "#     elif 4 <= month <= 6:\n",
    "#         return 2\n",
    "#     elif 7 <= month <= 9:\n",
    "#         return 3\n",
    "#     elif 10 <= month <= 12:\n",
    "#         return 4\n",
    "\n",
    "# # Apply the function to add the 'quarter' column\n",
    "# filtered_data_df['quarter'] = filtered_data_df['month'].apply(calculate_quarter)\n",
    "\n",
    "# Calculate annual donor receipts and demands for the provided years\n",
    "annual_donor_demands = filtered_data_df.groupby('year')['demand'].sum()\n",
    "\n",
    "# Load the additional data provided in the task\n",
    "average_daily_receipts_2022 = total_annual_reciepts_2022 / 256\n",
    "average_daily_receipts_2023 = total_annual_reciepts_2023 / 256\n",
    "average_daily_receipts_2024 = 5600  # Given average daily receipts for 2024\n",
    "\n",
    "num_working_days_2022 = 256\n",
    "num_working_days_2023 = 256\n",
    "num_working_days_2024 = 256\n",
    "\n",
    "total_annual_receipts_2022 = round(average_daily_receipts_2022 * num_working_days_2022, 2)\n",
    "print(f\"The total number of receipts for 2022: {total_annual_receipts_2022}\")\n",
    "\n",
    "total_annual_receipts_2023 = round(average_daily_receipts_2023 * num_working_days_2023, 2)\n",
    "print(f\"The total number of receipts for 2023: {total_annual_receipts_2023}\")\n",
    "\n",
    "total_annual_receipts_2024 = round(average_daily_receipts_2024 * num_working_days_2024, 2)\n",
    "print(f\"The total number of receipts for 2024: {total_annual_receipts_2024}\")\n",
    "\n",
    "# Calculate ratios of receipts to donors for 2022 and 2023\n",
    "ratio_receipt_donor_2022 = round(total_annual_receipts_2022 / annual_donor_demands[2022], 2)\n",
    "print(f\"The Ratio of total number of receipt to donor demands for 2022: {ratio_receipt_donor_2022}\")\n",
    "\n",
    "ratio_receipt_donor_2023 = round(total_annual_receipts_2023 / annual_donor_demands[2023], 2)\n",
    "print(f\"The Ratio of total number of receipt to donor demands for 2023: {ratio_receipt_donor_2023}\")\n",
    "\n",
    "# Estimate the total number of donors for 2024 based on historical ratios\n",
    "estimated_donors_2024 = round(total_annual_receipts_2024 / ((ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2), 2)\n",
    "print(f\"The estimate total number of donors for 2024 based on historical ratios: {estimated_donors_2024}\")\n",
    "\n",
    "# Age-specific distribution based on 2022 and 2023\n",
    "age_distribution_2022 = filtered_data_df[filtered_data_df['year'] == 2022].groupby('age')['demand'].sum() / annual_donor_demands[2022]\n",
    "print(f\"Age-specific distribution based on 2022: {age_distribution_2022}\")\n",
    "\n",
    "age_distribution_2023 = filtered_data_df[filtered_data_df['year'] == 2023].groupby('age')['demand'].sum() / annual_donor_demands[2023]\n",
    "print(f\"Age-specific distribution based on 2023: {age_distribution_2023}\")\n",
    "\n",
    "# Average age distribution\n",
    "average_age_distribution = round((age_distribution_2022 + age_distribution_2023) / 2, 6)\n",
    "print(f\"Average age-specific distribution based on 2022/2023: {average_age_distribution}\")\n",
    "\n",
    "# Estimate the age-specific number of donors for 2024\n",
    "age_specific_donors_2024 = estimated_donors_2024 * average_age_distribution\n",
    "print(f\"Age-specific distribution for 2024: {age_specific_donors_2024}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ask the user to specify the available quarters for 2024\n",
    "#available_quarters = input(\"Enter the quarters that data is available for 2024 (e.g., 1, 2): \")\n",
    "#available_quarters = list(map(int, available_quarters.split(',')))\n",
    "#available_quarters\n",
    "\n",
    "# Forecast the remaining months in 2024 based on the first quarter data\n",
    "first_quarter_data = filtered_data_df[(filtered_data_df['year'] == 2024)] #& (filtered_data_df['quarter'] == 1)]\n",
    "print(f\"The first quarter available data for 2024: {first_quarter_data}\")\n",
    "\n",
    "total_first_quarter_demand = first_quarter_data['demand'].sum()\n",
    "print(f\"The total first quarter available donor demands for 2024: {total_first_quarter_demand}\")\n",
    "\n",
    "remaining_demand_2024 = total_annual_receipts_2024 - total_first_quarter_demand\n",
    "print(f\"The remaining donor demands for 2024: {remaining_demand_2024}\")\n",
    "\n",
    "# Distribute the remaining demand across ages based on the average age distribution\n",
    "remaining_age_specific_donors_2024 = remaining_demand_2024 * average_age_distribution\n",
    "print(f\"The remaining age-specific donor demands for 2024: {remaining_age_specific_donors_2024}\")\n",
    "\n",
    "# Create a DataFrame to store the forecasted age-specific donors for the remaining months of 2024\n",
    "forecast_df = pd.DataFrame({\n",
    "    'age': average_age_distribution.index,\n",
    "    'forecasted_donors': remaining_age_specific_donors_2024\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(f\"The age-specific donor demands for 2024:\")\n",
    "print(forecast_df)\n",
    "forecast_df.to_csv('estimated age-specific donor demands for 2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialization: The class is initialized with the data file and constants for the number of working days and average daily receipts for 2024.\n",
    "# # Calculate Ratios: The calculate_ratios method computes the ratio of total annual receipts to annual donors for 2022, 2023, and 2024.\n",
    "# # Forecast Donors for 2024: The forecast_donors_2024 method estimates the total number of donors for 2024 based on the average ratio from 2022 and 2023.\n",
    "# # Age Distribution: The age_distribution method calculates the age distribution of donors for a given year.\n",
    "# # Forecast Age-Specific Donors for 2024: The forecast_age_specific_donors_2024 method estimates the age-specific count of donors for 2024 by applying the average age distribution from 2022 and 2023\n",
    "# # to the estimated total number of donors for 2024.\n",
    "\n",
    "# class DonorDemandForecast:\n",
    "#     def __init__(self, data_file):\n",
    "#         self.data = pd.read_csv(data_file)\n",
    "#         self.num_working_days_2024 = 256\n",
    "#         self.average_daily_receipts_2024 = 5600\n",
    "#         self.total_annual_receipts_2024 = self.average_daily_receipts_2024 * self.num_working_days_2024\n",
    "#         self.total_annual_receipts_2022 = 751967.5346260389\n",
    "#         self.total_annual_receipts_2023 = 970035.0282485875\n",
    "#         self.total_annual_donors_2022 = 675089\n",
    "#         self.total_annual_donors_2023 = 852627\n",
    "#         self.total_annual_donors_2024 = 568367\n",
    "\n",
    "#     def calculate_ratios(self):\n",
    "#         ratio_receipt_donor_2022 = self.total_annual_receipts_2022 / self.total_annual_donors_2022\n",
    "#         ratio_receipt_donor_2023 = self.total_annual_receipts_2023 / self.total_annual_donors_2023\n",
    "#         ratio_receipt_donor_2024 = self.total_annual_receipts_2024 / self.total_annual_donors_2024\n",
    "#         return ratio_receipt_donor_2022, ratio_receipt_donor_2023, ratio_receipt_donor_2024\n",
    "\n",
    "#     def forecast_donors_2024(self):\n",
    "#         ratio_receipt_donor_2022, ratio_receipt_donor_2023, ratio_receipt_donor_2024 = self.calculate_ratios()\n",
    "#         estimated_donors_2024 = self.total_annual_receipts_2024 / ((ratio_receipt_donor_2022 + ratio_receipt_donor_2023) / 2)\n",
    "#         return estimated_donors_2024\n",
    "\n",
    "#     def age_distribution(self, year):\n",
    "#         age_dist = self.data[self.data['year'] == year].groupby('age')['demand'].sum()\n",
    "#         return age_dist / age_dist.sum()\n",
    "\n",
    "#     def forecast_age_specific_donors_2024(self):\n",
    "#         estimated_donors_2024 = self.forecast_donors_2024()\n",
    "#         age_dist_2022 = self.age_distribution(2022)\n",
    "#         age_dist_2023 = self.age_distribution(2023)\n",
    "#         average_age_dist = (age_dist_2022 + age_dist_2023) / 2\n",
    "#         age_specific_donors_2024 = average_age_dist * estimated_donors_2024\n",
    "#         return age_specific_donors_2024\n",
    "\n",
    "# # Usage\n",
    "# forecast = DonorDemandForecast('annual_unique_donors.csv')\n",
    "# age_specific_donors_2024 = forecast.forecast_age_specific_donors_2024()\n",
    "# print(age_specific_donors_2024)\n",
    "# age_specific_donors_2024.to_csv('age_specific_donors_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function in python that apply uncertainty to a short-term forecsasts of number of demands from April 2024 for 2 years \n",
    "# by multiplying the SARIMA forecasted values by two ratios: 1. annual_donor_receipts (average daily demnads per year) divided \n",
    "# by annual_donor_demands (average daily reciepts per year) and 2. (age-specific demnads ratio (claculated by estimating the percentage \n",
    "#                                                                                               of demands per year for each age from 18 to 106). \n",
    "#                                                                   Also if there are no demands in a specific age in the corresponding year then consider \n",
    "#                                                                   a zero demand for that age. \n",
    "# Here is the age specific count of demnds in 2022, 2023, and January 2024, February 2024 and March 2024.  \n",
    "# To accomplish this task, we need to:\n",
    "\n",
    "# Forecast the number of demands for the next two years using a SARIMA model.\n",
    "# Apply uncertainty by multiplying the forecasted values by the specified ratios:\n",
    "# The ratio of annual donor receipts to annual donor demands.\n",
    "# The age-specific demands ratio.\n",
    "# Here's a step-by-step Python function to achieve this:\n",
    "\n",
    "# Forecasting using SARIMA: I'll assume the SARIMA model is already built and forecasted values are available.\n",
    "# Ratio Calculation:\n",
    "# Calculate the ratio of annual donor receipts to annual donor demands.\n",
    "# Calculate age-specific demands ratio.\n",
    "# Apply Ratios: Adjust the forecasted values by these ratios.\n",
    "\n",
    "# 1. Forecasting the overall demand.\n",
    "# 2. Distributing the forecasted demand among different age groups using age-specific ratios.\n",
    "# 3. Adjusting these distributed forecasts using the month and age-specific ratios.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "# Suppress warnings from statsmodels\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the historical data\n",
    "#historical_data_path = '/annual_unique_donors.csv'\n",
    "#pd.read_csv(historical_data_path)\n",
    "\n",
    "#historical_demand_daily['month'] = historical_demand_daily['month_year'].dt.month\n",
    "#historical_demand_daily['day'] = historical_demand_daily['receiptdate'].dt.day\n",
    "# Calculate annual donor receipts and demands\n",
    "# annual_donor_receipts = historical_data_df.groupby('year')['demand'].sum().reset_index(name='Yearly Receipt')\n",
    "# annual_donor_demands = historical_data_df.groupby('year')['demand'].sum()\n",
    "# Annual receipts and demands DataFrames\n",
    "annual_donor_receipts = filtered_annual_receipts  #pd.DataFrame({'year': [2022, 2023, 2024], 'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_donor_demands = filtered_annual_demands  #pd.Series({2022: 601254, 2023: 752898, 2024: 505219}, name='unique_key')\n",
    "\n",
    "# Age-specific demands DataFrame\n",
    "age_specific_demands = filtered_annual_demands_age_specific #pd.DataFrame({\n",
    "#     'year': [2022, 2022, 2022, 2023, 2023, 2023, 2024, 2024, 2024],\n",
    "#     'age': [18, 19, 20, 18, 19, 20, 18, 19, 20],\n",
    "#     'demand': [199, 286, 192, 249, 345, 243, 122, 267, 196]})\n",
    "\n",
    "# Calculate age-specific demands\n",
    "annual_donor_demands_age_specific = filtered_annual_demands_age_specific #historical_data_df.groupby(['year', 'age'])['demand'].sum().reset_index()\n",
    "\n",
    "# # Define a function to fit SARIMA model and forecast future demands\n",
    "# def fit_sarima_and_forecast(data, start_year, forecast_periods):\n",
    "#     model = sm.tsa.statespace.SARIMAX(data,\n",
    "#                                       order=(1, 1, 1),\n",
    "#                                       seasonal_order=(1, 1, 1, 12),\n",
    "#                                       enforce_stationarity=False,\n",
    "#                                       enforce_invertibility=False)\n",
    "#     results = model.fit(disp=False)\n",
    "#     forecast = results.get_forecast(steps=forecast_periods)\n",
    "#     forecast_values = forecast.predicted_mean\n",
    "#     forecast_index = pd.date_range(start=start_year, periods=forecast_periods, freq='MS')\n",
    "#     forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "#     return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to perform Naïve extrapolation\n",
    "def naive_extrapolation(data, forecast_periods, freq='Y'):\n",
    "    last_observed_value = data.iloc[-1]\n",
    "    forecast_values = np.repeat(last_observed_value, forecast_periods)\n",
    "    #data.set_index('year', inplace=True)\n",
    "    #forecast_index = pd.date_range(start=f\"{data.index[-1].year + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "    last_year = data.index[-1] #data['year'].iloc[-1] #\n",
    "    \n",
    "    # Modified to generate forecasts for different frequencies (Y, M, D).\n",
    "    if freq == 'Y': \n",
    "        forecast_index = pd.date_range(start=f\"{last_year + 1}\", periods=forecast_periods, freq='YS')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y'), periods=forecast_periods, freq='YS')\n",
    "        \n",
    "    elif freq == 'M': \n",
    "        tup = data.index[-1]\n",
    "        first, *middle, last = tup\n",
    "        middle = last\n",
    "        last = 1\n",
    "        # Calculate the date 6 months from today's date and print it in ISO 8601 format\n",
    "        #print((dt.date.today() + dt.timedelta(1 * 365 / 12)).isoformat())\n",
    "        forecast_index = pd.date_range(start=f\"{(dt.date(first, middle, last) + dt.timedelta((1 * 365 / 12)+1)).isoformat()}\", periods=forecast_periods, freq='MS')\n",
    "        #forecast_index = pd.date_range(start=f\"{last_year}-01\", periods=forecast_periods, freq='MS')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y-%m'), periods=forecast_periods, freq='MS')\n",
    "    elif freq == 'D':\n",
    "        tup = data.index[-1]\n",
    "        first, middle, last = tup \n",
    "        forecast_index = pd.date_range(start=f\"{(dt.date(first, middle, last) + dt.timedelta(3)).isoformat()}\", periods=forecast_periods, freq='D')\n",
    "        #forecast_index = pd.date_range(start=f\"{last_year}-01-01\", periods=forecast_periods, freq='D')\n",
    "        #forecast_index = pd.date_range(start=datetime(last_year, 1, 1).strftime('%Y-%m-%d'), periods=forecast_periods, freq='D')\n",
    "        \n",
    "    forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "    return forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast demand using SARIMA\n",
    "#start_year = '2024-04'\n",
    "#forecast_periods = 2 #24\n",
    "# Forecast overall demand using Naïve extrapolation\n",
    "forecast_periods_annual = 5  # 2 years of forecast\n",
    "forecast_periods_monthly = 24  # 24 months of forecast (2 years)\n",
    "forecast_periods_daily = 730  # 730 days of forecast (2 years)\n",
    "\n",
    "# Annual forecast\n",
    "historical_demand = historical_data_df.groupby('year')['demand'].sum()\n",
    "forecast_df_annual = naive_extrapolation(historical_demand, forecast_periods_annual, freq='Y')\n",
    "\n",
    "# Monthly forecast\n",
    "historical_demand_mon = historical_demand_monthly.reset_index()\n",
    "historical_demand_mon = historical_demand_monthly.groupby(['year', 'month'])['demand'].sum()\n",
    "forecast_df_monthly = naive_extrapolation(historical_demand_mon, forecast_periods_monthly, freq='M')\n",
    "\n",
    "\n",
    "# Daily forecast\n",
    "historical_demand_day = historical_demand_daily.reset_index()\n",
    "historical_demand_day = historical_demand_day.groupby(['year', 'month', 'day'])['demand'].sum() #.groupby(['year', 'month', 'day'])['demand'].sum()\n",
    "forecast_df_daily = naive_extrapolation(historical_demand_day, forecast_periods_daily, freq='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#forecast_df = fit_sarima_and_forecast(historical_data_df.set_index('year')['demand'], start_year, forecast_periods)\n",
    "#forecast_df = fit_sarima_and_forecast(historical_demand, start_year, forecast_periods)\n",
    "#forecast_df = naive_extrapolation(historical_demand, forecast_periods)\n",
    "\n",
    "# Calculate age-specific demand ratios\n",
    "age_specific_ratios = {}\n",
    "for year in historical_data_df['year'].unique():\n",
    "    print(f\"year: {year}\")\n",
    "    age_demand = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'] == year]\n",
    "    #print(f\"age_demand: {age_demand}\")\n",
    "    total_demand = age_demand['demand'].sum()\n",
    "    #print(f\"total_demand: {total_demand}\")\n",
    "    if total_demand > 0:\n",
    "        age_specific_ratios[year] = age_demand.set_index('age')['demand'] / total_demand\n",
    "        #print(f\"age_specific_ratios[year]: {age_specific_ratios[year]}\")\n",
    "    else:\n",
    "        age_specific_ratios[year] = pd.Series(0, index=range(18, 107))\n",
    "        #print(f\" Zero age: age_specific_ratios[year]: {pd.Series(0, index=range(18, 107))}\")\n",
    "# Function to apply uncertainty adjustments to the forecasts\n",
    "def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year, freq='Y'):\n",
    "#def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year):\n",
    "    # Filter Ages: We filter the data to include only ages between 18 and 106.\n",
    "    #adjusted_forecast = forecast_df.copy()\n",
    "    adjusted_forecast = pd.DataFrame(index=forecast_df.index, columns=range(18, 107))\n",
    "    \n",
    "    start_year = pd.to_datetime(forecast_start_year).year -1\n",
    "    \n",
    "    month_ratio_list = []#list()\n",
    "    \n",
    "    for i in range(len(forecast_df)):\n",
    "        if freq == 'Y':\n",
    "            forecast_year = start_year - i\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "        elif freq == 'M':\n",
    "            forecast_year = start_year - (i // 12)\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "        elif freq == 'D':\n",
    "            forecast_year = start_year - (i // 365)\n",
    "            print(f\" i: {i}  forecast_year: {forecast_year}\")\n",
    "    # Forecasting: We fit the SARIMA model to the historical data and obtain the overall forecast.\n",
    "#         Check Year Existence: Before calculating the month_ratio, we check if the forecast_year exists in both annual_donor_receipts and annual_donor_demands.\n",
    "#         Assign Zero Demand: If the year does not exist in either DataFrame, we assign zero demand for that period.\n",
    "        if forecast_year in annual_donor_receipts['year'].values and forecast_year in annual_donor_demands.index:\n",
    "            print(f\"## ------------------- ##\")\n",
    "            #print(f\"## ------------------- ##\")\n",
    "            #print(f\"## ------------------- ##\")\n",
    "            #print(f\"forecast_year for receipts: {annual_donor_receipts['year'].values}\")\n",
    "            #print(f\"forecast_year for donors: {annual_donor_demands.index}\")\n",
    "            #print(f\"forecast_year: {forecast_year}\")\n",
    "            month_ratio = round((annual_donor_receipts[annual_donor_receipts['year'] == forecast_year]['Yearly Receipt'].values[0] / ##annual_donor_receipts[annual_donor_receipts['year'] == 2023]['Yearly Receipt'].values[0] / annual_donor_demands[2023] \n",
    "                           annual_donor_demands[forecast_year]), 2)\n",
    "            #print(f\"month_ratio: {month_ratio}\")\n",
    "            \n",
    "            # Age-Specific Ratios: We calculate the demand ratios for each age group.\n",
    "            #age_specific_ratio = age_specific_ratios.get(year, pd.Series(0, index=range(18, 107)))\n",
    "            for age in range(18, 107):\n",
    "                age_specific_ratio = age_specific_ratios.get(forecast_year, pd.Series(0, index=range(18, 107)))\n",
    "                #print(f\"age_specific_ratio: {age_specific_ratio}\")\n",
    "                # Adjusting the Forecast:\n",
    "                # Initialize an empty DataFrame to hold the adjusted forecast values.\n",
    "                # For each forecasted period, calculate the monthly ratio.\n",
    "                if age in age_specific_ratio:\n",
    "                     # Distribute the forecasted demand among different age groups using the calculated age-specific ratios.\n",
    "                    #month_ratio_list = month_ratio_list.append(month_ratio) \n",
    "                    adjusted_forecast.iloc[i, age - 18] = (forecast_df.iloc[i]['Forecast'] * month_ratio * age_specific_ratio[age])\n",
    "                    print(f\" for i: {i}, year: {forecast_year}, age: {age} ==> month_ratio = {month_ratio}, age_specific_ratio[age]: {age_specific_ratio[age]}, adjusted_forecast: {adjusted_forecast.iloc[i, age - 18]}\")\n",
    "#                     if age not in dict:\n",
    "#                         dict[age] = []\n",
    "#                         dict[age].append(month_ratio)\n",
    "#                         print(dict)\n",
    "                   \n",
    "                    #.to_csv(f\"month_ratio_year{forecast_year}_age{age}.csv\", index=False)\n",
    "                    #age_specific_ratio[age].to_csv(f\"age_specific_ratio_year{forecast_year}_age{age}.csv\", index=False)\n",
    "                else: # If a specific age has no data, we assign a zero demand.\n",
    "                    adjusted_forecast.iloc[i, age - 18] = 0   \n",
    "        else:\n",
    "            # If the year is not found, assign zero demand\n",
    "            adjusted_forecast.iloc[i, :] = 0\n",
    "        \n",
    "        #adjusted_forecast.iloc[i] = adjusted_forecast.iloc[i] * month_ratio * age_specific_ratio.values\n",
    "        #forecast_value = adjusted_forecast.iloc[i]['Forecast']\n",
    "        #adjusted_values = forecast_value * month_ratio * age_specific_ratio.values\n",
    "        #adjusted_forecast.iloc[i]['Forecast'] = adjusted_values.sum()\n",
    "    return adjusted_forecast #, month_ratio_list)\n",
    "\n",
    "# Apply the uncertainty adjustments to the forecasts\n",
    "#adjusted_forecast_df = apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year)\n",
    "\n",
    "# Apply the uncertainty adjustments to the forecasts\n",
    "\n",
    "start_year = dt.date.today() #2024\n",
    "forecast_start_year = start_year\n",
    "pd.to_datetime(forecast_start_year).year -1\n",
    "\n",
    "# Adjusted annual forecast\n",
    "adjusted_forecast_annual_df = apply_uncertainty_adjustments(forecast_df_annual, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='Y')\n",
    "adjusted_forecast_annual_df.to_csv(f\"adjusted_forecast_annual.csv\", index=False)\n",
    "\n",
    "# Adjusted monthly forecast\n",
    "#adjusted_forecast_monthly_df = apply_uncertainty_adjustments(forecast_df_monthly, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='M')\n",
    "#adjusted_forecast_monthly_df.to_csv(f\"adjusted_forecast_monthly.csv\", index=False)\n",
    "\n",
    "# Adjusted daily forecast\n",
    "#adjusted_forecast_daily_df = apply_uncertainty_adjustments(forecast_df_daily, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year, freq='D')\n",
    "#adjusted_forecast_daily_df.to_csv(f\"adjusted_forecast_daily.csv\", index=False)\n",
    "\n",
    "# Display the adjusted forecasts\n",
    "print(\"Adjusted Annual Forecast:\")\n",
    "print(adjusted_forecast_annual_df.head())\n",
    "\n",
    "#print(\"Adjusted Monthly Forecast:\")\n",
    "#print(adjusted_forecast_monthly_df.head())\n",
    "\n",
    "#print(\"Adjusted Daily Forecast:\")\n",
    "#print(adjusted_forecast_daily_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical data\n",
    "historical_data_df = annual_unique_donors\n",
    "\n",
    "\n",
    "# Filter the data to include only ages from 18 to 106\n",
    "filtered_data_df = historical_data_df[(historical_data_df['age'] >= 18) & (historical_data_df['age'] <= 106)]\n",
    "\n",
    "# Calculate annual donor receipts and demands\n",
    "annual_donor_receipts = filtered_data_df.groupby('year')['demand'].sum().reset_index(name='Yearly Receipt')\n",
    "annual_donor_demands = filtered_data_df.groupby('year')['demand'].sum()\n",
    "\n",
    "# Calculate age-specific demands\n",
    "annual_donor_demands_age_specific = filtered_data_df.groupby(['year', 'age'])['demand'].sum().reset_index()\n",
    "\n",
    "# Define a function to perform Naïve extrapolation\n",
    "def naive_extrapolation(data, forecast_periods):\n",
    "    last_observed_value = data.iloc[-1]\n",
    "    forecast_values = np.repeat(last_observed_value, forecast_periods)\n",
    "    #forecast_index = pd.date_range(start=f\"{data.index[-1].year + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "    forecast_index = pd.date_range(start=f\"{data.index[-1] + 1}-01-01\", periods=forecast_periods, freq='YS')\n",
    "\n",
    "    forecast_df = pd.DataFrame({'Forecast': forecast_values}, index=forecast_index)\n",
    "    return forecast_df\n",
    "\n",
    "# Forecast overall demand using Naïve extrapolation\n",
    "forecast_periods = 2  # 2 years of forecast\n",
    "historical_demand = filtered_data_df.groupby('year')['demand'].sum()\n",
    "historical_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_df = naive_extrapolation(historical_demand, forecast_periods)\n",
    "forecast_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Calculate age-specific demand ratios\n",
    "# age_specific_ratios = {}\n",
    "# for year in filtered_data_df['year'].unique():\n",
    "#     age_demand = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'] == year]\n",
    "#     total_demand = age_demand['demand'].sum()\n",
    "#     if total_demand > 0:\n",
    "#         age_specific_ratios[year] = age_demand.set_index('age')['demand'] / total_demand\n",
    "#     else:\n",
    "#         age_specific_ratios[year] = pd.Series(0, index=range(18, 107))\n",
    "\n",
    "# # Function to apply uncertainty adjustments to the forecasts\n",
    "# def apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, forecast_start_year):\n",
    "#     adjusted_forecast = pd.DataFrame(index=forecast_df.index, columns=range(18, 107))\n",
    "#     start_year = pd.to_datetime(forecast_start_year).year\n",
    "#     for i in range(len(forecast_df)):\n",
    "#         forecast_year = start_year + i\n",
    "#         # Check if the year exists in both DataFrames\n",
    "#         if forecast_year in annual_donor_receipts['year'].values and forecast_year in annual_donor_demands.index:\n",
    "#             month_ratio = (annual_donor_receipts[annual_donor_receipts['year'] == forecast_year]['Yearly Receipt'].values[0] /\n",
    "#                            annual_donor_demands[forecast_year])\n",
    "#             for age in range(18, 107):\n",
    "#                 age_specific_ratio = age_specific_ratios.get(forecast_year, pd.Series(0, index=range(18, 107)))\n",
    "#                 if age in age_specific_ratio:\n",
    "#                     adjusted_forecast.iloc[i, age - 18] = (forecast_df.iloc[i]['Forecast'] * month_ratio * age_specific_ratio[age])\n",
    "#                 else:\n",
    "#                     adjusted_forecast.iloc[i, age - 18] = 0\n",
    "#         else:\n",
    "#             # If the year is not found, assign zero demand\n",
    "#             adjusted_forecast.iloc[i, :] = 0\n",
    "#     return adjusted_forecast\n",
    "\n",
    "# # Apply the uncertainty adjustments to the forecasts\n",
    "# start_year = 2024\n",
    "# adjusted_forecast_df = apply_uncertainty_adjustments(forecast_df, annual_donor_receipts, annual_donor_demands, age_specific_ratios, start_year)\n",
    "\n",
    "# # Display the adjusted forecast\n",
    "# print(adjusted_forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Calculates the growth rate for each age cohort.\n",
    "# Computes the average growth rate for each age cohort.\n",
    "# Uses the last year’s data to forecast the next year’s demand.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Calculates the growth rate for each age cohort.\n",
    "# Computes the average growth rate for each age cohort.\n",
    "# Uses the last year’s data to forecast the next year’s demand.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Applies seasonal decomposition to separate the trend and seasonal components.\n",
    "# Calculates the average growth rate for the trend component.\n",
    "# Forecasts the next year’s trend component and combines it with the seasonal component.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "def cohort_analysis_forecast(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "df = annual_donor_demands\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast(df)\n",
    "print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_uncertainty(forecast, annual_donor_receipts, annual_donor_demands, age_specific_demands):\n",
    "#     # Calculate the annual ratios\n",
    "#     annual_ratios = annual_donor_receipts['Yearly Receipt'] / annual_donor_demands\n",
    "\n",
    "#     # Calculate the age-specific demand ratios\n",
    "#     age_specific_ratios = age_specific_demands.groupby('age')['demand'].sum() / age_specific_demands['demand'].sum()\n",
    "\n",
    "#     # Create a DataFrame to store the adjusted forecast\n",
    "#     adjusted_forecast = pd.DataFrame(index=forecast.index, columns=forecast.columns)\n",
    "\n",
    "#     for year in range(2024, 2026):\n",
    "#         # Get the annual ratio for the current year\n",
    "#         annual_ratio = annual_ratios.loc[year]\n",
    "\n",
    "#         for age in range(18, 107):\n",
    "#             # Get the age-specific ratio for the current age\n",
    "#             age_ratio = age_specific_ratios.get(age, 0)\n",
    "\n",
    "#             # Apply the uncertainty to the forecast\n",
    "#             adjusted_forecast.loc[(forecast.index.year == year) & (forecast.columns == age), age] = (\n",
    "#                 forecast.loc[(forecast.index.year == year) & (forecast.columns == age), age] * annual_ratio * age_ratio\n",
    "#             )\n",
    "\n",
    "#     # Fill NaN values with 0\n",
    "#     adjusted_forecast = adjusted_forecast.fillna(0)\n",
    "\n",
    "#     return adjusted_forecast\n",
    "\n",
    "\n",
    "# def cohort_analysis_forecast_with_seasonality(df):\n",
    "#     # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "#     pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "#     # Initialize a DataFrame to store the forecast\n",
    "#     forecast_df = pd.DataFrame(index=pivot.index)\n",
    "    \n",
    "#     # Loop through each age cohort to apply seasonal decomposition and forecast\n",
    "#     for age in pivot.index:\n",
    "#         # Get the time series for the current age cohort\n",
    "#         ts = pivot.loc[age].dropna()\n",
    "        \n",
    "#         # Apply seasonal decomposition\n",
    "#         decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
    "        \n",
    "#         # Extract the trend and seasonal components\n",
    "#         trend = decomposition.trend.dropna()\n",
    "#         seasonal = decomposition.seasonal.dropna()\n",
    "        \n",
    "#         # Calculate the average growth rate for the trend component\n",
    "#         growth_rate = trend.pct_change().mean()\n",
    "        \n",
    "#         # Forecast the next year's trend component\n",
    "#         last_trend_value = trend.iloc[-1]\n",
    "#         forecast_trend = last_trend_value * (1 + growth_rate)\n",
    "        \n",
    "#         # Get the seasonal component for the next period (assuming seasonality repeats)\n",
    "#         next_seasonal_value = seasonal.iloc[-12 % len(seasonal)]\n",
    "        \n",
    "#         # Combine the forecasted trend and seasonal components\n",
    "#         forecast_value = forecast_trend * next_seasonal_value\n",
    "        \n",
    "#         # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "#         uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "#         forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "#         # Store the forecast in the DataFrame\n",
    "#         forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "#     # Return the forecast DataFrame\n",
    "#     return forecast_df\n",
    "\n",
    "# # Call the function and print the forecast\n",
    "# forecast = cohort_analysis_forecast_with_seasonality(df)\n",
    "# print(forecast)\n",
    "\n",
    "\n",
    "# Creates a pivot table with age as the index and year as the columns.\n",
    "# Applies STL decomposition to separate the trend and seasonal components.\n",
    "# Calculates the average growth rate for the trend component.\n",
    "# Forecasts the next year’s trend component and combines it with the seasonal component.\n",
    "# Incorporates uncertainty by multiplying the forecast by the average Uncertainty_Ratio.\n",
    "\n",
    "# import pandas as pd\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# # Assuming the dataframe has a 'year' column and a 'demand' column\n",
    "# df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "# df.set_index('year', inplace=True)\n",
    "\n",
    "# # Decompose the time series to observe seasonal patterns\n",
    "# decomposition = seasonal_decompose(df['demand'], model='additive', period=1)\n",
    "\n",
    "# # Fit the TSL model with seasonal components\n",
    "# model = ExponentialSmoothing(df['demand'], trend='add', seasonal='add', seasonal_periods=1)\n",
    "# fit_model = model.fit()\n",
    "\n",
    "# # Forecast the next period\n",
    "# forecast = fit_model.forecast(1)\n",
    "\n",
    "# # Add the forecast to the original function\n",
    "# def cohort_analysis_forecast(df, forecast_value):\n",
    "#     # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "#     pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "#     # Calculate the growth rate for each age cohort\n",
    "#     growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "#     # Calculate the average growth rate for each age cohort\n",
    "#     avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "#     # Get the last year of data for each age cohort\n",
    "#     last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "#     # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "#     forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "#     # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "#     # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "#     uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "#     forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "#     # Add the TSL forecast value\n",
    "#     forecast_with_uncertainty['TSL_Forecast'] = forecast_value\n",
    "    \n",
    "#     # Return the forecast with uncertainty\n",
    "#     return forecast_with_uncertainty\n",
    "\n",
    "# # Call the function and print the forecast with TSL seasonal forecasting\n",
    "# forecast_with_tsl = cohort_analysis_forecast(df, forecast.values[0])\n",
    "# print(forecast_with_tsl)\n",
    "\n",
    "# This code integrates STL seasonal forecasting into your existing cohort analysis forecast function. \n",
    "# It uses the STL decomposition from the statsmodels library to decompose the time series data and \n",
    "# then applies the Holt-Winters method for forecasting. \n",
    "# The forecast value is then adjusted by the age-specific Uncertainty_Ratio.\n",
    "\n",
    "# import pandas as pd\n",
    "# from statsmodels.tsa.seasonal import STL\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# # Assuming the dataframe has 'year' and 'age' columns and a 'demand' column\n",
    "# df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "# df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# # Function to apply STL and forecast\n",
    "# def cohort_analysis_forecast_with_stl(df):\n",
    "#     # Initialize a DataFrame to store the forecast\n",
    "#     forecast_df = pd.DataFrame()\n",
    "\n",
    "#     # Loop through each age cohort to apply STL and forecast\n",
    "#     for age in df.index.get_level_values(0).unique():\n",
    "#         # Get the time series for the current age cohort\n",
    "#         ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "#         # Apply STL decomposition\n",
    "#         stl = STL(ts, seasonal=13)\n",
    "#         result = stl.fit()\n",
    "        \n",
    "#         # Forecast the next year's demand using Holt-Winters method\n",
    "#         model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#         fit_model = model.fit()\n",
    "#         forecast_value = fit_model.forecast(1).iloc[0]\n",
    "        \n",
    "#         # Get the corresponding 'Uncertainty_Ratio' for the specific age and year\n",
    "#         uncertainty_ratio = df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        \n",
    "#         # Multiply the forecast value by the 'Uncertainty_Ratio'\n",
    "#         forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "#         # Store the forecast in the DataFrame\n",
    "#         forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "#     # Return the forecast DataFrame\n",
    "#     return forecast_df\n",
    "\n",
    "# # Call the function and print the forecast\n",
    "# forecast = cohort_analysis_forecast_with_stl(df)\n",
    "# print(forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "class DemandForecasting:\n",
    "    def __init__(self, file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "        self.df = self.df[self.df['year'].isin([2020, 2021, 2022, 2023])]\n",
    "        self.df.set_index(['age', 'year'], inplace=True)\n",
    "        self.variability_measures = None\n",
    "        self.forecast_df = None\n",
    "\n",
    "    def calculate_variability_measures(self):\n",
    "        measures = pd.DataFrame()\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "            std_dev = ts.std()\n",
    "            variance = ts.var()\n",
    "            range_val = ts.max() - ts.min()\n",
    "            iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "            cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "            mad = ts.mad()\n",
    "            qd = iqr / 2\n",
    "            measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "            measures.loc[age, 'Variance'] = variance\n",
    "            measures.loc[age, 'Range'] = range_val\n",
    "            measures.loc[age, 'IQR'] = iqr\n",
    "            measures.loc[age, 'CV'] = cv\n",
    "            measures.loc[age, 'MAD'] = mad\n",
    "            measures.loc[age, 'QD'] = qd\n",
    "        self.variability_measures = measures\n",
    "        return measures\n",
    "\n",
    "    def cohort_analysis_forecast_with_stl(self):\n",
    "        forecast_df = pd.DataFrame()\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            print(f\"age: {age}\")\n",
    "            ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "            # Ensure that the time series has a frequency for the STL decomposition\n",
    "            if not ts.index.inferred_freq:\n",
    "                ts = ts.asfreq('Y')\n",
    "            stl = STL(endog=ts, period=None, seasonal=13)\n",
    "            result = stl.fit()\n",
    "            model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "            fit_model = model.fit()\n",
    "            forecast_value = fit_model.forecast(1).iloc[0]\n",
    "            uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "            forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "            forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "        self.forecast_df = forecast_df\n",
    "        return forecast_df\n",
    "\n",
    "    def visualize_forecast_with_uncertainty(self):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        for age in self.df.index.get_level_values(0).unique():\n",
    "            ts = self.df.xs(age, level='age')['demand']\n",
    "            plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "        for age in self.forecast_df.index:\n",
    "            plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "        for age in self.forecast_df.index:\n",
    "            adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "            plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_variability_measures(self):\n",
    "        # Reset index to use 'age' as a column for the boxplot\n",
    "        df_reset = self.df.reset_index()\n",
    "        \n",
    "        # Check if there are any NaN values in 'age' or 'demand' columns\n",
    "        if df_reset['age'].isnull().any() or df_reset['demand'].isnull().any():\n",
    "            # Drop rows with NaN values in 'age' or 'demand' columns\n",
    "            df_reset = df_reset.dropna(subset=['age', 'demand'])\n",
    "        \n",
    "        # Check if there are enough data points to create a boxplot\n",
    "        if len(df_reset) > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.boxplot(x='age', y='demand', data=df_reset)\n",
    "            plt.title('Box Plot of Demand by Age')\n",
    "            plt.xlabel('Age')\n",
    "            plt.ylabel('Demand')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough data to create a boxplot.\")\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "        plt.title('Histogram of Demand')\n",
    "        plt.xlabel('Demand')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "        plt.title('Violin Plot of Demand by Age')\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "        std_demand = self.df.groupby('age')['demand'].std()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "        plt.title('Mean Demand with Standard Deviation by Age')\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "        plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Age')\n",
    "        plt.show()\n",
    "\n",
    "    def apply_uncertainty_to_forecast(self,start_period,end_period,average_annual_receipts,total_annual_donors,annual_donor_demands_age_specific):\n",
    "        # Load additional data\n",
    "        average_annual_receipts = average_annual_receipts\n",
    "        total_annual_donors = total_annual_donors \n",
    "        annual_donor_demands_age_specific = annual_donor_demands_age_specific\n",
    "\n",
    "        # Calculate the ratios\n",
    "        ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "        ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "        # Naive extrapolation for the specified period\n",
    "        forecast_dates = pd.date_range(start=start_period, end=end_period, freq='D')\n",
    "        last_known_value = self.df['demand'].iloc[-1]\n",
    "        forecast_values = pd.Series(last_known_value, index=forecast_dates)\n",
    "\n",
    "        # Apply the ratios to the forecasted values\n",
    "        forecast_with_uncertainty = forecast_values.copy()\n",
    "        for date in forecast_dates:\n",
    "            year = date.year\n",
    "            age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0] if 'age' in self.df.columns else None\n",
    "            ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "            ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "            forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "\n",
    "        # Return the forecast with applied uncertainty\n",
    "        return forecast_with_uncertainty\n",
    "    \n",
    "# Calculate variability measures\n",
    "variability_measures = forecasting.calculate_variability_measures()\n",
    "print(variability_measures)\n",
    "\n",
    "# Perform cohort analysis forecast with STL\n",
    "forecast = forecasting.cohort_analysis_forecast_with_stl()\n",
    "print(forecast)\n",
    "\n",
    "# Visualize the forecast with uncertainty\n",
    "forecasting.visualize_forecast_with_uncertainty()\n",
    "\n",
    "# Visualize variability measures\n",
    "#forecasting.visualize_variability_measures()\n",
    "\n",
    "file_path = 'annual_unique_donors.csv'\n",
    "forecasting = DemandForecasting(file_path)\n",
    "\n",
    "# Apply uncertainty to forecast using naive extrapolation\n",
    "start_period = pd.Timestamp('2024-04-01')\n",
    "end_period = pd.Timestamp('2026-03-31')\n",
    "\n",
    "annual_donor_receipts = pd.read_csv('annual_receipts.csv')\n",
    "average_annual_receipts = annual_donor_receipts.rename(columns={'Yearly Receipt': 'demand'})\n",
    "average_annual_receipts = average_annual_receipts[average_annual_receipts['year'].isin([2020, 2021, 2022, 2023])]\n",
    "average_annual_receipts.set_index('year', inplace=True)\n",
    "#pd.DataFrame({'year': [2022, 2023, 2024],'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_donor_demands = pd.read_csv('annual_unique_donors.csv') #pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "total_annual_donors = annual_donor_demands\n",
    "total_annual_donors = total_annual_donors[total_annual_donors['year'].isin([2020, 2021, 2022, 2023])]\n",
    "total_annual_donors = total_annual_donors.groupby('year')['demand'].sum()\n",
    "\n",
    "annual_donor_demands_age_specific = pd.read_csv('annual_demands_age_specific.csv') #pd.DataFrame({})\n",
    "annual_donor_demands_age_specific = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific)\n",
    "print(forecast_with_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands.xs(18, level='age')['demand'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands['demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.df = pd.read_csv(file_path)\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df = self.df[self.df['year'].isin([2020, 2021, 2022, 2023])]\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             print(f\"age: {age}\")\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "#     def apply_uncertainty_to_forecast(\n",
    "#         self, sarima_order, seasonal_order, start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific):\n",
    "#         # Load additional data\n",
    "#         average_annual_receipts = average_annual_receipts\n",
    "#         total_annual_donors = total_annual_donors \n",
    "#         annual_donor_demands_age_specific = annual_donor_demands_age_specific\n",
    "\n",
    "#         # Calculate the ratios\n",
    "#         ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "#         ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "#         # Fit SARIMA model\n",
    "#         sarima_model = SARIMAX(self.df['demand'], order=sarima_order, seasonal_order=seasonal_order)\n",
    "#         sarima_results = sarima_model.fit()\n",
    "\n",
    "#         # Forecast for the specified period\n",
    "#         #forecast = sarima_results.get_forecast(steps=(end_period - start_period).days)\n",
    "#         forecast_dates = pd.date_range(start=start_period, end=end_period, freq='D')\n",
    "#         forecast = sarima_results.get_forecast(steps=len(forecast_dates))\n",
    "#         forecast_values = forecast.predicted_mean\n",
    "\n",
    "#         # Apply the ratios to the forecasted values\n",
    "#         forecast_with_uncertainty = forecast_values.copy()\n",
    "#         for date in forecast_dates: #forecast_values.index:\n",
    "#             year = date.year\n",
    "#             print(f\"For year: {year}\")\n",
    "#             age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0] if 'age' in self.df.columns else None\n",
    "#             ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#             forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "#             print(f\"\"\"For year: {year}, the ratio_receipts_to_demands is: {ratio_1} \n",
    "#             and the ratio_receipts_to_demands is: {ratio_2}\"\"\")           \n",
    "#             #age = self.df.loc[date, 'age'] if 'age' in self.df.columns else None\n",
    "#             #age = self.df.loc[self.df.index.get_level_values('year') == date.year, 'age'].unique()[0]\n",
    "#             #ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             #ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].demand #.year\n",
    "#             #ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "\n",
    "#         # Return the forecast with applied uncertainty\n",
    "#         return forecast_with_uncertainty\n",
    "\n",
    "# # Example usage\n",
    "# file_path = 'annual_unique_donors.csv'\n",
    "# forecasting = DemandForecasting(file_path)\n",
    "# sarima_order = (1, 1, 1)\n",
    "# seasonal_order = (1, 1, 1, 12)\n",
    "# start_period = pd.Timestamp('2024-01-01')  #('2024-04-01')\n",
    "# end_period = pd.Timestamp('2026-01-01')\n",
    "# annual_donor_receipts = pd.read_csv('annual_receipts.csv')\n",
    "# average_annual_receipts = annual_donor_receipts.rename(columns={'Yearly Receipt': 'demand'})\n",
    "# average_annual_receipts = average_annual_receipts[average_annual_receipts['year'].isin([2020, 2021, 2022, 2023])]\n",
    "# average_annual_receipts.set_index('year', inplace=True)\n",
    "# #pd.DataFrame({'year': [2022, 2023, 2024],'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "# annual_donor_demands = pd.read_csv('annual_unique_donors.csv') #pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "# total_annual_donors = annual_donor_demands\n",
    "# total_annual_donors = total_annual_donors[total_annual_donors['year'].isin([2020, 2021, 2022, 2023])]\n",
    "# total_annual_donors = total_annual_donors.groupby('year')['demand'].sum()\n",
    "\n",
    "# annual_donor_demands_age_specific = pd.read_csv('annual_demands_age_specific.csv') #pd.DataFrame({})\n",
    "# annual_donor_demands_age_specific = annual_donor_demands_age_specific[annual_donor_demands_age_specific['year'].isin([2020, 2021, 2022, 2023])]\n",
    "\n",
    "# forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(\n",
    "#     sarima_order, seasonal_order, start_period, end_period, average_annual_receipts, total_annual_donors, annual_donor_demands_age_specific)\n",
    "# print(forecast_with_uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_receipts_to_demands = round((average_annual_receipts['demand']) / (total_annual_donors), 2)\n",
    "#ratio_receipts_to_demands.reset_index()\n",
    "#ratio_receipts_to_demands.loc['year']\n",
    "#ratio_receipts_to_demands.reset_index()\n",
    "ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].year #ratio_receipts_to_demands.loc[year]\n",
    "ratio_1 = ratio_receipts_to_demands.reset_index().loc[:].year\n",
    "\n",
    "#ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "#ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_receipts_to_demands.loc[2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start=start_period, end=end_period, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.df = pd.read_csv(file_path)\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "#     def apply_uncertainty_to_forecast(self, sarima_order, seasonal_order, start_period, end_period):\n",
    "#         # Load additional data\n",
    "#         annual_donor_receipts = pd.DataFrame({\n",
    "#             'year': [2022, 2023, 2024],\n",
    "#             'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]\n",
    "#         })\n",
    "#         annual_donor_demands = pd.Series([601254, 752898, 505219], index=[2022, 2023, 2024])\n",
    "#         annual_donor_demands_age_specific = pd.DataFrame({\n",
    "#             # Assuming this DataFrame contains the age-specific demand data as shown in the context\n",
    "#         })\n",
    "\n",
    "#         # Calculate the ratios\n",
    "#         ratio_receipts_to_demands = annual_donor_receipts['Yearly Receipt'] / annual_donor_demands\n",
    "#         ratio_age_specific = annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()\n",
    "\n",
    "#         # Fit SARIMA model\n",
    "#         sarima_model = SARIMAX(self.df['demand'], order=sarima_order, seasonal_order=seasonal_order)\n",
    "#         sarima_results = sarima_model.fit()\n",
    "\n",
    "#         # Forecast for the specified period\n",
    "#         forecast = sarima_results.get_forecast(steps=(end_period - start_period).days)\n",
    "#         forecast_values = forecast.predicted_mean\n",
    "\n",
    "#         # Apply the ratios to the forecasted values\n",
    "#         forecast_with_uncertainty = forecast_values.copy()\n",
    "#         for date in forecast_values.index:\n",
    "#             year = date.year\n",
    "#             age = self.df.loc[date, 'age'] if 'age' in self.df.columns else None\n",
    "#             ratio_1 = ratio_receipts_to_demands.loc[year]\n",
    "#             ratio_2 = ratio_age_specific.loc[(year, age)] if age in ratio_age_specific.index.get_level_values('age') else 0\n",
    "#             forecast_with_uncertainty[date] = forecast_values[date] * ratio_1 * ratio_2\n",
    "\n",
    "#         # Return the forecast with applied uncertainty\n",
    "#         return forecast_with_uncertainty\n",
    "\n",
    "# # Example usage\n",
    "# file_path = 'annual_unique_donors.csv'\n",
    "# forecasting = DemandForecasting(file_path)\n",
    "# sarima_order = (1, 1, 1)\n",
    "# seasonal_order = (1, 1, 1, 12)\n",
    "# start_period = pd.Timestamp('2024-04-01')\n",
    "# end_period = pd.Timestamp('2026-03-31')\n",
    "# forecast_with_uncertainty = forecasting.apply_uncertainty_to_forecast(sarima_order, seasonal_order, start_period, end_period)\n",
    "# print(forecast_with_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_donor_demands_age_specific.groupby(['year', 'age'])['demand'].sum() / annual_donor_demands_age_specific.groupby('year')['demand'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explanation\n",
    "# # Class Initialization:\n",
    "# # Loads the dataset and sets up the DataFrame.\n",
    "# # Calculate Variability Measures:\n",
    "# # Computes various measures of variability for each age cohort.\n",
    "# # Cohort Analysis Forecast with STL:\n",
    "# # Applies STL decomposition and Holt-Winters forecasting, adjusting the forecast with the uncertainty ratio.\n",
    "# # Visualize Forecast with Uncertainty:\n",
    "# # Plots the original demand, forecasted demand, and adjusted forecast with uncertainty.\n",
    "# # Visualize Variability Measures:\n",
    "# # Creates various plots (box plot, histogram, violin plot, scatter plot with error bars, and heatmap) to visualize the variability measures.\n",
    "# # You can use this class to load your data, perform the analysis, and visualize the results. Feel free to run the code and let me know if you need any further assistance!\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from statsmodels.tsa.seasonal import STL\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# class DemandForecasting:\n",
    "#     def __init__(self, historical_data):\n",
    "#         self.df = historical_data\n",
    "#         self.df['year'] = pd.to_datetime(self.df['year'], format='%Y')\n",
    "#         self.df.set_index(['age', 'year'], inplace=True)\n",
    "#         self.variability_measures = None\n",
    "#         self.forecast_df = None\n",
    "\n",
    "#     def calculate_variability_measures(self):\n",
    "#         measures = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             std_dev = ts.std()\n",
    "#             variance = ts.var()\n",
    "#             range_val = ts.max() - ts.min()\n",
    "#             iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "#             cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "#             mad = ts.mad()\n",
    "#             qd = iqr / 2\n",
    "#             measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "#             measures.loc[age, 'Variance'] = variance\n",
    "#             measures.loc[age, 'Range'] = range_val\n",
    "#             measures.loc[age, 'IQR'] = iqr\n",
    "#             measures.loc[age, 'CV'] = cv\n",
    "#             measures.loc[age, 'MAD'] = mad\n",
    "#             measures.loc[age, 'QD'] = qd\n",
    "#         self.variability_measures = measures\n",
    "#         return measures\n",
    "\n",
    "#     def cohort_analysis_forecast_with_stl(self):\n",
    "#         forecast_df = pd.DataFrame()\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand'].dropna()\n",
    "#             stl = STL(ts, seasonal=13)\n",
    "#             result = stl.fit()\n",
    "#             model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "#             fit_model = model.fit()\n",
    "#             forecast_value = fit_model.forecast(1).iloc[0]\n",
    "#             uncertainty_ratio = self.df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in self.df.columns else 1\n",
    "#             forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "#             forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "#         self.forecast_df = forecast_df\n",
    "#         return forecast_df\n",
    "\n",
    "#     def visualize_forecast_with_uncertainty(self):\n",
    "#         plt.figure(figsize=(14, 7))\n",
    "#         for age in self.df.index.get_level_values(0).unique():\n",
    "#             ts = self.df.xs(age, level='age')['demand']\n",
    "#             plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             plt.plot(self.forecast_df.columns, self.forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "#         for age in self.forecast_df.index:\n",
    "#             adjusted_forecast = self.forecast_df.loc[age] * self.df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "#             plt.plot(self.forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     def visualize_variability_measures(self):\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.boxplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Box Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.histplot(self.df['demand'], bins=20, kde=True)\n",
    "#         plt.title('Histogram of Demand')\n",
    "#         plt.xlabel('Demand')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.violinplot(x='age', y='demand', data=self.df.reset_index())\n",
    "#         plt.title('Violin Plot of Demand by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         mean_demand = self.df.groupby('age')['demand'].mean()\n",
    "#         std_demand = self.df.groupby('age')['demand'].std()\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "#         plt.title('Mean Demand with Standard Deviation by Age')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Demand')\n",
    "#         plt.show()\n",
    "\n",
    "#         pivot_table = self.df.reset_index().pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "#         plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Age')\n",
    "#         plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# historical_data = annual_unique_donors\n",
    "# forecasting = DemandForecasting(historical_data)\n",
    "# variability_measures = forecasting.calculate_variability_measures()\n",
    "# forecast = forecasting.cohort_analysis_forecast_with_stl()\n",
    "# forecasting.visualize_forecast_with_uncertainty()\n",
    "# forecasting.visualize_variability_measures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "can you add TSL seasonal forecasting to the code below based on the attched data?\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add TSL seasonal forecasting to the code based on the attached data\n",
    "\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "can you add TSL seasonal forecasting to the code below based on the attched data? def cohort_analysis_forecast(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast(df)\n",
    "print(forecast)\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add TSL seasonal forecasting to the code based on the attached data\n",
    "\n",
    "\n",
    "Sent by Copilot:\n",
    "It looks like there was an issue with the code execution because the dataset does not contain a ‘Date’ column. Let’s adjust the code to add TSL seasonal forecasting based on the data you provided.\n",
    "\n",
    "Here’s the updated code:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has a 'year' column and a 'demand' column\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index('year', inplace=True)\n",
    "\n",
    "# Decompose the time series to observe seasonal patterns\n",
    "decomposition = seasonal_decompose(df['demand'], model='additive', period=1)\n",
    "\n",
    "# Fit the TSL model with seasonal components\n",
    "model = ExponentialSmoothing(df['demand'], trend='add', seasonal='add', seasonal_periods=1)\n",
    "fit_model = model.fit()\n",
    "\n",
    "# Forecast the next period\n",
    "forecast = fit_model.forecast(1)\n",
    "\n",
    "# Add the forecast to the original function\n",
    "def cohort_analysis_forecast(df, forecast_value):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Calculate the growth rate for each age cohort\n",
    "    growth_rates = pivot.pct_change(axis=1)\n",
    "    \n",
    "    # Calculate the average growth rate for each age cohort\n",
    "    avg_growth_rates = growth_rates.mean(axis=1)\n",
    "    \n",
    "    # Get the last year of data for each age cohort\n",
    "    last_year_data = pivot.iloc[:, -1]\n",
    "    \n",
    "    # Forecast the next year's demand by applying the average growth rate to the last year's data\n",
    "    forecast = last_year_data * (1 + avg_growth_rates)\n",
    "    \n",
    "    # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "    # Assuming 'Uncertainty_Ratio' is a column in the dataframe\n",
    "    uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "    forecast_with_uncertainty = forecast * uncertainty_ratio\n",
    "    \n",
    "    # Add the TSL forecast value\n",
    "    forecast_with_uncertainty['TSL_Forecast'] = forecast_value\n",
    "    \n",
    "    # Return the forecast with uncertainty\n",
    "    return forecast_with_uncertainty\n",
    "\n",
    "# Call the function and print the forecast with TSL seasonal forecasting\n",
    "forecast_with_tsl = cohort_analysis_forecast(df, forecast.values[0])\n",
    "print(forecast_with_tsl)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code integrates TSL seasonal forecasting into your existing cohort analysis forecast function. It uses the ExponentialSmoothing model from the statsmodels library to forecast the next period based on the seasonal decomposition of the demand data. The forecast value is then incorporated into the final forecast with uncertainty.\n",
    "\n",
    "Feel free to run this code and let me know if you encounter any issues or need further adjustments!\n",
    "\n",
    "Learn more\n",
    "\n",
    "1\n",
    "\n",
    "annual_unique_donors.csv\n",
    "You\n",
    "Sent by you:\n",
    "How can I visualize the forecast results?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "You can visualize the forecast results using various plotting libraries in Python, such as matplotlib or seaborn. Here’s an example of how you can visualize the forecast results using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'forecast_with_tsl' is the DataFrame returned by the cohort_analysis_forecast function\n",
    "# and it includes the 'TSL_Forecast' column\n",
    "\n",
    "def visualize_forecast(df, forecast_with_tsl):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index, df['demand'], label='Original Demand', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    plt.plot(forecast_with_tsl.index, forecast_with_tsl, label='Forecasted Demand', marker='x')\n",
    "    \n",
    "    # Highlight the TSL forecast\n",
    "    plt.axvline(x=forecast_with_tsl.index[-1], color='r', linestyle='--', label='TSL Forecast')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with TSL Seasonal Forecasting')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast(df, forecast_with_tsl)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data and the forecasted demand, with a vertical line highlighting the TSL forecast. You can customize the plot further by adding more details or adjusting the style to suit your needs.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "can you add STL for forecasting time series data forecasting model and adjust and change the above code to ensure that multiplying the forecast value for a specific age in a specific year to be corresponded to the related age and year when choosing age_specific Uncertainty_Ratio to the code below based on the attched data? # Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')                                                                                                         def cohort_analysis_forecast_with_seasonality(df):\n",
    "    # Create a pivot table with 'year' as columns, 'age' as index, and 'demand' as values\n",
    "    pivot = df.pivot_table(index='age', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    # Initialize a DataFrame to store the forecast\n",
    "    forecast_df = pd.DataFrame(index=pivot.index)\n",
    "    \n",
    "    # Loop through each age cohort to apply seasonal decomposition and forecast\n",
    "    for age in pivot.index:\n",
    "        # Get the time series for the current age cohort\n",
    "        ts = pivot.loc[age].dropna()\n",
    "        \n",
    "        # Apply seasonal decomposition\n",
    "        decomposition = seasonal_decompose(ts, model='multiplicative', period=12)\n",
    "        \n",
    "        # Extract the trend and seasonal components\n",
    "        trend = decomposition.trend.dropna()\n",
    "        seasonal = decomposition.seasonal.dropna()\n",
    "        \n",
    "        # Calculate the average growth rate for the trend component\n",
    "        growth_rate = trend.pct_change().mean()\n",
    "        \n",
    "        # Forecast the next year's trend component\n",
    "        last_trend_value = trend.iloc[-1]\n",
    "        forecast_trend = last_trend_value * (1 + growth_rate)\n",
    "        \n",
    "        # Get the seasonal component for the next period (assuming seasonality repeats)\n",
    "        next_seasonal_value = seasonal.iloc[-12 % len(seasonal)]\n",
    "        \n",
    "        # Combine the forecasted trend and seasonal components\n",
    "        forecast_value = forecast_trend * next_seasonal_value\n",
    "        \n",
    "        # Incorporate uncertainty by multiplying the forecast by the 'Uncertainty_Ratio'\n",
    "        uncertainty_ratio = df['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "        # Store the forecast in the DataFrame\n",
    "        forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "    # Return the forecast DataFrame\n",
    "    return forecast_df\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast_with_seasonality(df)\n",
    "print(forecast)\n",
    "text\n",
    "annual_unique_donors.csv\n",
    "Copilot\n",
    "Executing Task:\n",
    "\n",
    "add STL for forecasting time series data forecasting model and adjust and change the code to ensure that multiplying the forecast value for a specific age in a specific year to be corresponded to the related age and year when choosing age_specific Uncertainty_Ratio to the code based on the attached data\n",
    "\n",
    "\n",
    "Sent by Copilot:\n",
    "It looks like there was an issue with the code execution because the dataset does not contain a ‘Date’ column. Let’s adjust the code to add STL seasonal forecasting based on the data you provided.\n",
    "\n",
    "Here’s the updated code:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year' and 'age' columns and a 'demand' column\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to apply STL and forecast\n",
    "def cohort_analysis_forecast_with_stl(df):\n",
    "    # Initialize a DataFrame to store the forecast\n",
    "    forecast_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each age cohort to apply STL and forecast\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        # Get the time series for the current age cohort\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Apply STL decomposition\n",
    "        stl = STL(ts, seasonal=13)\n",
    "        result = stl.fit()\n",
    "        \n",
    "        # Forecast the next year's demand using Holt-Winters method\n",
    "        model = ExponentialSmoothing(result.trend, trend='add', seasonal='add', seasonal_periods=13)\n",
    "        fit_model = model.fit()\n",
    "        forecast_value = fit_model.forecast(1).iloc[0]\n",
    "        \n",
    "        # Get the corresponding 'Uncertainty_Ratio' for the specific age and year\n",
    "        uncertainty_ratio = df.xs(age, level='age')['Uncertainty_Ratio'].mean() if 'Uncertainty_Ratio' in df.columns else 1\n",
    "        \n",
    "        # Multiply the forecast value by the 'Uncertainty_Ratio'\n",
    "        forecast_with_uncertainty = forecast_value * uncertainty_ratio\n",
    "        \n",
    "        # Store the forecast in the DataFrame\n",
    "        forecast_df.loc[age, 'Forecast'] = forecast_with_uncertainty\n",
    "    \n",
    "    # Return the forecast DataFrame\n",
    "    return forecast_df\n",
    "\n",
    "# Call the function and print the forecast\n",
    "forecast = cohort_analysis_forecast_with_stl(df)\n",
    "print(forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code integrates STL seasonal forecasting into your existing cohort analysis forecast function. It uses the STL decomposition from the statsmodels library to decompose the time series data and then applies the Holt-Winters method for forecasting. The forecast value is then adjusted by the age-specific Uncertainty_Ratio.\n",
    "\n",
    "Feel free to run this code and let me know if you encounter any issues or need further adjustments!\n",
    "\n",
    "Learn more\n",
    "\n",
    "1\n",
    "\n",
    "annual_unique_donors.csv\n",
    "You\n",
    "Sent by you:\n",
    "How can I interpret the forecast results?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Interpreting the forecast results involves understanding the different components and what they represent. Here’s a breakdown of how to interpret the forecast results from the code provided:\n",
    "\n",
    "Original Demand Data:\n",
    "This represents the historical demand data for each age cohort over the years. It’s the baseline data used for forecasting.\n",
    "STL Decomposition:\n",
    "Seasonal Component: This shows the repeating patterns or cycles in the data, such as yearly seasonality.\n",
    "Trend Component: This indicates the long-term progression of the data, showing whether the demand is generally increasing or decreasing over time.\n",
    "Residual Component: This represents the random noise or irregular fluctuations in the data that are not explained by the trend or seasonal components.\n",
    "Forecasted Demand:\n",
    "This is the predicted demand for the next period based on the historical data and the STL decomposition. It combines the trend and seasonal components to project future demand.\n",
    "Uncertainty Ratio:\n",
    "This factor adjusts the forecasted demand to account for uncertainty. It can vary by age and year, reflecting the variability in the data.\n",
    "Forecast with Uncertainty:\n",
    "This is the final forecasted demand after adjusting for uncertainty. It provides a more realistic prediction by incorporating potential variations.\n",
    "Example Interpretation\n",
    "Let’s say you have the following forecast results for a specific age cohort:\n",
    "\n",
    "Original Demand Data: Shows an increasing trend over the past 5 years.\n",
    "Seasonal Component: Indicates higher demand during certain months of the year.\n",
    "Trend Component: Shows a steady upward trend.\n",
    "Residual Component: Contains some random fluctuations but no significant outliers.\n",
    "Forecasted Demand: Predicts an increase in demand for the next year.\n",
    "Uncertainty Ratio: Adjusts the forecast slightly higher due to observed variability.\n",
    "Visualization\n",
    "To visualize these results, you can plot the original demand data, the decomposed components (seasonal, trend, residual), and the forecasted demand. This will help you see how the forecast is derived and how the different components contribute to the final prediction.\n",
    "\n",
    "Here’s an example of how to visualize the forecast results using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast(df, forecast_df):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with STL Seasonal Forecasting')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast(df, forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data and the forecasted demand for each age cohort. You can customize the plot further to highlight specific components or add more details.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How do I interpret the uncertainty ratio?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "The uncertainty ratio is a factor used to adjust the forecasted demand to account for variability and potential errors in the prediction. Here’s how you can interpret it:\n",
    "\n",
    "Understanding the Uncertainty Ratio\n",
    "Purpose:\n",
    "The uncertainty ratio is used to incorporate the inherent uncertainty in the forecast. It adjusts the forecasted values to reflect the possible range of outcomes, considering the variability in the historical data.\n",
    "Calculation:\n",
    "In your code, the uncertainty ratio is calculated as the mean of the ‘Uncertainty_Ratio’ column for each specific age cohort. If this column is not present, a default value of 1 is used, indicating no adjustment.\n",
    "Impact on Forecast:\n",
    "The forecasted demand is multiplied by the uncertainty ratio. If the uncertainty ratio is greater than 1, it increases the forecasted value, indicating higher variability and potential for greater demand. If it is less than 1, it decreases the forecasted value, indicating lower variability and potential for lesser demand.\n",
    "Example Interpretation\n",
    "Let’s say you have a forecasted demand of 100 units for a specific age cohort, and the uncertainty ratio for that cohort is 1.2. The adjusted forecast would be:\n",
    "\n",
    "[ \\text{Adjusted Forecast} = \\text{Forecasted Demand} \\times \\text{Uncertainty Ratio} ] [ \\text{Adjusted Forecast} = 100 \\times 1.2 = 120 ]\n",
    "\n",
    "This means that, considering the variability in the data, the forecasted demand is adjusted to 120 units.\n",
    "\n",
    "Practical Use\n",
    "Higher Uncertainty Ratio: Indicates more variability in the historical data, suggesting that the forecasted demand could be higher than initially predicted.\n",
    "Lower Uncertainty Ratio: Indicates less variability, suggesting that the forecasted demand could be lower or more stable.\n",
    "Visualization\n",
    "To visualize the impact of the uncertainty ratio, you can plot the original forecasted values and the adjusted values side by side. This will help you see how the uncertainty ratio modifies the forecast.\n",
    "\n",
    "Here’s an example of how to visualize this using matplotlib:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast_with_uncertainty(df, forecast_df):\n",
    "    # Plot the original demand data\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    # Plot the forecasted demand\n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    # Highlight the adjusted forecast with uncertainty\n",
    "    for age in forecast_df.index:\n",
    "        adjusted_forecast = forecast_df.loc[age] * df.xs(age, level='age')['Uncertainty_Ratio'].mean()\n",
    "        plt.plot(forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_forecast_with_uncertainty(df, forecast)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This code will create a line plot showing the original demand data, the forecasted demand, and the adjusted forecast with uncertainty for each age cohort. This visualization helps in understanding how the uncertainty ratio affects the forecasted values.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I calculate the uncertainty ratio for my specific data?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "To calculate the uncertainty ratio for your specific data, you need to quantify the variability or uncertainty in your historical demand data. This can be done using statistical measures such as the standard deviation or variance. Here’s a step-by-step guide on how to calculate the uncertainty ratio:\n",
    "\n",
    "Step-by-Step Guide\n",
    "Load Your Data: Ensure your data is loaded into a DataFrame and properly formatted.\n",
    "Calculate the Standard Deviation: Compute the standard deviation of the demand for each age cohort. The standard deviation measures the amount of variation or dispersion in the data.\n",
    "Calculate the Mean Demand: Compute the mean (average) demand for each age cohort.\n",
    "Calculate the Uncertainty Ratio: The uncertainty ratio can be calculated as the ratio of the standard deviation to the mean demand. This gives a relative measure of variability.\n",
    "Example Code\n",
    "Here’s an example of how you can calculate the uncertainty ratio for each age cohort in your dataset:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Calculate the uncertainty ratio for each age cohort\n",
    "def calculate_uncertainty_ratio(df):\n",
    "    # Initialize a DataFrame to store the uncertainty ratios\n",
    "    uncertainty_ratios = pd.DataFrame()\n",
    "\n",
    "    # Loop through each age cohort\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        # Get the demand time series for the current age cohort\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate the standard deviation and mean demand\n",
    "        std_dev = ts.std()\n",
    "        mean_demand = ts.mean()\n",
    "        \n",
    "        # Calculate the uncertainty ratio\n",
    "        uncertainty_ratio = std_dev / mean_demand if mean_demand != 0 else 0\n",
    "        \n",
    "        # Store the uncertainty ratio in the DataFrame\n",
    "        uncertainty_ratios.loc[age, 'Uncertainty_Ratio'] = uncertainty_ratio\n",
    "    \n",
    "    return uncertainty_ratios\n",
    "\n",
    "# Call the function and print the uncertainty ratios\n",
    "uncertainty_ratios = calculate_uncertainty_ratio(df)\n",
    "print(uncertainty_ratios)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Explanation\n",
    "Standard Deviation (std_dev): Measures the spread of the demand values around the mean. A higher standard deviation indicates more variability.\n",
    "Mean Demand (mean_demand): The average demand for the age cohort.\n",
    "Uncertainty Ratio (uncertainty_ratio): The ratio of the standard deviation to the mean demand. This provides a relative measure of the variability in the demand data.\n",
    "Using the Uncertainty Ratio\n",
    "Once you have calculated the uncertainty ratios, you can use them to adjust your forecasted demand values. This will help you account for the variability in the historical data and provide a more realistic forecast.\n",
    "\n",
    "Feel free to run this code with your data and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I interpret the uncertainty ratio in my specific context?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Interpreting the uncertainty ratio in your specific context involves understanding how it reflects the variability and reliability of your forecasted demand. Here’s a detailed guide to help you interpret it:\n",
    "\n",
    "What the Uncertainty Ratio Represents\n",
    "Variability in Historical Data:\n",
    "The uncertainty ratio is a measure of how much the demand has varied historically for a specific age cohort. A higher ratio indicates more variability, while a lower ratio indicates more stability.\n",
    "Adjustment to Forecast:\n",
    "The ratio adjusts the forecasted demand to account for this variability. It helps in providing a range of possible outcomes rather than a single point estimate, making the forecast more realistic.\n",
    "Interpreting Different Values\n",
    "High Uncertainty Ratio (> 1):\n",
    "Implication: There is significant variability in the historical demand data.\n",
    "Interpretation: The forecasted demand is adjusted upwards to account for potential higher demand. This suggests that the future demand could be more volatile and less predictable.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 1.5, the adjusted forecast would be 150 units.\n",
    "Low Uncertainty Ratio (< 1):\n",
    "Implication: There is less variability in the historical demand data.\n",
    "Interpretation: The forecasted demand is adjusted downwards, indicating more stable and predictable future demand.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 0.8, the adjusted forecast would be 80 units.\n",
    "Uncertainty Ratio = 1:\n",
    "Implication: The variability in the historical data is average or negligible.\n",
    "Interpretation: The forecasted demand remains unchanged, suggesting that the historical data is a good predictor of future demand without significant adjustments.\n",
    "Example: If the forecasted demand is 100 units and the uncertainty ratio is 1, the adjusted forecast remains 100 units.\n",
    "Practical Application\n",
    "Decision Making: Use the adjusted forecast to make informed decisions about inventory, resource allocation, and planning. A higher uncertainty ratio might prompt you to prepare for a wider range of outcomes.\n",
    "Risk Management: Understand the potential risks associated with high variability. A higher uncertainty ratio indicates a need for contingency plans to handle unexpected changes in demand.\n",
    "Performance Evaluation: Evaluate the performance of your forecasting model by comparing the adjusted forecasts with actual outcomes. This can help in refining the model and improving accuracy.\n",
    "Visualization\n",
    "Visualizing the impact of the uncertainty ratio can help in better understanding its effect on the forecast. Here’s an example of how to visualize the original forecast and the adjusted forecast:\n",
    "\n",
    "Python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_forecast_with_uncertainty(df, forecast_df, uncertainty_ratios):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand']\n",
    "        plt.plot(ts.index, ts, label=f'Original Demand (Age {age})', marker='o')\n",
    "    \n",
    "    for age in forecast_df.index:\n",
    "        plt.plot(forecast_df.columns, forecast_df.loc[age], label=f'Forecasted Demand (Age {age})', marker='x')\n",
    "    \n",
    "    for age in forecast_df.index:\n",
    "        adjusted_forecast = forecast_df.loc[age] * uncertainty_ratios.loc[age, 'Uncertainty_Ratio']\n",
    "        plt.plot(forecast_df.columns, adjusted_forecast, label=f'Adjusted Forecast (Age {age})', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Demand')\n",
    "    plt.title('Demand Forecast with Uncertainty Adjustment')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'uncertainty_ratios' is the DataFrame containing the calculated uncertainty ratios\n",
    "visualize_forecast_with_uncertainty(df, forecast, uncertainty_ratios)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "This visualization will help you see how the uncertainty ratio modifies the forecasted values and provides a clearer picture of potential future demand.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "What other statistical measures can help assess variability?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "In addition to the standard deviation and mean, several other statistical measures can help assess variability in your data. Here are some key measures:\n",
    "\n",
    "1. Variance\n",
    "Definition: Variance is the average of the squared differences from the mean. It provides a measure of how much the data points differ from the mean.\n",
    "Formula:\n",
    "Variance\n",
    "(\n",
    "σ\n",
    "2\n",
    ")\n",
    "=\n",
    "∑\n",
    "(\n",
    "x\n",
    "i\n",
    "−\n",
    "μ\n",
    ")\n",
    "2\n",
    "N\n",
    "Variance(σ2)=N∑(xi​−μ)2​\n",
    "\n",
    "Interpretation: A higher variance indicates more spread out data points.\n",
    "2. Range\n",
    "Definition: The range is the difference between the maximum and minimum values in the dataset.\n",
    "Formula:\n",
    "Range\n",
    "=\n",
    "Max\n",
    "−\n",
    "Min\n",
    "Range=Max−Min\n",
    "\n",
    "Interpretation: A larger range indicates a wider spread of data points.\n",
    "3. Interquartile Range (IQR)\n",
    "Definition: The IQR is the range between the first quartile (Q1) and the third quartile (Q3). It measures the spread of the middle 50% of the data.\n",
    "Formula:\n",
    "IQR\n",
    "=\n",
    "Q\n",
    "3\n",
    "−\n",
    "Q\n",
    "1\n",
    "IQR=Q3−Q1\n",
    "\n",
    "Interpretation: A larger IQR indicates more variability in the middle 50% of the data.\n",
    "4. Coefficient of Variation (CV)\n",
    "Definition: The CV is the ratio of the standard deviation to the mean, expressed as a percentage. It provides a standardized measure of dispersion.\n",
    "Formula:\n",
    "CV\n",
    "=\n",
    "σ\n",
    "μ\n",
    "×\n",
    "100\n",
    "CV=μσ​×100\n",
    "\n",
    "Interpretation: A higher CV indicates greater relative variability.\n",
    "5. Mean Absolute Deviation (MAD)\n",
    "Definition: MAD is the average of the absolute differences between each data point and the mean.\n",
    "Formula:\n",
    "MAD\n",
    "=\n",
    "∑\n",
    "∣\n",
    "x\n",
    "i\n",
    "−\n",
    "μ\n",
    "∣\n",
    "N\n",
    "MAD=N∑∣xi​−μ∣​\n",
    "\n",
    "Interpretation: A higher MAD indicates more variability.\n",
    "6. Quartile Deviation (QD)\n",
    "Definition: QD is half of the IQR and provides a measure of the spread of the middle 50% of the data.\n",
    "Formula:\n",
    "QD\n",
    "=\n",
    "Q\n",
    "3\n",
    "−\n",
    "Q\n",
    "1\n",
    "2\n",
    "QD=2Q3−Q1​\n",
    "\n",
    "Interpretation: A larger QD indicates more variability in the middle 50% of the data.\n",
    "Example Code to Calculate These Measures\n",
    "Here’s an example of how you can calculate these measures using Python:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to calculate variability measures\n",
    "def calculate_variability_measures(df):\n",
    "    variability_measures = pd.DataFrame()\n",
    "\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate measures\n",
    "        std_dev = ts.std()\n",
    "        variance = ts.var()\n",
    "        range_val = ts.max() - ts.min()\n",
    "        iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "        cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "        mad = ts.mad()\n",
    "        qd = iqr / 2\n",
    "        \n",
    "        # Store measures in DataFrame\n",
    "        variability_measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "        variability_measures.loc[age, 'Variance'] = variance\n",
    "        variability_measures.loc[age, 'Range'] = range_val\n",
    "        variability_measures.loc[age, 'IQR'] = iqr\n",
    "        variability_measures.loc[age, 'CV'] = cv\n",
    "        variability_measures.loc[age, 'MAD'] = mad\n",
    "        variability_measures.loc[age, 'QD'] = qd\n",
    "    \n",
    "    return variability_measures\n",
    "\n",
    "# Call the function and print the variability measures\n",
    "variability_measures = calculate_variability_measures(df)\n",
    "print(variability_measures)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Interpretation of Results\n",
    "Standard Deviation and Variance: Indicate the overall spread of the data.\n",
    "Range and IQR: Provide insights into the spread of the data, with IQR focusing on the middle 50%.\n",
    "Coefficient of Variation: Standardizes the measure of dispersion, making it easier to compare across different datasets.\n",
    "Mean Absolute Deviation and Quartile Deviation: Offer alternative measures of variability that are less sensitive to outliers.\n",
    "These measures can help you better understand the variability in your data and make more informed decisions based on the forecasted demand.\n",
    "\n",
    "Feel free to run this code and let me know if you need any further assistance!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I choose the most appropriate variability measure for my specific analysis?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Choosing the most appropriate variability measure for your specific analysis depends on several factors, including the nature of your data, the goals of your analysis, and the specific characteristics you want to capture. Here are some guidelines to help you make an informed decision:\n",
    "\n",
    "1. Nature of the Data\n",
    "Continuous Data: Measures like standard deviation, variance, and coefficient of variation are suitable for continuous data, as they provide insights into the spread and relative variability.\n",
    "Categorical Data: For categorical data, measures like range and interquartile range (IQR) might be more appropriate, as they can highlight the spread of categories.\n",
    "2. Goals of the Analysis\n",
    "Understanding Overall Spread: If your goal is to understand the overall spread of the data, standard deviation and variance are good choices. They provide a comprehensive measure of variability.\n",
    "Comparing Relative Variability: If you need to compare the variability of different datasets or groups, the coefficient of variation (CV) is useful. It standardizes the measure of dispersion, making it easier to compare across different scales.\n",
    "Identifying Outliers: If you are interested in identifying outliers or understanding the spread of the middle 50% of the data, the interquartile range (IQR) and mean absolute deviation (MAD) are helpful.\n",
    "3. Specific Characteristics\n",
    "Sensitivity to Outliers: Standard deviation and variance are sensitive to outliers, which can skew the results. If your data contains outliers, you might prefer measures like IQR or MAD, which are less affected by extreme values.\n",
    "Ease of Interpretation: Some measures are easier to interpret than others. For example, the range is straightforward and easy to understand, while the coefficient of variation provides a relative measure that can be more informative in certain contexts.\n",
    "Practical Examples\n",
    "Standard Deviation and Variance:\n",
    "Use When: You want to understand the overall spread of continuous data.\n",
    "Example: Analyzing the variability in monthly sales figures.\n",
    "Coefficient of Variation (CV):\n",
    "Use When: You need to compare the relative variability of different datasets.\n",
    "Example: Comparing the variability of sales figures across different regions.\n",
    "Interquartile Range (IQR):\n",
    "Use When: You want to focus on the spread of the middle 50% of the data and identify potential outliers.\n",
    "Example: Analyzing the distribution of test scores to identify students who are performing significantly above or below the median.\n",
    "Mean Absolute Deviation (MAD):\n",
    "Use When: You need a measure of variability that is less sensitive to outliers.\n",
    "Example: Assessing the consistency of delivery times for a logistics company.\n",
    "Example Code to Calculate and Compare Measures\n",
    "Here’s an example of how you can calculate and compare different variability measures using Python:\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "df.set_index(['age', 'year'], inplace=True)\n",
    "\n",
    "# Function to calculate and compare variability measures\n",
    "def compare_variability_measures(df):\n",
    "    measures = pd.DataFrame()\n",
    "\n",
    "    for age in df.index.get_level_values(0).unique():\n",
    "        ts = df.xs(age, level='age')['demand'].dropna()\n",
    "        \n",
    "        # Calculate measures\n",
    "        std_dev = ts.std()\n",
    "        variance = ts.var()\n",
    "        range_val = ts.max() - ts.min()\n",
    "        iqr = ts.quantile(0.75) - ts.quantile(0.25)\n",
    "        cv = (std_dev / ts.mean()) * 100 if ts.mean() != 0 else 0\n",
    "        mad = ts.mad()\n",
    "        \n",
    "        # Store measures in DataFrame\n",
    "        measures.loc[age, 'Standard Deviation'] = std_dev\n",
    "        measures.loc[age, 'Variance'] = variance\n",
    "        measures.loc[age, 'Range'] = range_val\n",
    "        measures.loc[age, 'IQR'] = iqr\n",
    "        measures.loc[age, 'CV'] = cv\n",
    "        measures.loc[age, 'MAD'] = mad\n",
    "    \n",
    "    return measures\n",
    "\n",
    "# Call the function and print the measures\n",
    "variability_measures = compare_variability_measures(df)\n",
    "print(variability_measures)\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Summary\n",
    "Standard Deviation and Variance: Best for understanding overall spread.\n",
    "Coefficient of Variation (CV): Ideal for comparing relative variability.\n",
    "Interquartile Range (IQR) and Mean Absolute Deviation (MAD): Useful for identifying outliers and understanding the spread of the middle 50% of the data.\n",
    "By considering these factors, you can choose the most appropriate variability measure for your specific analysis, ensuring that your insights are accurate and meaningful. If you have any specific questions or need further assistance, feel free to ask!\n",
    "\n",
    "You\n",
    "Sent by you:\n",
    "How can I visualize different variability measures for better insights?\n",
    "Copilot\n",
    "Sent by Copilot:\n",
    "Visualizing different variability measures can provide a clearer understanding of the data’s spread and help identify patterns or outliers. Here are some common ways to visualize these measures using Python’s matplotlib and seaborn libraries:\n",
    "\n",
    "1. Box Plot\n",
    "A box plot (or whisker plot) is useful for visualizing the distribution of data and highlighting the interquartile range (IQR), median, and potential outliers.\n",
    "\n",
    "Python\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('annual_unique_donors.csv')\n",
    "\n",
    "# Assuming the dataframe has 'year', 'age', and 'demand' columns\n",
    "df['year'] = pd.to_datetime(df['year'], format='%Y')\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='age', y='demand', data=df)\n",
    "plt.title('Box Plot of Demand by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "2. Histogram\n",
    "A histogram shows the frequency distribution of the data, which helps in understanding the spread and central tendency.\n",
    "\n",
    "Python\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['demand'], bins=20, kde=True)\n",
    "plt.title('Histogram of Demand')\n",
    "plt.xlabel('Demand')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "3. Violin Plot\n",
    "A violin plot combines aspects of a box plot and a kernel density plot. It shows the distribution of the data across different categories.\n",
    "\n",
    "Python\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='age', y='demand', data=df)\n",
    "plt.title('Violin Plot of Demand by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "4. Scatter Plot with Error Bars\n",
    "A scatter plot with error bars can show the mean demand and the variability (e.g., standard deviation) for each age cohort.\n",
    "\n",
    "Python\n",
    "\n",
    "# Calculate mean and standard deviation for each age cohort\n",
    "mean_demand = df.groupby('age')['demand'].mean()\n",
    "std_demand = df.groupby('age')['demand'].std()\n",
    "\n",
    "# Create a scatter plot with error bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.errorbar(mean_demand.index, mean_demand, yerr=std_demand, fmt='o', capsize=5)\n",
    "plt.title('Mean Demand with Standard Deviation by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "5. Heatmap\n",
    "A heatmap can visualize the variability measures across different age cohorts and years.\n",
    "\n",
    "Python\n",
    "\n",
    "# Pivot the data to create a matrix for the heatmap\n",
    "pivot_table = df.pivot_table(index='age', columns='year', values='demand', aggfunc='mean')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\")\n",
    "plt.title('Heatmap of Mean Demand by Age and Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n",
    "AI-generated code. Review and use carefully. More info on FAQ.\n",
    "Summary\n",
    "Box Plot: Visualizes the distribution, IQR, median, and outliers.\n",
    "Histogram: Shows the frequency distribution of the data.\n",
    "Violin Plot: Combines box plot and kernel density plot features.\n",
    "Scatter Plot with Error Bars: Displays mean demand with variability.\n",
    "Heatmap: Visualizes variability measures across different categories.\n",
    "These visualizations can help you gain better insights into the variability of your data and make more informed decisions based on the analysis. Feel free to run these examples with your data and let me know if you need any further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "# Suppress warnings from statsmodels\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def apply_uncertainty_to_forecast(forecast, annual_receipts, annual_demands, age_specific_demands):\n",
    "    # Calculate the annual donor receipt to demand ratio for each year\n",
    "    annual_ratio = annual_receipts['Yearly Receipt'] / annual_demands\n",
    "    \n",
    "    # Calculate the age-specific demands ratio\n",
    "    age_specific_ratio = age_specific_demands.groupby(['year', 'age']).sum().reset_index()\n",
    "    age_specific_ratio['total_demands'] = age_specific_ratio.groupby('year')['demand'].transform('sum')\n",
    "    age_specific_ratio['age_ratio'] = age_specific_ratio['demand'] / age_specific_ratio['total_demands']\n",
    "    \n",
    "    # Create an empty DataFrame to hold the adjusted forecast\n",
    "    adjusted_forecast = pd.DataFrame(columns=['date', 'age', 'adjusted_forecast'])\n",
    "    \n",
    "    # Apply the ratios to the forecasted values\n",
    "    for index, row in forecast.iterrows():\n",
    "        year = row['date'].year\n",
    "        age = row['age']\n",
    "        forecast_value = row['forecast']\n",
    "\n",
    "        # Calculate the adjusted forecast value\n",
    "        if year in annual_ratio.index and year in age_specific_ratio['year'].unique():\n",
    "            age_ratio = age_specific_ratio[(age_specific_ratio['year'] == year) & (age_specific_ratio['age'] == age)]\n",
    "            if not age_ratio.empty:\n",
    "                age_ratio_value = age_ratio['age_ratio'].values[0]\n",
    "            else:\n",
    "                age_ratio_value = 0\n",
    "            adjusted_value = forecast_value * annual_ratio.loc[year] * age_ratio_value\n",
    "        else:\n",
    "            adjusted_value = 0\n",
    "        \n",
    "        # Append the adjusted value to the DataFrame\n",
    "        adjusted_forecast = adjusted_forecast.append({'date': row['date'], 'age': age, 'adjusted_forecast': adjusted_value}, ignore_index=True)\n",
    "    \n",
    "    return adjusted_forecast\n",
    "\n",
    "def forecast_demand_with_sarima(historical_data, steps, seasonal_order=(1,1,1,12)):\n",
    "    # Fit a SARIMA model\n",
    "    model = SARIMAX(historical_data, order=(1,1,1), seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    \n",
    "    # Forecast future values\n",
    "    forecast = model_fit.forecast(steps=steps)\n",
    "    return forecast\n",
    "\n",
    "# Lpa historical data for fitting SARIMA\n",
    "historical_data = pd.Series(np.random.randint(100, 1000, 36), \n",
    "                            index=pd.date_range(start='2021-01-01', periods=36, freq='M'))\n",
    "\n",
    "# Forecast for the next 24 months (2 years)\n",
    "sarima_forecast = forecast_demand_with_sarima(historical_data, steps=24)\n",
    "\n",
    "# Prepare the forecast DataFrame for the next 24 months for ages 18 to 106\n",
    "forecast_dates = pd.date_range(start='2024-04-01', periods=24, freq='M')\n",
    "forecast_ages = np.random.randint(18, 106, 24)\n",
    "forecast_df = pd.DataFrame({'date': forecast_dates, 'age': forecast_ages, 'forecast': sarima_forecast})\n",
    "\n",
    "# Annual receipts and demands DataFrames\n",
    "annual_receipts = annual_donor_receipts  #pd.DataFrame({'year': [2022, 2023, 2024], 'Yearly Receipt': [7.519675e+05, 9.700350e+05, 1.124615e+06]})\n",
    "\n",
    "annual_demands = annual_donor_demands  #pd.Series({2022: 601254, 2023: 752898, 2024: 505219}, name='unique_key')\n",
    "\n",
    "# Age-specific demands DataFrame\n",
    "age_specific_demands = annual_donor_demands_age_specific #pd.DataFrame({\n",
    "#     'year': [2022, 2022, 2022, 2023, 2023, 2023, 2024, 2024, 2024],\n",
    "#     'age': [18, 19, 20, 18, 19, 20, 18, 19, 20],\n",
    "#     'demand': [199, 286, 192, 249, 345, 243, 122, 267, 196]})\n",
    "\n",
    "# Apply uncertainty to the SARIMA forecast\n",
    "adjusted_forecast = apply_uncertainty_to_forecast(forecast_df, annual_receipts, annual_demands, age_specific_demands)\n",
    "\n",
    "print(adjusted_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#def uncertainty_ratio(self, lpa_df_index, month_year):\n",
    "\n",
    "\n",
    "# Estimate the Uncertainty:\n",
    "\n",
    "\n",
    "#covid_impact_ratio = pre_covid_mean_demand / post_covid_mean_demand\n",
    "impact_ratio = filtered_annual_demands / filtered_annual_receipts \n",
    "\n",
    "# Apply the Uncertainty to Future Long-Term Forecasts:\n",
    "# Multiply the future long-term forecasts by the estimated uncertainty to incorporate the impact of the short-term period.\n",
    "\n",
    "print(f\"\"\"The ratio of {impact_ratio} indicates that the short-term demand during COVID \n",
    "        was {impact_ratio * 100}% higher than the long-term average.\"\"\")\n",
    "\n",
    "# # Apply the Uncertainty:\n",
    "# Adjusted_Long-Term_Forecast = Future_Long_Term_Forecast * covid_impact_ratio\n",
    "\n",
    "   \n",
    "# Extract and save data into a csv file\n",
    "lpa_data = monthly_unique_donors.rename(columns={'count': 'demand'})\n",
    "\n",
    "print(lpa_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# This script is designed to be modular, allowing you to call specific methods to perform different parts of the analysis.\n",
    "# split the code into three separate classes:\n",
    "\n",
    "# DataHandler: For handling file operations and initial data loading.\n",
    "# DataPreprocessor: For preprocessing the data and performing calculations on the data.\n",
    "# DataAnalyzer: For analyzing the data and Bayesian modeling.\n",
    "\n",
    "# Load and Preprocess Data:\n",
    "\n",
    "# Extract relevant columns.\n",
    "# Handle missing values.\n",
    "# Calculate age from the date of birth and receipt date.\n",
    "# Filter data by year and age range.\n",
    "# Calculate Age-Specific Demand:\n",
    "\n",
    "# Group data by year, gender, and age.\n",
    "# Calculate the number of unique donors.\n",
    "# Calculate Annual Demands Ratio:\n",
    "\n",
    "# Use the annual average daily application receipts.\n",
    "# Apply the annual demands ratio to incorporate uncertainty.\n",
    "# Forecast Age-Specific Demand:\n",
    "\n",
    "# Use the Bayesian model to forecast future demands.\n",
    "# Adjust the model to account for age-specific data.\n",
    "\n",
    "# use the Pymc Python package and Bayesian criteria while using Monte Carlo simulation for time series forecasting of donor application demands to \n",
    "# account for uncertainty and make more robust predictions, especially in scenarios with significant disruptions like post-COVID impacts after March 2021, \n",
    "# by having age-specific demand data (column names: year, gender, age, number of unique donors) from 2006 to 2024? Also, how do you make sure that, \n",
    "# from the actual data, you choose the right prior based on the distribution of donor demands per year and fluctuation before and after COVID? \n",
    "# to learn from the pre-COVID data and post-COVID data to decide which distribution should be used for the priors for pre-COVID and post-COVID parameters? \n",
    "# In addition, imagine we already have calculated average annual daily application receipts and then you can use average annual daily application receipts \n",
    "# and annual demands ratio (without considering age) to deal with uncertainty to improve long term forecasting of  donor application demands?\n",
    "\n",
    "\n",
    "## -------------------\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "## -------------------\n",
    "#%%\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "#%%\n",
    "## ------------------Step 3: DataAnalyzer Class-------------------- ##\n",
    "\n",
    "class DataAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def exploratory_data_analysis(self, data):\n",
    "        data.reset_index()\n",
    "        data.set_index('month_year', inplace=True)\n",
    "        data['demand'].plot(figsize=(14, 7))\n",
    "        plt.title('Donor Application Demands')\n",
    "        plt.xlabel('Month-Year')\n",
    "        plt.ylabel('Demand')\n",
    "        plt.show()\n",
    "\n",
    "        pre_covid = data.loc[:'Mar-21', 'demand']\n",
    "        post_covid = data.loc['Mar-21':, 'demand']\n",
    "\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        sns.histplot(pre_covid, kde=True, label='Pre-COVID', color='blue', bins=50)\n",
    "        sns.histplot(post_covid, kde=True, label='Post-COVID', color='red', bins=50)\n",
    "        plt.legend()\n",
    "        plt.title('Distribution of Donor Application Demands')\n",
    "        plt.xlabel('Demand')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "    def determine_priors(self, pre_covid, post_covid):\n",
    "        def test_distribution(data, dist, *args):\n",
    "            return kstest(data, dist, args=args)\n",
    "\n",
    "        print(\"Pre-COVID Data:\")\n",
    "        print(\"Normal:\", test_distribution(pre_covid, 'norm', np.mean(pre_covid), np.std(pre_covid)))\n",
    "        print(\"Log-Normal:\", test_distribution(pre_covid, 'lognorm', np.std(np.log(pre_covid[pre_covid > 0])), 0, np.exp(np.mean(np.log(pre_covid[pre_covid > 0])))))\n",
    "        print(\"Student's t:\", test_distribution(pre_covid, 't', len(pre_covid)-1, np.mean(pre_covid), np.std(pre_covid)))\n",
    "\n",
    "        print(\"\\nPost-COVID Data:\")\n",
    "        print(\"Normal:\", test_distribution(post_covid, 'norm', np.mean(post_covid), np.std(post_covid)))\n",
    "        print(\"Log-Normal:\", test_distribution(post_covid, 'lognorm', np.std(np.log(post_covid[post_covid > 0])), 0, np.exp(np.mean(np.log(post_covid[post_covid > 0])))))\n",
    "        print(\"Student's t:\", test_distribution(post_covid, 't', len(post_covid)-1, np.mean(post_covid), np.std(post_covid)))\n",
    "\n",
    "    def bayesian_modeling(self, pre_covid, post_covid):\n",
    "        model = pm.Model()\n",
    "        with model:\n",
    "            pre_covid_mean = pm.Normal('pre_covid_mean', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "            pre_covid_sd = pm.HalfNormal('pre_covid_sd', sigma=1)\n",
    "            post_covid_mean = pm.Normal('post_covid_mean', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "            post_covid_sd = pm.HalfNormal('post_covid_sd', sigma=1)\n",
    "\n",
    "            pre_covid_likelihood = pm.Normal('pre_covid_likelihood', mu=pre_covid_mean, sigma=pre_covid_sd, observed=pre_covid)\n",
    "            post_covid_likelihood = pm.Normal('post_covid_likelihood', mu=post_covid_mean, sigma=post_covid_sd, observed=post_covid)\n",
    "\n",
    "            trace = pm.sample(1000, tune=2000, return_inferencedata=True)\n",
    "        \n",
    "        az.plot_trace(trace)\n",
    "        plt.show()\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "\n",
    "data = lpa_data\n",
    "print(data.head(2))\n",
    "# Instantiate the DataAnalyzer\n",
    "data_analyzer = DataAnalyzer(data)\n",
    "data_analyzer.exploratory_data_analysis(data)\n",
    "pre_covid, post_covid = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "data_analyzer.determine_priors(pre_covid, post_covid)\n",
    "trace= data_analyzer.bayesian_modeling(pre_covid, post_covid)\n",
    "## ------------------\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "## ------------------Step 4: forecasting-------------------- ##\n",
    "post_covid_data = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "\n",
    "\n",
    "\n",
    "## ------------------\n",
    "\n",
    "    \n",
    "# %%\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "model = pm.Model()\n",
    "with model:\n",
    "    pre_covid_mean = pm.Normal('pre_covid_mean', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "    pre_covid_sd = pm.HalfNormal('pre_covid_sd', sigma=1)\n",
    "    post_covid_mean = pm.Normal('post_covid_mean', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "    post_covid_sd = pm.HalfNormal('post_covid_sd', sigma=1)\n",
    "\n",
    "    pre_covid_likelihood = pm.Normal('pre_covid_likelihood', mu=pre_covid_mean, sigma=pre_covid_sd, observed=pre_covid)\n",
    "    post_covid_likelihood = pm.Normal('post_covid_likelihood', mu=post_covid_mean, sigma=post_covid_sd, observed=post_covid)\n",
    "\n",
    "    trace = pm.sample(1000, tune=2000, return_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True, random_seed=rng)\n",
    "    \n",
    "print(trace.posterior_predictive)   #\n",
    "\n",
    "az.plot_ppc(trace, num_pp_samples=100); \n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "## ------------------Step 5: Monte Carlo simulations for forecasting-------------------- ##\n",
    "pre_covid_data, post_covid_data = data.loc[:'Mar-21', 'demand'], data.loc['Mar-21':, 'demand']\n",
    "\n",
    "trace = data_analyzer.bayesian_modeling(pre_covid_data, post_covid_data)\n",
    "pre_covid_data, post_covid_data = pre_covid.reset_index(), post_covid.reset_index() \n",
    "#trace = data_analyzer.bayesian_modeling(pre_covid_data, post_covid_data)\n",
    "trace['pre_covid_pred'], trace['post_covid_pred'] = pre_covid_likelihood, post_covid_likelihood\n",
    "\n",
    "with pm.Model() as model:\n",
    "    post_pred = pm.sample_posterior_predictive(trace, var_names=['pre_covid_pred', 'post_covid_pred'])\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "axes[0].plot(pre_covid_data['month_year'], pre_covid_data['demand'], label='Observed Pre-COVID')\n",
    "axes[0].plot(pre_covid_data['month_year'], post_pred['pre_covid_pred'].mean(axis=0), label='Predicted Pre-COVID Mean')\n",
    "axes[0].fill_between(pre_covid_data['month_year'], np.percentile(post_pred['pre_covid_pred'], 5, axis=0), \n",
    "                     np.percentile(post_pred['pre_covid_pred'], 95, axis=0), alpha=0.2, label='95% CI')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Pre-COVID Predictions')\n",
    "\n",
    "axes[1].plot(post_covid_data['month_year'], post_covid_data['demand'], label='Observed Post-COVID')\n",
    "axes[1].plot(post_covid_data['month_year'], post_pred['post_covid_pred'].mean(axis=0), label='Predicted Post-COVID Mean')\n",
    "axes[1].fill_between(post_covid_data['month_year'], np.percentile(post_pred['post_covid_pred'], 5, axis=0), \n",
    "                     np.percentile(post_pred['post_covid_pred'], 95, axis=0), alpha=0.2, label='95% CI')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Post-COVID Predictions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "## ------------------\n",
    "## ------------------\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "## ------------------Step 6: Specify the Model with PyMC-------------------- ##\n",
    "\n",
    "# Convert data to numpy array for PyMC\n",
    "demand_data = data['demand'].values\n",
    "\n",
    "# Define a Bayesian model with potential structural break after March 2021\n",
    "with pm.Model() as model:\n",
    "    # Priors for pre-COVID parameters (Normal distribution)\n",
    "    mu_pre = pm.Normal('mu_pre', mu=np.mean(pre_covid), sigma=np.std(pre_covid))\n",
    "    sigma_pre = pm.HalfNormal('sigma_pre', sigma=np.std(pre_covid))\n",
    "    \n",
    "    # Priors for post-COVID parameters (Normal distribution)\n",
    "    mu_post = pm.Normal('mu_post', mu=np.mean(post_covid), sigma=np.std(post_covid))\n",
    "    sigma_post = pm.HalfNormal('sigma_post', sigma=np.std(post_covid))\n",
    "    \n",
    "    # Indicator for structural break\n",
    "    switchpoint = len(pre_covid)\n",
    "    idx = np.arange(len(demand_data))\n",
    "    \n",
    "    # Likelihood\n",
    "    mu = pm.math.switch(idx < switchpoint, mu_pre, mu_post)\n",
    "    sigma = pm.math.switch(idx < switchpoint, sigma_pre, sigma_post)\n",
    "    \n",
    "    y = pm.Normal('y', mu=mu, sigma=sigma, observed=demand_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "## ------------------Step 5: Fit the Model Using MCMC-------------------- ##\n",
    "\n",
    "with model:\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True)\n",
    "\n",
    "# Inspect the trace\n",
    "az.plot_trace(trace)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "\n",
    "## ------------------Step 6: Posterior Predictive Checks-------------------- ##\n",
    "\n",
    "with model:\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=['y'])\n",
    "\n",
    "# Simulate future demands\n",
    "n_future = 365  # Simulate for one year\n",
    "future_simulations = []\n",
    "\n",
    "for sample in ppc['y']:\n",
    "    future_path = np.concatenate([demand_data, np.zeros(n_future)])\n",
    "    for t in range(len(demand_data), len(demand_data) + n_future):\n",
    "        future_path[t] = sample[t - len(demand_data)] + future_path[t - 1]\n",
    "    future_simulations.append(future_path[-n_future:])\n",
    "\n",
    "future_simulations = np.array(future_simulations)\n",
    "\n",
    "# Analyze future simulations\n",
    "mean_forecast = np.mean(future_simulations, axis=0)\n",
    "cred_interval = np.percentile(future_simulations, [2.5, 97.5], axis=0)\n",
    "\n",
    "\n",
    "## -----------------\n",
    "#%%\n",
    "\n",
    "## ------------------Step 7: Analyse and Visualize Results-------------------- ##\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, demand_data, label='Historical Data')\n",
    "plt.plot(pd.date_range(data.index[-1], periods=n_future, freq='D'), mean_forecast, label='Mean Forecast')\n",
    "plt.fill_between(pd.date_range(data.index[-1], periods=n_future, freq='D'), cred_interval[0], cred_interval[1], color='gray', alpha=0.5, label='95% Credible Interval')\n",
    "plt.axvline(data.index[switchpoint], color='r', linestyle='--', label='Post-COVID Impact')\n",
    "plt.legend()\n",
    "plt.title('Forecast of Daily Application Demands')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## -----------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class LPAForecast:\n",
    "    def __init__(self, post_covid_data, covid_data, historical_data): #, economic_data):\n",
    "        self.post_covid_data = post_covid_data\n",
    "        self.covid_data = covid_data\n",
    "        #self.economic_data = economic_data\n",
    "        self.historical_data = historical_data\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        # Merge historical data with COVID-19 impact data and economic data\n",
    "        self.data = historical_data #pd.merge(self.post_covid_data, self.covid_data, on='date', how='left')\n",
    "        #self.data = pd.merge(self.data, self.economic_data, on='date', how='left')\n",
    "        self.data.fillna(0, inplace=True)\n",
    "\n",
    "    def short_term_forecast(self, order=(5,1,0)):\n",
    "        # Split data into training and testing sets\n",
    "        train, test = train_test_split(self.data, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        # Fit ARIMA model\n",
    "        model = ARIMA(train['demand'], order=order, exog=train[['covid_impact']]) #, 'economic_indicator']])\n",
    "        self.model_fit = model.fit()\n",
    "        \n",
    "        # Forecast\n",
    "        self.short_term_predictions = self.model_fit.forecast(steps=len(test), exog=test[['covid_impact']]) #, 'economic_indicator']])\n",
    "        #baseline_forecast = self.model_fit.forecast(steps=24)  # Assuming 2 years monthly forecast\n",
    "        self.test = test\n",
    "\n",
    "    def quantify_uncertainty(self):\n",
    "        # Calculate confidence intervals\n",
    "        self.conf_int = self.model_fit.get_forecast(steps=len(self.test), exog=self.test[['covid_impact']]).conf_int() #, 'economic_indicator']]).conf_int()\n",
    "        #self.conf_int = self.model_fit.get_forecast(steps=len(self.test)).conf_int()\n",
    "        \n",
    "    def long_term_forecast(self, adjustment_factor=1.2):\n",
    "        # Baseline forecast using historical trend\n",
    "        #future_economic_data = self.economic_data.tail(24)  # Assuming 2 years monthly forecast\n",
    "        baseline_forecast = self.model_fit.forecast(steps=24, exog=future_economic_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "        #baseline_forecast = self.model_fit.forecast(steps=24)  # Assuming 2 years monthly forecast\n",
    "        \n",
    "        # Adjust for COVID-19 impact\n",
    "        self.long_term_predictions = baseline_forecast * adjustment_factor\n",
    "\n",
    "        \n",
    "# Write a function to apply exponential smoothing applied to the age-specific short-term forecasts to incorporate covid impact and do sentivitity tests \n",
    "# follow the excel formula in LPA model and control assumption:\n",
    "# =GB9*'LPA Control Assumptions'!$B$123+(1-'LPA Control Assumptions'!$B$123)*(GB9-GA9+GB9)\n",
    "    #def age_specific_uncertainty(self)\n",
    "    \n",
    "    \n",
    "    def forecast_by_age_group(self, age_groups):\n",
    "        self.age_group_forecasts = {}\n",
    "        for age_group in age_groups:\n",
    "            # Filter data for the age group\n",
    "            age_group_data = self.data[self.data['age_group'] == age_group]\n",
    "            \n",
    "            # Fit ARIMA model\n",
    "            model = ARIMA(age_group_data['demand'], order=(5,1,0), exog=age_group_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            # Forecast\n",
    "            forecast = model_fit.forecast(steps=24, exog=future_economic_data[['covid_impact']]) #, 'economic_indicator']])\n",
    "            self.age_group_forecasts[age_group] = forecast\n",
    "#         for age_group in age_groups:\n",
    "#             # Filter data for the age group\n",
    "#             age_group_data = self.data[self.data['age_group'] == age_group]\n",
    "#             # Fit ARIMA model\n",
    "#             model = ARIMA(age_group_data['registrations'], order=(5,1,0))\n",
    "#             model_fit = model.fit()\n",
    "#             # Forecast\n",
    "#             forecast = model_fit.forecast(steps=24)\n",
    "#             self.age_group_forecasts[age_group] = forecast\n",
    "    def validate_model(self):\n",
    "        # Compare predictions with actual values\n",
    "        self.validation_results = self.test['demand'] - self.short_term_predictions\n",
    "\n",
    "    def aggregate_by_age_group(self, bins, labels):\n",
    "        # Create a new column 'AgeGroup' with the age bins\n",
    "        self.data['AgeGroup'] = pd.cut(self.data['age'], bins=bins, labels=labels, right=False)\n",
    "        \n",
    "        # Aggregate data within each age group\n",
    "        aggregated_data = self.data.groupby('AgeGroup').agg({\n",
    "            'demand': 'sum',\n",
    "            'name': 'count'\n",
    "        }).rename(columns={'name': 'count'})\n",
    "        \n",
    "        return aggregated_data\n",
    "\n",
    "    def run_forecast(self, age_groups, bins, labels):\n",
    "        self.preprocess_data()\n",
    "        self.short_term_forecast()\n",
    "        self.quantify_uncertainty()\n",
    "        self.long_term_forecast()\n",
    "        self.forecast_by_age_group(age_groups)\n",
    "        self.validate_model()\n",
    "        return self.aggregate_by_age_group(bins, labels)\n",
    "\n",
    "# usage\n",
    "#historical_data = pd.read_csv('historical_data.csv')  # Replace with actual data source\n",
    "#covid_data = pd.read_csv('covid_data.csv')  # Replace with actual data source\n",
    "#economic_data = pd.read_csv('economic_data.csv')  # Replace with actual data source\n",
    "age_groups = ['18-20', '21-25', '26-30', '31-35', '36-40','41-45','46-50', '51-55', '56-60', '61-65', '66-70', '71+']\n",
    "bins = [18, 20, 30, 40, 50, 60, 70, 100]\n",
    "labels = ['18-20', '21-25', '26-30', '31-35', '36-40','41-45','46-50', '51-55', '56-60', '61-65', '66-70', '71+']\n",
    "\n",
    "forecast = LPAForecast(post_covid_data, covid_data, historical_data)# , economic_data)\n",
    "aggregated_data = forecast.run_forecast(age_groups, bins, labels)\n",
    "\n",
    "print(aggregated_data)\n",
    "\n",
    "#age_groups = ['18-30', '31-50', '51-70', '71+']\n",
    "\n",
    "#forecast = LPAForecast(post_covid_data, covid_data)\n",
    "#forecast.run_forecast(age_groups)\n",
    "#print(forecast.long_term_predictions)\n",
    "#print(forecast.age_group_forecasts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
